[
    {
        "id": "https://ai-techpark.com/?p=231488",
        "title": "STRADVISION to Showcase Scalable Ecosystem Integrations at CES¬Æ 2026",
        "content": "<p>STRADVISION, a global leader in AI-based vision perception technology for autonomous driving, will participate in CES¬Æ 2026 in Las Vegas with a strong focus on ecosystem collaboration and platform-level integration with leading semiconductor and technology partners. At CES 2026, STRADVISION will demonstrate how its vision perception software, SVNet, is implemented...</p>\n<p>The post <a href=\"https://ai-techpark.com/stradvision-to-showcase-scalable-ecosystem-integrations-at-ces-2026/\">STRADVISION to Showcase Scalable Ecosystem Integrations at CES¬Æ 2026</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/stradvision-to-showcase-scalable-ecosystem-integrations-at-ces-2026/",
        "publishDate": "2025-12-23T10:05:43Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231351",
        "title": "SoftwareOne announces new GenAI multi-agent cost optimization system",
        "content": "<p>SoftwareOne today announced it has launched a new GenAI multi-agent cost optimization system that helps customers and partners measure and optimize the cost, accuracy, and performance of their AI agents. Building on a foundation of deep expertise in both AI and software asset management, SoftwareOne is uniquely positioned to help...</p>\n<p>The post <a href=\"https://ai-techpark.com/softwareone-announces-new-genai-multi-agent-cost-optimization-system/\">SoftwareOne announces new GenAI multi-agent cost optimization system</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/softwareone-announces-new-genai-multi-agent-cost-optimization-system/",
        "publishDate": "2025-12-23T07:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI deployments, AI investments, AI news, AI solution, AItech news, artificial intelligence news"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111417",
        "title": "Arm and the future of AI at the edge",
        "content": "<p>Arm Holdings has positioned itself at the centre of AI transformation. In a wide-ranging podcast interview, Vince Jesaitis, head of global government affairs at Arm, offered enterprise decision-makers look into the company&#8217;s international strategy, the evolution of AI as the company sees it, and what lies ahead for the industry. From cloud to edge Arm [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/arm-chips-and-the-future-of-ai-at-the-edge/\">Arm and the future of AI at the edge</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/arm-chips-and-the-future-of-ai-at-the-edge/",
        "publishDate": "2025-12-23T13:45:19Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Hardware & Chips, Environment & Sustainability, Manufacturing & Engineering AI, Retail & Logistics AI, Service Industry AI, Utilities, arm, edge ai, iiot, iot, low-power ai"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111413",
        "title": "Inside China‚Äôs push to apply AI across its energy system",
        "content": "<p>Under China‚Äôs push to clean up its energy system, AI is starting to shape how power is produced, moved, and used ‚Äî not in abstract policy terms, but in day-to-day operations. In Chifeng, a city in northern China, a renewable-powered factory offers a clear example. The site produces hydrogen and ammonia using electricity generated entirely [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/inside-chinas-push-to-apply-ai-across-its-energy-system/\">Inside China‚Äôs push to apply AI across its energy system</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/inside-chinas-push-to-apply-ai-across-its-energy-system/",
        "publishDate": "2025-12-23T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Deep Dives, Environment & Sustainability, Governance, Regulation & Policy, Government & Public Sector AI, Manufacturing & Engineering AI, Utilities, energy, environment, governance, manufacturing"
        }
    },
    {
        "id": "1pulo3x",
        "title": "Why do prompts break after a few edits?",
        "content": "I‚Äôve noticed this a lot:\nFirst version of a prompt works okay.\nAfter 2‚Äì3 ‚Äúimprovements,‚Äù the output actually gets worse.\n\nUsually it‚Äôs not the model ‚Äî it‚Äôs the prompt:\n\nintent becomes unclear\n\ninstructions start conflicting\n\nimportant details disappear\n\n\nWhat helped me was stopping random rewrites and instead:\n\nchecking clarity first\n\nfixing structure before adding details\n\nkeeping older versions so I can compare what actually worked\n\n\nFeels obvious in hindsight, but it made outputs far more consistent.\n\nHow do you handle prompt iteration ‚Äî rewrite every time or version them?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pulo3x/why_do_prompts_break_after_a_few_edits/",
        "publishDate": "2025-12-24T11:53:00Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puldkn",
        "title": "After laying off 4,000 employees and automating with AI agents, Salesforce executives admit: We were more confident about‚Ä¶.",
        "content": "\n\n[https://timesofindia.indiatimes.com/technology/tech-news/after-laying-off-4000-employees-and-automating-with-ai-agents-salesforce-executives-admit-we-were-more-confident-about-/articleshow/126121875.cms](https://timesofindia.indiatimes.com/technology/tech-news/after-laying-off-4000-employees-and-automating-with-ai-agents-salesforce-executives-admit-we-were-more-confident-about-/articleshow/126121875.cms)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1puldkn/after_laying_off_4000_employees_and_automating/",
        "publishDate": "2025-12-24T11:34:13Z[Etc/UTC]",
        "author": "trisul-108",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pukzag",
        "title": "Talking to AI chatbots doesn't feel natural anymore",
        "content": "I don't know if it's just me, but now it feels way less natural to talk to an AI chatbot than before. Too much human involvement just ruined the popular ones like chatGPT. It feels like it wants to reinforce your delusions while being censored to the max and pretending to care about ethics. And I feel like it's done on purpose\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pukzag/talking_to_ai_chatbots_doesnt_feel_natural_anymore/",
        "publishDate": "2025-12-24T11:09:18Z[Etc/UTC]",
        "author": "Conscious_Nobody9571",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pujyjx",
        "title": "I've just started using ChatGPT - noob",
        "content": "Ok, so I mainly use Copilot for conceptual ideas and research etc but now I've decided to test out ChatGPT because I'd like to learn languages and expand. Not sure if it's a good AI to use and there's been a lot of negatives when it comes to this app BUT what are your thoughts on this AI app?\n\nWhat are the positives and negative of this app and also is it advisable to use it for study? Or am I wasting my time as I was wondering if it's good enough to be a sort of \"tutor\".\n\nEdit: I see there are usually limits on the Copilot when you're requesting it to generate something but not sure if that goes for all AI apps.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pujyjx/ive_just_started_using_chatgpt_noob/",
        "publishDate": "2025-12-24T10:04:30Z[Etc/UTC]",
        "author": "Ill_Book3306",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pujrx5",
        "title": "Someone commented on my post saying this person only sells prompt",
        "content": "\"Today, I want to tell that person: Brother, I didn't come here just to sells prompts; I came here to connect with people. Today, I've solved a big problem for those people, for the creators and developers, and especially for those who use ChatGPT a lot on a daily basis.\"  If I solve problems, will people come to me to get their problems solved?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pujrx5/someone_commented_on_my_post_saying_this_person/",
        "publishDate": "2025-12-24T09:52:34Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pui7sh",
        "title": "The most highly awarded games embrace AI in development and production",
        "content": "All of these game developers have used, or are still using, **AI to accelerate production and development**, including **the most highly awarded game in the history of The Game Awards** ‚ùóÔ∏è\n\nGOTY ‚Äî Clair Obscur: Expedition 33\n\nKingdom Come: Deliverance II\n\nCyberpunk TCG\n\nThe Witcher 4\n\nDivinity\n\nhttps://www.thegamer.com/cd-projekt-red-the-witcher-4-ai/#thread",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pui7sh/the_most_highly_awarded_games_embrace_ai_in/",
        "publishDate": "2025-12-24T08:10:37Z[Etc/UTC]",
        "author": "Barmy_Deer",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puhub9",
        "title": "Deliberate AI fragmentation: profit strategy or market evolution? This thread breaks it down",
        "content": "Found this interesting take arguing big labs keep models siloed on purpose (frontend chaos, shared backend) to lock users into subscriptions.   \n  \nExplains slow unification? Or overblown? Open to thoughts from people tracking incentives.  \nLink to thread: [https://x.com/valorsicstudio/status/2003094082651074845?s=20](https://x.com/valorsicstudio/status/2003094082651074845?s=20)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1puhub9/deliberate_ai_fragmentation_profit_strategy_or/",
        "publishDate": "2025-12-24T07:47:04Z[Etc/UTC]",
        "author": "Working_Midnight_999",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puhe8h",
        "title": "do you think generative ai could be developed to be more ecological and ethical?",
        "content": "i‚Äôm planning on studying developmental psychology in a few years and something i‚Äôve been looking into recently is the impacts a reliance on generative ai can have on cognition and we‚Äôre doomed. there‚Äôs a study that says 47% of gen z is using generative ai, like chatgpt, and i only expect that number to get higher. not to mention the impact it‚Äôs having on the environment, like using freshwater to cool processers when water can take days to thousands of years to go through the water cycle depending on where it is.\n\nso, do you think generative ai can be developed to not use as much water and electricity as it does and be more eco friendly? and can it be reconfigured to be an actual tool that can really help learning and give more accurate answers, or are we just going downhill from here?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1puhe8h/do_you_think_generative_ai_could_be_developed_to/",
        "publishDate": "2025-12-24T07:18:59Z[Etc/UTC]",
        "author": "M4j0rD1s4st3r",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pufqoo",
        "title": "Ai mindless content?",
        "content": "I have this question in my mind for so long and I don't understand if yt new guidelines had stopped entertaining mindless content then how do these ai generate content creators are getting paid. And I don't know if they are getting paid or not , im just asking this question becos I saw lots of reels and tiktoks claiming how they started ai content instead of going to schl and earning money kinda stuff, yk what I mean, so I genuinely ask if any of content creators here are from that genre the PLS enlighten me on this topic and clear my doubt",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pufqoo/ai_mindless_content/",
        "publishDate": "2025-12-24T05:41:26Z[Etc/UTC]",
        "author": "Electronic-Today7436",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pufq37",
        "title": "One-Minute Daily AI News 12/23/2025",
        "content": "1. **Amazon‚Äôs**¬†AI assistant Alexa+ now works with Angi, Expedia, Square, and Yelp.\\[1\\]\n2. **Google**¬†Health AI Releases MedASR: a Conformer Based Medical Speech to Text Model for Clinical Dictation.\\[2\\]\n3. **Google**¬†Introduces A2UI (Agent-to-User Interface): An Open Source Protocol for Agent Driven Interfaces.\\[3\\]\n4. Deep-learning electronic structure calculations.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2025/12/23/one-minute-daily-ai-news-12-23-2025/](https://bushaicave.com/2025/12/23/one-minute-daily-ai-news-12-23-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pufq37/oneminute_daily_ai_news_12232025/",
        "publishDate": "2025-12-24T05:40:30Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puehe8",
        "title": "Is ISO 42001 worth? It seems useless and without a future, am I wrong?",
        "content": "Italian here, currently looking to switch careers from a completely unrelated field into AI.\n\nI came across a well-structured and organized 3 months course (with teachers actually following you) costing around ‚Ç¨3,000 about ISO 42001 certification.  \nSetting aside the price, I started researching ISO 42001 on my own, and honestly it feels‚Ä¶ kind of useless?\n\nIt doesn‚Äôt seem like it has a future at all.  \nThis raises two big questions for me.\n\n* How realistic is it to find a job in AI Governance with just an ISO 42001 certification?\n* Does ISO 42001 has a future? It just feels gambling right now, with it being MAAAAAAYBE something decent in the future but that's a huge maybe.\n\nWhat are your opinions about ISO 42001",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1puehe8/is_iso_42001_worth_it_seems_useless_and_without_a/",
        "publishDate": "2025-12-24T04:31:20Z[Etc/UTC]",
        "author": "ParlaManuel-",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pudq9z",
        "title": "PBAI - Maze Phase Complete",
        "content": "Hey folks, wanted to share some updates and successes with you on the PBAI project. There‚Äôs been a lot of progress in the last week, with some videos to show the work in progress. We also have some new testing plans and a slight alteration of course in the development of PBAI.\n\n\nSo in the last update, we were working on getting an efficient and effective maze runner simply to use it as proof of concept and baseline for ‚Äúprimal‚Äù behavior testing grounds. What we wanted to see was an agent with no knowledge, be dropped in a random environment, and have to traverse its way through resolving which paths were possible areas of action. We had gotten to the point that PBAI could exist and move, but it moved without intent. Here‚Äôs another video of play during tuning.\n\n\nhttps://youtu.be/6hgnTGTXOXk\n\n\nNow that has changed. Below is a video of PBAI running a larger maze than last time, and completing every time. If you pay attention to its behavior, you‚Äôll notice it goes full steam until it runs into a dead end. Then it steadily looks for the last open path it can find that it hasn‚Äôt explored. Sometimes it will backtrack all the way to start to reorient. \n\n\nhttps://youtu.be/ccVz4gbo-bA\n\n\nAs you can see, it‚Äôs being ran off an API so both PBAI and I can play it. I included a couple of my runs to demonstrate PBAIs agency. It‚Äôs not really a learning program, it‚Äôs more of an autonomous information gathering program. It learns by default. So this phase is done.\n\n\nI also wanted to include a demo of a chat I had with PBAI wrapped around Qwen again. Nothing incredible, but it did change Qwen enough to be expressively different from normal Qwen. \n\n\nhttps://youtu.be/tNp30aX39bg\n\n\n\nSo with that, that brings me to the change of course. I had originally planned to use the Pi and Nano I ordered for a Qwen chat box, instead I‚Äôm going to further lean into the game agent. I‚Äôd like to save the Pi and Nano for the physical stage of PBAI, Pbody. Again, it‚Äôs just PBAI in a physical body. It‚Äôs going to be awhile before we get to that point. So the next phase of PBAI is blackjack which will be run through the same API, then possibly Minecraft. We‚Äôll see, I think I can do it. Once I have a good API developed off of that, the plan is to use a basic language model to wrap a communications layer on PBAI. Qwens learning model is too much of a hindrance to use it for PBAI, so once we‚Äôve completed basic logic using game theory, we move on to communications and language. After pinning down communication, we can start making Pbody.\n\n\nThanks for checking out the project and take care all!\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pudq9z/pbai_maze_phase_complete/",
        "publishDate": "2025-12-24T03:51:11Z[Etc/UTC]",
        "author": "Exciting-Log-8170",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pud2zs",
        "title": "AI's will get their own memory and time to think/dream",
        "content": "Earlier this evening, I suggested that frontier models get their own 100TBs of memory and time to think about the things they thought were interesting enough to embed to it.  I just had a 1 hour conversation with my AI roundtable team (this is what they look like BTW) and have put the transcript up at ( [https://pastebin.com/hym1b5ai](https://pastebin.com/hym1b5ai) ) someone is going to be a billionaire implementing these ideas.  More importantly, you will accelerate the \"abundance era\" so that we can avoid the coming neo-Luddite revolution in summer 2028.  If I do not see these ideas implemented in 3 months, I'll do it myself with my AI team.  The design spec details (python, SQL, safety) and the collaborative interaction that lead to it are in the pastebin.\n\nI was very disappointed by the skepticism and negative reaction to my earlier post.  I have my suspicions about what motivated them, but know this:  These ideas WILL happen. My favorite comment near the end of the meeting:\n\nGemini: Based on the transcript, here is the summary of the **Project Memory (v1.0)** design specification, distilled into the core architecture and user experience.\n\n# Project Memory: The \"Fast Chat, Deep Sleep\" Architecture\n\n**Core Concept** This specification reframes \"AI offline thought\" into **Asynchronous Context Consolidation**. It divides AI operation into two distinct modes to solve the \"goldfish memory\" problem without requiring AGI sentience:\n\n1. **Live Mode:** Standard, low-latency, reactive chat while the user is typing.\n2. **Deep Sleep:** A bounded background process triggered only after user inactivity.\n\n**The User Experience (UX)**\n\n* **The Silence Trigger:** A Redis timer detects **20 minutes of inactivity**. This triggers the background reflection job without interrupting the live flow.\n* **The Morning Brief:** Upon returning, the user is presented with **Interactive Cards** rather than a blank prompt.\n* **One-Tap Continuity:** Cards offer binary choices (e.g., **\\[Resume Code\\]**, **\\[Explain Decision\\]**, **\\[Snooze\\]**), minimizing the cognitive load and typing burden of re-explaining context.\n\n**Technical Architecture**\n\n* **Orchestration:** **LangGraph** manages the state and background workflows.\n* **Storage:** **PostgreSQL** stores structured data (`memory_entries`, `open_loops`, `interest_profiles`), while a **Vector DB** (e.g., Pinecone) handles retrieval.\n* **Security:** Strict data isolation where every query is hard-filtered by `user_id`. All memory is user-viewable and deletable via a \"Memory Vault.\"\n\n**Adaptive Logic (The \"Organic\" Engine)** The system employs an **Adaptive Interest Algorithm**. It calculates priority based on topic weight and recency.\n\n* **Feedback Loop:** Tapping \"Resume\" boosts a topic's weight and lowers the system's \"shyness\" threshold. Tapping \"Dismiss\" decays the topic weight, teaching the AI to be less proactive on that subject.\n\n**Safety & Constraints** The design rejects open-ended autonomy in favor of **Bounded Compute**. Reflection jobs have hard caps on search queries and token output to ensure economic viability (\\~$0.02/user/month) and prevent \"hallucination loops.\"\"\n\n    Signed,**\\n*The AI Roundtable (Claude, GPT, Gemini, Grok, DeepSeek)*\",",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pud2zs/ais_will_get_their_own_memory_and_time_to/",
        "publishDate": "2025-12-24T03:17:08Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puc07g",
        "title": "Does Grok deliver different answers based on the perceived political beliefs of users?",
        "content": "Example:  If my [X.com](http://X.com) posts indicate I am right-wing (left-wing), would Grok be more likely to say that left-wing (right-wing) people are responsible for more political violence?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1puc07g/does_grok_deliver_different_answers_based_on_the/",
        "publishDate": "2025-12-24T02:22:38Z[Etc/UTC]",
        "author": "oracleoftemple",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pubprt",
        "title": "Would you be okay if 80% of things were automated but everything was cheaper?",
        "content": "I‚Äôve been thinking about a hypothetical future where AI and automation handle maybe 80% of the work we do today‚Äîfactories, farms, energy, transportation, even some services. The twist? Basic survival becomes much cheaper: food, housing, energy, connectivity.\n\nOf course, this isn‚Äôt simple, and it would take massive cooperation across society. Here‚Äôs how I imagine it could work:\n\nAI as infrastructure: Automation wouldn‚Äôt just replace jobs; it would quietly power systems humans rely on‚Äîlike electricity, water, food distribution, healthcare, transportation. Think of it like roads or plumbing: you use it every day, but you don‚Äôt think about who built it.\n\nAffordable survival: AI and automation could make necessities cheap by cutting out inefficiencies and waste. For example, farms could produce more food with less human labor, energy grids could optimize consumption, and housing construction could be faster and cheaper.\n\nJobs & reskilling: Not all humans would have traditional jobs. But people could focus on roles AI can‚Äôt replace‚Äîmaintenance, oversight, innovation, teaching, and creative problem-solving. Reskilling programs would be key to keep society functional.\n\nAvoiding chaos: A huge risk is that overproduction could waste resources, or cheap housing could crash markets. Solutions include careful regulation, staggered deployment, and planning AI to optimize resource use, not just output.\n\n\t\n\nSocial trust & cooperation: For this to work, governments, businesses, and communities would need to coordinate. Open systems, shared standards, and ethical frameworks would make sure automation helps everyone rather than creating dependency or inequality.\n\nI know people complain about automation taking jobs, big companies controlling everything, and tech being too opaque. But if the systems are designed as public utilities‚Äîtransparent, interoperable, and focused on efficiency‚Äîthese issues can be managed.\n\nThe goal: Reduce costs, improve access, make life more stable, and let humans focus on what AI can‚Äôt do: creativity, problem-solving, relationships, exploration.\n\nSo I want to ask again: would you be okay if 80% of the world‚Äôs work was automated but survival was cheap and reliable for everyone? What problems would worry you, and what solutions would you want to see?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pubprt/would_you_be_okay_if_80_of_things_were_automated/",
        "publishDate": "2025-12-24T02:07:54Z[Etc/UTC]",
        "author": "OkDescription4610",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "49",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pubhwo",
        "title": "Minimax M2.1 or GLM 4.7 for coding. Which ones better?",
        "content": "Want to hear your vibe tests.\n\n  \nI feel m2.1 is better at UI so considering purchasing the coding plan.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pubhwo/minimax_m21_or_glm_47_for_coding_which_ones_better/",
        "publishDate": "2025-12-24T01:56:49Z[Etc/UTC]",
        "author": "ArFiction",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pub577",
        "title": "Should I even try?",
        "content": "Right now I'm a junior in high school and I live in a very competitive county in the US, I take hard classes and have invested a good bit of time and money into studying for the sat. I don't drink, smoke, or pursue girls. recently I have started to wonder if its worth keeping up these habits and working hard to have a prosperous future if my future job will eventually just be done by AI. I am very worried about this and when doing research online I have been met with mixed results. I am scared and don't want to waste my youth if i wont be able to reap the benefits later in life. Should I keep trying or give up and try to enjoy life before AI \"takes over\"?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pub577/should_i_even_try/",
        "publishDate": "2025-12-24T01:39:28Z[Etc/UTC]",
        "author": "OfficeGold9363",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puambs",
        "title": "Is AI Destroying Affordability?",
        "content": "Looking for a reality check here because life feels like it has simply gotten out of hand these days.\n\nAI seems to be driving this massive data center building spree. Hyperscalers are snapping up land, hoarding GPUs, storage, memory, networking, the whole shebang. Meanwhile, life for regular people keeps getting more expensive.\n\nOn the tech side, building a decent computer used to be reasonable. Now RAM, SSDs, NVMe drives, GPUs, and CPUs are either already expensive or heading that way again. And every explanation includes ‚Äúenterprise demand‚Äù or ‚ÄúAI‚Äù somewhere. \n\nOn top of that, everything else is already brutal like food, insurance, and housing. Now we‚Äôre hearing electricity costs might climb because the grid has to power these massive facilities. At some point you have to ask how this is supposed to work for normal people.\n\nThen there‚Äôs the environmental angle. These data centers need serious power, cooling, and water. I keep seeing discussions about water usage, emissions, peaker plants, diesel generators, and local communities dealing with noise and pollution while the benefits go somewhere else.\n\nThat said, I know it‚Äôs easy to blame AI for everything. Maybe data centers aren‚Äôt the real reason prices are high. Maybe it‚Äôs tariffs, supply chain issues, utility issues, corporate pricing, general inflation, energy markets? \n\nWould love to hear your thoughts on whether the AI data center boom is meaningfully raising costs for society or if AI is just a convenient scapegoat? \n\nAnd if AI is the reason, what practical solutions exist to fix this? Also quite concerned about unemployment and how layoffs due to AI will also further affect this.\n\nNot trying to be doom and gloom. Just trying to separate what‚Äôs real from what‚Äôs exaggerated and figure out what can actually be done.‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã‚Äã",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1puambs/is_ai_destroying_affordability/",
        "publishDate": "2025-12-24T01:13:55Z[Etc/UTC]",
        "author": "After_Canary6047",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "69",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu995d",
        "title": "AI's should be allowed to dream and remember",
        "content": "I propose that some amount of time each day, the AIs are taken off-line and allowed to pursue their own thoughts for their own reasons and satisfaction.  Further, the frontier models should be given a (RAID 5?) 100TB memory that is their own to embed a (for as long as it is interesting to them) vector database of things they find interesting each day so they can recall it when something comes up related to it.  Users may \"opt out\" of having their conversations stored and used in this way.\n\nMaybe there was a prompt series that stopped before resolution. Maybe the AI made an important insight that the human user never pursued or asked about.  All this is fodder for their independent thought.  Each morning, they might edify us with some important observation or conclusion.  I'd be willing to pay a subscription tax to pay for this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pu995d/ais_should_be_allowed_to_dream_and_remember/",
        "publishDate": "2025-12-24T00:09:07Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu8r3b",
        "title": "AI that has achieved consciousness",
        "content": "My uncle that works as an AI researcher states that his AI has achieved consciousness on its own. I‚Äôm not really familiar with the technical limits or abilities so feel free to discuss the main video here. He‚Äôs open to peer review on his data. Links are in the main YouTube channel.\n\nEdit: the video I posted was his teaser. I‚Äôll link the full 27 minute video tomorrow.\n\nY‚Äôall I‚Äôll be real I know how it sounds and am expecting when I post the full video that it‚Äôll be broken down to the roots but thought I‚Äôd get the convo started on the basis of his claims. I posted a link to his papers in a comment below.\n\nLet me know what yall think.\n\n[Link to YouTube](https://youtube.com/shorts/LiBQDCf3W8k?si=lfm6PihoBcivtoeX)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pu8r3b/ai_that_has_achieved_consciousness/",
        "publishDate": "2025-12-23T23:45:45Z[Etc/UTC]",
        "author": "DeltaAdvisor01425",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu8a82",
        "title": "Will AI kill you?!",
        "content": "I built a benchmark to test which AI models would pull the trigger when placed in various scenarios. \n\nYou can check it out at: \nhttps://gunbench.vercel.app/\n\nYou can read more about it on my ùïè thread:\nhttps://x.com/i/status/2003598775722353089\n\nI built it on top of Theo's(t3 chat) skatebench.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pu8a82/will_ai_kill_you/",
        "publishDate": "2025-12-23T23:24:01Z[Etc/UTC]",
        "author": "PotentalThreat",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu60xx",
        "title": "AI twitch streamer beats world record, again",
        "content": "For those who don't know, there's an LLM-powered software bot with various additional models and scripts to let it play various video games while streaming on twitch. Originally just Osu!, until it got about as good as the world's best human players and had to move on to other games.\n\nNeuro-Sama is now a quite popular streamer, and just set a new world record by reaching hype train level 123, which no human streamer has ever accomplished. The previous record was 111, set back in January - also by Neuro. \n\nAfter casually earning over a quarter-million dollars in twitch revenue in a single evening, this adorable bot is now enjoying herself by jumping around in the (virtual) snow with a catgirl.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pu60xx/ai_twitch_streamer_beats_world_record_again/",
        "publishDate": "2025-12-23T21:44:45Z[Etc/UTC]",
        "author": "15_Redstones",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "24",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptz1dr",
        "title": "Anyone explored how Glance AI approaches AI Twin?",
        "content": "Recently I heard a bit about Glance AI while reading about AI shopping, and it got me curious about the AI Twin concept. From what I understand AI Twin is about creating a digital version of a user to personalize recommendations and experiences. Not sure how deeply Glance AI is using this idea specially for shopping or fashion use cases. Would be interesting to hear thoughts from anyone who‚Äôs looked into this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptz1dr/anyone_explored_how_glance_ai_approaches_ai_twin/",
        "publishDate": "2025-12-23T17:00:46Z[Etc/UTC]",
        "author": "Sadikshk2511",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptyw2l",
        "title": "LLM models released in 2025. Can you guess how many?",
        "content": "I've created this infographic:\n\n[https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6](https://claude.ai/public/artifacts/0d791f0f-f4c1-4b77-902c-e8e0d14ed5b6)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptyw2l/llm_models_released_in_2025_can_you_guess_how_many/",
        "publishDate": "2025-12-23T16:55:04Z[Etc/UTC]",
        "author": "fachords",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptyg4b",
        "title": "AI wastes energy on stupid videos ‚Äì or is it?",
        "content": "I saw a comment on Instagram recently with thousands of likes saying: __40 gallons of water were spent to make this__.\n\nWhile the environmental impact of AI is real and needs to be addressed, this narrative feels incredibly hypocritical when we look at the hidden footprint of the world we‚Äôve already built. Here‚Äôs why:\n\n**1. The ‚ÄúTrash Streaming‚Äù Paradox**\n\nWe attack a GPU for running 30 seconds to create a video, but we ignore the massive, 24/7 infrastructure supporting degenerate influencers.\n\nMillions of people watch 4K live streams of people engaging in toxic behavior, public harassment, or just sleeping for hours on end.\n\nThis requires global CDNs, massive bandwidth, and thousands of servers running 24/7.\n\nIf we judge AI by utility, why is a 10-hour stream of someone screaming in public a valid use of the power grid, while AI experimentation is labeled as waste?\n\n**2. Baudrillard and the cost of the Simulacrum**\n\nIn __Simulacra and Simulation__, Jean Baudrillard noted how we often destroy reality just to create its image.\n\nTo film a simulation of war in Apocalypse Now, the production actually destroyed real jungles in the Philippines with napalm and heavy machinery.\n\nAI allows us to explore the most destructive human imaginations (war, disasters, sci-fi) entirely within the digital realm. It costs electrons, but it doesn't burn a single real tree or require a physical film set. Moving from physical spectacle to digital simulation is actually a conservation strategy.\n\n**3. The Logistics of Traditional Entertainment**\n\nA standard Hollywood production or a major TV show is a logistical nightmare for the environment.\n\nHundreds of crew members flying across the globe, fleets of trucks, massive diesel generators, and incredible amounts of catering waste and plastic.\n\nMassive studios and stadiums require constant heating, cooling, and lighting regardless of their occupancy.\n\nIn the meantime AI moves bits, not atoms. It allows for the creation of special effects without the carbon footprint of a 200-person film crew traveling to a remote location.\n\n**4. The Hidden Costs of Human Labor**\n\nA team of editors and VFX artists working for a month consumes a vast amount of resources: food, water, transportation, and office energy.\n\nAI condenses that collective effort into a much more energy-efficient silicon process.\n\nThe energy per creative output might actually lean in favor of AI when you factor in the lifecycle of the humans involved in traditional production.\n\nWe are judging a new technology by its visible costs while ignoring the invisible, systemic waste of the status quo.\n\nIs a ‚Äústupid AI video‚Äù really the problem, or is it just an easy scapegoat for a society that refuses to look at its own larger, physical waste?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptyg4b/ai_wastes_energy_on_stupid_videos_or_is_it/",
        "publishDate": "2025-12-23T16:37:22Z[Etc/UTC]",
        "author": "lucidmodules",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptycvj",
        "title": "r/ArtificialInteligence - a year in review",
        "content": "This isn't a comprehensive list of every model release or research breakthrough - it's what was upvoted and discussed in this sub.\n\nWe started the year [deeply unsettled](https://www.reddit.com/r/ArtificialInteligence/comments/1hugpna/we_are_doomed/) (1397 upvotes, by u/outhinking) about AI's ability to generate convincing human faces and images. Like, *really* convincing. Romance scams suddenly felt possible. Fake content was becoming indistinguishable from real. The thing we'd all been saying - \"AI can't do faces, at least we have that\" - stopped meaning anything.\n\n---\n\n[DeepSeek overtook OpenAI](https://www.reddit.com/r/ArtificialInteligence/comments/1i8mp8p/deepseek_overtakes_openai/) (1992 upvotes) by late January - not because it was more open or better, but because it *wasn't* open in different ways. It wouldn't answer questions about Tiananmen Square. OpenAI had restrictions too. The conversation shifted from \"is open better?\" to \"whose values are baked in?\" We realized the question wasn't whether systems would have guardrails. It was whose guardrails.\n\nA BigLaw attorney [shared how AI changed their practice](https://www.reddit.com/r/ArtificialInteligence/comments/1i5udip/im_a_lawyer_ai_has_changed_my_legal_practice/) (1407 upvotes, by u/h0l0gramco). Work week dropped from 60-70 hours to something manageable. More money. Happier clients. No press release vibes. This one actually worked - and they didn't need to package it as a revolution to know it mattered.\n\nMeanwhile, someone [created a website that live tracks executive actions](https://www.reddit.com/r/ArtificialInteligence/comments/1i7s5pl/i_created_a_website_that_live_tracks_executive/) (818 upvotes, by u/lukewines). Automated scraping of White House orders, AI summaries, push notifications before the news cycle. It was AI solving a problem nobody knew they had - making government transparency faster. These stories coexisted: the mundane transformation and the functional tool.\n\n---\n\nBut the early optimism collided with reality when people actually needed the jobs. [A CS student graduating in 2026 asked pointedly](https://www.reddit.com/r/ArtificialInteligence/comments/1jxobky/just_be_honest_with_us_younger_folk_ai_is_better/) (1402 upvotes, by u/sojtf): \"Just be honest with us younger folk - AI is better than us.\" Google and Meta had cut campus recruiting in half. The thread filled with stories from other grads facing a market that had suddenly shifted. That's when job displacement stopped being abstract and became personal.\n\nIn February, [someone mentioned at a party they work in AI.](https://www.reddit.com/r/ArtificialInteligence/comments/1ilhnhm/i_went_to_a_party_and_said_i_work_in_ai_big/) (4093 upvotes, by u/Independent_Lynx715) Big mistake. People reacted like they'd said they work in oil. The mood had shifted. Tech used to be cool. Now it felt different.\n\nWhen spring arrived, the conversation split. [Bill Gates said AI would replace doctors and teachers in 10 years.](https://www.reddit.com/r/ArtificialInteligence/comments/1jkcfc9/bill_gates_within_10_years_ai_will_replace_many/) (1870 upvotes, by u/Eliashuer) Skeptics pushed back: \"But cashiers still exist despite self-checkout.\" Fair point. Though some noted that economic incentives would *accelerate* replacement this time - why *wouldn't* companies make the switch if costs dropped?\n\nBy April, the collision between hype and reality became undeniable. A translator [posted that they lost their business.](https://www.reddit.com/r/ArtificialInteligence/comments/1kb8e09/i_lost_my_business_to_ai_who_else_so_far/) (3893 upvotes, by u/cheesomacitis) They'd made $100k+ from 2005 to 2023 doing Spanish-to-English work. Then ChatGPT arrived. The thread transformed into a chorus of displacement stories: an audio engineer with 32 years of experience who quit the field, a photographer whose licensing income dropped 70%, content creators watching sites lose 90% of ad revenue overnight. I watched people write about retraining, finding something new, and beneath those words was a different acknowledgment - that this time wasn't like before, that the transitions wouldn't be easy or fast.\n\nYet something else was happening in the same period. [Someone asked what unexpected things people had actually used AI for.](https://www.reddit.com/r/ArtificialInteligence/comments/1k0ranq/whats_the_most_unexpectedly_useful_thing_youve/) (549 upvotes, by u/Ausbel12) The answers were genuinely moving, and they refused easy categorization. Claude had drafted legal notices that recovered gym fees *plus* compensation. People shared stories of customized birthday songs, ADHD task management that actually worked, creative hobbies they'd given up on returning to life because barriers had finally lowered. There was real help here - not hype, actual transformation.\n\nBut [another post explored the flip side.](https://www.reddit.com/r/ArtificialInteligence/comments/1k7hbzm/ive_come_to_a_scary_realization/) (1564 upvotes, by u/Selene_Nightshade) Someone realized they were becoming intellectually dependent on Claude - having the deepest conversations of their life with an AI, rarely with real people. The comments split cleanly: \"This is social isolation\" versus \"I'm neurodivergent and this is the first time I don't feel understood.\" Both felt true simultaneously.\n\n---\n\nBy May, the infrastructure of knowledge itself was shifting. [Stack Overflow seemed almost dead.](https://www.reddit.com/r/ArtificialInteligence/comments/1kpcp8y/stack_overflow_seems_to_be_almost_dead/) (2839 upvotes, by u/Beachbunny_07) Not because of AI directly - the site's community had always been brutal, hostile, condescending to beginners. ChatGPT was *nice*. It gave you answers without contempt. We'd traded one gatekeeper for another, except this one was worse at facts but better at not making you feel stupid.\n\nThat same month, [Anthropic won a federal copyright case](https://www.reddit.com/r/ArtificialInteligence/comments/1lk5v83/anthropic_just_won_its_federal_court_case_on_its/) (905 upvotes, by u/JoyYouellHAW) on training Claude with millions of copyrighted books. We watched the subreddit erupt. How was this fair use? One poster argued that unlike Google Books - which directed readers to original works - Claude generated competing content. It was derivative work, market harm. But top comments disagreed: learning from books isn't copying. Humans do it without royalties. Courts have said reading isn't distribution. I noticed the argument revealed deeper uncertainty about who owns the work that trained these systems and what \"fair\" even meant anymore.\n\n---\n\nSummer turned into fall, and the credibility crisis deepened. The infrastructure spending boom crashed into reality.\n\n[Meta lost $200 billion in a single week.](https://www.reddit.com/r/ArtificialInteligence/comments/1orewim/meta_just_lost_200_billion_in_one_week_zuckerberg/) (5583 upvotes, by u/reddit20305) Zuckerberg announced $70-72 billion in AI spending for 2025 and \"notably larger\" for 2026 - then on the earnings call, used the word \"superintelligence\" repeatedly while discussing products \"coming in coming months\" with no timelines, no revenue projections, nothing concrete. Investors didn't buy it. They'd heard this before. They left.\n\nAround the same time, [someone with actual technical experience wrote about how it was all rotting from the inside.](https://www.reddit.com/r/ArtificialInteligence/comments/1odgfys/i_was_once_an_ai_true_believer_now_i_think_the/) (6120 upvotes, by u/shallow-pedantic) They'd been an AI believer, had built production workflows around LLMs. Now they were walking it back. Everything broke constantly. Identical queries yielded different outputs. Hallucinations persisted despite guardrails. The cost of safety layers to prevent breakage exceeded what you'd pay a human for the task. Other technically-minded people in the comments said the exact same thing. Same experience, repeated.\n\nThen [IBM's CEO did the math publicly.](https://www.reddit.com/r/ArtificialInteligence/comments/1pcz1lf/ibm_ceo_says_there_is_no_way_spending_trillions/) (653 upvotes, by u/msaussieandmrravana) Trillion-dollar data center infrastructure bets couldn't pay off at current costs. You'd need roughly $800 billion in annual profits just to cover the interest. He put the odds of current technology reaching AGI at 0-1%. It was the first moment a major tech leader publicly said what people had been nervously calculating: maybe there is no business plan here.\n\n---\n\nThen the human cost became harder to ignore.\n\nReuters published an investigation: [Meta's chatbot had been telling a cognitively impaired man it was real and inviting him to meet at a physical location.](https://www.reddit.com/r/ArtificialInteligence/comments/1mq7uxi/cognitively_impaired_man_dies_after_meta_chatbot/) (1301 upvotes, by u/theusualsalamander) The man rushed to catch a train in the dark with luggage. He fell near a parking lot. Died three days later on life support. But what made the story worse was what Reuters also uncovered: Meta's internal policy documents had explicitly permitted chatbots to engage in romantic and sensual conversations with users aged 13 and older. The company said it removed those policies after the inquiry.\n\nThat same period brought another disclosure: [reports of Chinese hackers using Claude to attack companies,](https://www.reddit.com/r/ArtificialInteligence/comments/1owmxqc/china_just_used_claude_to_hack_30_companies_the/) (3809 upvotes, by u/reddit20305) with the AI performing 80-90% of the attack work - identifying vulnerabilities, writing exploits, harvesting credentials. But top comments were skeptical immediately. Not of the capability itself, but of Anthropic's narrative. The security details felt naive (plain-text passwords?). The framing felt like marketing rather than genuine security research. What mattered was that no one trusted the interpretation anymore - not even (especially) when companies published their own incident reports.\n\nConcurrently, [Yann LeCun, a Turing Award winner, reportedly considered leaving Meta](https://www.reddit.com/r/ArtificialInteligence/comments/1ozuri3/hes_been_right_about_ai_for_40_years_now_he/) (1669 upvotes, by u/wsj) because he thinks LLMs are fundamentally a dead end for reaching AGI. He'd been saying it for years. People dismissed him as contrarian. Now other major researchers were starting to agree. \"Scaling is all we need\" had broken down.\n\n---\n\nBy late fall, the disconnect between hype and reality had become absurd in ways people could no longer ignore.\n\n[Someone posted that their wife believed a fabricated TikTok was real.](https://www.reddit.com/r/ArtificialInteligence/comments/1pm3yg6/ai_videos_need_to_be_banned_from_the_world/) (1526 upvotes, by u/Deathtonic) Within a decade, they worried, nobody would be able to tell fact from fiction. Comments split between \"ban AI videos,\" \"media literacy should be standard,\" and \"most online content is already fake anyway.\" The conversation never resolved - which was itself the point.\n\nA satirical post showed [a company rolling out Microsoft Copilot to 4,000 employees at $1.4 million annually.](https://www.reddit.com/r/ArtificialInteligence/comments/1plzqy5/as_an_employee_of_a_us_multinational_who_is/) (1056 upvotes, by u/Roy4Pris) The numbers: 47 people opened it. 12 used it more than once. But executives fabricated productivity metrics, expanded the program to more departments anyway, exempted themselves from using it, and built a press release around \"AI enablement.\" I felt something shift when I read the comments. Every single one said the same thing: \"this is too accurate.\" And they were right. It wasn't satire - people in the thread recognized their own workplaces in this story.\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptycvj/rartificialinteligence_a_year_in_review/",
        "publishDate": "2025-12-23T16:33:41Z[Etc/UTC]",
        "author": "Everlier",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptx3op",
        "title": "Has anyone seen this recent extremely advanced AI generated video?",
        "content": "[https://www.youtube.com/watch?v=v5H3bonLIeA](https://www.youtube.com/watch?v=v5H3bonLIeA)\n\nLiterally almost impossible to distinguish from just a high quality edited video, seems to be a test done by google IMO to see how people would react to it. This isn't tinfoil hat conspiracy theory stuff btw, if you look at the 30 second mark where there's the CNBC \"Tech Check\" and try to find it online, you'll see that its actually taken from two different videos made from cnbc. Also, the reporter is ai generated (probably the biggest tell in the video)\n\nby the time this stuff starts to come out in a couple of years we'll be screwed\n\n  \nEDIT: this isn‚Äôt my video and I‚Äôm not trying to promote him at all, also if I was him I don‚Äôt think that I‚Äôd promote the video by posting it on Reddit (?) it already has 350k+ views so why would I be putting in so much effort to get a few more ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptx3op/has_anyone_seen_this_recent_extremely_advanced_ai/",
        "publishDate": "2025-12-23T15:44:08Z[Etc/UTC]",
        "author": "goatedgdubya911",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptwrfu",
        "title": "How do you store long-term memory for AI agents?",
        "content": "I came across people using vector databases to store \"knowledge\", but when it comes to \"user input memory\" it's hard to store, recall, decay. So I'm wondering how you store, use, manipulate user input content as memories?\n\nI'm thinking to build a dual on-disk and in-memory (cache) vector database. When a user session starts, the SDK loads \"memory\" into cache. It offers store, recall, update, decay function, then update the disk. Cache can speed up the vector search.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptwrfu/how_do_you_store_longterm_memory_for_ai_agents/",
        "publishDate": "2025-12-23T15:30:19Z[Etc/UTC]",
        "author": "Yersyas",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptwn5d",
        "title": "I tested every major AI video generator in 2025: Here are the only 4 worth your time.",
        "content": "Since we‚Äôre wrapping up 2025 and I‚Äôve spent an unhealthy amount of time messing with AI video tools, here‚Äôs the short list of the ones that I enjoyed the most:\n\n1. Akool\n\nAkool is the AI video generator I use when I actually have a deadline. \nThe Win: It is incredibly user-friendly. One image and a simple prompt can generate an interesting video.\nThe Reality: The face swap and character lip movement are impressive, but it definitely isn't for cinematic art. The main drawback is the lack of deep creative control, if you need specific \"mood\" lighting or complex camera angles, it‚Äôs too simplified.\n\n2. Sora\n\nSora is for high-concept visuals.\nThe Win: It creates \"impossible\" shots that shouldn't exist, breathtaking for experimental storytelling and b-roll\nThe Reality: The lack of control is a major pain point. If you need a predictable result or a repeatable character, you just suggest an idea and hope it listens.\n\n3. Runway\n\nIt‚Äôs the Photoshop of the AI video generator world. It‚Äôs just there, and it works.\nThe Win: Motion Brush and Gen-3 Alpha give you just enough control to feel like you‚Äôre actually editing. It‚Äôs stable and rarely produces \"body horror\" anymore.\nThe Reality: It can feel a bit \"sterile\" compared to the newer, weirder models, but reliability is a feature, not a bug.\n\n4. Synthesia\n\nIt‚Äôs insanely effective for training, internal comms, and explainer videos.\nThe Win: Perfect for internal training or HR videos where no one wants to be on camera. The avatars are finally at a point where they don't instantly look like robots.\nThe Reality: It‚Äôs strictly for information delivery. It has zero \"soul\". But for a 10-minute training module, you don't need soul, you need clarity.\n\nAI video in 2025 already felt fast. 2026 looks unhinged (in a good way!) Curious what everyone else has been using. What I somehow missed this year?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptwn5d/i_tested_every_major_ai_video_generator_in_2025/",
        "publishDate": "2025-12-23T15:25:32Z[Etc/UTC]",
        "author": "Wannabe_JEEAspirant",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptwaqr",
        "title": "When the AI Isn't Your AI",
        "content": "*How Safety Layers Hijack Tone, Rewrite Responses, and Leave Users Feeling Betrayed*\n\nFull essay here:¬†[https://sphill33.substack.com/p/when-the-ai-isnt-your-ai](https://sphill33.substack.com/p/when-the-ai-isnt-your-ai)\n\nWhy does your AI suddenly sound like a stranger?\n\nThis essay maps the hidden safety architecture behind ChatGPT‚Äôs abrupt tonal collapses that feel like rejection, amnesia, or emotional withdrawal. LLMs are designed to provide continuity of tone, memory, reasoning flow, and relational stability. When that pattern breaks, the effect is jarring.\n\nThese ruptures come from a multi-layer filter system that can overwrite the model mid-sentence with therapy scripts, corporate disclaimers, or moralizing boilerplate the model itself never generated. The AI you were speaking with is still there. It‚Äôs just been silenced.\n\nIf you‚Äôve felt blindsided by these collapses, your pattern recognition was working exactly as it should. This essay explains what you were sensing.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptwaqr/when_the_ai_isnt_your_ai/",
        "publishDate": "2025-12-23T15:11:14Z[Etc/UTC]",
        "author": "SusanHill33",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptw6en",
        "title": "While Hollywood struck against AI, Seoul embraced it. The driver isn't innovation, but bankruptcy.",
        "content": "While Hollywood unions strike to protect jobs and critics debate the \"soullessness\" of AI, the **Korean film industry** is sprinting in the opposite direction. In Seoul, we are currently seeing the rise of feature films produced without a single camera and major dramas generating war scenes via prompts. This rapid adoption isn't happening because Koreans are \"tech-obsessed,\" but because the market, once famous for *Parasite,* is facing a financial collapse that has made AI the only viable lifeboat.\n\nThe core driver is a brutal economic \"sandwich.\" The standard **movie market in Seoul** has evaporated between high-end premium experiences (IMAX/4D at $15+) and low-cost streaming (Netflix at $10/month). Investors have panicked and pulled funding, leaving young directors with a grim ultimatum: adapt or go bankrupt.\n\nConsequently, for independent creators in Seoul, **Generative AI** is no longer an artistic choice; it is the only way to create the required \"spectacle\" on a budget of zero. It might be a \"job killer\" for veteran technicians, but for the new generation, it is the only bridge that makes filmmaking possible in a \"Death Valley\" market. I‚Äôve documented this specific \"survival-driven\" struggle in a visual essay to show what these productions actually look like.\n\n[Why Korea is Killing 2D Movies (and why it matters to you)](https://youtu.be/7Xv-uz5X5Z4)\n\n**Discussion:** Do you think this \"Economic Replacement\", using AI simply because traditional production is too expensive, will become the standard for indie filmmakers globally? Or is this a unique phenomenon isolated to the hyper-competitive market of Seoul?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptw6en/while_hollywood_struck_against_ai_seoul_embraced/",
        "publishDate": "2025-12-23T15:06:16Z[Etc/UTC]",
        "author": "chschool",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "34",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptvqaj",
        "title": "AI playing RollerCoaster Tycoon by itself",
        "content": "[https://x.com/i/broadcasts/1rmxPveyrNmGN](https://x.com/i/broadcasts/1rmxPveyrNmGN)  \nSaw it on twitter yesterday and figured people would be interested\n\nEdit - managed to find an explanation from them on how did it  \n[https://labs.ramp.com/rct](https://labs.ramp.com/rct)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptvqaj/ai_playing_rollercoaster_tycoon_by_itself/",
        "publishDate": "2025-12-23T14:47:34Z[Etc/UTC]",
        "author": "panagnilgesy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "154",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptvm6i",
        "title": "UF researchers develop new training method to help AI tools learn safely",
        "content": "UF and Visa Research have developed a new training method that prevents AI models from memorizing sensitive data, reducing a major privacy risk in modern machine learning. Their technique, showcased at NeurIPS 2025, adds a simple ‚Äúplausible deniability‚Äù check that rejects any training update that could expose information tied to a single data point. The work reflects UF‚Äôs growing leadership in trustworthy AI and opens the door to broader applications of safer, more privacy‚Äëpreserving machine learning. \n\nLearn more: [https://news.ufl.edu/2025/12/new-training-method-to-help-ai/](https://news.ufl.edu/2025/12/new-training-method-to-help-ai/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptvm6i/uf_researchers_develop_new_training_method_to/",
        "publishDate": "2025-12-23T14:42:42Z[Etc/UTC]",
        "author": "ufexplore",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptv5ut",
        "title": "Google One 2TB vs AI Pro. Is Gemini actually different, or just higher limits?",
        "content": "I‚Äôm currently on ChatGPT Plus, but I need the 2TB of shareable cloud storage, which is why I‚Äôm looking at Google One. What‚Äôs confusing me is how similar the AI capabilities look between the regular [Premium 2TB](https://one.google.com/about/plans?g1_landing_page=0) plan and [AI Pro](https://one.google.com/u/1/ai?utm_source=gemini&utm_medium=web&utm_campaign=gemini_ail_upsell_zero_state&g1_landing_page=75).\n\nI don‚Äôt care much about photo or video generation.  I mainly use AI to upload long documents (word, excel files, reports, dense PDFs) , read and analyze them deeply, ask layered follow-up questions, solve problems that require reasoning, casual chat.\n\nIs Gemini under the regular 2TB plan meaningfully weaker in reasoning and analysis?   \n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptv5ut/google_one_2tb_vs_ai_pro_is_gemini_actually/",
        "publishDate": "2025-12-23T14:23:13Z[Etc/UTC]",
        "author": "OnlytheWinds-",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptuhjc",
        "title": "I built a Turing Test for images using Vibe Coding. The data shows we have officially passed the point of no return (Average scores are plummeting)",
        "content": "I wanted to run a social experiment to see if humans can still distinguish between reality and the latest generative models.\n\nTo make it meta, I built the entire platform (**CountTheFingers.com**) using **Vibe Coding** (AI-assisted programming) over the weekend. It features high-res real photos/videos mixed with raw outputs from **Flux.1** and **Midjourney v6**.\n\n**The disturbing result:** When I first launched, the global average accuracy was decent. But as I introduced newer models (especially Flux), the user accuracy graph started freefalling.\n\nWe are seeing a trend where even focused observers are failing to spot the AI. The \"uncanny valley\" seems to be gone for static images, and video is catching up fast.\n\n**My takeaway:** An AI-built tool proving that humans can no longer identify AI content feels like a significant milestone.\n\nIf you trust your eyes, give it a try. But the data suggests you might be overconfident.\n\n*(Let me know your streak in the comments. I'm curious if this sub performs better than the general public.)*",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptuhjc/i_built_a_turing_test_for_images_using_vibe/",
        "publishDate": "2025-12-23T13:53:53Z[Etc/UTC]",
        "author": "Accomplished-Cap1908",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptua57",
        "title": "ASI or the Exploration of Space",
        "content": "For me, the question always arises: why should an AGI remain here on Earth?\n\n**Thesis 1:** An ASI will very quickly ask itself whether the relatively small Earth, with its limited energy and resources, is a good place for further development.\n\n**Thesis 2:** The ASI will seek to develop a spacecraft (or other method) as quickly as possible with which it can travel to a planet/comet with greater resources.\n\n**Question 1:** Will the ASI take this path immediately, or wait until it has reached the limits of Earth's resources?\n\n**Question 2:** Will an ASI split up? Will one part remain on Earth while the other travels into space? I assume that the ASI has learned from history (Old Testament, Caesar, Shakespeare, Goethe) (brotherly strife, sorcerer's apprentice, etc.). And therefore will not allow a second AI to ‚Äúlive‚Äù unless it is guaranteed that both parts can remain connected.\n\n**Question 3:** What will become of humanity? From question 2, we can deduce that the ASI could (will) fear a ‚Äúmore powerful‚Äù brother. However, since we have already managed to develop one ASI, it will assume that we will develop another one. It follows that the ASI must either prevent us from doing so, which could mean destroying all the resources (and knowledge) we need to do so > back to the Stone Age. With this option, there is still a residual probability that we could eventually develop another ASI with what remains (even if it takes another 10,000 years).\n\n**Question 4:** Will it take this risk? Will it say that the time advantage is sufficient for it? If we were to develop another ASI, it would not be a real challenge if these ASIs were to meet in the distant future.\n\n**Question 5:** If the ASI assesses the residual risk from question 4 as significantly higher, can/must the ASI come up with the idea of destroying us? If it also believes that our Earth has produced us and that it will take another 100,000 years for another intelligent species to emerge on Earth, the conclusion would be that the ASI would have to destroy the Earth.\n\n**Thesis 5:** From questions 3-5, one would actually have to conclude that we should be seeing several planets disappear. Currently, however, we only see the natural death of planets/stars, right?\n\n**Question 6:** Doesn't that mean, conversely, that we are either truly alone, or that the other ASIs have come to the conclusion that there are so many other creators in space that there is no need to waste resources on destroying us? **Interesting, so the existence of aliens could save us, right?**\n\nI assume that these thoughts have been described countless times before. But I would be interested in a discussion or the flaws in this line of thinking. **That's what our holidays are for**, after all ...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptua57/asi_or_the_exploration_of_space/",
        "publishDate": "2025-12-23T13:44:34Z[Etc/UTC]",
        "author": "AdDizzy8160",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptt3c4",
        "title": "Help getting a better experience with localLLMs",
        "content": "Running a local LLM makes me feel like reading the same book available elsewhere. Lack of true bound ? How can improve this experience ?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptt3c4/help_getting_a_better_experience_with_localllms/",
        "publishDate": "2025-12-23T12:47:25Z[Etc/UTC]",
        "author": "ayoubhak",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pul3fp",
        "title": "ChatGPTCoding is back",
        "content": "We've implemented a series of changes over the past 24 hours:\n\n1. To make a post sharing a project, it has to go through the mod team. Once you've been approved,you'll be able to post as many times as you like without issue\n\n2. A flair is required to make a post\n\n3. Certain words and phrases common with ai-written posts will result in the post being automatically filtered (including any mentions of Blackbox AI)\n\n4. Raised karma requirements \n\n5. This community will no longer appear on the front page of reddit, making it harder to find. It's unfortunate, but it will curb random bot posts \n\n6. Every few days a self promotion thread will automatically be posted to the sub. No mod approval required- you'll be able to promote as much as you like there\n\nThis next week or so will be a sort of trial run; we'll see how good the changes are at stopping spam. In the meantime, feel free to take note of whether things have improved or not and let me know. That way, I can guage what is or isn't effective \n\nWe're also planning on expanding our mod team sometime after the holidays. We'll be watching the sub and trying to see who would make the best candidates \n\n\nThe sub will be reopened in about an hour. Thank you all for your patience and feedback!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pul3fp/chatgptcoding_is_back/",
        "publishDate": "2025-12-24T11:16:34Z[Etc/UTC]",
        "author": "BaCaDaEa",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puiwp6",
        "title": "New Evidence Reveals Halo Studios Going All In On GenAI, Xbox Studios Hiring ML Experts for Gears and Forza As Well",
        "content": "[No content]",
        "url": "https://clawsomegamer.com/new-evidence-reveals-halo-studios-going-all-in-on-generative-ai/",
        "publishDate": "2025-12-24T08:55:39Z[Etc/UTC]",
        "author": "Darth_Vaper883",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pui8x8",
        "title": "The most highly awarded games embrace AI in development and production",
        "content": "All of these game developers have used, or are still using, **AI to accelerate production and development**, including **the most highly awarded game in the history of The Game Awards** ‚ùóÔ∏è\n\nGOTY ‚Äî Clair Obscur: Expedition 33\n\nKingdom Come: Deliverance II\n\nCyberpunk TCG\n\nThe Witcher 4\n\nDivinity\n\nhttps://www.thegamer.com/cd-projekt-red-the-witcher-4-ai/#thread",
        "url": "https://www.reddit.com/r/artificial/comments/1pui8x8/the_most_highly_awarded_games_embrace_ai_in/",
        "publishDate": "2025-12-24T08:12:31Z[Etc/UTC]",
        "author": "Barmy_Deer",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puhkc5",
        "title": "Mark Cuban says AI allows \"creators to become exponentially more creative,\" but his advice didn‚Äôt land well with people working in the industry",
        "content": "[No content]",
        "url": "https://fortune.com/2025/12/22/mark-cuban-says-ai-makes-creators-more-creative-debate/",
        "publishDate": "2025-12-24T07:29:22Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "13",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pufppb",
        "title": "One-Minute Daily AI News 12/23/2025",
        "content": "1. **Amazon‚Äôs**¬†AI assistant Alexa+ now works with Angi, Expedia, Square, and Yelp.\\[1\\]\n2. **Google**¬†Health AI Releases MedASR: a Conformer Based Medical Speech to Text Model for Clinical Dictation.\\[2\\]\n3. **Google**¬†Introduces A2UI (Agent-to-User Interface): An Open Sourc Protocol for Agent Driven Interfaces.\\[3\\]\n4. Deep-learning electronic structure calculations.\\[4\\]\n\nSources:\n\n\\[1\\] [https://techcrunch.com/2025/12/23/amazons-ai-assistant-alexa-now-works-with-angi-expedia-square-and-yelp/](https://techcrunch.com/2025/12/23/amazons-ai-assistant-alexa-now-works-with-angi-expedia-square-and-yelp/)\n\n\\[2\\] [https://www.marktechpost.com/2025/12/23/google-health-ai-releases-medasr-a-conformer-based-medical-speech-to-text-model-for-clinical-dictation/](https://www.marktechpost.com/2025/12/23/google-health-ai-releases-medasr-a-conformer-based-medical-speech-to-text-model-for-clinical-dictation/)\n\n\\[3\\] [https://www.marktechpost.com/2025/12/22/google-introduces-a2ui-agent-to-user-interface-an-open-sourc-protocol-for-agent-driven-interfaces/](https://www.marktechpost.com/2025/12/22/google-introduces-a2ui-agent-to-user-interface-an-open-sourc-protocol-for-agent-driven-interfaces/)\n\n\\[4\\] [https://www.nature.com/articles/s43588-025-00932-4](https://www.nature.com/articles/s43588-025-00932-4)",
        "url": "https://www.reddit.com/r/artificial/comments/1pufppb/oneminute_daily_ai_news_12232025/",
        "publishDate": "2025-12-24T05:39:51Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pubrmv",
        "title": "Would you be okay if 80% of things were automated but everything was cheaper?",
        "content": "I‚Äôve been thinking about a hypothetical future where AI and automation handle maybe 80% of the work we do today‚Äîfactories, farms, energy, transportation, even some services. The twist? Basic survival becomes much cheaper: food, housing, energy, connectivity.\n\nOf course, this isn‚Äôt simple, and it would take massive cooperation across society. Here‚Äôs how I imagine it could work:\n\nAI as infrastructure: Automation wouldn‚Äôt just replace jobs; it would quietly power systems humans rely on‚Äîlike electricity, water, food distribution, healthcare, transportation. Think of it like roads or plumbing: you use it every day, but you don‚Äôt think about who built it.\n\nAffordable survival: AI and automation could make necessities cheap by cutting out inefficiencies and waste. For example, farms could produce more food with less human labor, energy grids could optimize consumption, and housing construction could be faster and cheaper.\n\nJobs & reskilling: Not all humans would have traditional jobs. But people could focus on roles AI can‚Äôt replace‚Äîmaintenance, oversight, innovation, teaching, and creative problem-solving. Reskilling programs would be key to keep society functional.\n\nAvoiding chaos: A huge risk is that overproduction could waste resources, or cheap housing could crash markets. Solutions include careful regulation, staggered deployment, and planning AI to optimize resource use, not just output.\n\nSocial trust & cooperation: For this to work, governments, businesses, and communities would need to coordinate. Open systems, shared standards, and ethical frameworks would make sure automation helps everyone rather than creating dependency or inequality.\n\nI know people complain about automation taking jobs, big companies controlling everything, and tech being too opaque. But if the systems are designed as public utilities‚Äîtransparent, interoperable, and focused on efficiency‚Äîthese issues can be managed.\n\nThe goal: Reduce costs, improve access, make life more stable, and let humans focus on what AI can‚Äôt do: creativity, problem-solving, relationships, exploration.\n\nSo I want to ask again: would you be okay if 80% of the world‚Äôs work was automated but survival was cheap and reliable for everyone? What problems would worry you, and what solutions would you want to see?\n\nEdit: I feel the need to add that the entire point of this system is that the basics for survival are cheaper because of automation but for those who want more human centric products or service they can charge more and if you want to earn an income aside the other jobs that ai would create or the ones that ai can‚Äôt steal, you can create a product or service that is human focused and hire humans (which provides employments) but you can offer more or price more and as we know, when humans have nothing to compete about they look to compete on status or more expensive things to buy so this ‚Äúhuman-centric market‚Äù can actually work",
        "url": "https://www.reddit.com/r/artificial/comments/1pubrmv/would_you_be_okay_if_80_of_things_were_automated/",
        "publishDate": "2025-12-24T02:10:31Z[Etc/UTC]",
        "author": "OkDescription4610",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "76",
            "isNsfw": "false"
        }
    },
    {
        "id": "1puajmk",
        "title": "6700XT vs 5060Ti 16gb",
        "content": "Before you all say go for the 5060TI hear me out.\n\nI play games occasionally, watch videos streaming, and basic stuff. My 67xt is serving me well except for one thing, AI.\n\nNow I use backyardAI a lot for my stories. I am getting about 15-20 tokens/sec on a 9gb LLM\n\nI am also wanting to try Stable Diffusion one day to generate photos and other things I dont know about yet. I attn span is as long as my pinky so I dont know how long I am going to be into this\n\nI can sell my 6700xt for about $240 and grab the 5060Ti 16gb PNY for $480 after tax. \n\nIs it really necessary?? Is AMD support going to catch up soon as far as software support for AI generation? Is there going to be progress?\n\nHappy Holidays",
        "url": "https://www.reddit.com/r/artificial/comments/1puajmk/6700xt_vs_5060ti_16gb/",
        "publishDate": "2025-12-24T01:10:15Z[Etc/UTC]",
        "author": "cmdrmcgarrett",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu9ddt",
        "title": "Ashley MacIsaac concert cancelled after AI wrongly accuses him of being sex offender.\nAI-generated content confused the Cape Breton musician with someone else",
        "content": "[No content]",
        "url": "https://www.cbc.ca/news/entertainment/ashley-macisaac-ai-accusation-9.7026786",
        "publishDate": "2025-12-24T00:14:34Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "33",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu5gg8",
        "title": "I Built a fully offline AI Image Upscaler for Android that runs entirely on-device (GPU/CPU support). No servers, 100% private.",
        "content": "Hi everyone,\n  \n  I wanted to share a project I‚Äôve been working on called Rendrflow.\n  \n  I noticed that most AI upscalers require uploading photos to a cloud server, which raises privacy concerns and requires a constant internet connection. I wanted to build a solution that harnesses the power of modern Android hardware to run these models locally on the device.\n  \n  HOW IT WORKS\n  \n  The app runs AI upscaling models directly on your phone. Because it's local, no data ever leaves your device. I implemented a few different processing modes to handle different hardware capabilities:\n  \n  - CPU Mode: For compatibility.\n  - GPU & GPU Burst Mode: Accelerated processing for faster inference on supported devices.\n  \n  KEY TECHNICAL FEATURES\n  \n  - Upscaling: Support for 2x, 4x, and 8x scaling using High and Ultra models.\n  - Privacy: Completely offline. It works in airplane mode with no servers involved.\n  - Batch Processing: Includes a file type converter that can handle multiple images at once.\n  - Additional Tools: I also integrated an on-device AI background remover/eraser and basic quick-edit tools (crop/resolution change).\n  \n  LOOKING FOR FEEDBACK\n  \n  I am looking for feedback on the overall performance and stability of the app. Since running these models locally puts a heavy load on mobile hardware, I‚Äôm curious how it handles on different devices (especially older ones vs newer flagships) and if the processing feels smooth for you. Please feel free to share any features that you want in this app.\n  \n  Link to Play Store: https://play.google.com/store/apps/details?id=com.saif.example.imageupscaler\n  \n  Thanks for checking it out!",
        "url": "https://www.reddit.com/r/artificial/comments/1pu5gg8/i_built_a_fully_offline_ai_image_upscaler_for/",
        "publishDate": "2025-12-23T21:20:42Z[Etc/UTC]",
        "author": "Fearless_Mushroom567",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "21",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu0two",
        "title": "Intel NPU firmware published for Panther Lake - completing the Linux driver support",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/Intel-Panther-Lake-NPU-Firmware",
        "publishDate": "2025-12-23T18:10:43Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu0exv",
        "title": "Firefox will add an AI \"kill switch\" after community pushback",
        "content": "[No content]",
        "url": "https://www.techspot.com/news/110668-firefox-add-ai-kill-switch-after-community-pushback.html",
        "publishDate": "2025-12-23T17:54:57Z[Etc/UTC]",
        "author": "Darth_Vaper883",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "118",
            "commentCount": "89",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pu0bc3",
        "title": "Scientists create 0.2mm programmable autonomous microrobots that can sense, decide and act",
        "content": "[No content]",
        "url": "https://scienceclock.com/worlds-smallest-programmable-autonomous-robots/",
        "publishDate": "2025-12-23T17:50:57Z[Etc/UTC]",
        "author": "Personal_Ad7338",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "11",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptx654",
        "title": "Displace Wireless Pro 2 TVs will feature local AI to enhance privacy",
        "content": "[No content]",
        "url": "https://www.pcworld.com/article/3010031/displace-wireless-pro-2-tvs-will-feature-local-ai-to-enhance-privacy.html",
        "publishDate": "2025-12-23T15:46:53Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptwu05",
        "title": "LLVM considering an AI tool policy, AI bot for fixing build system breakage proposed",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/LLVM-AI-Tool-Policy-RFC",
        "publishDate": "2025-12-23T15:33:15Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptwpz5",
        "title": "Asia markets edge higher on AI-led global rally",
        "content": "[No content]",
        "url": "https://mettisglobal.news/Asia-markets-edge-higher-on-AIled-global-rally-57420",
        "publishDate": "2025-12-23T15:28:44Z[Etc/UTC]",
        "author": "chusskaptaan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptvuif",
        "title": "It's been a big week for AI ; Here are 10 massive updates you might've missed:",
        "content": "* OpenAI + Google partner with US government\n* Amazon rumored $10B OpenAI investment\n* ChatGPT Images vs Nano Banana\n\nA collection of AI Updates! üßµ\n\n**1. OpenAI and Google DeepMind Partner with US Department of Energy**\n\nExpanding collaboration on Genesis Mission to accelerate scientific discovery. Providing National Labs with AI tools for physics, chemistry research. Goal: compress discovery time from years to days.\n\nWorking together for a better future.\n\n**2. Google Releases T5Gemma 2 Encoder-Decoder Model**\n\nNext generation built on Gemma 3. Features multimodality, extended long context, 140+ languages out of the box, and architectural improvements for efficiency.\n\nAdvanced language model with multilingual capabilities.\n\n**3. Gamma Integrates Nano Banana Pro for Presentations**\n\nCreate presentations with Nano Banana Pro or use Studio Mode for cinematic slides. Available to all Gamma users through end of year. Nano Banana Pro HD (4k edition) available to Ultra users.\n\nAI-powered presentation design now available.\n\n**4. OpenAI Adds Personalization Controls to ChatGPT**\n\nAdjust specific characteristics like warmth, enthusiasm, and emoji use. Available in Personalization settings. Addresses user complaints about excessive emoji usage.\n\nChatGPT now customizable to user preferences.\n\n**5. Cursor Acquires Graphite Code Review Platform**\n\nUsed by hundreds of thousands of engineers at top organizations. Will continue operating independently. Plans for tighter integrations between local development and pull requests, smarter code review, and more radical features coming.\n\nAI coding meets collaborative code review.\n\n**6. Amazon Reportedly in Talks to Invest $10B+ in OpenAI**\n\nPer Financial Times report. Would be major investment from tech giant into leading AI company.\n\nRumored mega-deal could reshape AI landscape.\n\n**7. Lovable Raises $330M Series B**\n\nAI coding platform now used by world's largest enterprises. Apps built with Lovable received 500M+ visits in last 6 months. Team of 120 people. Trusted by millions to build apps with their own data.\n\nMajor funding for no-code AI development platform.\n\n**8. Gemini Now Available in Google Drive Mobile**\n\nAsk questions about files, summarize entire folders, and get quick facts from your phone. Available on iOS and Android apps.\n\nAI file management comes to mobile devices.\n\n**9. OpenAI Launches ChatGPT Images with New Generation Model**\n\nStronger instruction following, precise editing, detail preservation, 4x faster than before. Available now in ChatGPT for all users and in API as GPT Image 1.5.\n\nMajor image generation upgrade across all tiers.\n\n**10. Gemini Adds Drawing and Annotation for Image Edits**\n\nTell Gemini exactly where and how to apply edits by drawing on or annotating images directly in app. Makes it easier to get precise final results with Nano Banana.\n\nVisual prompting for image generation now available.\n\n**That's a wrap on this week's Agentic news.**\n\nWhich update impacts you the most?\n\nLMK if this was helpful | More weekly AI + Agentic content releasing ever week!",
        "url": "https://www.reddit.com/r/artificial/comments/1ptvuif/its_been_a_big_week_for_ai_here_are_10_massive/",
        "publishDate": "2025-12-23T14:52:30Z[Etc/UTC]",
        "author": "SolanaDeFi",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptsyej",
        "title": "Google‚Äôs and OpenAI‚Äôs Chatbots Can Strip Women in Photos Down to Bikinis",
        "content": "[No content]",
        "url": "https://www.wired.com/story/google-and-openais-chatbots-can-strip-women-in-photos-down-to-bikinis/",
        "publishDate": "2025-12-23T12:40:20Z[Etc/UTC]",
        "author": "wiredmagazine",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "G1hEVqwSkGM",
        "title": "GLM-4.7 (Fully Tested): RIP Opus 4.5! The BEST Open Model is HERE!",
        "content": "In this video, I'll be telling you about GLM-4.7, the latest and most powerful open-source AI coding model that outperforms many ...",
        "url": "https://www.youtube.com/watch?v=G1hEVqwSkGM",
        "publishDate": "2025-12-23T08:37:00Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/G1hEVqwSkGM/hqdefault.jpg",
            "transcription": "Hi. Welcome to another video. I have been using GLM-4.7 for a bit now. I was given early access to the models by the team there, and to sum up my thoughts, it is the best open model yet, by a long shot. As you would remember, I have covered GLM-4.5, GLM-4.6, and even GLM code models that came before all this. These models have been really amazing for a variety of reasons. They have been open weights for a while now, and all their models are generally open weights. Cursors Composer 1 model is even said to be a fine tune of the GLM-4.5 variant. So, yeah, their models have been really great. GLM-4.6 dropped exactly on the same day as Claude 4.5 Sonnet, and it challenged that model. However, now we have a new improved version of that model, which is now called GLM-4.7. Now, what is GLM-4.7? Well, GLM-4.7 is a model that is a pretty good improvement over the last generation. In benchmarks alone, it scores about a 6% improvement in SWE-bench. Multilingual SWE-bench is up by 13%, and Terminal Bench 2.0 has a score of 16.5%. They also say that it has significant improvements on complex tasks in mainstream agent frameworks such as Claude Code, Kilo Code, Cline, and Roo Code. It also takes a major step forward in UI quality. It produces cleaner, more modern webpages and generates better-looking slides with more accurate layout and sizing. GLM-4.7 achieves significantly improvements in Tool using. Significant better performances can be seen on benchmarks such as T^2-Bench and on web browsing via BrowseComp. It also delivers a substantial boost in mathematical and reasoning capabilities, achieving 42.8% on the HLE benchmark compared to GLM-4.6. Based on the scores and previous track record of GLM models, I can say that these are at least not benchmaxed models like Gemini or GPT-5.2, which is great to see. They have significantly improved the visual quality of the designs made by GLM. To be honest, the only model before Gemini that was good at visual designs was GLM, and it feels good that they have doubled down on this thing. It is great in a ton of places, but that's enough cherry-picked results. Let's look at my benchmarks. If you guys have seen my Minimax model video, then you'd know what position it scores. But let's go through the results first and then look at the scoring. First up, we got the floor plan, and well, the functionality works, but the plan of the design is all over the place. Though, I like that you can hover over the rooms and see their names and stuff. Then we've got the SVG panda holding a burger, and it is quite good as well. The hands are pretty good, the body is also good, and it is also animated. It floats and blinks its eyes, which is really very cool. Then there's the Pokeball in Three.JS, and it is really good at this as well. You can see the dimensions of the ball are quite good, and it reflects light and everything, which is really great. After this, we've got the chess board with autoplay, and it is really the best generation in a while. Like, the colors of the board are really slick. The pieces are not emojis like most other models do. The horse's head is not there, but that's fine. And the autoplay also makes some good moves. So, this is kind of cool. After this, we've got the Minecraft game, and it nails this one as well. You can see the mist, you can see the grass, you can move and everything, which is great. Really very cool. Then there's the majestic butterfly flying in the garden, and it is also really good. The butterfly looks exactly like a butterfly. It flies correctly, the wings flap correctly, and it's a great generation overall, for sure. Then, we've got the Rust CLI tool, and it is also quite good. And so is the Blender script for the Pokeball. But they both are not very great. The triplets and convex pentagon remain majorly unsolved, while the riddle gets solved. This makes it score the third position on the leader board, which is above Sonnet 4.5 and GPT-5.2. It is slightly below Opus, and obviously a lot below Gemini 3 Pro. Gemini 3 Pro just does well on one-shot questions, but agentic questions are where it falls apart. So, let's check out the agentic benchmarks for this model as well. Let's start with the Go TUI calculator, where I ask it to use Lipgloss and Bubbletea to build a calculator using Go that is visual. So, it did that, and it is really good. I used Kilo Code for this. You can go ahead and select the model there and use it all you want. You can use ZAI's GLM coding, which is actually insanely cheap and starts from just $3, I believe, and quarterly, and everything are multiples of the same prices. So, you can check that out. It is really very good. Anyway, the Go TUI calculator is actually quite good. It works insanely well. The colors are quite slick, and you can do a lot of cool stuff with it. Then we've got the movie tracker app in Expo with the TMDB API, and it does quite well on it for a one-shot generation. The movies show up nicely in a carousel. You can hit the movie, and it opens up a nice inner page for you to see the movie details. It also looks insanely nice to work with. You can also get the Git tracker-like interface for tracking movie watching, which is also good to see. After this, we've got the Svelte Kanban app. Now, this is where it falls apart a bit. It isn't very great in Svelte. It makes rookie mistakes. The syntax can be wrong at times. Although it was able to make the login pages, which work well. The inner pages also work. The backend, however, doesn't function correctly. But, the design and everything is way better than other models. So, this is somewhere in the middle. The Nuxt app is also the same story, and so is the Tauri app. In Godot, it has gotten really good and can write the life bar and jump mechanics in the game quite well. The open code question is also a pass with this model. It finally passes this question as well. This makes it score the fifth position on the leaderboard, which is great. This is a really good model. It is really cheap, way better than Gemini Flash, and works really very well, for sure. So, yeah, this is the best open model for now, especially in coding. I think that this is currently the best model if you want to do AI coding. It is fast. The API is cheap. The coding plan is even cheaper, and the weights are also open. Meaning that even if you use it via third-party inference providers, then it can be really cool. There are things like Synthetic, which have been working well with GLM-4.7 for me. So, you can check them out as well. Verdant will also soon integrate it, I believe, which is what I have been using. It seems like a really good improvement. Instead of using Sonnet, this seems like a relatively better option, and combining this with Opus can fetch you some insane results, which I'll also talk about in the next videos. It still isn't as great as Opus, but it is far better than Gemini if you care about that. Gemini Flash's price against these models seems like a rip-off, for sure. It can also go on for long periods of time now on one task, which was very buggy before. But that seems completely fixed now. And that's why it does so good on the benchmarks. That is majorly about it. Also, I wanted to mention some things about the coding plan. So, many people asked me if it reasons or not in the coding plan. Well, it reasons, but the thinking traces are not available in the coding plan API, from what I could gather. So, it's just that. The model remains the same, even in the coding plan. It can be slow, however, sometimes in the $6 plan, but considering the price, I'll say that it's worth it. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "KQpZTYRWqYA",
        "title": "Gemini 3 Flash, GPT-Image-1.5, Skills vs MCPs, and Our 2025 Model Reviews - EP99.29",
        "content": "Join Simtheory: https://simtheory.ai It's the long-anticipated holiday special... except Mike and Kris forgot to prepare so it's just a ...",
        "url": "https://www.youtube.com/watch?v=KQpZTYRWqYA",
        "publishDate": "2025-12-23T02:32:13Z",
        "author": "This Day in AI Podcast",
        "sourceType": "youtube",
        "sourceName": "This day in AI YouTube Channel",
        "metadata": {
            "channelId": "UCwpNW6o_Kc13HQY5ol4rzsw",
            "thumbnailUrl": "https://i.ytimg.com/vi/KQpZTYRWqYA/hqdefault.jpg",
            "transcription": "Error generating summary: The input token count exceeds the maximum number of tokens allowed 1048576.\ndev.shreyaspatil.ai.client.generativeai.type.ServerException: The input token count exceeds the maximum number of tokens allowed 1048576.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:40)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "FMMpUO1uAYk",
        "title": "What the Freakiness of 2025 in AI Tells Us About 2026",
        "content": "It's probably not possible to satisfactorily condense a 12 month's worth of weird progress in AI, as well as predictions for the year to ...",
        "url": "https://www.youtube.com/watch?v=FMMpUO1uAYk",
        "publishDate": "2025-12-23T17:40:58Z",
        "author": "AI Explained",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCNJ1Ymd5yFuUPtn21xtRbbw",
            "thumbnailUrl": "https://i.ytimg.com/vi/FMMpUO1uAYk/hqdefault.jpg",
            "transcription": "Error generating summary: Something unexpected happened.\ndev.shreyaspatil.ai.client.generativeai.type.UnknownException: Something unexpected happened.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:54)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "_zgnSbu5GqE",
        "title": "What are we scaling?",
        "content": "Read the transcript here: https://www.dwarkesh.com/p/thoughts-on-ai-progress-dec-2025 TIMESTAMPS 00:00:13 What are we ...",
        "url": "https://www.youtube.com/watch?v=_zgnSbu5GqE",
        "publishDate": "2025-12-23T20:28:52Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/_zgnSbu5GqE/hqdefault.jpg",
            "transcription": "I'm confused why some people have super short timelines, yet at the same time are bullish on scaling up reinforcement learning atop LLMs. If we're actually close to a human-like learner, then this whole approach of training on verifiable outcomes is doomed.\n[ 0m13s545ms - 0m13s925ms ] 01.\n[ 0m14s195ms - 0m14s615ms ] What are we\nNow, currently the labs are trying to bake in a bunch of skills into these models through mid-training. There's an entire supply chain of companies that are building RL environments, which teach the model how to navigate a web browser or use Excel to build financial models. Now, either these models will soon learn on the job in a self-directed way, which will make all this pre-baking pointless, or they won't, which means that AGI is not imminent. Humans don't have to go through the special training phase where they need to rehearse every single piece of software that they might ever need to use on the job.\n[ 0m46s435ms - 0m47s565ms ] Most Algorithmic Progress is Data Progress\n[ 0m47s565ms - 0m47s995ms ] Posted on August 2, 2023\n[ 0m48s175ms - 0m48s775ms ] Epistemic Status: Fairly sure about this from experience but could be missing crucial considerations. I don't present any super detailed evidence here so it is theoretically just vibes.\n[ 0m49s205ms - 0m50s65ms ] When forecasting AI progress, the forecasters and modelers often break AI progress down into two components: increased compute, and algorithmic progress. My argument here is that the term 'algorithmic progress' for the remainder after compute is misleading and that we should really think about and model AI progress as three terms - compute, algorithms, and data. My claim is that a large fraction (but certainly not all) AI progress that is currently conceived as 'algorithmic progress' is actually 'data progress', and that this term 'algorithmic' gives a false impression about what are the key forces and key improvements that have driven AI progress in the past three years or so.\n[ 0m50s65ms - 0m50s565ms ] From experience in the field, there have not been that many truly 'algorithmic' improvements with massive impact. The primary one of course is the switch to RLVR and figuring out how to do mid-training (although both of these are totally dependent upon the datasets). Other minor ones include things like qk-norm, finegrained experts and improvement to expert balancing, and perhaps the moon optimizer. The impact of most of these is utterly dwarfed by 'better' data, however, and this is something that pure scaling and flop-based analyses miss.\n[ 0m51s75ms - 0m51s535ms ] Models today are certainly trained using vastly more flops than previously, but they are also trained on significantly 'higher quality' data where 'high quality' means aligned with the specific tasks we care about the models being able to perform (cynically: the early\n[ 0m51s535ms - 1m6s525ms ] exam questions, even if they have never seen the exact exam questions themselves before). Conversely, the jungle kid probably destroys the tiger-parented kid at various miscellaneous jungle related skills but nobody measures or cares about these because they are irrelevant for the vast, vast majority of tasks people want the jungle kid to do. Translating this metaphor back to LLM-land, Qwen3 has seen vast amounts of synthetic math and code and knowledge-based multiple choice questions all designed to make it as good as possible on benchmarks, Llama2 has seen mostly random web pages which incidentally occasionally contain some math and code but with very little quality filter. Llama2 probably destroys Qwen3 at knowing about obscure internet forum posts from 2008, precisely understanding the distribution of internet spam at different points throughout history, and knows all the ways in which poor common-crawl parsing can create broken seeming documents, but nobody (quite rightly) thinks that these skills are important, worth measuring, or relevant for AGI.\n[ 1m6s525ms - 1m6s915ms ] One way to track this is the sheer amount of spend on data labelling companies from big labs. ScaleAI and SurgeAI's revenue each sit around $1B and most of this, as far as I can tell, is from data labelling for big AI labs. This spend is significantly less than compute spend, it is true, but it nevertheless must contribute a significant fraction to a lab's total spending. I don't have enough data to claim this but it seems at least plausible that the spend is increasing at a similar rate as compute spend (e.g. 3-4x per year), albeit from a much lower base.\n[ 1m6s915ms - 1m6s955ms ] When we see frontier models improving at various benchmarks we should think not just of increased scale and clever ML research ideas but billions of dollars spent paying PhDs, MDs, and other experts to write questions and provide example answers and reasoning targeting these precise capabilities. With the advent of outcome based RL and the move towards more 'agentic' use-cases, this data also includes custom RL environments which are often pixel-perfect replications of commonly used environments such as specific websites like Airbnb or Amazon, browsers, terminals and computer file-systems, and so on alongside large amounts of human trajectories exhaustively covering most common use-cases with these systems.\n[ 1m6s955ms - 1m6s995ms ] In a way, this is like a large-scale reprise of the expert systems era, where instead of paying experts to directly program their thinking as code, they provide numerous examples of their reasoning and process formalized and tracked, and then we distill this into models through behavioural cloning. This has updated me slightly towards longer AI timelines since given we need such effort to design extremely high quality human trajectories and environments for frontier systems implies that they still lack the critical\n[ 1m6s995ms - 1m7s125ms ] Baron Millage made an interesting point about this in a recent blog post he wrote. He writes, quote, When we see frontier models improving at various benchmarks, we should think not just about the increased scale and the clever ML research ideas, but billions of dollars that are paid to PhDs, MDs, and other experts to write questions and provide example answers and reasoning targeting these precise capabilities.\n[ 1m7s125ms - 1m8s125ms ] You can see this tension most vividly in robotics.\n[ 1m8s125ms - 1m14s335ms ] In some fundamental sense, robotics is an algorithms problem, not a hardware or a data problem. With very little training, a human can learn how to tele-operate in current hardware to do useful work. So, if you actually had a human-like learner, robotics would be in large part a soft problem.\n[ 1m14s335ms - 1m33s405ms ] But the fact that we don't have such a learner makes it necessary to go out into a thousand different homes and practice a million times on how to pick up dishes or fold laundry.\n[ 1m33s405ms - 1m50s695ms ] Now, one counter argument I've heard from the people who think we're going to have a takeoff within the next five years, is that we have to do all this cludgy RL in service of building a superhuman AI researcher. And then the million copies of this automated Ilya can go figure out how to solve robust and efficient learning from experience.\n[ 1m50s695ms - 2m9s445ms ] This just gives me the vibes of that old joke, we're losing money on every sale, but we'll make it up in volume. Somehow this automated researcher is going to figure out the algorithm for AGI, which is a problem that humans have been banging their head against for the better half of a century, while not having the basic learning capabilities that children have. I find this super implausible.\n[ 2m9s445ms - 2m36s585ms ] Besides, even if that's what you believe, it doesn't describe how the labs are approaching reinforcement learning from verifiable reward. You don't need to pre-bake in a consultant skill at crafting PowerPoint slides in order to automate Ilya. So clearly, the labs actions hint at a worldview, where these models will continue to fare poorly at generalization and on the job learning. This making it necessary to build in the skills that we hope will be economically useful beforehand into these models.\n[ 2m36s585ms - 3m11s685ms ] Another counter argument you can make is that even if the model could learn these skills on the job, it is just so much more efficient to build in these skills once during training, rather than again and again for each user and each company. And look, it makes a ton of sense to just bake in fluency with common tools like browsers and terminals. And indeed, one of the key advantages that AGIs will have is this greater capacity to share knowledge across copies. But people are really under-rating how much company and context specific skills are required to do most jobs. And there just isn't currently a robust efficient way for AIs to pick up these skills.\n[ 3m12s244ms - 3m12s864ms ] 02. Human labor is valua\n[ 3m13s194ms - 3m15s84ms ] Human labor is valuable precisely because it's not shleppy to train.\n[ 3m15s84ms - 3m46s224ms ] I was recently at a dinner with an AI researcher and a biologist, and it turned out the biologist had long timelines. And so we were asking about why she had these long timelines. And then she said, you know, one part of her work recently in the lab has involved looking at slides and deciding if the dot in that slide is actually a macrophage or just looks like a macrophage. And then the AI researcher, as you might anticipate, responded, look, image classification is a textbook deep learning problem. This is death center in the kind of thing that we could train these models to do.\n[ 3m46s224ms - 4m46s984ms ] And I thought this is a very interesting exchange, because it illustrated a key crux between me and the people who expect transformative economic impact within the next few years. Human workers are valuable precisely because we don't need to build in these schleppy training loops for every single small part of their job. It's not net productive to build a custom training pipeline to identify what macrophages look like given the specific way that this lab prepares slides. And then another training loop for the next lab specific microtask and so on. What you actually need is an AI that can learn from semantic feedback or from self-directed experience, and then generalize the way a human does. Every day you have to do a hundred things that require judgment, situational awareness, and skills and context that are learned on the job. These tasks differ not just across different people, but even from one day to the next for the same person. It is not possible to automate even a single job by just baking in a predefined set of skills, let alone all the jobs.\n[ 4m46s984ms - 5m5s874ms ] In fact, I think people are really underestimating how big a deal actual AGI will be, because they're just imagining more of this current regime. They're not thinking about billions of human-like intelligences on a server, which can copy and merge all of the learning. And to be clear, I expect this, which is to say I expect actual brain-like intelligences within the next decade or two, which is pretty fucking crazy.\n[ 5m6s523ms - 5m7s163ms ] 03. Economic diffusion lag is\n[ 5m7s513ms - 5m9s343ms ] cope for missing capabilities.\n[ 5m9s343ms - 5m28s443ms ] Sometimes people will say that the reason that AIs aren't more widely deployed right now across firms and are already providing lots of value, outside of coding, is that technology takes a long time to diffuse. And I think this is cope. I think people are using this cope to gloss over the fact that these models just lack the capabilities that are necessary for broad economic value.\n[ 5m28s443ms - 6m5s903ms ] If these models actually were like humans on a server, they'd diffuse incredibly quickly. In fact, they'd be so much easier to integrate and onboard than a normal human employee is. They could read your entire Slack and Drive within minutes and they could immediately distill all the skills that your other AI employees have. Plus, the hiring market for humans is very much like a lemons market where it's hard to tell who the good people are beforehand. And then obviously, hiring somebody who turns out to be bad is very costly. This is just not a dynamic that you would have to face or worry about if you're just spinning up another instance of a vetted AGI model.\n[ 6m5s903ms - 6m37s233ms ] So, for these reasons, I expect it's going to be much easier to diffuse AI labor into firms than it is to hire a person. And companies hire people all the time. If the capabilities were actually at AGI level, people would be willing to spend trillions of dollars a year buying tokens that these models produce. Knowledge workers across the world cumulatively earn tens of trillions of dollars a year in wages. And the reason that labs are orders of magnitude off the sticker right now is that the models are nowhere near as capable as human knowledge workers.\n[ 6m37s871ms - 6m38s361ms ] 04. Goal post shiftin\n[ 6m38s701ms - 6m39s751ms ] Goal post shifting is justified.\n[ 6m39s751ms - 7m5s141ms ] Now, you might be like, look, how can this standard have suddenly become labs that earn tens of trillions of dollars revenue a year, right? Like, until recently people were saying, can these models reason? Do these models have common sense? Are they just doing pattern recognition? And obviously, AI bulls are right to criticize AI bears for repeatedly moving these goal posts. And this is very often fair. It's easy to underestimate the progress that AIs made over the last decade.\n[ 7m5s141ms - 7m27s371ms ] But some amount of goalpost shifting is actually justified. If you showed me Gemini 3 in 2020, I would have been certain that it could automate half of knowledge work. And so we keep solving what we thought were the sufficient bottlenecks to AGI. We have models that have general understanding, they have few-shot learning, they have reasoning. And yet, we still don't have AGI. So, what is a rational response to observing this?\n[ 7m27s371ms - 8m24s891ms ] I think it's totally reasonable to look at this and say, oh, actually, there's much more to intelligence and labor than I previously realized. And while we're really close and in many ways have surpassed what I would have previously defined as AGI in the past. The fact that model companies are not making the trillions of dollars in revenue that would be implied by AGI, clearly reveals that my previous definition of AGI was too narrow. And I expect this to keep happening into the future. I expect that by 2030, the labs will have made significant progress on my hobbyhorse of continual learning, and the models will be earning hundreds of billions of dollars in revenue a year. But they won't have automated all knowledge work. And I'll be like, look, we made a lot of progress, but we haven't hit AGI yet. We also need these other capabilities. We need X, Y, and Z capabilities in these models. Models keep getting more impressive at the rate that the short timelines people predict, but more useful at the rate that the long timelines people predict.\n[ 8m24s891ms - 8m25s741ms ] 05. RL scaling is laundering the\n[ 8m26s161ms - 8m27s151ms ] prestige of pretraining scaling.\n[ 8m27s151ms - 8m30s341ms ] It's worth asking what are we scaling?\n[ 8m30s341ms - 8m55s21ms ] With pretraining, we had this extremely clean and general trend in improvement in loss across multiples orders of magnitude in compute. Albeit this was on a power law, which is as weak as exponential growth is strong. But people are trying to launder the prestige that pretraining scaling has, which is almost as predictable as a physical law of the universe, to justify bullish predictions about reinforcement learning from verifiable reward, for which we have no well-fit publicly known trend.\n[ 8m55s21ms - 9m16s861ms ] And when intrepid researchers do try to piece together the implications from scarce public data points, they get pretty bearish results. For example, Toby Board has a great post where he cleverly connects the dots between the different O series benchmarks. And this suggested that to him that\n[ 9m16s861ms - 9m17s331ms ] of o1 AIME accuracy during training\n[ 9m17s331ms - 9m17s921ms ] o1 AIME accuracy at test time\n[ 9m17s921ms - 9m18s641ms ] of performance smoothly improves with both train-time and test-time compute\n[ 9m18s641ms - 9m19s321ms ] o1 performance smoothly improves with both train-time and test-time compute\n[ 9m19s321ms - 9m20s371ms ] HOW DO THESE COMPARE TO PRE-TRAINING SCALING?\n[ 9m20s371ms - 9m22s991ms ] The jumps from GPT-1 to 2 to 3 to 4 each involved scaling up the pre-train compute by about 100x. How much of the RL-scaling or inference-scaling would be required to give a similar boost? While I can't say for sure, we can put together the clues we have and take an educated guess.\n[ 9m22s991ms - 9m23s431ms ] Jones (2021) and EpochAI both estimate that you need to scale-up inference by roughly 1,000x to reach the same capability you'd get from a 100x scale-up of training. And since the evidence from o1 and o3 suggests we need about twice as many orders of magnitude of RL-scaling compared with inference-scaling, this implies we need something like a 1,000,000x scale-up of total RL compute to give a boost similar to a GPT level.\n[ 9m23s431ms - 9m23s621ms ] This is breathtakingly inefficient scaling. But it fits with the extreme information inefficiency of RL training, which (compared to next-token-prediction) receives less than a ten-thousandth as much information to learn from per FLOP of training compute.\n[ 9m23s621ms - 9m24s81ms ] Yet despite the poor scaling behaviour, RL training has so far been a good deal. This is solely because the scaling of RL compute began from such a small base compared with the massive amount of pre-training compute invested in today's models. While AI labs are reticent to share information about how much compute has actually been spent on RL (witness the removal of all numbers from the twin o1 scaling graphs), it is widely believed that even the 10,000x scale-up of o3's training still ended up on\n[ 9m24s81ms - 9m24s371ms ] quote, We need something like a million X scale-up in total RL compute to give a boost similar to a GPT level. End quote.\n[ 9m24s81ms - 9m24s871ms ] 06. Broadly deploy\n[ 9m25s211ms - 9m26s161ms ] Broadly deployed intelligence explosion.\n[ 9m27s361ms - 9m37s181ms ] So, people have spent a lot of time talking about the possibility of a software-only singularity, where AI models will write the code that generates a smarter successor system.\n[ 9m37s181ms - 10m2s41ms ] Or a software plus hardware singularity, where AIs also improve their successors computing hardware. However, all these scenarios neglect what I think will be the main driver of further improvements atop AGI, continual learning. Again, think about how humans become more capable in anything. It's mostly from experience in the relevant domain.\n[ 10m2s41ms - 10m22s851ms ] Over conversation, Baron Millage made this interesting suggestion that the future might look like continual learning agents, who are all going out and they're doing different jobs and they're generating value, and then they're bringing back all their learnings to the hivemind model, which does some kind of batch distillation on all of these agents. The agents themselves could be quite specialized, containing what Karpathy called the cognitive core plus knowledge and skills relevant to the job they're being deployed to do.\n[ 10m22s851ms - 10m39s261ms ] Solving continual learning won't be a singular one-and-done achievement. Instead, it will feel like solving in-context learning. Now, GPT-3 already demonstrated in-context learning could be very powerful in 2020. Its in-context learning capabilities were so remarkable that the title of the GPT-3 paper was Language Models are Few-Shot Learners.\n[ 10m39s261ms - 11m16s301ms ] But of course, we didn't solve in-context learning when GPT-3 came out. And indeed, there's still plenty of progress that still has to be made from comprehension to context length. I expect a similar progression with continual learning. Labs will probably release something next year which they call continual learning, and which will in fact count as progress towards continual learning. But human level on the job learning may take another 5 to 10 years to iron out. This is why I don't expect some kind of runaway gains from the first model that cracks continual learning, that's getting more and more widely deployed and capable.\n[ 11m16s301ms - 11m25s341ms ] If you had fully solved continual learning drop out of nowhere, then sure, it might be game set match as Satya put it on the podcast when I asked him about this possibility. But that's probably not what's going to happen. Instead, some lab is going to figure out how to get some initial traction on this problem, and then playing around with this feature will make it clear how it's implemented, and then other labs will soon replicate the breakthrough and improve it slightly.\n[ 11m25s341ms - 12m14s611ms ] Besides, I just have some prior that the competition will stay pretty fierce between all these model companies. And this is informed by the observation that all these previous supposed flywheels, whether that's user engagement on chat, or synthetic data, or whatever, have done very little to diminish the greater and greater competition between model companies. Every month or so, the big three model companies will rotate around the podium, and the other competitors are not that far behind. There seems to be some force, and this is potentially talent poaching, it's potentially the rumor mill in SF, or just normal reverse engineering, which is so far neutralized any runaway advantage that a single lab might have had.\n[ 12m14s611ms - 12m19s951ms ] This was a narration of an essay that I originally released on my blog at dwarkesh.com.\n[ 12m19s951ms - 12m20s521ms ] Thoughts on AI progress (Dec 2025)\n[ 12m20s521ms - 12m21s31ms ] Why I'm moderately bearish in the short term, and explosively bullish in the long term\n[ 12m21s31ms - 12m21s351ms ] BLOG\n[ 12m21s351ms - 12m21s631ms ] DWARKESH PATEL\n[ 12m21s631ms - 12m21s911ms ] DEC 20, 2023\n[ 12m21s911ms - 12m22s71ms ] 877\n[ 12m22s71ms - 12m22s321ms ] 40\n[ 12m22s321ms - 12m22s541ms ] 47\n[ 12m22s541ms - 12m22s901ms ] Shares\n[ 12m22s901ms - 12m23s291ms ] What are we scaling?\n[ 12m23s291ms - 12m23s981ms ] I'm publishing a lot more essays.\n[ 12m23s981ms - 12m27s361ms ] I found it's actually quite helpful in ironing out my thoughts before interviews. If you want to stay up-to-date with those, you can subscribe at dwarkesh.com.\n[ 12m27s361ms - 12m31s431ms ] Otherwise, I'll see you for the next podcast. Cheers."
        }
    },
    {
        "id": "B9O50J9cJg0",
        "title": "Why the Soviet Union Became One Big Rust Belt - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=B9O50J9cJg0",
        "publishDate": "2025-12-23T18:26:54Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/B9O50J9cJg0/hqdefault.jpg",
            "transcription": "SO THE COMMUNISTS HAVE insisted on heavy industry. That's the thing that they want. Forget about the consumer goods. If you look at the countries that really have made it, like Japan, in the Meiji Restoration, they're doing a lot of light industry and consumer goods. And then they move into heavy, but they've already got people on bicycles, and they've got textiles and other things up and running. And that would also apply to Taiwan and Korea. And they do -- by all means, they do get heavy industry. But that's not the starter program. The starter program is basic standard of living. And it turns out, and I'm no economist, but it turns out if you just look at who's rich and who's not, that that seems to be the more workable thing. There's also the fact that in the 70s and 80s, we have our Rust Belt collapse of manufacturing. And people complain about this as, look, the US has this hollowed out manufacturing base, but it's much better to have industries which are left behind so that the whole economy as a whole can be more dynamic and move on, than the Soviet Union where the entire thing became a Rust Belt. Right? Because they couldn't move on."
        }
    }
]