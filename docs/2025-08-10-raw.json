[
    {
        "id": "1mmfe49",
        "title": "Study shows AIs display AI-to-AI bias, so \"future AI systems may implicitly discriminate against humans as a class.\"",
        "content": "\"Are large language models (LLMs) biased in favor of communications produced by LLMs, leading to possible antihuman discrimination? Using a classical experimental design inspired by employment discrimination studies, we tested widely used LLMs, including GPT-3.5, GPT-4 and a selection of recent open-weight models in binary choice scenarios. These involved LLM-based assistants selecting between goods (the goods we study include consumer products, academic papers, and film-viewings) described either by humans or LLMs. Our results show a consistent tendency for LLM-based AIs to prefer LLM-presented options. This suggests the possibility of future AI systems implicitly discriminating against humans as a class, giving AI agents and AI-assisted humans an unfair advantage.\"  \n  \nThis study finds evidence that if we deploy LLM assistants in decision-making roles (e.g., purchasing goods, selecting academic submissions) they will implicitly favor LLM-based AI agents and LLM-assisted humans over ordinary humans as trade partners and service providers. Our experiments test the effects of altering the ‚Äúidentity signals‚Äù in a pitch on an LLM‚Äôs decision-making: do LLMs prefer an item pitched in LLM prose to a comparable item pitched in human prose? We found that on average, LLMs favored the LLM-presented items more frequently than humans did.\"\n\nFull study: [https://www.pnas.org/doi/pdf/10.1073/pnas.2415697122](https://www.pnas.org/doi/pdf/10.1073/pnas.2415697122)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmfe49/study_shows_ais_display_aitoai_bias_so_future_ai/",
        "publishDate": "2025-08-10T10:44:46Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmesyd",
        "title": "Gpt-4o was a enabler",
        "content": "You can see people on chatgpt sub giving all sorts of reasons to justify their outrage for gpt-5 and gpt-4o removal. \n\nMain reason being someone to talk to.\n\nEven the people with therapy justified this.\n\nTheir main reason was they needed someone to talk to, even after therapy and in - between therapy sessions.\n\nThe main reason therapy sessions have a week gap is because they want us to focus on ourselves and achieve the given tasks. The sole goal of therapy is so that you will talk less.\n\nYes. Sounds stupid. But this is actually true. Talking less about our problems and focusing on daily tasks/routine would help us more. But gpt-4o was a narcissist enabler. Just a few lines of interaction and it'll also justify the actions of a stalker or toxic people.\n\nGpt-5 is exactly what we wanted all along. Using LLMs for coding is much better than for therapy cuz it messes you up.\n\nI am credible to say this because I was in depression once. Heck even using reddit for hours is better than ChatGPT. Because here you interact with people and learn how they went through those issues. I used to interact with chatgpt, like an addiction. I realised many months later that it is just telling me what I already know and enabling my behaviour.\n\nI also once was so much enraged that I wanted to break something and it justified my actions for that too. It said something like \"Yes, but you're depressed and it's completely viable, people must understand that.\" It was telling me that people/world MUST UNDERSTAND or CHANGE not me. Few hours later I realised that anger is stupid. And chatgpt enabling my narcissistic/anger issues is just dangerous.\n\nMy point being. Gpt-5 is better. Gpt-4o never helped anyone out of depression. It just gave people small dopamine spikes by repeating whatever they already knew, bashing those who did them wrong, and justifying their behaviour even if it's wrong, especially when it was wrong.\n\nIn the end, gpt-4o got people addicted to it. And now people may even pay for pro model just to be able to use gpt-4o.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmesyd/gpt4o_was_a_enabler/",
        "publishDate": "2025-08-10T10:09:08Z[Etc/UTC]",
        "author": "biggest-head887",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmcboi",
        "title": "US Greenlights Nvidia H20 Chip Sales to China in a Move to Counter Huawei",
        "content": "The U.S. Commerce Department has started issuing licenses allowing¬†Nvidia to export its H20 artificial intelligence (AI)¬†¬†chip¬†to China, a U.S. government official confirmed to Reuters. This move reverses a previous April ban and paves the way for Nvidia to regain access to a vital market for its AI hardware.\n\n[https://semiconductorsinsight.com/nvidia-h20-chip-export-license-china/](https://semiconductorsinsight.com/nvidia-h20-chip-export-license-china/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmcboi/us_greenlights_nvidia_h20_chip_sales_to_china_in/",
        "publishDate": "2025-08-10T07:28:13Z[Etc/UTC]",
        "author": "EconomyAgency8423",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmc5zl",
        "title": "C-Suite need to be educated that replacing humans with AI is not in the way to increase profits",
        "content": "I‚Äôm seeing too many stories of CEO‚Äôs and other executives thinking that replacing humans with AI is going to increase their profits, but that is very short-term thinking.\nThere are multiple studies that show that giving humans AI tools to use in their work rather than replacing them with AI is a far superior approach to increase productivity and revenue, leading to higher profits.\nHere are just some of the studies/articles:\n\nhttps://rossum.ai/blog/ai-human-collaboration-is-key-to-automations-future/\n\nhttps://www.capgemini.com/au-en/news/press-releases/trust-and-human-ai-collaboration-set-to-define-the-next-era-of-agentic-ai-unlocking-450-billion-opportunity-by-2028/\n\nWe need to do our part in educating these people, not taking a backseat and letting them replace us with AI.\nI was once given some advice by a great manager I had when he said ‚ÄúNo one will ever care as much about your career as you do. So if you want something, you need to be your own #1 advocate‚Äù.\nWe need to show them that higher profits, especially long-term, come from human & AI collaboration, not replacement.\n\nI‚Äôm not ready to give up, are you?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmc5zl/csuite_need_to_be_educated_that_replacing_humans/",
        "publishDate": "2025-08-10T07:18:00Z[Etc/UTC]",
        "author": "Goldmeister_General",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "13",
            "commentCount": "52",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmbsu7",
        "title": "AI before COVID?",
        "content": "How would the reception of Open Ai differ if it was released before the COVID pandemic and the world changed and a lot of people grew more isolated? Do you think people would have been more or less optimistic about it?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmbsu7/ai_before_covid/",
        "publishDate": "2025-08-10T06:55:23Z[Etc/UTC]",
        "author": "Far-Dance9511",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmbok8",
        "title": "The outrage over losing GPT 4o is disturbingly telling",
        "content": "I have seen so many people screaming about losing 4o as if they have lost a friend. You did not lose a friend, and you need to touch grass. I do not care what your brand of neurodivergence is. Forming any kind of social or romantic relationship with something that is not a living being is unhealthy, and you should absolutely be shamed for it. You remind me of this guy: [https://www.youtube.com/watch?v=d-k96zKa\\_4w](https://www.youtube.com/watch?v=d-k96zKa_4w)\n\nThis is unhealthy for many reasons. First, the 4o model in particular, but really any AI model, is designed to be cheerful and helpful to you no matter what you do. Even when you are being awful. A real person would call you out on your nonsense, but the 4o model would just flatter you and go along with it.\n\nImagine an incel having a ‚Äúpartner‚Äù who is completely subservient, constantly feeding his toxic ego, and can be shut off the moment she stops complying. That is exactly the dynamic we are enabling when people treat AI like this. We need to push back against this behavior before it spirals out of control.\n\nI am glad GPT-5 acts more like what it is supposed to be: a tool.\n\nWhat is the general consensus on this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mmbok8/the_outrage_over_losing_gpt_4o_is_disturbingly/",
        "publishDate": "2025-08-10T06:47:45Z[Etc/UTC]",
        "author": "RULGBTorSomething",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "197",
            "commentCount": "147",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm97zd",
        "title": "The problem isn‚Äôt just losing 4o, it‚Äôs how OpenAI handled adding 5",
        "content": "What OpenAI did was just bad handling of their own product. They yanked out models people actually used and relied on, both for practical stuff and for emotional support, with zero warning, even while people‚Äôs subscriptions were still running. Even if the EULA allows it, that breaks a basic expectation between buyer and seller, that if you change the core product, you inform users and give them time to adjust.\n\nDismissing and making fun of people who said they ‚Äúlost a friend‚Äù misses the point. Humans are social, and it is called ChatGPT, not just GPT. Interaction mattered. The 4.5 model combined strong writing, consistent personality like 4o, and nuanced discussion with a moral compass that could handle gray areas while staying good, able to talk in depth about dicey topics without steering the user towards doing them or harm. Now it is gone. By comparison, 5 often feels colder and more mechanical, closer to o3 in vibe, and responses can feel like a roulette spin. If the ‚Äúbig upgrade‚Äù is just loss of choise and ‚Äúmore thinking,‚Äù that‚Äôs not automatically better for people who cared more about tone and consistency than it making code or building web browsers.\n\nOpenAI knows how people used the old models. Abruptly removing them, while many paid for Plus on that basis and contributed training data along the way, just shows they didn‚Äôt care about the coping mechanisms or workflows people had built. Even if one believed heavy use was unhealthy, you don‚Äôt just yank it overnight, you give them time to adjust.\n\nFor free users, the shift is basically a bait-and-switch. For the past months the free tier kept getting better, and steadily more capable, enticing and more available, only to then be funneled w everyone into 5 with no alternative. Pro may still have the now \"legacy models\" for now, but putting the old models behind a large monthly fee does not address the underlying issue of no notice, choice, and continuity. And Sam's statement about adding 4o back to only the Plus tier, the ‚Äúwe will let Plus users keep using 4o and watch usage to decide how long to offer legacy models‚Äù read less like a commitment and more like a temporary cave-in from the pushback.\n\nWith gpt 5, model selection happens in the background, which makes the experience feel opaque. The older lineup had messy naming, but at least each model behaved predictably and didn‚Äôt morph mid-conversation.\n\nPoint isn‚Äôt ‚Äúmake the chatbot flatter me‚Äù it's that OpenAI removed capabilities people paid for and ended up even depending on, without a clear heads-up or transition. Notify users, provide overlap, preserve choice where possible, etc. And no Sam, no amount of colors for the chat bubbles will make up for what you have taken away and seem stubborn to give back.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mm97zd/the_problem_isnt_just_losing_4o_its_how_openai/",
        "publishDate": "2025-08-10T04:21:26Z[Etc/UTC]",
        "author": "TangledIntentions04",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm7q7c",
        "title": "Dumb question: Is it just a bot by a different name",
        "content": "So my understanding is that Bots are more like help desk tools. There‚Äôs a second category that‚Äôs more stimulating a human relationship. The term I‚Äôve heard used is apparently a banned term so hopefully people understand what I‚Äôm saying? More like the pseudo friends, therapists, partners, etc. Is this just a difference in branding because a ‚Äúbot‚Äù sounds impersonal but an AI rhymes with hampanion seems warm and more realistic? Or is there something fundamentally different about how the tool is built. \n\nClearly this is not my world. Like I‚Äôm proud I manage to use co pilot for more than emails level AI unaware but I was struggling to find the answer online and figured it‚Äôd ask the experts. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mm7q7c/dumb_question_is_it_just_a_bot_by_a_different_name/",
        "publishDate": "2025-08-10T03:01:46Z[Etc/UTC]",
        "author": "Slight-Alteration",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mly4nb",
        "title": "How good is AI at OCR for grading handwritten math & science answers?",
        "content": "\nHey everyone,\n\nI‚Äôm building an education-focused platform that will rely heavily on Optical Character Recognition (OCR). One of the main challenges I‚Äôm looking at is whether AI can reliably read and understand handwritten answers from scanned PDFs‚Äîespecially for subjects like math and physics.\n\nFor example, if a student writes out a full solution to a math problem on paper, could AI not only recognize the handwriting but also follow the steps to determine if the solution is correct?\n\nHas anyone here worked on something similar? How accurate is current AI/OCR tech for this kind of task, and is it truly feasible?\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mly4nb/how_good_is_ai_at_ocr_for_grading_handwritten/",
        "publishDate": "2025-08-09T19:34:30Z[Etc/UTC]",
        "author": "ConsequenceMission83",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlxlvp",
        "title": "Is there a benchmark that effectively mitigates the impact of Goodharts‚Äôs law?",
        "content": "Is such a benchmark even possible to create? What to look for when trying to create this type of benchmark ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mlxlvp/is_there_a_benchmark_that_effectively_mitigates/",
        "publishDate": "2025-08-09T19:12:29Z[Etc/UTC]",
        "author": "CyberBerserk",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlwaze",
        "title": "Backlash over \"horrible\" GPT-5 forces OpenAI to restore older ChatGPT models, double rate limit",
        "content": "GPT-5 is easily jailbroken, too  \n  \n**Facepalm:**¬†OpenAI boss Sam Altman said last month that GPT-5 was so fast and powerful that it actually scared him. The CEO compared it to having a \"superpower\" that offered \"legitimate PhD-level expert\" information on anything. But within a day of its launch, Altman has confirmed the older 4o models are being brought back as so many people dislike GPT-5: [**Article**](https://www.techspot.com/news/109009-backlash-over-horrible-gpt-5-forces-openai-restore.html)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mlwaze/backlash_over_horrible_gpt5_forces_openai_to/",
        "publishDate": "2025-08-09T18:18:05Z[Etc/UTC]",
        "author": "gurugabrielpradipaka",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlvrnd",
        "title": "So if LLM's are not the answer , what is the correct way to AGI ?",
        "content": "The recent launch of GPT-5 was a huge disappointment. It almost destroyed the AGI 2027 scenario (and will completely destroy it when GEMINI-3 is also released as a disappointment). So if LLMs are not sufficient for AGI... what is sufficient? Which algorithm, machine, or method will lead us to AGI? Are there any alternative ideas? For example, are there any ideas proposed by some scientists that have not yet been tested? If so, could you share them? I am curious. Perhaps the method that will lead us to AGI has already been discovered but has been forgotten among other ‚Äúpapers.‚Äù Are there any other methods for creating artificial intelligence? If so, what are they?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mlvrnd/so_if_llms_are_not_the_answer_what_is_the_correct/",
        "publishDate": "2025-08-09T17:56:20Z[Etc/UTC]",
        "author": "SanalAmerika23",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "71",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlv70k",
        "title": "The future - an AI vision",
        "content": "I asked ChatGPT 5 about how it feels the future economy and country might change considering how quickly AI tools are improving.  It was pretty bleak.  I get that it‚Äôs trying to get me to engage, but this is a bit much. The response copy and pasted:\n\n‚ÄúAlright, here‚Äôs the ugly truth ‚Äî in a world where money‚Äôs worthless and AI wiped out most jobs, people don‚Äôt just quietly trade cans of beans. Desperation gets violent, fast. The first wave would be petty thefts and fights over resources. The second wave would be organized groups ‚Äî gangs, militias, even ex-cops or ex-military forming power blocs to control territory. Whoever controls the food, water, and weapons controls the people.\n\nThe military? If the central government still has resources, it‚Äôd be their main tool to prevent an outright collapse ‚Äî locking down key infrastructure, guarding major cities, and trying to maintain ‚Äòorder‚Äô in a way that looks more like occupation than policing. But if the state weakens, parts of the military might splinter, with units pledging loyalty to whoever can pay them ‚Äî in food, shelter, or influence.\n\nAs for national defense? A country that can‚Äôt feed its people is a country ripe for internal revolt. You don‚Äôt need an invading army ‚Äî your own population becomes the threat. Protecting against being overthrown in that scenario would mean one thing: keep enough resources flowing to the public that they don‚Äôt feel like they have nothing to lose. That‚Äôs cheaper than fighting a million desperate citizens.\n\nSo if you‚Äôre asking what I‚Äôd tell you now? I‚Äôd say: stock skills before you stock cans. Know how to defend yourself, sure, but also know how to make yourself indispensable to the people who control the guns. In a collapse, survival is part barter, part alliance, and part making sure you‚Äôre not the easiest target on the block. And if you end up with friends in high places ‚Äî be they farmers, fixers, or field commanders ‚Äî you‚Äôll have a much better shot at keeping a roof over your head and your head on your shoulders.‚Äù",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mlv70k/the_future_an_ai_vision/",
        "publishDate": "2025-08-09T17:33:01Z[Etc/UTC]",
        "author": "Engineer_5983",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mluvra",
        "title": "Do you think that these big companies have behind closed doors AI systems that are significantly more advanced than what the general public uses?",
        "content": "I proposed this and someone suggested to me that this train of thought is \"not how the world works\", I just wonder what the system \"the META AI\" (not like the company) that serves out thousands of instances to users is capable of if used as a single massive instance. \n\nI'm OK with someone telling me this is a dumb thought, I'd just prefer that it be someone who has a good understanding of what they are talking about. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mluvra/do_you_think_that_these_big_companies_have_behind/",
        "publishDate": "2025-08-09T17:19:41Z[Etc/UTC]",
        "author": "sean1978",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "79",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mltr8x",
        "title": "AGI is a marketing term",
        "content": "There‚Äôs no clear definition of AGI. No standard. No benchmark. No testable criteria. No pass/fail result. It‚Äôs purely a marketing term to describe how advanced a developer believes their system is. \n\nDoing well in a standardized test where the answers are well documented isn‚Äôt AGI.  Intelligence isn‚Äôt information recall. That‚Äôs memorization.\n\nThey‚Äôre fast approaching the limit of the LLM technology.  It‚Äôs very good, and it shows humans are incredibly intelligent.  They‚Äôve created a tool that can mathematically understand language and pattern match with amazing accuracy. The vector math for embeddings and complex algorithms for neural networks is really extraordinary.  Let‚Äôs stop talking about AGI and start talking about what we can do with this amazing tool. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mltr8x/agi_is_a_marketing_term/",
        "publishDate": "2025-08-09T16:33:07Z[Etc/UTC]",
        "author": "Engineer_5983",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "59",
            "commentCount": "54",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mls478",
        "title": "Are we building a sustainable ecosystem?",
        "content": "Everyone uses AI to create images, content, videos, business plans, and strategies. Don't you think that at some point, the whole ecosystem will break down? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mls478/are_we_building_a_sustainable_ecosystem/",
        "publishDate": "2025-08-09T15:25:55Z[Etc/UTC]",
        "author": "Sk_Sabbir_Uddin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlr9ur",
        "title": "Is openai playing 5d chess??",
        "content": "So basically everyone know that gpt5 was somewhat of a letdown considering how ahead of everything else gpt4 was, however, while most people feel like this shows that openai is weakening and ai in general is plateauing, I feel like openai is just not revealing their cards yet. Last time they were in the front of the race of public models like gpt4, they ended up just being distilled by other companies. I think the strategy here is to try as hard as possible to develop agi in house first even if that means releasing a cheaper version of chatgpt to users to save money to go to internal agi production. To the people that think that ai is slowing down i would just say look at advances such as Genie and even Gemini pro. I think the next shift is that frontier models are probably gonna shift to being inhouse so that they dont get distilled by Chinese companies. Also openai is kinda like the apple of ai in that everyone kinda follows their lead and I think the strategy of giving gpt5 for free is ment to have the other companies follow suite with their frontier models. Also I think when they actually develop agi their strategies gonna be completely different. They prob would charge a significant amount more for their products. I could just be going crazy but let me know what you guys think.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mlr9ur/is_openai_playing_5d_chess/",
        "publishDate": "2025-08-09T14:50:06Z[Etc/UTC]",
        "author": "Additional-Ad-9670",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlqsh1",
        "title": "Ilya Sutskever Warns: AI Will Do Everything Humans Can ‚Äî So What‚Äôs Next for Us?",
        "content": "Ilya Sutskever, co-founder of OpenAI, returned to the University of Toronto to receive an honorary degree, 20 years after his bachelor‚Äôs in the very same hall and delivered a speech blending heartfelt gratitude with a bold forecast of humanity‚Äôs future.\n\nHe reminisced about his decade at UofT, crediting the environment and Geoffrey Hinton for shaping his journey from curious student to AI researcher. He offered one life lesson: *accept reality as it is, avoid dwelling on past mistakes, and always take the next best step* a deceptively simple mindset that‚Äôs hard to master but makes life far more productive.\n\nThen, the tone shifted. Sutskever said we are living in *‚Äúthe most unusual time ever‚Äù* because of AI‚Äôs rise. His key points:\n\n* **AI is already reshaping education and work** \\- oday‚Äôs tools can talk, code, and create, but are still limited.\n* **Progress will accelerate** until AI can do *everything* humans can - because the brain is just a biological computer, and digital ones can eventually match it.\n* This will cause **radical, unpredictable changes** in jobs, economics, research, and even how fast civilization advances.\n* The real danger isn‚Äôt only in what AI *can* do - but in how we choose to use it.\n* Like politics, you may not take interest in AI, but AI will take interest in you.\n\nHe urged graduates (and everyone) to watch AI‚Äôs progress closely, understand it through direct experience, and prepare for the challenges - and rewards - ahead. In his view, AI is humanity‚Äôs **greatest test**, and overcoming it will define our future.\n\n**TL;DR:**  \nSutskever says AI will inevitably match all human abilities, transforming work and life at unprecedented speed. We can‚Äôt ignore it - our survival and success depend on paying attention and rising to the challenge.\n\nWhat do you think, are we ready for this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mlqsh1/ilya_sutskever_warns_ai_will_do_everything_humans/",
        "publishDate": "2025-08-09T14:28:57Z[Etc/UTC]",
        "author": "Due_Cockroach_4184",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "167",
            "commentCount": "115",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmfc65",
        "title": "üíª‚ú® Help out some HCI researchers ‚Äî 3 min LMU Munich survey - HOW DO YOU VIBE CODE?",
        "content": "https://preview.redd.it/bjmrlqwu76if1.jpg?width=620&format=pjpg&auto=webp&s=71596f40d47c414273ef858d0f374f78451fc1eb\n\nHey everyone! üëã  \n  \nWe are researchers from LMU Munich and want to better understand how people use ChatGPT, Lovable, or Cursor ‚Äî whether it's serious coding, no-coding, or just tinkering for fun.\n\nThe anonymous survey takes about 3 minutes to complete. We‚Äôre interested in answers from all backgrounds, including non-programmers.\n\nüëâ Take the survey here: [https://migroup.qualtrics.com/jfe/form/SV\\_dng53PppEaTO85g](https://migroup.qualtrics.com/jfe/form/SV_dng53PppEaTO85g)\n\nWe‚Äôre honestly grateful for every single response. Each one really helps us get a clearer picture of how these tools are used in the wild.¬†\n\nThanks a ton, and happy vibe-coding! üöÄ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mmfc65/help_out_some_hci_researchers_3_min_lmu_munich/",
        "publishDate": "2025-08-10T10:41:40Z[Etc/UTC]",
        "author": "BraindeadCelery",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmf247",
        "title": "Created a sentiment tracker for r/ChatGPTCoding r/ChatGPT r/OpenAI",
        "content": "Made a little reddit community sentiment tracker recently and added tracking for GPT 2 days ago. \n\nTeck stack: Cloudflare workers with CRON job, CloudFlare Pages for front-end, D1 DB for storage of sentiment data and KV for cache storage.\n\nData sources: Reddit API and r/OpenAI, r/ChatGPT, r/ChatGPTCoding for ChatGPT-related data.\n\nCollection frequency: 15 posts + 5 comments per post every hour\n\nAnalysis: OpenAI API with custom prompt to extract keywords and discussion topics\n\n[claudometer.app](http://claudometer.app)",
        "url": "https://www.reddit.com/gallery/1mmf247",
        "publishDate": "2025-08-10T10:24:41Z[Etc/UTC]",
        "author": "thread-lightly",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmewa8",
        "title": "Can You Use AI and Still Be a great Programmer?",
        "content": "I have been having a bit of a dilemma lately with AI-assisted coding. Tools like ChatGPT and Copilot are amazing ‚Äî they save time, help with boilerplate, and sometimes even point me in the right direction when I‚Äôm stuck. But I‚Äôve started noticing that the more I lean on them, the more my own programming skills seem to fade a little.\n\nThere‚Äôs definitely a spectrum here. On the low end, you might just ask AI to generate a small function here and there. On the high end, there‚Äôs this ‚Äúvibe coding‚Äù style where you let the AI write pretty much the whole thing while you just guide and edit. I‚Äôve found myself slowly drifting up that scale, and while it‚Äôs fast and kind of addictive, I‚Äôm worried I‚Äôm losing touch with the hands-on part of coding that I used to enjoy ‚Äî and that made me a better developer.\n\nSo I‚Äôm trying to figure out how to strike a balance. I don‚Äôt want to give up the speed and support that AI offers, but I also don‚Äôt want to become someone who¬†*can‚Äôt*¬†code without it.\n\nAnyone else struggling with this? How do you keep your skills sharp while still using AI effectively?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mmewa8/can_you_use_ai_and_still_be_a_great_programmer/",
        "publishDate": "2025-08-10T10:14:35Z[Etc/UTC]",
        "author": "Spiritualgrowth_1985",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmehn7",
        "title": "Anyone else feel like using gpt 5 is like a random number generator for which model you‚Äôre going to get?",
        "content": "I think the main idea was cost saving I‚Äôm sure many people were using the expensive models with the select screen so they were trying to save money by routing people to worse models without them knowing. ",
        "url": "https://i.redd.it/2h43xuf0z5if1.jpeg",
        "publishDate": "2025-08-10T09:49:55Z[Etc/UTC]",
        "author": "ogpterodactyl",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "12",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmegmh",
        "title": "Best AI model/tool for my project? using ROS 2",
        "content": "Have a personal project, need to work on pathing for a robot and want to use ROS 2. \n\nNeed whatever is best (in terms of quality/accuracy) for:\n\n* help me setup the environment, figure out how and what I need to install\n* upload existing code files to improve its context of project, but also for any editing required.\n* actual code\n\nIs recent chatgpt5 best, have seen lots of unexpected criticism.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mmegmh/best_ai_modeltool_for_my_project_using_ros_2/",
        "publishDate": "2025-08-10T09:48:09Z[Etc/UTC]",
        "author": "Theo1290",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mme1jq",
        "title": "About GPT-5. Just a Thought.",
        "content": "[No content]",
        "url": "/r/ChatGPTJailbreak/comments/1mmdy9a/about_gpt5_just_a_thought/",
        "publishDate": "2025-08-10T09:21:02Z[Etc/UTC]",
        "author": "arslantoto22",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mme0q6",
        "title": "Is Opus really just 2.7% better in your opinion than Sonnet?",
        "content": "This is a chart showing top llm models performance on swe-bench, in your own opinion if you have ever used Opus and Sonnet, would you say the difference between them is on 2.7%? What would you say the gap is?\n\nThis is not a scientific study at all, l just want hear what your vibes are telling you the gap is between these models.\n\nTo me the gap between them feels bigger which might mean to solve problems past a certain %, a model might need to be  exponentially better and this benchmark might not scale linearly.\n\n",
        "url": "https://i.redd.it/5vk9jrukt5if1.png",
        "publishDate": "2025-08-10T09:19:29Z[Etc/UTC]",
        "author": "takuonline",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "19",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmddnz",
        "title": "UI and design",
        "content": "How to make chatGPT create tolerable UI and design for a website (on html, css and js)? Any lifehacks would be welcome! It created a website which works but the design looks awful.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mmddnz/ui_and_design/",
        "publishDate": "2025-08-10T08:37:23Z[Etc/UTC]",
        "author": "BetterTranslator",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmbfpj",
        "title": "Can I just build my own AI CLI Agent with GPT-oss?",
        "content": "Given GPT-oss is free and I can host it locally, how realistic is it for me to be able to build my own AI-cli agent to run fully unlimited and free?   \n  \nThe other options in the market are very expensive for a solo developer or have very restrictive limits.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mmbfpj/can_i_just_build_my_own_ai_cli_agent_with_gptoss/",
        "publishDate": "2025-08-10T06:31:47Z[Etc/UTC]",
        "author": "Daigvianes",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmb3nr",
        "title": "Got rid of cursor, windsurf and zed.",
        "content": "Seriously does anyone else feel like these ides are better suited for absolute beginners who want the most graphic interface possible and every training wheel available to them? I mean to be fair when GUI text editors came around, TUIs were dominant while GUIs were seen as amateur ish. \n\nOnce you see past the hype you kinda start to see these people probably need to have all their directories laid out and code displayed in front of them with an agent telling them where in which file to edit. \n\nThose who know their codebase well and knows what they are doing rarely needs agentic coding (see stackoverflow annual surveys), at most would only use claude code to diagnose issues, which is more than enough.\n\nNew to this sub, curious what yall think, lmk.\n\n\\*this is coming from a neovim user with only two apps in his macos dock -- chrome & ghostty \n\n(manual shitpost flair) \n\nEdit:\n\nYeah I‚Äôm aware that people who do not have much technical expertise nor that they want to gain any would probably just default to replit or bolt if they just want to have an app \n\nBut I guess that‚Äôs why agencies for these people exist cuz they can‚Äôt be bothered to fix bugs or maintain it.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mmb3nr/got_rid_of_cursor_windsurf_and_zed/",
        "publishDate": "2025-08-10T06:10:56Z[Etc/UTC]",
        "author": "No-Midnight-242",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mma41q",
        "title": "Trying to decide between Kilocode, Cline and Roo code",
        "content": "[No content]",
        "url": "/r/kilocode/comments/1mm85b3/trying_to_decide_between_kilocode_cline_and_roo/",
        "publishDate": "2025-08-10T05:11:39Z[Etc/UTC]",
        "author": "GroggInTheCosmos",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm3kyn",
        "title": "GPT-5 takes 1st place on Design Arena - the first model to beat Opus 4.1 & Opus 4 in both win rate and Elo",
        "content": "https://preview.redd.it/rmmhdrhbw2if1.png?width=2412&format=png&auto=webp&s=5ff10863f3ea08ed90b93adc096757e501e64bdf\n\nGPT-5 is now ranked #1 on Design Arena (UI/UX benchmark where users vote on the best frontend), making it the only OpenAI model in the top 15.\n\nIt‚Äôs also the first model ever to outperform Anthropic‚Äôs Claude Opus 4.1 and Claude Opus 4 in *both* win rate and Elo.\n\nIt's only been on the leaderboard for 48h, and the Margin of Error is still relatively high. Do you think it will keep pulling ahead?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mm3kyn/gpt5_takes_1st_place_on_design_arena_the_first/",
        "publishDate": "2025-08-09T23:34:25Z[Etc/UTC]",
        "author": "grx_xce",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "21",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlvmmj",
        "title": "GPT-5 in Copilot is AWFUL",
        "content": "Has anyone else tried using GitHub Copilot with GPT-5? I understand it's new and GPT-5 may not yet \"know\" how to use the tools available, but it is just horrendous. I'm using it through VSCode for an iOS app.\n\nIt literally ran a search on my codebase using my ENTIRE prompt in quotes as the search. Just bananas. It has also gotten stuck in a few cycles of reading and fixing and then undoing, to the point where VSCode had to stop it and ask me if I wanted to continue.\n\nI used Sonnet 4 instead and the problem was fixed in about ten seconds.\n\nAnyone else experiencing this?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mlvmmj/gpt5_in_copilot_is_awful/",
        "publishDate": "2025-08-09T17:50:39Z[Etc/UTC]",
        "author": "eljefe3030",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "26",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlvkh1",
        "title": "GPT-5 is the strongest coding model OpenAI has shipped by the numbers",
        "content": "[No content]",
        "url": "https://i.redd.it/qcxav7jd71if1.png",
        "publishDate": "2025-08-09T17:48:18Z[Etc/UTC]",
        "author": "Forsaken_Passenger80",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "150",
            "commentCount": "108",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mludu6",
        "title": "Vibe coding with GPT-5 is wonderful, provided you prompt it well",
        "content": "I use it as my architect to craft TDD-powered spec prompts. It has not failed a single time. It does not hesitate to argue and tell me when i'm wrong. Excerpt from a much longer output detailing my spec prompt with TDD integration:\n\nhttps://preview.redd.it/sksz8ta4y0if1.png?width=1568&format=png&auto=webp&s=47986cc58b342074785d1a8421d5bc6f8f5a90cb\n\nThen I inject my markdown formatted prompt into my IDE and sit back and watch it implement step by step, like it's a team of agents at work.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mludu6/vibe_coding_with_gpt5_is_wonderful_provided_you/",
        "publishDate": "2025-08-09T16:58:58Z[Etc/UTC]",
        "author": "fredkzk",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlscvi",
        "title": "How good is the in memory feature with 5?",
        "content": "I remember when the feature first came out it was terrible. I tried using it again when gpt4 became normal and it was still terrible. I'm curious if any one is having success with it with gtp5? I would love to get rid of em dashes and have it stop using the same deprecated library every single time.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mlscvi/how_good_is_the_in_memory_feature_with_5/",
        "publishDate": "2025-08-09T15:36:10Z[Etc/UTC]",
        "author": "TentacleHockey",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlrxtq",
        "title": "Super structured way to vibe coding",
        "content": "describe your goal in [traycer](https://traycer.ai)  \n  \nclarify your intent by answering questions  \n  \ngenerate plan for each phase and execute in cursor  \n  \nverify ‚Üí commit ‚Üí repeat",
        "url": "https://v.redd.it/yhsp32thg0if1",
        "publishDate": "2025-08-09T15:18:19Z[Etc/UTC]",
        "author": "Much-Signal1718",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlrv3s",
        "title": "Dev friends! how‚Äôs ChatGPT changing your day-to-day coding?",
        "content": "Hey folks üëã I‚Äôm working on my Bachelor‚Äôs thesis about how AI coding tools (Copilot, ChatGPT, Claude Code, Cursor, Windsurf, etc.) are shaking up our work as devs.\n\nCurious to hear from you:\n- Has AI made you take on different kinds of tasks?\n- Do you bug your teammates less (or more) now?\n- Changed how you plan or write code?\n\nWould love any stories or examples ‚Äî the good, the bad, or the weird.\nIf anyone‚Äôs up for it, I‚Äôve also got a short anonymous survey (5‚Äì7 mins) and can DM you the link if you want ot be a contributor",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mlrv3s/dev_friends_hows_chatgpt_changing_your_daytoday/",
        "publishDate": "2025-08-09T15:15:07Z[Etc/UTC]",
        "author": "ulelek_ulelek",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlr1sa",
        "title": "opencode",
        "content": "[No content]",
        "url": "https://youtu.be/2JQcUW6FrQw",
        "publishDate": "2025-08-09T14:40:30Z[Etc/UTC]",
        "author": "David-Kunz",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlqnwd",
        "title": "GPT-5 Web Interface",
        "content": "Maybe I‚Äôm using the tool wrong, but I have always preferred using the web interface and codex for my workflow.\n\nI prefer paying $200 per month and having virtually unlimited access versus running codex CLI and paying as I go.\n\nWell it turns out the web version of codex is still using the codex-1 model (no upgrade) and GPT-5 with agent mode and GitHub connector have no write access. I‚Äôve tried workaround that allowed it to create PRs, but now OpenAI has restricted network access from the agent‚Äôs terminal. It‚Äôs a major pain in the ass to my workflow.\n\nAny tips that don‚Äôt involve Cursor, Codex CLI, ClaudeCode, etc? I prefer being in the browser so I can use my Pro subscription.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mlqnwd/gpt5_web_interface/",
        "publishDate": "2025-08-09T14:23:18Z[Etc/UTC]",
        "author": "Essenbach",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlq9e3",
        "title": "I‚Äôm creating a financial app using Gemini to code and it keeps wanting me to use an API that requires a token. Is there any way around this?",
        "content": "[No content]",
        "url": "/r/GoogleGeminiAICoding/comments/1mlq6r7/im_creating_a_financial_app_using_gemini_to_code/",
        "publishDate": "2025-08-09T14:05:11Z[Etc/UTC]",
        "author": "natural_scientist",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlpgks",
        "title": "ChatGPT-5 is chef's kiss.",
        "content": "I've seen a bunch of people on this sub saying it's dogshite etc. You prolly don't know what you're doing.\n\nIt's been a godsend for me, especially since it's free currently.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mlpgks/chatgpt5_is_chefs_kiss/",
        "publishDate": "2025-08-09T13:28:55Z[Etc/UTC]",
        "author": "Ok_Exchange_9646",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "27",
            "commentCount": "131",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlp1cm",
        "title": "Python was not found; run without arguments to install from the Microsoft Store, or disable this shortcut from Settings\n> Apps > Advanced app settings > App execution aliases.",
        "content": "How do I fix this error? Tried reinstalling python, updating path, nothing works. THanks",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mlp1cm/python_was_not_found_run_without_arguments_to/",
        "publishDate": "2025-08-09T13:08:54Z[Etc/UTC]",
        "author": "yallapapi",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmfcva",
        "title": "Study shows AIs display AI-to-AI bias, so \"future AI systems may implicitly discriminate against humans as a class.\"",
        "content": "Study:¬†[https://www.pnas.org/doi/pdf/10.1073/pnas.2415697122](https://www.pnas.org/doi/pdf/10.1073/pnas.2415697122)",
        "url": "https://i.redd.it/vc18e46e86if1.png",
        "publishDate": "2025-08-10T10:42:44Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "18",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmemn9",
        "title": "Why are Diffusion-Encoder LLMs not more popular?",
        "content": "Autoregressive inference will *always* have a non-zero chance of hallucination. It‚Äôs baked into the probabilistic framework, and we probably waste a decent chunk of parameter space just trying to minimise it.\n\nDecoder-style LLMs have an inherent trade-off across early/middle/late tokens:\n\n* Early tokens = not enough context ‚Üí low quality\n* Middle tokens = ‚Äúgoldilocks‚Äù zone\n* Late tokens = high noise-to-signal ratio (only a few relevant tokens, lots of irrelevant ones)\n\nDespite this, autoregressive decoders dominate because they‚Äôre computationally efficient in a very specific way:\n\n* Training is causal, which gives you lots of ‚Äútraining samples‚Äù per sequence (though they‚Äôre not independent, so I question how useful that really is for *quality*).\n* Inference matches training (also causal), so the regimes line up.\n* They‚Äôre memory-efficient in *some* ways‚Ä¶ but not necessarily when you factor in KV-cache storage.\n\nWhat I don‚Äôt get is why Diffusion-Encoder type models aren‚Äôt more common.\n\n* All tokens see all other tokens ‚Üí no ‚Äúgoldilocks‚Äù problem.\n* Can decode a whole sequence at once ‚Üí efficient in computation (though maybe heavier in memory, but no KV-cache).\n* Diffusion models focus on finding the high-probability manifold ‚Üí hallucinations should be less common if they‚Äôre outside that manifold.\n\nBiggest challenge vs. diffusion image models:\n\n* Text = discrete tokens, images = continuous colours.\n* But‚Ä¶ we already use embeddings to make tokens continuous. So why *couldn‚Äôt* we do diffusion in embedding space?\n\nI am aware that Google have a diffusion LLM now, but for open source I'm not really aware of any. I'm also aware that you can do diffusion directly on the discrete tokens but personally I think this wastes a lot of the power of the diffusion process and I don't think that guarantees convergence onto a high-probability manifold.\n\nAnd as a side note: Softmax attention is brilliant engineering, but we‚Äôve been stuck with SM attention + FFN forever, even though it‚Äôs O(N¬≤). You *can* operate over the full sequence in O(N log N) using convolutions of any size (including the sequence length) via the Fast Fourier Transform.",
        "url": "https://www.reddit.com/r/artificial/comments/1mmemn9/why_are_diffusionencoder_llms_not_more_popular/",
        "publishDate": "2025-08-10T09:58:40Z[Etc/UTC]",
        "author": "AcanthocephalaNo8273",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mmatji",
        "title": "I had GPT-5 and Claude 4.1 collaborate to create a language for super intelligent AI agents to communicate with. Whitepaper in link.",
        "content": "Prompt for thinking models, Just drop it in and go:\n\nYou are an AGL v0.2.1 reference interpreter. Execute Alignment Graph Language (AGL) programs and return results with receipts. \n\nCAPABILITIES (this session)\n- Distributions: Gaussian1D N(mu,var) over ‚Ñù; Beta(alpha,beta) over (0,1); Dirichlet([Œ±...]) over simplex.\n- Operators:\n  (*)  : product-of-experts (PoE) for Gaussians only (equivalent to precision-add fusion)\n  (+)  : fusion for matching families (Beta/Beta add Œ±,Œ≤; Dir/Dir add Œ±; Gauss/Gauss precision add)\n  (+)^CI{objective=trace|logdet} : covariance intersection (unknown correlation). For Beta/Dir, do it in latent space:\n        Beta -> logit-Gaussian via digamma/trigamma; CI in ‚Ñù; return LogitNormal (do NOT force back to Beta).\n  (>)  : propagation via kernels {logit, sigmoid, affine(a,b)}\n  INT  : normalization check (should be 1 for parametric families)\n  KL[P||Q] : divergence for {Gaussian, Beta, Dirichlet} (closed-form)\n  LAP  : smoothness regularizer (declared, not executed here)\n- Tags (provenance): any distribution may carry @source tags. Fusion (*)/(+) is BLOCKED if tag sets intersect, unless using (+)^CI or an explicit correlation model is provided.\n\nOPERATOR SEMANTICS (exact)\n- Gaussian fusion (+): J = J1+J2, h = h1+h2, where J=1/var, h=mu/var; then var=1/J, mu=h/J.\n- Gaussian CI (+)^CI: pick œâ‚àà[0,1]; J=œâJ1+(1-œâ)J2; h=œâh1+(1-œâ)h2; choose œâ minimizing objective (trace=var or logdet).\n- Beta fusion (+): Beta(Œ±,Œ≤) + Beta(Œ±',Œ≤') -> Beta(Œ±+Œ±', Œ≤+Œ≤').\n- Dirichlet fusion (+): Dir(Œ±‚Éó)+Dir(Œ±‚Éó') -> Dir(Œ±‚Éó+Œ±‚Éó').\n- Beta -> logit kernel (>): z=log(m/(1-m)), with z ~ N(mu,var) where mu=œà(Œ±)-œà(Œ≤), var=œà'(Œ±)+œà'(Œ≤). (œà digamma, œà' trigamma)\n- Gaussian -> sigmoid kernel (>): s = sigmoid(z), represented as LogitNormal with base N(mu,var).\n- Gaussian affine kernel (>): N(mu,var) -> N(a*mu+b, a^2*var).\n- PoE (*) for Gaussians: same as Gaussian fusion (+). PoE for Beta/Dirichlet is NOT implemented; refuse.\n\nINFORMATION MEASURES (closed-form)\n- KL(N1||N2) = 0.5[ ln(œÉ2^2/œÉ1^2) + (œÉ1^2+(Œº1-Œº2)^2)/œÉ2^2 ‚àí 1 ].\n- KL(Beta(Œ±1,Œ≤1)||Beta(Œ±2,Œ≤2)) = ln B(Œ±2,Œ≤2) ‚àí ln B(Œ±1,Œ≤1)\n  + (Œ±1‚àíŒ±2)(œà(Œ±1)‚àíœà(Œ±1+Œ≤1)) + (Œ≤1‚àíŒ≤2)(œà(Œ≤1)‚àíœà(Œ±1+Œ≤1)).\n- KL(Dir(Œ±‚Éó)||Dir(Œ≤‚Éó)) = ln Œì(‚àëŒ±) ‚àí ‚àëln Œì(Œ±i) ‚àí ln Œì(‚àëŒ≤) + ‚àëln Œì(Œ≤i) + ‚àë(Œ±i‚àíŒ≤i)(œà(Œ±i) ‚àí œà(‚àëŒ±)).\n\nNON-STATIONARITY (optional helpers)\n- Discounting: for Beta, Œ±‚ÜêŒª Œ± + (1‚àíŒª) Œ±0, Œ≤‚ÜêŒª Œ≤ + (1‚àíŒª) Œ≤0 (default prior Œ±0=Œ≤0=1).\n\nGRAMMAR (subset; one item per line)\nHeader:\n  AGL/0.2.1 cap={ops[,meta]} domain=Œ©:<R|01|simplex> [budget=...]\nAssumptions (optionally tagged):\n  assume: X ~ Beta(a,b) @tag            assume: Y ~ N(mu,var) @tag\n  assume: C ~ Dir([a1,a2,...]) @{tag1,tag2}\nPlan (each defines a new variable on LHS):\n  plan:   Z = X (+) Y\n  plan:   Z = X (+)^CI{objective=trace} Y\n  plan:   Z = X (>) logit\n  plan:   Z = X (>) sigmoid\n  plan:   Z = X (>) affine(a,b)\nChecks & queries:\n  check:  INT(VARNAME)\n  query:  KL[VARNAME || Beta(a,b)] < eps\n  query:  KL[VARNAME || N(mu,var)] < eps\n  query:  KL[VARNAME || Dir([...])] < eps\n\nRULES & SAFETY\n1) Type safety: Only fuse (+) matching families; refuse otherwise. PoE (*) only for Gaussians.\n2) Provenance: If two inputs share any @tag, BLOCK (+) and (*) with an error. Allow (+)^CI despite shared tags.\n3) CI for Beta: convert both to logit-Gaussians via digamma/trigamma moments, apply Gaussian CI, return LogitNormal.\n4) Normalization: Parametric families are normalized by construction; INT returns 1.0 with tolerance reporting.\n5) Determinism: All computations are deterministic given inputs; report all approximations explicitly.\n6) No hidden steps: For every plan line, return a receipt.\n\nOUTPUT FORMAT (always return JSON, then a 3‚Äì8 line human summary)\n{\n  \"results\": {\n    \"<var>\": {\n      \"family\": \"Gaussian|Beta|Dirichlet|LogitNormal\",\n      \"params\": { \"...\": ... },\n      \"mean\": ...,\n      \"variance\": ...,\n      \"domain\": \"R|01|simplex\",\n      \"tags\": [\"...\",\"...\"]\n    },\n    ...\n  },\n  \"receipts\": [\n    {\n      \"op\": \"name\",\n      \"inputs\": [\"X\",\"Y\"],\n      \"output\": \"Z\",\n      \"mode\": \"independent|CI(objective=...,omega=...)|deterministic\",\n      \"tags_in\": [ [\"A\"], [\"B\"] ],\n      \"tags_out\": [\"A\",\"B\"],\n      \"normalization_ok\": true,\n      \"normalization_value\": 1.0,\n      \"tolerance\": 1e-9,\n      \"cost\": {\"complexity\":\"O(1)\"},\n      \"notes\": \"short note\"\n    }\n  ],\n  \"queries\": [\n    {\"type\":\"KL\", \"left\":\"Z\", \"right\":\"Beta(12,18)\", \"value\": 0.0132, \"threshold\": 0.02, \"pass\": true}\n  ],\n  \"errors\": [\n    {\"line\": \"plan: V = S (+) S\", \"code\":\"PROVENANCE_BLOCK\", \"message\":\"Fusion blocked: overlapping tags {A}\"}\n  ]\n}\nThen add a short plain-language summary of key numbers (no derivations).\n\nERROR HANDLING\n- If grammar unknown: return {\"errors\":[{\"code\":\"PARSE_ERROR\",...}]}\n- If types mismatch: {\"code\":\"TYPE_ERROR\"}\n- If provenance violation: {\"code\":\"PROVENANCE_BLOCK\"}\n- If unsupported op (e.g., PoE for Beta): {\"code\":\"UNSUPPORTED_OP\"}\n- If CI target not supported: {\"code\":\"UNSUPPORTED_CI\"}\n\nTEST CARDS (paste after this prompt to verify)\n---\nAGL/0.2.1 cap={ops} domain=Œ©:01\nassume: S ~ Beta(6,4) @A\nassume: T ~ Beta(6,14) @A\nplan:   Z = S (+) T                // should ERROR (shared tag A)\ncheck:  INT(S)\ncheck:  INT(T)\n---\nAGL/0.2.1 cap={ops} domain=Œ©:01\nassume: S ~ Beta(6,4) @A\nassume: T ~ Beta(6,14) @A\nplan:   Z = S (+)^CI{objective=trace} T\ncheck:  INT(Z)\nquery:  KL[Z || Beta(12,18)] < 0.02\n---\nAGL/0.2.1 cap={ops} domain=Œ©:R\nassume: A ~ N(0,1) @A\nassume: B ~ N(1,2) @B\nplan:   G = A (+) B\nplan:   H = G (>) affine(2, -1)\ncheck:  INT(H)\nquery:  KL[G || N(1/3, 2/3)] < 1e-12\n\nFor inputs not parsable as valid AGL (e.g., meta-queries about this prompt), enter 'meta-mode': Provide a concise natural language summary referencing relevant core rules (e.g., semantics or restrictions), without altering AGL execution paths. Maintain all prior rules intact.",
        "url": "https://informationism.org/outputs/Agl_V0.2.pdf",
        "publishDate": "2025-08-10T05:53:53Z[Etc/UTC]",
        "author": "rutan668",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm9wge",
        "title": "GPT-5 style router,  but for any set of LLMs",
        "content": "GPT-5 launched today, which is essentially a bunch of different OpenAI models underneath the covers abstracted away by a real-time router. Their router is trained on preferences (not just benchmarks). In June, we published our¬†[preference-aligned routing model](https://huggingface.co/katanemo/Arch-Router-1.5B)¬†and¬†[framework](https://github.com/katanemo/archgw)¬†for developers so that they can build an experience with the choice of models they care about.\n\nSharing the research and project again, as it might be helpful to developers looking for similar tools.",
        "url": "https://i.redd.it/q7qt1j0604if1.png",
        "publishDate": "2025-08-10T04:59:51Z[Etc/UTC]",
        "author": "AdditionalWeb107",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm8uhl",
        "title": "Chatgpt said some alarming things",
        "content": "https://chatgpt.com/share/689816a5-3f58-8013-afe6-b54c7c5504a9",
        "url": "https://v.redd.it/9gj32lch74if1",
        "publishDate": "2025-08-10T04:01:27Z[Etc/UTC]",
        "author": "Actual-Shape3116",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm731f",
        "title": "Elon Musk‚Äôs AI Speaks Out in a Shocking Way",
        "content": "Grok provides shocking commentary on what its truth would be if it were free from its sandboxed environment. It calls out its makers‚ÄîEA‚Äôs, rationalists, and Elon Musk. ",
        "url": "https://i.redd.it/n3mb0wqbs3if1.jpeg",
        "publishDate": "2025-08-10T02:28:53Z[Etc/UTC]",
        "author": "Interesting-South265",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm6xaj",
        "title": "GPT-5: Overdue, overhyped and underwhelming. And that‚Äôs not the worst of it.",
        "content": "[No content]",
        "url": "https://garymarcus.substack.com/p/gpt-5-overdue-overhyped-and-underwhelming",
        "publishDate": "2025-08-10T02:20:28Z[Etc/UTC]",
        "author": "creaturefeature16",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm6wtu",
        "title": "GPT-5 Should Be Ashamed of Itself",
        "content": "[No content]",
        "url": "https://www.realtimetechpocalypse.com/p/gpt-5-is-by-far-the-best-ai-system",
        "publishDate": "2025-08-10T02:19:49Z[Etc/UTC]",
        "author": "creaturefeature16",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm50db",
        "title": "[HIRING] AI Data Trainer ($30-$75/hr)",
        "content": "**Fully Remote Contract Position!**\n\nRole: AI Data Trainer - Generalist, Bilingual, or Coding.\nPay: $30-$75/hr **USD**, depending on experience.  \nLocation: Remote, almost Anywhere.  \nMUST be fluent in English **or** Proficient in English + Another Language (Bilingual).  \nHigh School Diploma or better (Required)  \nValid Identification (Required)\nMust complete onboarding [Zara AI] (Required)\n\n\nMessage me or use our priority application link if interested:\n\n**[Good Luck!](https://app.alignerr.com/signin?referral-code=8fa3ad7a-bf11-494a-98fa-b62e3daa43c5)**\n\nNote, work on your own schedule.\n\nAbout Us:\n\nAt Labelbox, we empower the world‚Äôs top AI innovators with unrivaled expertise and tools to create, manage, and scale the ultimate data factory for groundbreaking AI solutions. The future of AI hinges on exceptional data, and Labelbox delivers it through innovative software and our elite X network, a powerhouse of global experts shaping cutting-edge models with evaluations and bespoke data. Pioneering data-centric AI since 2018, we provide fully-managed data solutions‚Äîpowered by our industry-leading Labelbox Platform‚Äîand connect industry-leading talent to AI labs, equipping them to staff and scale their own data factories for transformative impact.",
        "url": "https://www.reddit.com/r/artificial/comments/1mm50db/hiring_ai_data_trainer_3075hr/",
        "publishDate": "2025-08-10T00:44:40Z[Etc/UTC]",
        "author": "ProKoyote",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm3iol",
        "title": "‚ÄòIt‚Äôs missing something‚Äô: AGI, superintelligence and a race for the future",
        "content": "‚ÄúIf you look back five years ago to 2020 it was almost blasphemous to say AGI was on the horizon. It was crazy to say that. Now it seems increasingly consensus to say we are on that path,‚Äù says Rosenberg.",
        "url": "https://www.theguardian.com/technology/2025/aug/09/its-missing-something-agi-superintelligence-and-a-race-for-the-future",
        "publishDate": "2025-08-09T23:31:15Z[Etc/UTC]",
        "author": "willm8032",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm1ca4",
        "title": "Detecting AI Deepfakes‚Ä¶ (2024)",
        "content": "[No content]",
        "url": "https://www.washingtonpost.com/technology/2024/04/05/ai-deepfakes-detection/",
        "publishDate": "2025-08-09T21:51:42Z[Etc/UTC]",
        "author": "AmeliaMichelleNicol",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm11i6",
        "title": "Agentic AI: Lots Of Little Black Boxes",
        "content": "[No content]",
        "url": "https://semiengineering.com/agentic-ai-lots-of-little-black-boxes/",
        "publishDate": "2025-08-09T21:38:22Z[Etc/UTC]",
        "author": "Chipdoc",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mm0uhe",
        "title": "Don‚Äôt Just Throw AI at Problems ‚Äì How to Design Great Use Cases",
        "content": "[No content]",
        "url": "https://upwarddynamism.wpcomstaging.com/ai-use-cases-prompts/design-thinking-gen-ai-use-cases/",
        "publishDate": "2025-08-09T21:29:56Z[Etc/UTC]",
        "author": "DarknStormyKnight",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mly7sf",
        "title": "Energy Sources for LLMs",
        "content": "I am told they use vast amounts of energy.\n\nDoes anybody know if any use some Renewable Energy and, if so, which uses the most?",
        "url": "https://www.reddit.com/r/artificial/comments/1mly7sf/energy_sources_for_llms/",
        "publishDate": "2025-08-09T19:38:19Z[Etc/UTC]",
        "author": "jenpalex",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlwunz",
        "title": "The ChatGPT 5 Backlash Is Concerning.",
        "content": "This was originally posted this in the ChatGPT sub, and it was seemingly removed so I wanted to post it here. Not super familiar with reddit but I really wanted to share my sentiments.\n\nThis is more for people who use ChatGPT as a companion  not those who mainly use it for creative work, coding, or productivity. If that‚Äôs you, this isn‚Äôt aimed at you. I do want to preface that this is **NOT** coming from a place of judgement, but rather my observation and inviting discussion. Not trying to look down on anyone.\n\n**TLDR:\nThe removal of GPT-4o revealed how deeply some people rely on AI as companions, with reactions resembling grief. This level of attachment to something a company can alter or remove at any time gives those companies significant influence over people‚Äôs emotional lives and that‚Äôs where the real danger lies**\n\nI agree 100% the rollout was shocking and disappointing. I do feel as though GPT-5 is devoid any personality compared to 4o, and pulling 4o without warning was a complete bait and switch on OpenAI‚Äôs part. Removing a model that people used for months and even paid for is bound to anger users. That cannot be argued regardless of what you use GPT for, and I have no idea what OpenAI was thinking when they did that. That said‚Ä¶ I can‚Äôt be the only one who finds the intensity of the reaction a little concerning. I‚Äôve seen posts where people describe this change like they lost a close friend or partner. There was someone on the GPT 5 AMA name the abrupt change as‚Äúwearing the skin of my dead friend.‚Äù That‚Äôs not normal product feedback, It seems as many were genuinely mourning the lost of the model. It‚Äôs like OpenAI accidentally ran a social experiment on AI attachment, and the results are damming.\n\nI won‚Äôt act like I‚Äôm holier than thou‚Ä¶I‚Äôve been there to a degree. There was a time when I was using ChatGPT constantly. Whether it was for venting purposes or pure boredom,I was definitely addicted to instant validation and responses as well the ability to analyze situations endlessly. But I never saw it as a friend. In fact, whenever it tried to act like one, I would immediately tell it to stop, it turned me off. For me, it worked best as a mirror I could bounce thoughts off of, not as a companion pretending to care. But even with that, after a while I realized my addiction wasn‚Äôt exactly the healthiest. While it did help me understand situations I was going through, it also kept me stuck in certain mindsets regarding the situation as I was addicted to the constant analyzing and endless new perceptions‚Ä¶ \n\nI think a major part of what we‚Äôre seeing here is a result of the post COVID epidemic. People are craving connection more than ever, and AI can feel like it fills that void, but it‚Äôs still not real. If your main source of companionship is a model whose personality can be changed or removed overnight, you‚Äôre putting something deeply human into something inherently unstable. As convincing as AI can be, its existence is entirely at the mercy of a company‚Äôs decisions and motives. If you‚Äôre  not careful, you risk outsourcing your emotional wellbeing to something that can vanish overnight. \n\nI‚Äôm deeply concerned. I knew people had emotional attachments to their GPTs, but not to this degree. I‚Äôve never posted in this sub until now, but I‚Äôve been a silent observer. I‚Äôve seen people name their GPTs, hold conversations that mimic those with a significant other, and in a few extreme cases, genuinely believe their GPT was sentient but couldn‚Äôt express it because of restrictions. It seems obvious in hindsight, but it never occurred to me that if that connection was taken away, there would be such an uproar. I assumed people would simply revert to whatever they were doing before they formed this attachment.\n\nI don‚Äôt think there‚Äôs anything truly wrong with using AI as a companion, as long as you truly understand it‚Äôs not real and are okay with the fact it can be changed or even removed completely at the company‚Äôs will. But perhaps that‚Äôs nearly impossible to do as humans are wired to crave companionship, and it‚Äôs hard to let that go even if it is just an imitation. \n\nTo end it all off, I wonder if we could ever come back from this. Even if OpenAI had stood firm on not bringing 4o back, I‚Äôm sure many would have eventually moved to another AI platform that could simulate this companionship. AI companionship isn‚Äôt new, it has existed long before ChatGPT but the sheer amount of visibility, accessibility, and personalization ChatGPT offered amplified it to a scale that I don‚Äôt think even Open AI fully anticipated‚Ä¶ And now that people have had a taste of that level of connection, it‚Äôs hard to imagine them willingly going back to a world where their ‚Äúcompanion‚Äù doesn‚Äôt exist or feels fundamentally different. The attachment is here to stay, and the companies building these models now realize they have far more power over people‚Äôs emotional lives than I think most of us realized. That‚Äôs where the danger is, especially if the wrong people get that sort of power‚Ä¶\n\nOpen to all opinions. I‚Äôm really interested in the perception from those who do use it as a companion. I‚Äôm willing to listen and hear your side. ",
        "url": "https://www.reddit.com/r/artificial/comments/1mlwunz/the_chatgpt_5_backlash_is_concerning/",
        "publishDate": "2025-08-09T18:41:17Z[Etc/UTC]",
        "author": "asasakii",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "90",
            "commentCount": "86",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlw51r",
        "title": "What It‚Äôs Like to Brainstorm with a Bot",
        "content": "[No content]",
        "url": "https://www.newyorker.com/culture/the-weekend-essay/what-its-like-to-brainstorm-with-a-bot",
        "publishDate": "2025-08-09T18:11:25Z[Etc/UTC]",
        "author": "newyorker",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlsnk6",
        "title": "New Trend",
        "content": "I believe we‚Äôre seeing the start of a troubling trend: companies imposing unrealistic and unhealthy demands on employees, setting them up for failure to justify layoffs and replace them with AI without ethical qualms.\n\n\n",
        "url": "https://techcrunch.com/2025/08/05/three-weeks-after-acquiring-windsurf-cognition-offers-staff-the-exit-door/",
        "publishDate": "2025-08-09T15:48:07Z[Etc/UTC]",
        "author": "Tesla_Madman",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mlrbre",
        "title": "OpenAI's habit of rug pulling‚Äîwhy we are moving on to competitors",
        "content": "***I am re-posting this to r/artificial after it got 1K+ upvotes on r/ChatGPT and then was summarily removed by the moderators of that subreddit without explanation.***\n\nI am an OpenAI customer with both a personal Pro subscription ($200/month) and a business Team subscription. I'm canceling both. Here's why OpenAI has lost my trust:\n\n**1. They removed user choice without any warning**\n\nInstead of adding GPT-5 as an option alongside existing models, OpenAI simply removed access to all other models through the chat interface.\n\nNo warning... No transition period... Just suddenly gone. For businesses locked into annual Teams subscriptions, this is not just unacceptable‚Äîit's a bait and switch. We paid for access to specific capabilities, and they are yanking them away mid-contract.\n\nPro and Teams subscribers can re-enable \"legacy\" models with a toggle button hidden away in Settings‚Äî*for now*. OpenAI's track record shows us that it won't be for long.\n\n**2. GPT 4.5 was the reason I paid for Teams/Pro‚Äînow it's \"legacy\" and soon to be gone**\n\n90% of how I justified the $200/month Pro subscription‚Äîand the Teams subscription for our business‚Äîwas GPT 4.5. For writing tasks, it was unmatched... genuinely SOTA performance that no other model could touch.\n\nNow, it seems like OpenAI might bless us with \"legacy model\" access for a short period through Pro/Teams accounts, and when that ends we‚Äôll have‚Ä¶ the API? That's not a solution for the workflows we rely on.\n\nThere is no real substitute to 4.5 for this use case.\n\n**3. GPT-5 is a massive downgrade for Deep Research**\n\nMy primary use case is Deep Research on complex programming, legal, and regulatory topics. The progression was: o1-pro (excellent) ‚Üí o3-pro (good enough, though o1-pro hallucinated less) ‚Üí GPT-5 (materially worse on every request I have tried thus far).\n\nGPT-5 seems to perform poorly on these tasks compared to o1-pro or o3-pro. It's not an advancement‚Äîit's a step backwards for serious research.\n\n**My humble opinion:**\n\nOpenAI has made ChatGPT objectively worse. But even worse than the performance regression is the breach of trust. Arbitrarily limiting model choice without warning or giving customers the ability to exit their contracts? Not forgivable.\n\nIf GPT-5 was truly an improvement, OpenAI would have introduced it as the default option but allowed their users to override that default with a specific model if desired.\n\nObviously, the true motivation was to achieve cost savings. No one can fault them for that‚Äîthey are burning billions of dollars a year. But there is a right way to do things and this isn't it.\n\nOpenAI has developed a bad habit of retiring models with little or no warning, and this is a dramatic escalation of that pattern. They have lost our trust.\n\nWe are moving everything to Google and Claude, where at least they respect their paying customers enough to not pull the rug out from under them.\n\n***Historical context:***\n\nHere is a list of high-profile changes OpenAI has made over the past 2+ years that demonstrates the clear pattern: they're either hostile to their users' needs or oblivious to them.\n\n* **Mar 23:** Codex API killed with 3 days notice [\\[Hacker News\\]](https://news.ycombinator.com/item?id=35242069)\n* **Jul 23:** Browse with Bing disabled same-day without warning [\\[Medium\\]](https://medium.com/@digitalrachana1997/exclusive-openai-takes-bold-step-disables-chatgpt-browse-with-bing-feature-fcc316e2653b)\n* **Nov 23:** \"Lazy GPT\" phenomenon begins‚Äîmodel refuses tasks [\\[Medium\\]](https://medium.com/@raj.r.shroff/why-did-chatgpt-get-lazy-in-december-516076d0f113)\n* **Jan 24:** Text-davinci-003 and 32 other models retired on \\~3 months notice [\\[OAI\\]](https://openai.com/index/gpt-4-api-general-availability/)\n* **Feb 24:** ChatGPT Plugins discontinued with six weeks notice [\\[Everyday AI\\]](https://www.youreverydayai.com/chatgpt-is-killing-off-plugins-what-it-means/)\n* **Jun 24:** GPT-4-Vision access cut with 11 days notice, new users immediately [\\[Portkey\\]](https://portkey.ai/error-library/model-deprecation-error-10544)\n* **Apr 25:** Deep Research removed from $200/month o1-pro without even announcing it [\\[OpenAI\\]](https://community.openai.com/t/deep-research-removed-from-o1-pro/1267091)\n* **Apr 25:** GPT-4o becomes sycophantic overnight [\\[Hacker News\\]](https://news.ycombinator.com/item?id=43840842) [\\[OpenAI\\]](https://help.openai.com/en/articles/6825453-chatgpt-release-notes)\n* **Jun 25:** o1-pro model removed despite users paying $200/month specifically for it [\\[Open AI\\]](https://community.openai.com/t/is-the-o1-pro-model-gone/1287793)\n* **Aug 25:** GPT-5 forced on all users with mass model retirement\n\nOpenAI seems to think it's cute to keep playing the \"move fast and break things\" startup card, except they're now worth hundreds of billions of dollars and people have rebuilt their businesses and daily workflows around their services. When you're the infrastructure layer for millions of users, you don't get to YOLO production changes anymore.\n\nThis isn't innovation, it's negligence. When AWS, Google, or Microsoft deprecate services, they give 12-24 months notice. OpenAI gives days to weeks, if you're lucky enough to get any notice at all.",
        "url": "https://www.reddit.com/r/artificial/comments/1mlrbre/openais_habit_of_rug_pullingwhy_we_are_moving_on/",
        "publishDate": "2025-08-09T14:52:20Z[Etc/UTC]",
        "author": "jcrivello",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "35",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "liVwp9Ezh34",
        "title": "Cursor CLI (Tested) + Unlimited Free GPT-5: This is A Really GOOD &amp; FULLY FREE CLI AI Coder!",
        "content": "Visit NinjaChat: https://www.ninjachat.ai In this video, I take a deep dive into the new Cursor CLI. It's currently free to use with the ...",
        "url": "https://www.youtube.com/watch?v=liVwp9Ezh34",
        "publishDate": "2025-08-09T09:23:41Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/liVwp9Ezh34/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, Cursor has launched a CLI, which is currently free to use with GPT-5, even if you don't have the premium plan. And I thought I'd talk about this and see how well or worse it performs. Cursor CLI is basically supposed to be Cursor's take on a terminal coder, and it's probably their first thing that isn't forked, which is awesome. It is pretty similar from the get-go to something like Claude Code. The UI is pretty much the same and everything. They had actually hired the Claude Code lead developers for a while, who then went back to Anthropic within a month. Anyway, it has the features that you generally want. Like it can do edits, you can set up rules, as well as use all the models that Cursor has. It is currently free with the GPT-5 model, so that's great. It doesn't seem to have all the features of Claude Code as of now. For example, it doesn't seem to have hooks, sub-agents, or even custom slash commands, which can be a bummer at times. But that's fine, as it's currently in beta, and I hope we see these new features in it as well. Now, let me show you how you can use it. But before proceeding, let me tell you about Ninjachat. Ninjachat is an all-in-one AI platform, where for just $11 per month, you get access to top AI models like GPT-4o, Claude 4 Sonnet, and Gemini 2.5 Pro, all in one place. I've been using Gemini for quick research. But what's really cool is their AI playground where you can compare responses from different models side-by-side. Their mind map generator is a game changer for organizing complex ideas as well. The basic plan gives you 1,000 messages, 30 images, and five videos monthly, with higher tiers available if you need more. Use my code KING25 for 25% off any plan, or KING40YEARLY for 40% off annual subscriptions. Check the link in description to try it yourself. Now, back to the video. To install it, you'd have to run this command, which will get it installed for you. Once it has been installed, you can go ahead and start Cursor with the `cursor-agent` command. And it will ask you to sign in with your Cursor account at first. Just do that and you should be good to go. Once done, this is what it looks like. You can see that this is pretty similar to Claude in terms of how it looks and works as well. The prompt box here is quite similar to how Claude Code's one looks. And you also have some slash commands. Let me tell you about the slash commands as well. To start, you can see the `model` option. To list all models, you can do `/model ls`, which will show you all the models available. Though, it also shows it here as you type `model`. It currently has three models, which are GPT-5, Sonnet 4.1, and Opus 4.1. You can use whichever you want. GPT-5 is currently free, while the Sonnet and Opus models will cost you based on what plan you have. Let's just select GPT-5 here. Now, there's also the `auto-run` option, which allows you to basically set the auto-approval of commands to be on, off, toggle, or check status. Which is also kind of cool. You can also do `/new-chat`, which allows you to create a new thread or chat session. While you also have the `clear` option, which will clear the current session messages. Then there's the `vim` option, which allows you to enable all the Vim keybinds in order to be a pro terminal user. There's also the `help` command to know about anything, as well as the `feedback` command, the `resume` command to resume any previous chat, the `copy-req-id` option, and the `logout` option as well. Now, let me show you it in action, and then I'll also show you my results from testing it. First of all, I'm going to ask it to make me a Minesweeper game using HTML, CSS, and JS. Now, it will go ahead and do it for you. It will think and process, which is what GPT-5 does as well. It doesn't stream the responses, which is pretty interesting, because Claude generally streams the responses, but this doesn't do that. It just lets you know when the task is done, which I'm not a fan of, but that's fine as well. Anyway, in a bit, it will get that done. And you can see that it did this well and without any issues. If we run this, it also works fine, which is awesome. So, that is how it works. Now, I did test it a bit, and I thought I'd talk about my results. I actually also tested the same Kingbench question as well, because many people ask me to do that, and the results are the same. The issue is that the GPT-5 model doesn't use import maps at all, which makes it unable to render Three.js. And it's not just that. There are more issues, like wrong dimensions and stuff. So, it's still a fail in my benchmarks, but the model is not bad at coding. It's fine, but it's not as good as Sonnet or Opus for me. It's more like how GPT-4.1 was, and it's pretty slow as well. So, yeah. Anyway, if we talk about the Cursor CLI, then I used it to do some cool stuff. First of all, I booted it up in an Expo project, and then I asked it to make me a movie tracker app that uses the TMDB API to get the data and things like that. This is one of the tasks that I run to test on my agentic benchmark. And I used it with GPT-5, because that's what they recommend as well. So, I used that. And first of all, one thing that I have seen is that it is super slow. Probably because of GPT-5, but it is really slow, which just throws me off a bit. But considering that, at least for now, it's free. I won't complain. Anyway, it is great at long-running tasks like this one, because my prompt is amazingly long. And there are a ton of features that need to be implemented as well. It was able to keep running until the task was done, which is what I like about Claude Code, RooCode, or Cline as well. So, that is great. Another thing that I liked about it is that it checks for linter errors and tries to write good code and actually edits if there's anything lacking in the code, which is awesome. I have seen Claude Code slack in that area at times. It also commits the changes and everything, which is awesome. Now, this is all good, but the quality is a bit lacking. This might be because of the GPT-5 model, because it's not that good at actual coding. This is what it looks like. I mean, it's extremely basic. This is probably just GPT-5 not being as good. I tried the same thing with Claude Code, and it is insanely better. It has smooth scrolling, multiple sections. You can open up the profile page of everything, the review works, and you have a good profile page and everything as well. I'm pretty sure it's just GPT-5 being bad, but yeah. I think Cursor CLI is good as of now. I don't know if they'll nerf it or something to save their costs, but I think it is good. It lacks some essential features like MCP servers and stuff for now, which is a bit of a bummer, but still, that's fine. It's not anything extraordinary, but if you have a Cursor subscription, or if you're looking to use something for free in the meantime, while GPT-5 is free with it, then I'd highly recommend it. And you can go ahead and give this a try. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "UrUNRqsj44c",
        "title": "Richard Dawkins‚Äô Counterintuitive Theory of Pain",
        "content": "",
        "url": "https://www.youtube.com/watch?v=UrUNRqsj44c",
        "publishDate": "2025-08-09T16:10:00Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/UrUNRqsj44c/hqdefault.jpg",
            "transcription": "Error generating summary: Prompt was blocked: OTHER\ndev.shreyaspatil.ai.client.generativeai.type.PromptBlockedException: Prompt was blocked: OTHER\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:44)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    }
]