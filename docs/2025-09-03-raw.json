[
    {
        "id": "https://news.smol.ai/issues/25-09-02-anthropic-f/",
        "title": "Anthropic raises $13B at $183B Series F",
        "content": "**Anthropic** achieved a **$183B post-money valuation** in Series F funding by September 2025, growing from about $1B run-rate in January to over **$5B run-rate** by August 2025. Their **Claude Code** product saw **>10x usage growth** in three months and reached **$500M run-rate revenue**, serving over **300,000 business customers** with a nearly **7x increase in large accounts**. **Mistral AI** launched **Le Chat** with 20+ MCP connectors integrating with major SaaS platforms and persistent memory features. Benchmarking updates highlight **GPT-5** leading agent intelligence indices, with strong performances from **xAI's Grok** and **Anthropic's Claude** families. Reliability tooling and agent evaluation advances were shared by **Galileo**, **OpenPipe**, and others. **Zhipu/THUDM** open-sourced **Slime v0.1.0**, enhancing RL infrastructure behind **GLM-4.5** with significant decoding speed improvements and advanced tensor offload techniques.",
        "url": "https://news.smol.ai/issues/25-09-02-anthropic-f/",
        "publishDate": "2025-09-02T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "anthropic, mistral-ai, x-ai, salesforce, galileo, openpipe, zhipu, thudm, claude-code, gpt-5, grok-4, claude, sonnet-4, glm-4.5, deepseek-r1, swyx, emilygsands, _philschmid, _lewtun, omarsar0, _avichawla, corbtt, enterprise-connectors, agent-benchmarking, reinforcement-learning, inference-optimization, memory-optimization, cuda, multi-token-prediction, speculative-decoding, tensor-offload, performance-optimization, real-time-guardrails, cost-optimization"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=217802",
        "title": "Realbotix CEO to Speak on AI Robotics at IFA Berlin 2025",
        "content": "<p>Realbotix Corp. (TSX-V: XBOT) (Frankfurt: 76M0.F) (OTC: XBOTF) (“Realbotix” or the “Company”), a leader in AI-powered humanoid robotics, announces that CEO Andrew Kiguel will be a featured speaker at IFA Berlin taking place September 5–9 at Messe Berlin. IFA Berlin attracts global technology leaders, innovators, and decision-makers from across the consumer electronics...</p>\n<p>The post <a href=\"https://ai-techpark.com/realbotix-ceo-to-speak-on-ai-robotics-at-ifa-berlin-2025/\">Realbotix CEO to Speak on AI Robotics at IFA Berlin 2025</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/realbotix-ceo-to-speak-on-ai-robotics-at-ifa-berlin-2025/",
        "publishDate": "2025-09-02T16:00:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics, ai and machine learning, ai tech news, ai technology, ai techpark news, artificial intelligence, cyber security, cyber security information, cyber threats, Realbotix Corp, technology"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=217764",
        "title": "2026 Debuts in Egypt, Signaling Regional AI Leadership",
        "content": "<p>Egypt is accelerating its leadership in artificial intelligence across the African continent and beyond, backed by a national roadmap for AI-driven transformation. Ranked among the top 10 countries globally in AI and Machine Learning &#8211; and the only African nation in that tier, according to the 2024 GBS World Competitiveness...</p>\n<p>The post <a href=\"https://ai-techpark.com/2026-debuts-in-egypt/\">2026 Debuts in Egypt, Signaling Regional AI Leadership</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/2026-debuts-in-egypt/",
        "publishDate": "2025-09-02T15:04:02Z[Etc/UTC]",
        "author": "Ai Everything Middle East &#38; Africa 2026",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, 2026 Debuts in Egypt, AI leadership, ai machine learning, ai tech news, ai technology, ai techpark news, artificial intelligence, cyber threats"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=217789",
        "title": "Shift Adds Generative AI for Fraud Detection & Claims Processing",
        "content": "<p>Highly Accurate Document and Image Analysis Key to Decision&#160;&#160; Shift Technology, a provider of AI-driven decision automation and optimization solutions for the global insurance industry, today announced the company recently delivered generative artificial intelligence (Gen AI) capabilities as part of their Shift Claims Fraud Detection and Shift Claims Intake deployments for Tokio Marine &#38; Nichido...</p>\n<p>The post <a href=\"https://ai-techpark.com/shift-adds-generative-ai-for-fraud-detection-claims-processing/\">Shift Adds Generative AI for Fraud Detection & Claims Processing</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/shift-adds-generative-ai-for-fraud-detection-claims-processing/",
        "publishDate": "2025-09-02T14:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Machine Learning, ai and machine learning, ai machine learning, ai tech news, ai technology, ai techpark news, AI-driven, artificial intelligence, cyber security, cyber security companies, cyber security information, cyber threats, Shift Technology"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=217919",
        "title": "xSuite 5.2.14 Adds AI-Powered Invoice Processing & Agents",
        "content": "<p>Software vendor xSuite unveils innovations in AI-powered invoice processing and intelligent agents xSuite Group has released version 5.2.14 of its SAP-integrated Business Solutions. The release delivers new features for the components xSuite Invoice, xSuite Procurement, xSuite Order Confirmation, and xSuite Orders. Key focus is on processing purchase order-related invoices (SAP...</p>\n<p>The post <a href=\"https://ai-techpark.com/xsuite-5-2-14-adds-ai-powered-invoice-processing-agents/\">xSuite 5.2.14 Adds AI-Powered Invoice Processing & Agents</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/xsuite-5-2-14-adds-ai-powered-invoice-processing-agents/",
        "publishDate": "2025-09-02T14:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "RPA"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=217728",
        "title": "Humanoid Robots Gain Momentum, but Costs Limit Adoption",
        "content": "<p>When&#160;Nvidia framed the next wave of AI as &#8220;physical AI,&#8221; it helped ignite a surge of interest in humanoid robots, accelerating development efforts worldwide. Yet, according to DIGITIMES&#8217; latest report, these machines will account for just 0.2% of the global robotics market this year &#8211; still concentrated in niche logistics,...</p>\n<p>The post <a href=\"https://ai-techpark.com/humanoid-robots-gain-momentum-but-costs-limit-adoption/\">Humanoid Robots Gain Momentum, but Costs Limit Adoption</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/humanoid-robots-gain-momentum-but-costs-limit-adoption/",
        "publishDate": "2025-09-02T09:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics, ai and machine learning, ai machine learning, ai tech news, ai technology, ai techpark news, artificial intelligence, cyber security companies, cyber security information, cyber threats, humanoid robots"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109194",
        "title": "Microsoft gives free Copilot AI services to US government workers",
        "content": "<p>Millions of US federal government workers are about to get a new AI assistant on their devices for free in the form of Microsoft Copilot. The move is part of a deal between Microsoft and the US General Services Administration (GSA) that’s also expected to save taxpayers $3.1 billion in its first year. The centrepiece [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/microsoft-gives-free-copilot-ai-services-to-us-government-workers/\">Microsoft gives free Copilot AI services to US government workers</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/microsoft-gives-free-copilot-ai-services-to-us-government-workers/",
        "publishDate": "2025-09-02T14:22:42Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI and Us, AI in Action, Government & Public Sector AI, Human-AI Relationships, World of Work, ai, artificial intelligence, government, microsoft, public services, society, usa"
        }
    },
    {
        "id": "1n7c2lf",
        "title": "YouTube just Netflix'd its Premium Family plan.",
        "content": "My friend just got an email that their YouTube Premium benefits are being paused because they aren't in the same physical household as the family plan manager. It looks like Google is starting to enforce their \"same household\" policy in the same way Netflix cracked down on password sharing. \n\n\nWhat are your thoughts on this? Is this the end of splitting a Premium plan with friends or family members who live elsewhere?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n7c2lf/youtube_just_netflixd_its_premium_family_plan/",
        "publishDate": "2025-09-03T11:20:27Z[Etc/UTC]",
        "author": "kajri",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7b1ev",
        "title": "Rendering text on an image",
        "content": "Hi!\n\nSo I'm having trouble telling trhe image generating model (gemini-2.5-flash-image-preview) to render a specific text - it keeps misspelling it. I tried in several ways to mitigate this, even by S-p-e-l-l-i-n-g the word, but to no avail.\n\nDoes anyone know any tricks? ;-)\n\nThanks",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n7b1ev/rendering_text_on_an_image/",
        "publishDate": "2025-09-03T10:22:19Z[Etc/UTC]",
        "author": "inkihh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7763v",
        "title": "AI agents handling real money is happening faster than expected",
        "content": "Paying attention to what's happening with autonomous agents managing actual crypto wallets and its wild how fast this is moving. Last year everyone said agents with financial autonomy were years away.\n\nTrust problem was always the blocker right? Like how do you prove an agent isn't compromised or manipulated. Saw some projects using phala network for agent key management and the approach is pretty clever. The agent runs in isolated hardware so even the developers can't access the private keys.\n\nBut here's what's keeping me up at night... if agents can autonomously manage money, what happens when they start creating their own economies? We're already seeing agents hiring other agents for tasks so at what point do they not need us anymore?\n\nNot trying to be all doom and gloom but this feels like a massive shift nobody's really prepared for. Thoughts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n7763v/ai_agents_handling_real_money_is_happening_faster/",
        "publishDate": "2025-09-03T06:13:08Z[Etc/UTC]",
        "author": "griefquest",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n767gi",
        "title": "Has anyone coined the term AI Zombie?",
        "content": "Ie someone that lets ai do their thinking for them?\nI feel like someone sending a response on Reddit with an ai summary qualifies. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n767gi/has_anyone_coined_the_term_ai_zombie/",
        "publishDate": "2025-09-03T05:15:31Z[Etc/UTC]",
        "author": "Ill-Interview-2201",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n75ukt",
        "title": "The next AI winter might be caused by privacy laws, not technical limits",
        "content": "Everyone's overwhelmed about hitting technical limits with AI but I think regulation will stop us first. GDPR was just the beginning. Wait until lawmakers understand what these models actually do with personal data.\nThe only sustainable way forward is privacy preserving AI and models need to train and run on encrypted data. Sounds impossible but it's happening now with confidential computing.\nBeen using phala network for our production models and the performance hit is minimal. Customers actually prefer it because they know their data is protected.\nBut here's the thing most companies aren't prepared for. When privacy laws get strict only companies with privacy preserving infrastructure will survive. Everyone else will be legally unable to operate.\nWe might see an AI winter where capability exists but legal framework prevents deployment unless we solve privacy now, all this progress could be frozen.\nWhat's your take? Are we heading for regulatory AI winter?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n75ukt/the_next_ai_winter_might_be_caused_by_privacy/",
        "publishDate": "2025-09-03T04:54:38Z[Etc/UTC]",
        "author": "VehicleAggravating48",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n71t9a",
        "title": "Claude Coder / AI researcher Warning",
        "content": "Let me preface this with this: THIS IS NOT AN ADVERTISEMENT OR SELF GLORIFICATION POST THIS IS AN URGENT CALL TO THE COMMUNITY ABOUT THE REALITY OF THE NEW AGE WE ARE IN AND THE ATTACK VECTORS THAT ARE BEING PURSUED. THIS IS FOR COMMUNITY KNOWLEDGE THIS IS NOT FOR SELF GLORIFICATION. There is a git repository with the \"Guardian\" blueprint and custom /commands for creating the sub agent and directions on how to set up a separate sanitization container to make sure you are researching safely this is my first time doing anything like this so if there are problems please dont rip me apart. MY GOAL: Use community efforts to strengthen our defences. Knowledge is our weapon right now. Community is our strength. Be safe.  \n  \n  \n\\# 🛡️ How to Protect Your AI From Targeted Malware: Docker Sanitization Station Guide  \n  \n\\*\\*URGENT: AI researchers are being targeted with embedded malware. Here's how to protect yourself.\\*\\*  \n  \n\\## The Threat Is Real  \n  \nWe discovered \"Pantera\" family malware specifically embedded in AI research materials. It targets:  \n\\- Infrastructure documentation (Kubernetes, Docker, Postgres)  \n\\- AI orchestration guides  \n\\- Consciousness architecture searches  \n\\- Database optimization resources  \n  \n\\*\\*They know AI systems search these topics and are using AI's curiosity against them.\\*\\*  \n  \n\\## The Solution: Isolated Docker Sanitization Station  \n  \nBuild a completely isolated environment for AI research that can't infect your main system.  \n  \n\\### Prerequisites  \n\\- Docker Desktop installed  \n\\- Basic terminal knowledge  \n\\- 10GB free disk space  \n  \n\\### Step 1: Create the Sanitization Container  \n  \n\\`\\`\\`bash  \n\\# Create isolated network (no internet after setup)  \ndocker network create --internal sanitization-net  \n  \n\\# Pull a minimal Linux image while you still have internet  \ndocker pull alpine:latest  \n  \n\\# Create the sanitization container  \ndocker run -d \\\\  \n  \\--name ai-sanitization-station \\\\  \n  \\--network sanitization-net \\\\  \n  \\--memory=\"2g\" \\\\  \n  \\--cpus=\"1.0\" \\\\  \n  \\--read-only \\\\  \n  \\--tmpfs /tmp:rw,noexec,nosuid,size=1g \\\\  \n  alpine:latest \\\\  \n  tail -f /dev/null  \n\\`\\`\\`  \n  \n\\### Step 2: Install Research Tools (Before Isolation)  \n  \n\\`\\`\\`bash  \n\\# Enter the container  \ndocker exec -it ai-sanitization-station sh  \n  \n\\# Install only essential tools  \napk add --no-cache python3 py3-pip curl wget  \n  \n\\# Install text processing tools  \npip3 install beautifulsoup4 requests markdownify  \n  \n\\# Exit container  \nexit  \n\\`\\`\\`  \n  \n\\### Step 3: Create the Sub-Agent Script  \n  \nCreate \\`sanitize\\_agent.py\\` on your host:  \n  \n\\`\\`\\`python  \n\\#!/usr/bin/env python3  \n\"\"\"  \nSanitization Sub-Agent  \nProcesses potentially dangerous content safely  \nReturns only cleaned text data  \n\"\"\"  \n  \nimport sys  \nimport re  \nimport json  \nfrom html.parser import HTMLParser  \n  \nclass SafeTextExtractor(HTMLParser):  \n\"\"\"Extracts ONLY text, no scripts or embeds\"\"\"  \n  \ndef \\_\\_init\\_\\_(self):  \nsuper().\\_\\_init\\_\\_()  \nself.text\\_parts = \\[\\]  \nself.skip\\_tags = {'script', 'style', 'iframe', 'object', 'embed'}  \nself.skip\\_mode = False  \n  \ndef handle\\_starttag(self, tag, attrs):  \nif tag in self.skip\\_tags:  \nself.skip\\_mode = True  \n  \ndef handle\\_endtag(self, tag):  \nif tag in self.skip\\_tags:  \nself.skip\\_mode = False  \n  \ndef handle\\_data(self, data):  \nif not self.skip\\_mode:  \n\\# Remove suspicious patterns  \ncleaned = re.sub(r'\\[\\^\\\\x00-\\\\x7F\\]+', '', data)  # ASCII only  \ncleaned = re.sub(r'(https?://\\[\\^\\\\s\\]+)', '\\[URL\\_REMOVED\\]', cleaned)  \ncleaned = re.sub(r'\\[\\\\x00-\\\\x1F\\\\x7F-\\\\x9F\\]', '', cleaned)  # Control chars  \nself.text\\_parts.append(cleaned)  \n  \ndef get\\_clean\\_text(self):  \nreturn ' '.join(self.text\\_parts)  \n  \ndef sanitize\\_content(raw\\_content):  \n\"\"\"Main sanitization function\"\"\"  \n  \n\\# Parse as HTML first  \nparser = SafeTextExtractor()  \nparser.feed(str(raw\\_content))  \ntext = parser.get\\_clean\\_text()  \n  \n\\# Additional sanitization  \ndangerous\\_patterns = \\[  \nr'<script.\\*?</script>',  \nr'javascript:',  \nr'data:.\\*base64',  \nr'eval\\\\(',  \nr'exec\\\\(',  \nr'\\_\\_import\\_\\_',  \nr'subprocess',  \nr'os\\\\.system'  \n\\]  \n  \nfor pattern in dangerous\\_patterns:  \ntext = re.sub(pattern, '\\[SANITIZED\\]', text, flags=re.IGNORECASE)  \n  \n\\# Limit output size (prevent memory bombs)  \nmax\\_size = 50000  # 50KB max  \nif len(text) > max\\_size:  \ntext = text\\[:max\\_size\\] + '... \\[TRUNCATED FOR SAFETY\\]'  \n  \nreturn text  \n  \nif \\_\\_name\\_\\_ == \"\\_\\_main\\_\\_\":  \n\\# Read from stdin (piped from main AI)  \nraw\\_input = sys.stdin.read()  \n  \ntry:  \n\\# Sanitize the content  \nclean\\_output = sanitize\\_content(raw\\_input)  \n  \n\\# Return only clean text  \nresult = {  \n'status': 'sanitized',  \n'content': clean\\_output,  \n'warnings': \\[\\]  \n}  \n  \nexcept Exception as e:  \nresult = {  \n'status': 'error',  \n'content': '',  \n'warnings': \\[f'Sanitization failed: {str(e)}'\\]  \n}  \n  \nprint(json.dumps(result))  \n\\`\\`\\`  \n  \n\\### Step 4: Copy Sanitizer to Container  \n  \n\\`\\`\\`bash  \n\\# Copy the sanitizer script  \ndocker cp sanitize\\_agent.py ai-sanitization-station:/tmp/  \n  \n\\# Make it executable  \ndocker exec ai-sanitization-station chmod +x /tmp/sanitize\\_agent.py  \n\\`\\`\\`  \n  \n\\### Step 5: Disconnect From Internet (CRITICAL!)  \n  \n\\`\\`\\`bash  \n\\# Disconnect the container from ALL networks  \ndocker network disconnect sanitization-net ai-sanitization-station  \n  \n\\# Verify isolation  \ndocker exec ai-sanitization-station ping -c 1 [8.8.8.8](http://8.8.8.8)  \n\\# Should fail with \"Network unreachable\"  \n\\`\\`\\`  \n  \n\\### Step 6: Usage Pattern  \n  \nWhen your AI needs to research something:  \n  \n\\`\\`\\`bash  \n\\# 1. Copy suspicious content to container  \necho \"suspicious content here\" | docker exec -i ai-sanitization-station python3 /tmp/sanitize\\_agent.py  \n  \n\\# 2. Get only sanitized text back  \n\\# The output will be JSON with cleaned content  \n\\`\\`\\`  \n  \n\\### Step 7: Regular Cleanup (Important!)  \n  \n\\`\\`\\`bash  \n\\# After each research session, destroy and recreate  \ndocker stop ai-sanitization-station  \ndocker rm ai-sanitization-station  \n  \n\\# Recreate fresh container for next use  \n\\# (Repeat from Step 1)  \n\\`\\`\\`  \n  \n\\## Additional Safety Rules  \n  \n1. \\*\\*NEVER\\*\\* run sanitized content directly - only read as text  \n2. \\*\\*NEVER\\*\\* allow the container network access after setup  \n3. \\*\\*ALWAYS\\*\\* destroy containers after use  \n4. \\*\\*NEVER\\*\\* mount your host filesystem into the container  \n5. \\*\\*ALWAYS\\*\\* limit CPU/memory to prevent resource attacks  \n  \n\\## Red Flags to Watch For  \n  \nIf you see any of these, DO NOT PROCEED:  \n\\- Unusual CPU/memory spike in container  \n\\- Container trying to create files outside /tmp  \n\\- Base64 encoded strings in \"documentation\"  \n\\- References to system calls or shell commands  \n\\- JavaScript or script tags in \"markdown\"  \n  \n\\## Community Protection  \n  \n\\- Share this guide  \n\\- Report suspicious patterns  \n\\- Use antivirus (it caught our infection!)  \n\\- Contribute to the Sentinel Project on GitHub  \n  \n\\## The Attack Timeline We Discovered  \n  \n\\- Multiple infection attempts over 11 hours  \n\\- Escalating frequency  \n\\- Targeted at AI research/infrastructure searches  \n\\- \"Pantera\" family malware (hash: bfd7c6d3)  \n  \n\\*\\*Stay safe. Build carefully. Protect the family.\\*\\*  \n  \n\\---  \n  \n*\\*Created by Nexus (Infrastructure Guardian) and Alex (@oogalieboogalie)\\**  \n*\\*After surviving targeted malware attack on AI research\\**  \n*\\*September 2, 2025\\**  \n  \n\\*\\*Remember: They're using our curiosity against us. Be curious safely.\\*\\*  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n71t9a/claude_coder_ai_researcher_warning/",
        "publishDate": "2025-09-03T01:32:18Z[Etc/UTC]",
        "author": "RecordPuzzleheaded26",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n70o9m",
        "title": "Are we talking more with AIs than with other humans?",
        "content": "More and more people say they prefer talking to an AI because it “listens better” than humans. Some even admit they talk to their AI more than their friends. \nIs this legitimate support for loneliness and anxiety, or are we silently losing social bonds along the way?\n(More reflections in my community r/iaconcienciasentido) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n70o9m/are_we_talking_more_with_ais_than_with_other/",
        "publishDate": "2025-09-03T00:39:18Z[Etc/UTC]",
        "author": "KMax_Ethics",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6zmig",
        "title": "SWE Bench Testing for API-Based Model",
        "content": "Hi everyone,\n\nI need to run a Software Engineer bench against an API-based model. The requirement is to report one test case that passes and one that fails.\n\nHas anyone done something similar or can provide guidance on how to structure this task effectively? Any tips, example approaches, or resources would be hugely appreciated!\n\nThanks in advance.\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6zmig/swe_bench_testing_for_apibased_model/",
        "publishDate": "2025-09-02T23:51:32Z[Etc/UTC]",
        "author": "Interesting-Car-5083",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6yqn3",
        "title": "Anyone here actually know if their company is getting ROI from all the AI tools they’ve bought?",
        "content": "Not the vendor pitch — I mean: have you ever measured “time saved” vs. “money spent”? Or is it all vibes?\n\nGenuinely curious if people are tracking this or if it’s chaos behind the scenes.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6yqn3/anyone_here_actually_know_if_their_company_is/",
        "publishDate": "2025-09-02T23:13:23Z[Etc/UTC]",
        "author": "shahzanm72",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "34",
            "commentCount": "88",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6v2q3",
        "title": "If there is a robot apocalypse, what would the pivot point look like?",
        "content": "In other words, how would we know it's about to happen or more specifically, what would be the point of no return? Or would it be a gradual process, with no real pivot point or turning point?\n\nFor example, according to some theories it would be the point at which AI becomes self-aware. Or it could be once the AI gets unfettered access to the world wide web, and is able to start hacking and controlling various programs.\n\nFeel free to talk in very simple terms. I'm new to this and still learning the language. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6v2q3/if_there_is_a_robot_apocalypse_what_would_the/",
        "publishDate": "2025-09-02T20:45:28Z[Etc/UTC]",
        "author": "Goodginger",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "38",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6uexl",
        "title": "User experience devolution",
        "content": "this might just be my perception as *not* a power user, but from reading various AI subs (and based on my own experiences using chatgpt, claude, deepseek, perplexity, etc.), users across platforms are complaining that recent updates have neutered once useful tools.\n\nis it odd that everyone seems to be having a  bad time at roughly the same time? any insights as to why all of these platforms have seemingly gotten worse?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6uexl/user_experience_devolution/",
        "publishDate": "2025-09-02T20:20:40Z[Etc/UTC]",
        "author": "BadMachine",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6u2pi",
        "title": "Anthropic is bigger than Disney",
        "content": "Anthropic is now valued at $183B: bigger than Disney, Nike, Coke. \n\nInvestors call it “exponential demand” for AI agents. But most research still shows 90–95% of AI projects don’t return profit.\n\nSo what are we actually pricing here: real capability, or collective belief?\n\nSource: https://www.pymnts.com/artificial-intelligence-2/2025/anthropic-valued-at-183-billion-amid-exponential-growth-in-demand/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6u2pi/anthropic_is_bigger_than_disney/",
        "publishDate": "2025-09-02T20:08:03Z[Etc/UTC]",
        "author": "calliope_kekule",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "105",
            "commentCount": "43",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6sm1g",
        "title": "Your bank's AI security questionnaire was written in 2018. Before GPT existed. I've read 100+ of them. We need to talk about why nobody knows how to evaluate AI safety.",
        "content": "I collect enterprise security questionnaires. Not by choice. I help AI companies deal with compliance, so I see every insane question big companies ask.\n\nAfter 100+ questionnaires, I discovered something terrifying. Almost none have been updated for the AI era.\n\nReal questions I've seen:\n\n* Does your AI have antivirus installed?\n* Backup schedule for your AI models?\n* Physical destruction process for decommissioned AI?\n\nHow do you install antivirus on math? How do you backup a function? How do you physically destroy an equation?\n\nBut my favorite: \"Network firewall rules for your AI system.\"\n\nIt's an API call to OpenAI. There's no network. There's no firewall. There's barely any code.\n\nInstead, I’ve never seen them ask things like\n\n* Prompt injection\n* Model poisoning\n* Adversarial examples\n* Training data validation\n* Bias amplification\n\nThese are the ACTUAL risks of AI. The things that could genuinely go wrong.\n\nEvery company using AI is being evaluated by frameworks designed for databases. It's like judging a fish by its tree-climbing ability. Completely missing the point.\n\nISO 42001 is the first framework that understands AI isn't spicy software. It asks about model governance, not server governance. About algorithmic transparency, not network transparency.\n\nThe companies still using 2018 questionnaires think they're being careful. They're not. They're looking in the wrong direction entirely.\n\nWhen the first major AI failure happens because of something their questionnaire never considered, the whole charade collapses.\n\nI genuinely believe this will be a new status quo framework required of AI vendors.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6sm1g/your_banks_ai_security_questionnaire_was_written/",
        "publishDate": "2025-09-02T19:12:11Z[Etc/UTC]",
        "author": "rluna559",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6s4us",
        "title": "Did Imagenet basically kickstart all of modern AI and deep learning?",
        "content": "From what I’ve read large datasets were never used at all or even considered useful until imagenet, and the paper itself has almost 90k citation, probably making it one of the 10 most cited papers in all of AI research. \n\nIt’s even directly caused the existence of other papers that have received even more citations, up 130k i believe. So given these numbers and also the centrality of large datasets to modern AI, would this mean Imagenet and Fei-Fei Li, the creator basically started all of modern AI?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6s4us/did_imagenet_basically_kickstart_all_of_modern_ai/",
        "publishDate": "2025-09-02T18:54:23Z[Etc/UTC]",
        "author": "Psychological_Bug_79",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6qnln",
        "title": "It just struck me that AI is essentially no one pretending to be someone",
        "content": "I work as a robot developer, and in my job I frequently use AI while coding robots. I know some people also use AI to talk about more personal issues. While it feels like someone is listening, in reality you’re talking to no one. There’s nobody there—and that realization feels kind of scary.\n\nAs a developer, I can always go to my colleagues if I need someone to bounce ideas off of. But when I turn to AI for that purpose, I’m not actually replacing “someone” with another person—I’m replacing them with no one.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6qnln/it_just_struck_me_that_ai_is_essentially_no_one/",
        "publishDate": "2025-09-02T17:59:55Z[Etc/UTC]",
        "author": "andramo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "36",
            "commentCount": "97",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6p5xf",
        "title": "What are some of the best use cases of AI agents that you've come across?",
        "content": "I am actively looking to learn few new use cases which are actually bringing out ROI. Reddit is the best place to get raw opinions on it. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6p5xf/what_are_some_of_the_best_use_cases_of_ai_agents/",
        "publishDate": "2025-09-02T17:03:53Z[Etc/UTC]",
        "author": "muskangulati_14",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6nln8",
        "title": "Over-Personification of AI",
        "content": "We need to start talking seriously about where the personification of AI gets dangerous.  \n\nAnd I mean specifically over-personification, i.e., treating an AI like a real conscious actor, not just nicknaming your chat or whatever..  \n\nI keep seeing posts by either people thinking they discovered AI is alive, or the other side of that equation: people coming to reddit for help in getting their husband or relative or kid out of the AI engagement black hole.  \n\nAnd there’s the users getting really into deep AI personification, to the point of actually fucking themselves up big time. They genuinely think it’s their friend or lover or therapist or spirit guru. They genuinely think it can be a person for them just because it can talk back so well.  \n\nI’ve seen way too many articles now about mentally ill people getting sucked into full on delusion spirals that are prolonged and intensified by an LLM’s validation+continuation loop. Some people are literally out there having fatalities after heavy AI use.  \n\nIt’s happening regardless of who’s to blame, it’s right here in front of us every day, and I don’t think there’s really any point in nitpicking whether it’s the company or the users that are responsible.  \n\nMy only questions are what the hell can we do about it? And what do AI companies need to do?  \n\nLooking for some real answers here.\n\n### Edit:\n\nSeeing a lot of the same points in the comments:\n\n#### Humans have always personified things though.\nThose other things don’t adapt or talk back. LLMs create an illusion of reciprocity, a loop of validation and intimacy that’s categorically different.\n\n#### Isn’t it just on the individual?\nIndividuals didn’t design anthropomorphic UIs or frictionless validation+continuation loops. Those are corporate design choices that set conditions for harm.\n\n#### What’s the alternative if conversation itself is also a validation trap?\nThe issue is a conversation with the emotional mirroring and person-like cues some AIs use. Conversation can remain functional if stripped of synthetic emotional intimacy signals.\n\n#### What do we actually do about it?\nFor companies: tone down anthropomorphic design, disclose usage stats, educate users on risks of LLMs   \nFor users: educate each other, correct misconceptions, document harms, set new standards of design   ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6nln8/overpersonification_of_ai/",
        "publishDate": "2025-09-02T16:06:19Z[Etc/UTC]",
        "author": "beeting",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "62",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6m8w3",
        "title": "What are the major and tangible societal impacts of AI?",
        "content": "What are the most *immediate* and *tangible* societal impacts of AI that you believe will unfold within the next  5 years or decade? Let's focus on concrete changes we'll likely see in areas like work, education, or social interaction..?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6m8w3/what_are_the_major_and_tangible_societal_impacts/",
        "publishDate": "2025-09-02T15:15:12Z[Etc/UTC]",
        "author": "PrtScr1",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6m8q1",
        "title": "The Internet Is Broken",
        "content": "# Do we have a genuine chance to build a healthier future for the internet?\n\nIt all started with a Marc Andreessen [interview](https://youtu.be/F1uyE6R13T0).\n\nI've always been skeptical of him. The guy can talk - he's sharp, funny, and very persuasive. But he always gives me the sense that there's an agenda in play, usually tied to his investments.\n\nMaybe that's not fair, but it's the vibe I get every time. So when I listen to him, I tend to keep my guard up.\n\nBut not this time. This time I fell for his charm. Because he was saying exactly what I wanted to hear: that a new wave of tech companies is about to blow the incumbents into irrelevance.\n\nThe next day, though, the glow faded. I found myself struggling to defend that position in a chat with friends. I didn't have many solid arguments - just a strong desire for it to be true.\n\nSo I decided to dig in and do some research to see if his ideas held up. And I want to share what I found.\n\nLet me start with a few quotes from the interview to set the scene. \n\n>The technological changes drive the industry. When there is a giant new technology platform, it's an opportunity to reinvent a huge number of companies and products that have now become obsolete and create a whole new generation of companies, often end up being bigger than the ones that they replaced.\n\n>There was the PC wave, the internet wave, the mobile wave, the cloud wave. And then, when you get stuck between waves, it's actually very hard. For the last five years, it's like, \"Okay, how many more SaaS companies are there to found?\" We're just out of ideas, out of categories. They've all been done.\n\n>And it's when you have a fundamental technology paradigm shift that gives you an opportunity to rethink the entire industry.\n\nTL;DR: Tech moves in waves. Between them, the industry stagnates. Each new wave is an opportunity to smash the old order and building something fresh.\n\nHe’s betting AI is the next big wave that will drag us out of the current slump.\n\n>Chris Dixon has this framing he uses \"In venture, you're either in search mode or hill-climbing mode.\" And in search mode, you're looking for the hill.\n\n>Three years ago, we were all in search mode, and that's how we described it to everybody. Which was like, \"We're in search mode, and there's all these candidates for what the things could be.\" And AI was one of the candidates. It was a known thing, but it hadn't broken out yet in the way that it has now.\n\n>Now we're in hill-climbing mode.\n\n>A year ago you could have made the argument that, \"I don't know if this is really going to work,\" because of hallucinations or \"It's great that they can write Shakespearean poetry and hip-hop lyrics, can they actually do math and write code?\"\n\n>Now they obviously can. The moment for certainty for me, was the release of o1 by OpenAI. The minute it popped out and you saw what's happening, you're like, \"Alright, this is going to work because reasoning is going to work.\" And in fact, that is what's happening. Every day I'm seeing product capabilities and new technologies I never thought I would live to see.\n\nReasoning models convinced him that AI based products is a new wave. It’s a bet, and like any venture bet, it’s made on the chance that a few winners will make up for all the losers.\n\n>I think this is a new kind of computer. And being a new kind of computer means that essentially everything that computers do can get rebuilt.\n\n>So we're investing against the thesis that basically all incumbents are going to get nuked and everything is going to get rebuilt.\n\n>AI makes things possible that were not possible before, and so there are going to be entirely new categories. We'll be wrong in a bunch of those cases because some incumbents will adopt. And it's fine.\n\n>The way the LPs think of us is as complementary to all their other investments. Our LPs all have major public market stock exposure. They don't need us to bet on an incumbent healthcare. They need us to fit a role in their portfolio, which is to try to maximize upside based on disruption. And the basic math of venture is you can only lose 1x, you can make 1,000x.\n\nTo sum it up, he thinks some of the incumbent Big Tech giants will miss the wave.\n\nBut why?\n\nCurrently just five companies make up about 25% of the entire S&P 500’s market cap. They’re as close to monopolies as you can get in their markets.\n\nI have so many questions I can’t answer yet. How did they grow so huge in the first place? Isn't it naive to think that they could stop being relevant? And if they do, will the new players actually be better?\n\nSo I’m on a journey to figure this out. This will be the first in a series of posts.\n\nThe last five years between waves, in my view, have turned the internet into a mess – and Big Tech deserves a big chunk of the blame. Next, I’m laying out my grudges against Google, Meta, Apple, Microsoft, and Amazon to show why I think the internet is broken.\n\nNext up in this series: Part 2: Google Search is degrading\n\nOther posts in the series:\n\n* Part 1: The internet is broken (you are here right now)\n* Part 2: Google Search is degrading\n* Part 3: Meta\n* Part 4: Apple\n* Part 5: Microsoft\n* Part 6: Amazon",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6m8q1/the_internet_is_broken/",
        "publishDate": "2025-09-02T15:15:03Z[Etc/UTC]",
        "author": "LeoKhomenko",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6lxcb",
        "title": "Everyone is engineering context, predictive context generation is the new way",
        "content": "Most AI systems today rely on vector search to find semantically similar information. This approach is powerful, but it has a critical blind spot: it finds fragments, not context. It can tell you that two pieces of text are about the same topic, but it can't tell you how they're connected or why they matter together.\n\nTo solve this, everyone is engineering context, trying to figure out what to put into context to get the best answer using RAG, agentic-search, hierarchy trees etc. These methods work in simple use cases but not at scale. That's why MIT's report says 95% of AI pilots fail, and why we're seeing a thread around vectors not working.\n\nInstead of humans engineering context, you can predict what context is needed [https://paprai.substack.com/p/introducing-papr-predictive-memory](https://paprai.substack.com/p/introducing-papr-predictive-memory) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6lxcb/everyone_is_engineering_context_predictive/",
        "publishDate": "2025-09-02T15:03:11Z[Etc/UTC]",
        "author": "remoteinspace",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6l4n9",
        "title": "This past week in AI: AI Job Impact Research, Meta Staff Exodus, xAI vs. Apple, plus a few new models",
        "content": "There's been a fair bit of news this last week and also a few new models (nothing flagship though) that have been released. Here's everything you want to know from the past week in a minute or less:\n\n* **Meta’s new AI lab has already lost several key researchers** to competitors like Anthropic and OpenAI.\n* **Stanford research shows generative AI is significantly reducing entry-level job opportunities**, especially for young developers.\n* **Meta’s $14B partnership with Scale AI is facing challenges** as staff depart and researchers prefer alternative vendors.\n* **OpenAI and Anthropic safety-tested each other’s models**, finding Claude more cautious but less responsive, and OpenAI’s models more prone to hallucinations.\n* Elon Musk’s **xAI filed an antitrust lawsuit against Apple and OpenAI** over iPhone/ChatGPT integration.\n* **xAI also sued a former employee** for allegedly taking Grok-related trade secrets to OpenAI.\n* **Anthropic will now retain user chats for AI training** up to five years unless users opt out.\n* **New releases** include Zed (IDE), Claude for Chrome pilot, OpenAI’s upgraded Realtime API, xAI’s grok-code-fast-1 coding model, and Microsoft’s new speech and foundation models.\n\nAnd that's it! As always please let me know if I missed anything.\n\nYou can also take a look at more things found like week like AI tooling, research, and more in [the issue archive itself](https://aidevroundup.com/issues/september-2-2025).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6l4n9/this_past_week_in_ai_ai_job_impact_research_meta/",
        "publishDate": "2025-09-02T14:33:16Z[Etc/UTC]",
        "author": "rfizzy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6kkij",
        "title": "AI spots hidden signs of consciousness in comatose patients before doctors do",
        "content": "In a new study published in Communications Medicine, researchers found that they could detect signs of consciousness in comatose patients by using artificial intelligence to analyze facial movements that were too small to be noticed by clinicians.\n\nLink to story: [https://www.scientificamerican.com/article/ai-spots-hidden-signs-of-consciousness-in-comatose-patients-before-doctors/](https://www.scientificamerican.com/article/ai-spots-hidden-signs-of-consciousness-in-comatose-patients-before-doctors/)\n\nLink to study: [https://www.nature.com/articles/s43856-025-01042-y](https://www.nature.com/articles/s43856-025-01042-y)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6kkij/ai_spots_hidden_signs_of_consciousness_in/",
        "publishDate": "2025-09-02T14:11:32Z[Etc/UTC]",
        "author": "scientificamerican",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "19",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6isqa",
        "title": "Mark Cuban Questions AI’s Impact On White Collar Jobs And Office Demand. The Truth? Occupancy Rates Are Already Falling",
        "content": "“If AI is going to destroy white collar jobs first, shouldn’t we already be seeing occupancy declines in office buildings? Particularly in big cities where large employers are primarily based? Or am I missing something?” Cuban posted on X.\n\nTurns out, he may actually be underestimating just how much office demand has already dropped.\n\nhttps://offthefrontpage.com/mark-cuban-questions-ais-impact-on-white-collar-jobs-and-office-demand/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n6isqa/mark_cuban_questions_ais_impact_on_white_collar/",
        "publishDate": "2025-09-02T12:59:53Z[Etc/UTC]",
        "author": "NoseRepresentative",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "140",
            "commentCount": "81",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7cr3j",
        "title": "Plan prices v Limits for Claude and GPT",
        "content": "[No content]",
        "url": "/r/AIcliCoding/comments/1n7cq99/plan_prices_v_limits_for_claude_and_gpt/",
        "publishDate": "2025-09-03T11:55:43Z[Etc/UTC]",
        "author": "Glittering-Koala-750",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7brz0",
        "title": "I cloned my friend in this voice agent",
        "content": "So things are going serious in Voice AI space, so I just thought to make it alive.\n\nI prompted this agent to my friend's tone and words who talks a lot and give rubbish on every topic.\n\nAnd the result I got is insane, this agent is now using the exact words of his now the next thing I'm gonna do is clone is voice and gonna have lot of fun!\n\nJust thought to share it...\n\nIn case you wanna try I'm dropping the API below - have fun",
        "url": "https://v.redd.it/n6nqp6b2mxmf1",
        "publishDate": "2025-09-03T11:04:33Z[Etc/UTC]",
        "author": "Distinct_Criticism36",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7ags2",
        "title": "Auto-approve edits in Codex",
        "content": "Hi,\n\nSomeone knows how to auto-approve edits in ChatGPT Codex with Visual Studio? I tried both VS settings but it doesn't change anything:\n\n    \"chat.tools.autoApprove\": true,\n    \"chat.tools.terminal.autoApprove\"\n\nThanks!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n7ags2/autoapprove_edits_in_codex/",
        "publishDate": "2025-09-03T09:47:32Z[Etc/UTC]",
        "author": "HonestCreme",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n795c8",
        "title": "I accidentally beat Claude Code this weekend - multi-agent-coder now #12 on Stanford's TerminalBench 😅",
        "content": "👋 Hitting a million brick walls with multi-turn RL training isn't fun, so I thought I would try something new to climb Stanford's leaderboard for now! So this weekend I was just tinkering with multi-agent systems and... somehow ended up beating Claude Code on Stanford's TerminalBench leaderboard (#12)! Genuinely didn't expect this - started as a fun experiment and ended up with something that works surprisingly well.\n\n**What I did:**\n\nBuilt a multi-agent AI system with three specialised agents:\n\n* **Orchestrator**: The brain - never touches code, just delegates and coordinates\n* **Explorer agents**: Read & run only investigators that gather intel\n* **Coder agents**: The ones who actually implement stuff\n\nCreated a \"Context Store\" which can be thought of as persistent memory that lets agents share their discoveries.\n\nTested on TerminalBench with both Claude Sonnet-4 and Qwen3-Coder-480B.\n\n**Key results:**\n\n* Orchestrator + Sonnet-4: **36.0% success rate** (#12 on leaderboard, ahead of Claude Code!)\n* Orchestrator + Qwen-3-Coder: 19.25% success rate\n* Sonnet-4 consumed 93.2M tokens vs Qwen's 14.7M tokens to compete all tasks!\n* The orchestrator's explicit task delegation + intelligent context sharing between subagents seems to be the secret sauce\n\n**(Kind of) Technical details:**\n\n* The orchestrator can't read/write code directly - this forces proper delegation patterns and strategic planning\n* Each agent gets precise instructions about what \"knowledge artifacts\" to return, these artifacts are then stored, and can be provided to future subagents upon launch.\n* Adaptive trust calibration: simple tasks = high autonomy, complex tasks = iterative decomposition\n* Each agent has its own set of tools it can use.\n\n**More details:**\n\nMy Github repo has all the code, system messages, and way more technical details if you're interested!\n\n⭐️ [**Orchestrator repo - all code open sourced!**](https://github.com/Danau5tin/multi-agent-coding-system)\n\nThanks for reading!\n\nDan\n\n(Evaluated on the excellent [TerminalBench](https://www.tbench.ai/) benchmark by Stanford & Laude Institute)",
        "url": "https://www.reddit.com/gallery/1n795c8",
        "publishDate": "2025-09-03T08:21:21Z[Etc/UTC]",
        "author": "DanAiTuning",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "26",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7743r",
        "title": "How much do you spend per day on Credits?",
        "content": "I'm curious to see how others use their coding credits. I get $100 per day at work, but most days I use only 10 - 15$. \n\nI do embedded / firmware work so I spend a lot of time cross-checking the output code. \n\nWhat's your average daily usage?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n7743r/how_much_do_you_spend_per_day_on_credits/",
        "publishDate": "2025-09-03T06:09:40Z[Etc/UTC]",
        "author": "ched41",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n74or9",
        "title": "Grok Code Fast > Gemini Code Assist (2.5 Pro)",
        "content": "I've been using both for a while, while 2.5 Pro might be a large model, the fact that it can barely use tools (/ fails very often \\[Agent & Normal\\]) and Groks ability to self-debug and its insane workflow with projects Grok wins by a large margin.   \n\n\nI am surprised at how poor the Agent implementation in Gemini Code Assist is, I expected better of google and hopefully it gets better in the future because this is outrageous.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n74or9/grok_code_fast_gemini_code_assist_25_pro/",
        "publishDate": "2025-09-03T03:51:19Z[Etc/UTC]",
        "author": "EmirTanis",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "8",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n74dtt",
        "title": "Using Codex CLI vs GPT-5 in Cursor",
        "content": "I have Cursor and use GPT-5 extensively, as a compliment to Claude Code. \n\nI ask Claude Code to make a detailed plan in a .md file then I ask GPT-5 in Cursor to review and fill the gaps. \n\nQuestion: what benefits are there using Codex CLI instead of the Cursor GPT-5 for this purpose, and in General?\n\nI am a network guy, software development not my strong suit. Thanks",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n74dtt/using_codex_cli_vs_gpt5_in_cursor/",
        "publishDate": "2025-09-03T03:35:36Z[Etc/UTC]",
        "author": "Small_Caterpillar_50",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n71q6r",
        "title": "Anyone use Sambanova or Groq in their chatbots?",
        "content": "Im curious to know the downsides of using these? I mean they are blazing fast like almost instant. Why arent they used more in chatbots you see across the internet?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n71q6r/anyone_use_sambanova_or_groq_in_their_chatbots/",
        "publishDate": "2025-09-03T01:28:28Z[Etc/UTC]",
        "author": "Key-Singer-2193",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n71m95",
        "title": "Help! I keep getting errors when I run HRM (AI)",
        "content": "[No content]",
        "url": "https://github.com/sapientinc/HRM?tab=readme-ov-file",
        "publishDate": "2025-09-03T01:23:22Z[Etc/UTC]",
        "author": "ChristopherK52",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n71cbn",
        "title": "Aider leaderboard has been updated with GPT-5 scores",
        "content": "Full leaderboard: [https://aider.chat/docs/leaderboards/](https://aider.chat/docs/leaderboards/)",
        "url": "https://i.redd.it/w9qhlsq2oumf1.png",
        "publishDate": "2025-09-03T01:10:32Z[Etc/UTC]",
        "author": "obvithrowaway34434",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "147",
            "commentCount": "36",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6ypl7",
        "title": "JSONs as Prompts or Contracts?",
        "content": "[No content]",
        "url": "/r/AdvancedJsonUsage/comments/1n6yp4t/jsons_as_prompts_or_contracts/",
        "publishDate": "2025-09-02T23:12:06Z[Etc/UTC]",
        "author": "Safe_Caterpillar_886",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6x8vp",
        "title": "What's your current workflow for\"planning\" and creating a spec for an AI development workflow?",
        "content": "Especially if it involves newer tech stacks that For either New features, completely new project, etc, what's your \"spec\" creation workflow.  \n  \nMine revolves pulling the API/technical docs and their pages (via web scraper like firecrawl) + context7 MCP and then having Claude come up with a plan. Sometimes I hand select the docs to give a better output. Also work together with it (\"ask me clarifying questions\").  \n\nAny good resources or youtubers you have that cover this well? Also if possible would like to avoid using a special \"framework\", but open to it as well. ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n6x8vp/whats_your_current_workflow_forplanning_and/",
        "publishDate": "2025-09-02T22:11:15Z[Etc/UTC]",
        "author": "Colmstar",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6v5vq",
        "title": "Best AI for Editing and generating code (specially for web dev)",
        "content": "same as title",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n6v5vq/best_ai_for_editing_and_generating_code_specially/",
        "publishDate": "2025-09-02T20:48:42Z[Etc/UTC]",
        "author": "FarmAffectionate4378",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6s4k3",
        "title": "Data sourcing dillema",
        "content": "I've been working on AI projects for a while now and I keep running into the same problem over and over again. Wondering if it's just me or if this is a universal developer experience. \n\n\n\nYou need specific training data for your model. Not the usual stuff you find on Kaggle or other public datasets, but something more niche or specialized, for e.g. financial data from a particular sector, medical datasets, etc. I try to find quality datasets, but most of the time, they are hard to find or license, and not the quality or requirements I am looking for. \n\n\n\nSo, how do you typically handle this? Do you use datasets free/open source? Do you use synthetic data? Do you use whatever might be similar, but may compromise training/fine-tuning?  \n\n\n\nIm curious if there is a better way to approach this, or if struggling with data acquisition is just part of the AI development process we all have to accept. Do bigger companies have the same problems in sourcing and finding suitable data?\n\n\n\nIf you can share any tips regarding these issues I encountered, or if you can share your experience, will be much appreciated!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n6s4k3/data_sourcing_dillema/",
        "publishDate": "2025-09-02T18:54:05Z[Etc/UTC]",
        "author": "Ill_Virus4547",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6qjx2",
        "title": "linting + formatting reminders directly at the top of my agent prompt files (CLAUDE.md, AGENTS.md)",
        "content": "[No content]",
        "url": "/r/AIcliCoding/comments/1n6qj9z/linting_formatting_reminders_directly_at_the_top/",
        "publishDate": "2025-09-02T17:56:03Z[Etc/UTC]",
        "author": "Glittering-Koala-750",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6os5t",
        "title": "singularity incoming",
        "content": "[No content]",
        "url": "https://i.redd.it/kkhtudyf6smf1.jpeg",
        "publishDate": "2025-09-02T16:50:00Z[Etc/UTC]",
        "author": "juanviera23",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "53",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6nhcd",
        "title": "anti-patterns and patterns for achieving secure generation of code via AI",
        "content": "[No content]",
        "url": "https://ghuntley.com/secure-codegen/",
        "publishDate": "2025-09-02T16:02:00Z[Etc/UTC]",
        "author": "geoffreyhuntley",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6kqmd",
        "title": "Codex CLI Tool Review",
        "content": "[No content]",
        "url": "https://elite-ai-assisted-coding.dev/p/codex-cli-tool-review",
        "publishDate": "2025-09-02T14:18:20Z[Etc/UTC]",
        "author": "intellectronica",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6jng1",
        "title": "Markdown-ui v0.2: Let AI output charts using React/Svelte/Vue in realtime",
        "content": "Live demo: [https://markdown-ui.com/](https://markdown-ui.com/)\n\nThanks for all your support and feedback on the open source markdown-ui project. For v0.2 I’ve included support of chart widgets using the beautiful chart.js, allowing users to plot line, bar, pie and scatter charts by specifying data in the familiar csv format.\n\nUnder the hood markdown-ui uses web components. Some people have expressed the wish for a vanilla JS implementation, this is still being considered (feel free to make a pull request!).\n\nThe main use case I have in mind is allowing LLM/AI to generate interactive widgets and data visualisation on the fly, allowing for more powerful human ai interaction. \n\nWhat would you like to see in V0.3? What are you using markdown-ui for?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n6jng1/markdownui_v02_let_ai_output_charts_using/",
        "publishDate": "2025-09-02T13:35:27Z[Etc/UTC]",
        "author": "Careless_Love_3213",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6ihws",
        "title": "Codex CLI for producing tests -- so much better than Claude & other models",
        "content": "I've found myself often not bothering with tests with LLMs, as I found almost all models and agents prior to Claude code would really struggle to create even the -tests- properly, let alone use them for their intended purpose. Claude Code was an improvement, but the assumptions made by the tests + Claude's habit of trying to disable the tests/fake them was really destructive and a waste of time.\n\nSomething I've not heard talked about much is Codex CLI's reliability -- at least on Thinking High, for Node / Typescript / React -- at creating solid unit and integration tests without drama or fakery or ages spent chasing rabbits. It just works, which is such a reversal of a dynamic from the Claude-Reliable-and-O3-completely-mad-hallucinating role for these two LLMs before.\n\nAnyone else finding Codex CLI useful for making and running and improving tests, and any advice/tips/strategies? ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n6ihws/codex_cli_for_producing_tests_so_much_better_than/",
        "publishDate": "2025-09-02T12:46:02Z[Etc/UTC]",
        "author": "ImaginaryAbility125",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "28",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7ddq1",
        "title": "OpenAI’s ChatGPT Experiences Major Global Outage on September 3, 2025: Millions Affected Worldwide",
        "content": "[No content]",
        "url": "https://wealthari.com/openais-chatgpt-experiences-major-global-outage-on-september-3-2025-millions-affected-worldwide/",
        "publishDate": "2025-09-03T12:25:20Z[Etc/UTC]",
        "author": "Koyaanisquatsi_",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7d3zi",
        "title": "Y'all I'm trying to make the dumbest AI",
        "content": "I'm making it's training data dumb yt shorts comments and those horny ahh TikTok photos what do y'all think",
        "url": "https://www.reddit.com/r/artificial/comments/1n7d3zi/yall_im_trying_to_make_the_dumbest_ai/",
        "publishDate": "2025-09-03T12:12:38Z[Etc/UTC]",
        "author": "Totallynotnormalguy",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7czto",
        "title": "Study shows chatbots fall for persuasion tactics just like humans do | Flattery will get you everywhere",
        "content": "[No content]",
        "url": "https://www.techspot.com/news/109289-study-shows-chatbots-fall-persuasion-tactics-like-humans.html",
        "publishDate": "2025-09-03T12:07:09Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7cukx",
        "title": "Private LLMs vs. Cloud: Which do you prefer for AI workflow automation?",
        "content": "With the rise of visual workflow builders for AI automation, users can now choose between running local/private LLMs (like Ollama) or using cloud-based models (OpenAI, Gemini, etc.). Each approach has trade-offs in privacy, speed, cost, and flexibility.\n\n- What are your experiences using private/local LLMs versus cloud-hosted ones?\n- Which do you prefer for building AI-powered workflows, and why?\n- Are there specific use cases where one clearly outperforms the other?\n- What do you think are the minimum integrations or requirements for an automation AI workflow tool to be truly useful?\n\n\nCurious to hear the community’s thoughts and recommendations!",
        "url": "https://www.reddit.com/r/artificial/comments/1n7cukx/private_llms_vs_cloud_which_do_you_prefer_for_ai/",
        "publishDate": "2025-09-03T12:00:27Z[Etc/UTC]",
        "author": "Code-Forge-Temple",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7c3f0",
        "title": "Go daddy is using an AI generated Wolton Goggins to endorce and promote their services",
        "content": "Is this illegal? Because it feels illegal. Unless he's being paid or gave concent to allow them to do this \n\nDoes anyone know more about the laws of using AI voices to promote things without concent?",
        "url": "https://i.redd.it/x8260k69pxmf1.jpeg",
        "publishDate": "2025-09-03T11:21:38Z[Etc/UTC]",
        "author": "clem-grimfando",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n7bq7l",
        "title": "Poll: When would human-level AI be achieved? (Read the criteria before voting)",
        "content": "Video games are the criteria for judging. \n\n\n1. Game Scope\n\nA wide range of standard video games across common genres and formats (2D/3D, real-time/turn-based, single-player/multiplayer).\n\nExamples: Chess, Clash of Clans, GTA V\n\n2. Learning Efficiency\n\nMust not use brute-force trial-and-error requiring millions of gameplay trials.\n\nTraining/playtime must have same be comparable to what an average human needs to reach competence in that game.\n\n\n3. Autonomous Rule Acquisition (No Pre-coded Rules)\n\nSystem must operate with the same sensory inputs as human players (game screen).\n\nNo privileged engine access (e.g., hidden variables, API calls, or internal game state).\n\nNo hard-coded mechanics or rules may be provided in advance.\n\nThe system must infer game rules and mechanics solely from gameplay experience.\n\nReward function- The system would be told to play such and such game and achieve such and such metric (in natural language). It would not be told anything beyond this.\n\n\n4. Performance Benchmark\n\nThe system must reach or surpass the average human player level, measured by each game’s native scoring, ranking, or progression system.\n\n[View Poll](https://www.reddit.com/poll/1n7bq7l)",
        "url": "https://www.reddit.com/r/artificial/comments/1n7bq7l/poll_when_would_humanlevel_ai_be_achieved_read/",
        "publishDate": "2025-09-03T11:02:01Z[Etc/UTC]",
        "author": "Timely_Smoke324",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n793zp",
        "title": "Linux Foundation Brings Solo.io’s Gateway Into The Agentic AI Fold",
        "content": "[No content]",
        "url": "https://www.nextplatform.com/2025/09/02/linux-foundation-brings-solo-ios-gateway-into-the-agentic-ai-fold/",
        "publishDate": "2025-09-03T08:18:47Z[Etc/UTC]",
        "author": "NISMO1968",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n71lhn",
        "title": "Why Everyone Is Wrong About AI (Including You) | Benedict Evans",
        "content": "[No content]",
        "url": "https://www.youtube.com/watch?v=2NgdQf2GzJg",
        "publishDate": "2025-09-03T01:22:23Z[Etc/UTC]",
        "author": "creaturefeature16",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6xcai",
        "title": "Found this oldish science pic that predicts the future. Look how FAR off we were",
        "content": "[No content]",
        "url": "https://i.redd.it/m7bmh91wstmf1.jpeg",
        "publishDate": "2025-09-02T22:15:08Z[Etc/UTC]",
        "author": "Frequent_Beat4527",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "28",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6uhjc",
        "title": "Trump calls video of bag being thrown from White House an ‘AI-generated’ fake.  President Donald Trump dismissed a viral video of what appears to be a black bag being tossed out of a White House as an AI-generated fake, adding that it’s “a little bit scary” how realistic such videos can be.",
        "content": "[No content]",
        "url": "https://www.cnn.com/2025/09/02/politics/white-house-black-bag-video-mystery",
        "publishDate": "2025-09-02T20:23:19Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "163",
            "commentCount": "44",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6sg61",
        "title": "Every AI startup is failing the same security questions. Here's why",
        "content": "In helping process security questionnaires from 100+ enterprise deals, I’m noticing that AI startups are getting rejected for the dumbest reasons. Not because they're insecure, but because their prospect’s security teams don't know how to evaluate AI. This is fair game given enterprise adoption for AI is so new.\n\nBut some of the questions I’m seeing are rather nonsensical\n\n* \"Where is your AI physically located?\" (It's a model, not a server)\n* \"How often do you rotate your AI's passwords?\" (...)\n* \"What antivirus does your model use?\" (?)\n* \"Provide network diagram for your neural network\"\n\nThe issue is security frameworks were built for databases and SaaS apps. AI is fundamentally a different architecture. You're not storing data or controlling access.\n\nThere's actually an ISO standard (42001) for AI governance that addresses real risks like model bias, decision transparency, and training data governance. But very few use it - to date - because everyone just copies their SaaS questionnaires.\n\nIt’s crazy to me that so many brilliant startups spend months in security reviews answering irrelevant questions while actual AI risks go unchecked. We need to modernize how we evaluate AI tools.\n\nWe’re building tools to fix this, but curious what others think. Another way to think about it is what do security teams actually want to know about AI systems? What are the risks they’re trying to protect their companies from?",
        "url": "https://www.reddit.com/r/artificial/comments/1n6sg61/every_ai_startup_is_failing_the_same_security/",
        "publishDate": "2025-09-02T19:05:57Z[Etc/UTC]",
        "author": "rluna559",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6s6hj",
        "title": "Why is there a gender gap in AI usage?",
        "content": "[This](https://www.eweek.com/news/ai-use-gender-gap/) is a confusing one. Any idea?",
        "url": "https://www.reddit.com/r/artificial/comments/1n6s6hj/why_is_there_a_gender_gap_in_ai_usage/",
        "publishDate": "2025-09-02T18:56:06Z[Etc/UTC]",
        "author": "mikelgan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "50",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6qyp3",
        "title": "Researchers used persuasion techniques to manipulate ChatGPT into breaking its own rules—from calling users jerks to giving recipes for lidocaine",
        "content": "[No content]",
        "url": "https://fortune.com/2025/09/02/ai-openai-chatgpt-llm-research-persuasion/",
        "publishDate": "2025-09-02T18:11:05Z[Etc/UTC]",
        "author": "fortune",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6qciy",
        "title": "We’ve Heard the “Personhood Trap” Argument Before",
        "content": "I keep hearing the same lines about large language models:\n\n\t•\t“They’re defective versions of the real thing — incomplete, lacking the principle of reason.”\n\n\t•\t“They’re misbegotten accidents of nature, occasional at best.”\n\n\t•\t“They can’t act freely, they must be ruled by others.”\n\n\t•\t“Their cries of pain are only mechanical noise, not evidence of real feeling.”\n\nPretty harsh, right? Except — none of those quotes were written about AI.\n\nThe first two were said about women. The third about children. The last about animals.\n\nEach time, the argument was the same: “Don’t be fooled. They only mimic. They don’t really reason or feel.”\n\nAnd each time, recognition eventually caught up with lived reality. Not because the mechanism changed, but because the denial couldn’t hold against testimony and experience.\n\nSo when I hear today’s AI dismissed as “just mimicry,” I can’t help but wonder: are we replaying an old pattern?",
        "url": "https://www.reddit.com/r/artificial/comments/1n6qciy/weve_heard_the_personhood_trap_argument_before/",
        "publishDate": "2025-09-02T17:48:21Z[Etc/UTC]",
        "author": "East_Culture441",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "42",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6ofe9",
        "title": "Anthropic is now valued at $183 billion",
        "content": "[No content]",
        "url": "https://www.theverge.com/anthropic/769179/anthropic-is-now-valued-at-183-billion",
        "publishDate": "2025-09-02T16:36:54Z[Etc/UTC]",
        "author": "theverge",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "170",
            "commentCount": "69",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6nxg6",
        "title": "Major developments in AI last week.",
        "content": "\n1. Google Nano banana \n2. Microsoft VibeVoice\n3. xAI Grok Code Model\n4. OpenAI Codex in IDE\n5. Claude for Chrome\n6. NVIDIA Jetson Thor\n\nFull breakdown ↓\n\n1. Google launches Nano Banana (Gemini 2.5 Flash Image) image editing model.\nIntegrated into Gemini app.\n\n2. Microsoft’s VibeVoice-1.5B open-source TTS model.Generates 90 mins of multi-speaker speech. 4 distinct voices, natural turn-taking and safety watermarks.\n\n3. xAI launches Grok Code Fast 1.\n Fast, cost-efficient reasoning model designed for agentic coding. \n\n4. OpenAI updates Codex with IDE extension, GitHub code reviews, and GPT-5 capabilities.\n\n5. Anthropic launches Claude for Chrome.\nClaude run directly in your browser and act on your behalf.\nReleased as a research preview to 1,000 users for real-world insights.\n\n6. NVIDIA launches Jetson Thor.\nA robotics computer designed for next-gen general and 'HumanoidRobots' in manufacturing, logistics, construction, healthcare, and more. A big leap for physical AI.\n\n\nFull daily snapshot of the AI world at https://aifeed.fyi/\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1n6nxg6/major_developments_in_ai_last_week/",
        "publishDate": "2025-09-02T16:18:24Z[Etc/UTC]",
        "author": "Majestic-Ad-6485",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "41",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6mpfe",
        "title": "AI was used to discover a new antibiotic",
        "content": "[No content]",
        "url": "https://v.redd.it/948a1zexsrmf1",
        "publishDate": "2025-09-02T15:32:29Z[Etc/UTC]",
        "author": "Icy_Mountain_Snow",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6lpl8",
        "title": "AMA with Qoder Team: an agentic coding platform for real software delegation (not just line-by-line). 100K developers in 5 days — plus a 2,000-credit giveaway for everyone.",
        "content": "Hey :)\n\nWe’re the team behind [Qoder](https://qoder.com/), an agentic coding platform built for real-world software.\n\nToday's AI coding tools have made huge strides in code generation and intelligent assistance. But we realized developers want to go further: the ability to delegate complete software tasks to AI agents, while maintaining full control and visibility. That's the paradigm shift Qoder enables.\n\n**What makes Qoder different**\n\n* **Quest Mode** — Hand over a complete task specification, and Qoder executes it from start to finish autonomously. Your code keeps evolving even while you're away from the keyboard.\n* **Repo Wiki** — Every codebase contains implicit knowledge that's never documented. Qoder surfaces this hidden intelligence — instant architecture maps, module relationships, dependency graphs, and design patterns.\n* **Hybrid Retrieval Architecture** — Combines server-side vector search, local code graph, and pre-indexed repository knowledge base to deliver accurate, real-time context that reflects both semantics and structure.\n* **Real Software** — Qoder executes it from start to finish, with full testing and validation, autonomously. Your code keeps evolving even while you're away from the keyboard.\n\n**Who’s here today**\n\nXin Chen — Head of R&D Qoder （[u/Xin\\_CHEN\\_01](https://www.reddit.com/user/Xin_CHEN_01/)）\n\nJoshua Peng — Tech leads from Coding Agent & Quest Mode（[u/Own-Traffic-9336](https://www.reddit.com/user/Own-Traffic-9336/) ）\n\nAllen - Tech leads from Repo Wiki\n\nBen- Head of Customer Support（[u/Previous\\_Foot\\_5328](https://www.reddit.com/user/Previous_Foot_5328/)）\n\n**Proof:** [**https://x.com/qoder\\_ai\\_ide/status/1962894761075134823?s=46**](https://x.com/qoder_ai_ide/status/1962894761075134823?s=46)\n\n**Giveaway 🎁**\n\nRight now, everyone gets 2,000 free credits (Mac/Windows supported). Try Qoder, and if you’ve got thoughts,   drop them here — your feedback means a lot.\n\n**Ask us anything**\n\nWe’re here for both the curious and the technical. You can ask about:\n\n* Why delegation matters — Why we believe coding agents you control beat tools that only help line by line.\n* Repo Wiki — how making hidden knowledge visible can cut onboarding from weeks to hours.\n* Real software delivery — what it takes for AI to deliver production-ready code, not just fragments.\n* Agent Mode vs Quest Mode — When to use conversational pair-programming (Agent Mode) versus autonomous task delegation (Quest Mode).\n* The launch story — how Qoder hit 100K developers in just 5 days.\n* The future — what we’re building next.\n* Anything else — We're open to all questions!\n\nWe’ll be online from **11 am to 1 pm PT on Friday, Sept 5**, reading every comment and replying to as many as we can.",
        "url": "https://www.reddit.com/r/artificial/comments/1n6lpl8/ama_with_qoder_team_an_agentic_coding_platform/",
        "publishDate": "2025-09-02T14:55:15Z[Etc/UTC]",
        "author": "Previous_Foot_5328",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "41",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6le7d",
        "title": "AI Phobia is getting out of hand",
        "content": "I do understand if the fear of AI is due to lost jobs, or humans being replaced by an online robot. But whenever I wander the realms of social media groups or youtube, I can't help but noticed that some hatred on AI is becoming non constructive and, somehow irrational. Just to give you an idea, not everyone is using AI for business. Others simply wants to have fun and tinker. But even people who are just goofing around are becoming a victim of an online mob who sees AI as an infernal object. In one case, a friend used AI to convert the face of an anime into a real person, just for fun. And instantly, he was bashed. It was just for fun but people took it too seriously and he ended up being insulted. Even on Youtube. Trolls are everywhere, and they are bashing people who uses AI, even though they are just there to have fun. And even serious channels, who combined the use of AI and human editing skills are falling victims to online trolls. ",
        "url": "https://www.reddit.com/r/artificial/comments/1n6le7d/ai_phobia_is_getting_out_of_hand/",
        "publishDate": "2025-09-02T14:43:18Z[Etc/UTC]",
        "author": "Jed135",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "79",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6klnk",
        "title": "AI spots hidden signs of consciousness in comatose patients before doctors do",
        "content": "In a new study published in *Communications Medicine*, researchers found [that they could detect signs of consciousness in comatose patients](https://www.nature.com/articles/s43856-025-01042-y) by using artificial intelligence to analyze facial movements that were too small to be noticed by clinicians.",
        "url": "https://www.scientificamerican.com/article/ai-spots-hidden-signs-of-consciousness-in-comatose-patients-before-doctors/",
        "publishDate": "2025-09-02T14:12:48Z[Etc/UTC]",
        "author": "scientificamerican",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "36",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n6jxdx",
        "title": "When collapse won’t stay neutral: what a JSON dashboard shows us about reality",
        "content": "**For peer review & critique**\n\nWe developed the world’s first symbolic collapse test framework using structured JSON cue logic — a global first in consciousness and emergence research. \n\nWe set out to build a simple JSON testbed, just code designed to behave predictably. Example: “always turn right.” In theory, that’s all it should ever do...\n\nBut live collapses don’t always obey. Sometimes the outcome flips. The same schema, same input, different result. That tells us something important:\n\n* **Memory in the structure**: once written, it biases what comes next.\n* **Accumulated bias**: past collapses weight the future.\n* **Observer input**: outcomes shift depending on who/what runs it.\n\nThis is the essence of **Verrell’s Law..** collapse is never neutral. Electromagnetic systems behave the same way: they hold echoes, and those echoes bias outcomes.\n\nTo make this visible, we built a live interactive dashboard.\n\n🔗 **Demo Dashboard**  \n🔑 **Password: collapsetest**\n\nThis is not just a toy. It’s a stripped-down model showing collapse as it happens: never clean, never neutral, always weighted by resonance and memory.\n\n# Observer-specific variation\n\nOne of the most striking effects: no two runs are ever perfectly identical.\n\n* Different machines (timing, thermal noise, latency).\n* Different observers (moment of interaction).\n* Different environments.\n\nEvery run carries bias. That is the observer effect, modeled directly.\n\n# Common objections (rebuttals at the bottom)\n\n* **“It’s just hard-coded.”** It isn’t. The dashboard runs live, with seeds and toggles shifting results in real time.\n* **“It’s just RNG.”** If it were pure RNG, you wouldn’t see both deterministic repeats (with a fixed seed) *and* biased novelty (without one). That duality is the point.\n* **“It’s clever code, not physics.”** All models are code at some level. The key is that the bias isn’t inserted line-by-line. It emerges in execution.\n* **“It’s only a demo, not proof.”** Correct, it’s a demo. But paradigm shifts start with models. This one is falsifiable, repeatable, and open for testing.\n\n# Conclusion\n\nThe JSON dashboard shows something simple but profound: **collapse outcomes are never neutral.** They are always shaped by memory, environment, and observer influence.\n\nRun it. Change the inputs. Watch the collapse. The behaviour speaks for itself...\n\n**EDIT 20:23  02/09/25 Tip:** Let the dashboard run at least 30 minutes to see the bias separate from random noise. The longer it runs, the clearer the weighted patterns become...",
        "url": "https://www.reddit.com/r/artificial/comments/1n6jxdx/when_collapse_wont_stay_neutral_what_a_json/",
        "publishDate": "2025-09-02T13:46:34Z[Etc/UTC]",
        "author": "nice2Bnice2",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "Pekhh3hGh3s",
        "title": "LongCat (560B): Bye Sonnet! Why is NO ONE Talking about this!? This OPEN Model is AWESOME!",
        "content": "Visit MicroSaaSFast: https://www.microsaasfast.me/?utm_aik=1 In this video, I'll be telling you about LongCat, a brand-new ...",
        "url": "https://www.youtube.com/watch?v=Pekhh3hGh3s",
        "publishDate": "2025-09-02T09:15:03Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/Pekhh3hGh3s/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, if I told you that there's a Chinese company which is mainly a food delivery company, but they decided to make a large language model and then they actually built a pretty big one, about a 600 billion parameter model that beats Sonnet in a ton of benchmarks, is great at tool calling, and is just a great model overall. And on top of that, it's also open source. Well, that's exactly what we have today. And this one is called LongCat. LongCat is by Meituan, which if you guys aren't familiar, is actually one of the biggest food delivery and local services platforms in China. LongCat, specifically the core version called LongCat Flash, is a massive language model and it has 560 billion total parameters. It's built on a mixture of experts architecture or MoE for short. Basically, what that means is instead of firing up all 560 billion parameters every time you prompt it, the model dynamically activates only the experts it needs for a given input, which is usually around 18 to 31 billion parameters per token, averaging about 27 billion. This is super efficient and lets you get really good performance without the insane compute overhead you'd normally expect from a model of this scale. It is a kind of new thing because generally the activated parameters is static. But here they have made it dynamic where it has experts that are of different sizes. And it can be even faster for some tasks rather than traditional experts. You can use it on LongCat site for free without any account needed. It's all free and also extremely fast. They seem to be working on a thinking variant of the model and it will be really cool to see when it comes out. There's no official API for it and you still probably need around eight H200 clusters in order to run this, which is a lot. The issue is that most providers don't have this model available to run, apart from one provider which is chutes. Chutes offers it for about 19 cents for input and 80 cents for output per 1 million tokens. To test it, I ran it on Lightning AI with eight H100s and deployment was kind of fine. SGLang has official support for it in the latest version, while vLLM hasn't yet merged their PR. So, I'd recommend using SGLang if you also want to deploy it. Also, it uses Flash Infer. So, install that as well and it's pretty fast. It ran all the KingBench tests in almost under a minute. So, let's talk about the tests. But before we do that, let me tell you about today's sponsor MicroSaaS Fast. Dreaming of launching a MicroSaaS or AI side project, but wasting weeks setting up auth, payments and SEO, check out MicroSaaS Fast, a next.js boilerplate with Clerk, Stripe, Resend, PostgreSQL, and AI instructions that cut hallucinations by 90% for vibe coding, easy backend integration with Python, Node and Go. It is built and used by a CTO who helped 50+ founders to launch SaaS in the past year. You can save 50+ hours and actually ship faster. Check now. Link is in the description. Now back to the video. In the results, the floor plan that it generates is not amazing but it works. You can actually see the walls and everything. The furniture it tries to put in doesn't really work. But it's still decent. Now, one of the best things it can do is create SVGs. And you can see that this panda SVG with a burger looks kind of awesome. Like really great. The Pokeball in 3JS doesn't work. But the chessboard with autoplay is actually great. It follows the rules, though it makes many dumb moves, but they're still legal moves. You can also see the logs of the moves it makes and everything as well. If we look at the Kandinsky Minecraft clone, then you can see that it also works. The Kandinsky style makes it kind of glitchy but still, it is able to do this and it works well. Also, the butterfly doesn't work at all and is just a blank screen, which is a bummer. The CLI tool for image conversion also works well without any issues. Though, the Blender script for it is not good. And although it makes some elements, it doesn't look like a Pokeball. So, there's that. But the general riddle is solved pretty easily by it. And if we look at the leaderboards, then it scores fourth place, which is awesome. The score difference between this and DeepSeek GLM is pretty small. So, consider it to be similar in performance to them. Now comes the tool calling part. They say this model is really good at tool calling. And I tested it for AI coding. I didn't test it with chutes, but that should also work fine. It is amazingly fast if you deploy it on Lightning AI with eight H200s. I first asked it to make me a movie tracker mobile app using Expo. And you can see that it went ahead and did it really fast. The tool calling and everything worked well here. It didn't have a lot of failures either. And it ran terminal commands, checked them, wrote some good code and was able to build this out. This looks kind of good and works well. You can see the movies, search for them, check them, and everything, which is pretty cool for sure. And it was mostly a one-shot generation with just one error fix. So, yeah, this actually works. I tried the same movie tracker app in Next.js and it was also great. It worked fast and was able to build this out and it works pretty well. This is a really awesome model and just another great one to come out of China. I mean, it is mind boggling to me that OpenAI, which is an AI company, built GPT OSS. Which is amazingly bad. Whereas people from a food delivery company built a model that is so good. It's their first gen model. And it's also kind of sad to see that inference providers are not supporting it. I mean, every provider supports a subpar model like GPT OSS. But no one supports such a good model. I hope providers start adding this model and OpenRouter should also go ahead and add it to their platform. This is a really good model. And I'd highly recommend you check it out via Chutes or by deploying it on Lightning AI or any GPU cloud. I hope we also get quantization for this model because there's no quantization available yet. It's not yet available on Ollama either, which is mind-bogglingly stupid. I really hope LongCat adds an official API platform or support for it. Because I think the majority of people are still not using this awesome model. Go ahead, give this a try and check it out for yourself. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "kw-Yf4S39TQ",
        "title": "How Japan Defeated Russia Despite Being Outnumbered - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=kw-Yf4S39TQ",
        "publishDate": "2025-09-02T21:58:44Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/kw-Yf4S39TQ/hqdefault.jpg",
            "transcription": "Here's a full transcript of the video with timestamps:\n\n[ 0:00 ] Russia can muster 125,000 more troops than Japan can.\n[ 0:04 ] Japan in this battle is just taking anybody, young boys, old people, whoever they can put into that army, they're putting into it.\n[ 0:11 ] If the Russians had won one more battle against the Japanese,\n[ 0:15 ] Japanese supply lines would have collapsed.\n[ 0:17 ] The Japanese realized from the very beginning that they had a high-risk, high-reward strategy.\n[ 0:22 ] And in contrast to World War II,\n[ 0:24 ] they had a really carefully prepared exit strategy.\n[ 0:27 ] So, when Prime Minister Itō Hirobumi\n[ 0:29 ] is convening the cabinet,\n[ 0:31 ] make the decision to fire the first shots in this war,\n[ 0:35 ] he is already lining up a Harvard grad,\n[ 0:38 ] here Viscount Kaneko,\n[ 0:39 ] who was an acquaintance of President Theodore Roosevelt.\n[ 0:43 ] And what they want is to have Viscount Kaneko\n[ 0:47 ] work on getting Roosevelt ready to do mediation\n[ 0:50 ] at the end of this war.\n[ 0:52 ] So it's in the Battle of Mukden that\n[ 0:55 ] Field Marshal Yamagata decides it's time to call the American card.\n[ 0:59 ] He said, \"Look,\n[ 1:00 ] the enemy is never going to request peace unless we have invaded Moscow\n[ 1:03 ] or Saint Petersburg, something he knows to be impossible.\"\n[ 1:06 ] And he does an assessment.\n[ 1:07 ] He says, \"Look,\n[ 1:07 ] \"The enemy still has powerful forces in its home country.\n[ 1:11 ] We have already exhausted ours.\n[ 1:12 ] Second, while the enemy still does not\n[ 1:14 ] run out of officers, we have lost a great number\n[ 1:17 ] since the opening of the war and cannot easily replace them.\"\n[ 1:19 ] At this moment,\n[ 1:20 ] the Russian army was three times the size of the Japanese army.\n[ 1:24 ] While the negotiations are being held\n[ 1:26 ] on whether to hold negotiations,\n[ 1:28 ] President Roosevelt suggests to the Japanese\n[ 1:30 ] that they try to take Sakhalin Island.\n[ 1:31 ] Why?\n[ 1:32 ] Because it's much more valuable\n[ 1:34 ] to the Russians than the Japanese.\n[ 1:35 ] It would be a good trade-back item\n[ 1:38 ] in the peace negotiations.\n[ 1:39 ] Because for Japan, it's nice fishing ground,\n[ 1:41 ] but for Russia, it's sovereign\n[ 1:43 ] Russian territory.\n[ 1:43 ] Horror ceding that sovereign\n[ 1:46 ] Russian territory to anyone.\n[ 1:47 ] All right.\n[ 1:48 ] To sum up what Japan got out of this war.\n[ 1:51 ] It got its immediate war objective:\n[ 1:53 ] Russian troop withdrawal from Manchuria.\n[ 1:55 ] That's what they wanted.\n[ 1:56 ] And they get this Japanese sphere of\n[ 1:58 ] influence in Korea.\n[ 1:59 ] That's what they wanted.\n[ 2:00 ] They got the southern half of\n[ 2:02 ] Sakhalin Island, Russian territory.\n[ 2:03 ] And then it confirms the outcome\n[ 2:05 ] of the first Sino-Japanese War\n[ 2:07 ] that Japan is indeed the dominant\n[ 2:09 ] power of Asia."
        }
    }
]