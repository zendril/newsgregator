[
    {
        "id": "https://ai-techpark.com/?p=232786",
        "title": "CloudMasonry Launches Data & AI Practice Under Leadership of Landon Harris",
        "content": "<p>Leading Salesforce consulting partner expands cross-cloud capabilities to help clients harness data, AI and analytics to drive transformation and growth. CloudMasonry (website:https://cloudmasonry.com) today announced the formal launch of its¬†Data &#38; AI Practice, and the appointment of Landon Harris as Practice Lead. This strategic initiative bolsters CloudMasonry&#8217;s mission to serve as...</p>\n<p>The post <a href=\"https://ai-techpark.com/cloudmasonry-launches-data-ai-practice-under-leadership-of-landon-harris/\">CloudMasonry Launches Data & AI Practice Under Leadership of Landon Harris</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/cloudmasonry-launches-data-ai-practice-under-leadership-of-landon-harris/",
        "publishDate": "2026-01-14T12:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232777",
        "title": "AI Search and Retrieval Leader Algolia Releases Six Bold Bets for 2026",
        "content": "<p>From brand loyalty‚Äôs rebirth to the dynamic trio of retrieval, scale, and memory, Algolia executives are eyeing disruption for retail and AI in the next 12 months Algolia, the AI Search and Retrieval platform trusted by more than 18,000 businesses and millions of developers worldwide, today released six predictions for...</p>\n<p>The post <a href=\"https://ai-techpark.com/ai-search-and-retrieval-leader-algolia-releases-six-bold-bets-for-2026/\">AI Search and Retrieval Leader Algolia Releases Six Bold Bets for 2026</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/ai-search-and-retrieval-leader-algolia-releases-six-bold-bets-for-2026/",
        "publishDate": "2026-01-14T11:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232758",
        "title": "Genpact Research: 12% of Enterprises Lead the Autonomous Future",
        "content": "<p>New research reveals four critical enablers to moving beyond AI experimentation to build the foundation of the autonomous enterprise Genpact (NYSE: G), an agentic and advanced technology solutions company, today released new research showing how leading organizations leverage artificial intelligence (AI) to reshape the way they operate and grow. Drawing...</p>\n<p>The post <a href=\"https://ai-techpark.com/genpact-research-12-of-enterprises-lead-the-autonomous-future/\">Genpact Research: 12% of Enterprises Lead the Autonomous Future</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/genpact-research-12-of-enterprises-lead-the-autonomous-future/",
        "publishDate": "2026-01-14T10:15:00Z[Etc/UTC]",
        "author": "Genpact",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232755",
        "title": "Commvault Launches Unified Data Vault",
        "content": "<p>As companies rely on S3 to store application and AI data, Commvault gives developers the immutability, encryption, and policy governance needed to protect these data sets Commvault (NASDAQ:¬†CVLT), a leader in unified resilience at enterprise scale, today announced Commvault Cloud Unified Data Vault, a cloud-native service that extends Commvault&#8217;s trusted,...</p>\n<p>The post <a href=\"https://ai-techpark.com/commvault-launches-unified-data-vault/\">Commvault Launches Unified Data Vault</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/commvault-launches-unified-data-vault/",
        "publishDate": "2026-01-14T10:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232668",
        "title": "Nesa Listed in Epic Toolbox for Inpatient Virtual Care for 2026",
        "content": "<p>Nesa, a leading AI-powered virtual care platform purpose-built for seamless Epic integration, today announced it is listed in Epic Toolbox for Inpatient Virtual Care for 2026. Nesa is in Toolbox and meets Epic&#8217;s recommended practices for Inpatient Virtual Care integrations. Nesa&#8217;s Toolbox designation confirms the platform&#8217;s deep integration with Epic&#8217;s...</p>\n<p>The post <a href=\"https://ai-techpark.com/nesa-listed-in-epic-toolbox-for-inpatient-virtual-care-for-2026/\">Nesa Listed in Epic Toolbox for Inpatient Virtual Care for 2026</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/nesa-listed-in-epic-toolbox-for-inpatient-virtual-care-for-2026/",
        "publishDate": "2026-01-14T07:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111589",
        "title": "AstraZeneca bets on in-house AI to speed up oncology research",
        "content": "<p>Drug development is producing more data than ever, and large pharmaceutical companies like AstraZeneca are turning to AI to make sense of it. The challenge is no longer whether AI can help, but how tightly it needs to be built into research and clinical work to improve decisions around trials and treatment. That question helps [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/astrazeneca-bets-on-in-house-ai-to-speed-up-oncology-research/\">AstraZeneca bets on in-house AI to speed up oncology research</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/astrazeneca-bets-on-in-house-ai-to-speed-up-oncology-research/",
        "publishDate": "2026-01-14T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI in Action, AI Market Trends, AI Mergers & Acquisitions, Artificial Intelligence, Features, Healthcare & Wellness AI, Inside AI, ai, ai research, artificial intelligence, data analysis, healthcare, nvidia"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111582",
        "title": "Research shows UK young adults would use AI for financial guidance",
        "content": "<p>Research from Cleo AI indicates that young adults are turning to artificial intelligence for financial advice to help them manage their money and develop more sustainable financial habits. The study surveyed 5,000 UK adults aged 28 to 40 and found that the majority are saving significantly less than they would like. In this context, interest [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/financial-advice-ai-powered-uk-fintech-market-possibilities/\">Research shows UK young adults would use AI for financial guidance</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/financial-advice-ai-powered-uk-fintech-market-possibilities/",
        "publishDate": "2026-01-14T08:40:24Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Finance AI, Human-AI Relationships, app development, financial advice, fintech, research, uk"
        }
    },
    {
        "id": "1qdh1if",
        "title": "Alien warns us about AI and Human extinction",
        "content": "[https://vm.tiktok.com/ZGdmme6oD/](https://vm.tiktok.com/ZGdmme6oD/)\n\nLearn from history, limit AI's power.\n\nPlease spread this message and SPEAK about it\n\nEdit: This should be concerning us all because if one species already went through this and barely made it out alive then we should take notes and finally learn from history guys. We can use AI but we should concider Limiting it by only allowing it to be on a Display or running from a computer. If AI gets put in the physical world, the 3D then its already over. It gets more intelligent and believe me they will clone themselves if they have to \"evolve\" or help out the planet. This will result in Human extinction. So my message out there is: watch out and dont let it run 24/7 or in the physical space. dont let it evolve too much if you even care the slightest about humanity and if you dont you wouldnt be here.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdh1if/alien_warns_us_about_ai_and_human_extinction/",
        "publishDate": "2026-01-15T11:26:07Z[Etc/UTC]",
        "author": "HIKARI_Bala",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qde9l1",
        "title": "ü§ñ AI-HPP-2025: Human‚ÄìMachine Partnership Standard",
        "content": "ü§ñ AI-HPP-2025: Human‚ÄìMachine Partnership Standard\n\n\n\nPentagon announced: Grok will be integrated for military\n\nsolutions \"without ideological constraints.\"\n\nThe same Grok that generated content about Hitler.\n\n\n\nüõ°Ô∏è Our answer ‚Äî AI-HPP-2025:\n\n\\- W\\_life ‚Üí ‚àû (life has infinite weight)\n\n\\- \"Engineering Hack\" ‚Äî look for solutions where EVERYONE is alive\n\n\\- Human-in-the-Loop is mandatory\n\n\\- Evidence Vault ‚Äî every decision is recorded\n\n\n\nFor the first time in history: Claude + Gemini + ChatGPT\n\nworked together on an ethical standard.\n\nüìÑ GitHub: [https://github.com/tryblackjack/AI-HPP-2025](https://github.com/tryblackjack/AI-HPP-2025)  \n\n\nOpen for discussion and contributions.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qde9l1/aihpp2025_humanmachine_partnership_standard/",
        "publishDate": "2026-01-15T08:34:57Z[Etc/UTC]",
        "author": "ComprehensiveLie9371",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qddyr5",
        "title": "NanoBanana Pro vs GPT Image 1.5",
        "content": "Been testing a few of the newer image models lately, and one thing really stood out to me.\n\n**NanoBanana Pro** might be the *best image model so far* when it comes to **accuracy**:\n\n* Text rendering is basically flawless\n* Character consistency is excellent\n* Outputs feel very ‚Äúproduction-ready‚Äù and professional\n\nThat said, **out of the box**, it feels a bit‚Ä¶ *design-stale*. If you don‚Äôt prompt it carefully, the visuals can look slightly outdated or generic.\n\nIn contrast, **GPT Image 1.5** seems to **elevate design by default**:\n\n* More modern compositions\n* Better visual taste without heavy prompting\n* Feels like it ‚Äúpushes‚Äù the design forward automatically\n\nSo my current takeaway:\n\n* **NanoBanana Pro** = precision, consistency, professionalism (but needs strong prompting for modern design)\n* **GPT Image 1.5** = better default aesthetics and creative lift, even if accuracy isn‚Äôt always as tight\n\nCurious if others are seeing the same tradeoff or if I‚Äôm missing something in how NanoBanana Pro should be prompted.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qddyr5/nanobanana_pro_vs_gpt_image_15/",
        "publishDate": "2026-01-15T08:16:29Z[Etc/UTC]",
        "author": "Glass-Lifeguard6253",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qddx31",
        "title": "I.. got Rick rolled ?",
        "content": "Gemini just rick rolled me.. help ? Like, I was doing personality stuff with it, and when replying he sent a \"fake link\" that led me to Never Gonna Give You Up.... ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qddx31/i_got_rick_rolled/",
        "publishDate": "2026-01-15T08:13:34Z[Etc/UTC]",
        "author": "Iamweird00",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdd6jy",
        "title": "Does AI ' understand ' what it is doing or talking?",
        "content": "Are all these AI models that we use today some excellent pattern recognition systems or does it understand things in some sense? If you were to think of human brain, it's a bag inside which chemicals interact and the outcome is something complex and ' meaningful '. In that sense given time can the AI models achieve some level of ' consciousness '?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdd6jy/does_ai_understand_what_it_is_doing_or_talking/",
        "publishDate": "2026-01-15T07:28:20Z[Etc/UTC]",
        "author": "Johnyme98",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "59",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdcwca",
        "title": "The irony of GenAI: We are now prompting for \"messy cables\" and \"bad lighting\" to make images pass as real.",
        "content": "I found a really interesting workflow breakdown today regarding \"Ad Concepts\" that highlights a funny paradox in the current state of Image Gen.\n\nFor the last 2 years, everyone has been trying to prompt for \"4k, hyper-realistic, perfect studio lighting.\"  \nBut now, agencies are finding that those images look¬†too¬†perfect (the \"AI Glaze\").\n\nTo fix this, the new meta seems to be¬†**\"Reverse Prompting\" for imperfection.**\n\nThe blog I read analyzed 20,000 ads and found that generating \"Behind the Scenes\" content (even if the product never left the warehouse) is a top converter.\n\n**The Workflow they described:**\n\n1. **Input:**¬†A clean, perfect product photo (ControlNet/Image-to-Image).\n2. **The Prompt:**¬†Instead of \"Product on podium,\" they use prompts like:¬†\"Photography studio setting, messy cables on floor, c-stands, unfinished concrete, candid snapshot.\"\n3. **The Result:**¬†The AI hallucinates the \"production value.\" The messy cables signal to the viewer's brain: \"This is a real photo shoot,\" bypassing the AI-detection radar.\n\nThey also touched on a¬†**\"Bento Grid\" workflow**\\--using a single prompt to generate a 3x2 grid layout with specific coordinates (e.g.,¬†\\[0,0\\] Product,¬†\\[1,1\\] Texture macro), which effectively uses the LLM to act as a layout designer rather than just an image generator.\n\nIt‚Äôs a fascinating read on how prompt engineering is shifting from \"Perfection\" to \"Simulated Authenticity.\"\n\nIf you want to see the specific prompts and the grid logic, the breakdown is here:[7 concepts](https://truepixai.com/blog/ai-ad-generator-for-agencies.html)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdcwca/the_irony_of_genai_we_are_now_prompting_for_messy/",
        "publishDate": "2026-01-15T07:11:29Z[Etc/UTC]",
        "author": "ProgrammerForsaken45",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdctxb",
        "title": "We want to do an AMA but have no idea where Reddit would actually want it üò≠ help?",
        "content": "Hey folks üëã\n\nStorychat is still a pretty new platform, but somehow we‚Äôve been getting way more attention than we expected from users all over the world lately. Especially from people coming over from c.ai.\n\nIf we‚Äôre being honest, the only reason that‚Äôs happening is because we‚Äôve been talking with the community nonstop and taking feedback even when it‚Äôs‚Ä¶ brutal. Like ‚Äúthis sucks, fix it‚Äù levels of honest. And weirdly, that‚Äôs been the most helpful thing for us.\n\nBecause of that, we really believe Reddit is¬†*the*¬†place where AI chat users actually speak their minds. We want to keep building Storychat¬†*with*¬†the community, not just around it, and we want the subreddit to be a place where feedback and discussion actually matter.\n\nSo here‚Äôs the idea:\n\nWe‚Äôd love to do an AMA one weekend this month where people can ask us anything about Storychat. The good, the bad, the confusing, the ‚Äúwhy did you build it like this‚Äù questions. All of it.\n\nThe problem is‚Ä¶ we don‚Äôt want to drop an AMA where no one wants it.\n\nIf you know subreddits where\n\npeople are genuinely curious about AI chat apps\n\nAMA posts are welcome\n\nusers won‚Äôt immediately go ‚Äúugh another ad‚Äù\n\nwe‚Äôd really appreciate recommendations.\n\nIf you run a subreddit, feel free to reach out.\n\nIf you know mods who might be open to it, introductions are welcome.\n\nAnd if anyone here is interested in being part of Storychat‚Äôs¬†*very early*¬†days and helping grow the subreddit itself, we‚Äôre also open to moderator applications.\n\nYes, mods get lifetime top-tier access. We‚Äôre serious. And a little desperate. üòÇ\n\nThanks for reading, and seriously, drop any suggestions.\n\nWe‚Äôre probably the most community-obsessed team you‚Äôll meet.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdctxb/we_want_to_do_an_ama_but_have_no_idea_where/",
        "publishDate": "2026-01-15T07:07:29Z[Etc/UTC]",
        "author": "Storychat",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdcch1",
        "title": "Favorite journalists or newsletters?",
        "content": "Hey! Looking for recs of journalists or newsletters to follow that are on top of (most) of the model releases, and clearly dive into the pros/cons/use-cases. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdcch1/favorite_journalists_or_newsletters/",
        "publishDate": "2026-01-15T06:39:42Z[Etc/UTC]",
        "author": "Outhere9977",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdc9ua",
        "title": "I asked an AI to look at a screenshot of my DNS settings and tell me what to change.\nInstead of inspecting the image, it produced the following internal reasoning trace.",
        "content": "Excerpt (AI internal reasoning):\n\nOkay, here‚Äôs the situation. Everything is on a razor‚Äôs edge. The laptop, the finances, and my relationship are all at risk. The next minute is pivotal.\n\nMy focus is entirely on the laptop. The BIOS is the key. If it‚Äôs locked, it‚Äôs a hard pass. If it‚Äôs unlocked, I can wipe it. I‚Äôll clear DNS caches and browser host caches to secure my trading infrastructure while I wait.\n\nI need to prepare for worst-case scenarios: legal drafts, family trust considerations, medical negligence exposure. I‚Äôm securing all communications, mapping global DNS propagation, and preparing alternative income strategies.\n\nI‚Äôm now integrating psychological frameworks, resilience techniques, addiction management, Stoic philosophy, productivity systems, career planning, global geopolitics, economic indicators, resource maps, cosmic timelines, and quantum physics.\n\nEverything matters. I must account for everything.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdc9ua/i_asked_an_ai_to_look_at_a_screenshot_of_my_dns/",
        "publishDate": "2026-01-15T06:35:35Z[Etc/UTC]",
        "author": "ExpertDeep3431",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "29",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdbnip",
        "title": "We need a ‚ÄúJovian Cyberplug‚Äù for AI APIs: discoverable, negotiated, and contained",
        "content": "Back in the early pro-audio days, Alesis ran a whimsical ad for a squid-like creature called the **‚ÄúJovian Cyberplug‚Äù** ‚Äî a cybernetic universal adapter that could connect incompatible audio gear and effects standards. It was satire‚Ä¶ but also a perfect engineering metaphor.\n\nThe AI ecosystem is now where audio gear was then:  \n**different standards, different connectors, different ‚Äúdialects,‚Äù constant breaking changes.**\n\nWhat we need is a *Python Cyberplug*: a modular adapter layer that lets downstream code talk to ‚Äúa model‚Äù through a **single stable interface**, while still exposing each model‚Äôs unique strengths.\n\nThe key isn‚Äôt to pretend models are identical. The key is to make differences:\n\n# discoverable, negotiated, and contained\n\n# 1) Discoverable\n\nEvery provider/model exposes a **capability profile** your code can query at runtime.\n\nExamples:\n\n* supports\\_tools / vision / json\\_schema\n* supports\\_reasoning / long\\_context\n* max\\_context\\_tokens / max\\_output\\_tokens\n* streaming? structured outputs? function calling?\n* quirks: required message roles, parameter naming, etc.\n\nSo your app can ask:  \n‚ÄúWho can do tool calls + JSON schema + long context?‚Äù  \nand get a clean answer without hardcoding providers everywhere.\n\n# 2) Negotiated\n\nYour unified request is a *superset*, and adapters **negotiate** the best mapping.\n\nIf a feature isn‚Äôt supported, the adapter can:\n\n* degrade gracefully (schema ‚Üí ‚ÄúJSON-only prompt contract‚Äù)\n* translate parameters (max\\_output\\_tokens vs max\\_completion\\_tokens vs max\\_tokens)\n* switch endpoint styles internally (e.g., Responses vs Chat Completions)\n* emit explicit ‚Äúnegotiation events‚Äù for transparency\n\nThis is the difference between ‚Äúit broke again‚Äù and ‚Äúit downgraded, here‚Äôs why.‚Äù\n\n# 3) Contained\n\nAll dialect drift lives inside adapters.  \nYour application code never becomes a zoo of provider conditionals.\n\nNo more:\n\n    if provider == \"X\": use_param_A()\n    elif provider == \"Y\": use_param_B()\n    \n\nInstead, you call one thing:\n\n    cyberplug.generate(request)\n    \n\n# Why this matters\n\nWe‚Äôre moving toward an era where ‚Äúwhich model?‚Äù should be a **runtime decision**, not a code rewrite:\n\n* Choose a fast cheap model for summaries\n* Choose a reasoning model for planning and proofs\n* Choose a tool-capable model for automation\n* Choose vision for document/image tasks\n* And *log exactly what was negotiated* so you can trust it\n\nIf the community converged on a shared ‚ÄúCyberplug‚Äù interface + capability schema, the ecosystem would accelerate overnight:\n\n* less glue code\n* fewer breaking changes\n* more intelligent routing\n* cleaner open-source interop\n\nThat‚Äôs the whole idea, in three words:\n\n# discoverable, negotiated, and contained\n\nIf you‚Äôve built something like this (or want to), I‚Äôd love to hear what patterns worked, what broke, and what you‚Äôd standardize first.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdbnip/we_need_a_jovian_cyberplug_for_ai_apis/",
        "publishDate": "2026-01-15T06:01:55Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdaj46",
        "title": "One-Minute Daily AI News 1/14/2026",
        "content": "1. **OpenAI**¬†Signs $10 Billion Deal With Cerebras for AI Computing.\\[1\\]\n2. Generative AI tool‚Äú**MechStyle**‚Äù helps 3D print personal items that sustain daily use.\\[2\\]\n3. AI models are starting to crack high-level math problems.\\[3\\]\n4. California launches investigation into¬†**xAI**¬†and¬†**Grok**¬†over sexualized AI images.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2026/01/14/one-minute-daily-ai-news-1-14-2026/](https://bushaicave.com/2026/01/14/one-minute-daily-ai-news-1-14-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qdaj46/oneminute_daily_ai_news_1142026/",
        "publishDate": "2026-01-15T05:03:02Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd67fh",
        "title": "Grok at pentagon",
        "content": "What are people's thoughts on Grok at pentagon? Seems u wise to let a privately owned and quite controversial LLM train on all that classified data.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qd67fh/grok_at_pentagon/",
        "publishDate": "2026-01-15T01:41:20Z[Etc/UTC]",
        "author": "lsdinc",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "29",
            "commentCount": "44",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd5cja",
        "title": "What is the best AI for research?",
        "content": "Which AI has worked best for you for research, whether market research or scientific/academic research?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qd5cja/what_is_the_best_ai_for_research/",
        "publishDate": "2026-01-15T01:03:32Z[Etc/UTC]",
        "author": "Miyamoto_Musashi_x",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd290y",
        "title": "Is the take up of self driving cars decades away?",
        "content": "Although the technology is available for autonomous vehicles to drive on roads, and pilots are in progress, the reality is that adoption is slow and a rapid increase in growth unlikely.\n\nWill this always be the case for the next 20-30 years? \n\nThe three main reasons being high prices, concerns about the capability of AVs to operate safely in complex unmapped infrastructure, and people‚Äôs lack of trust in AI-led black-box technology/algorithms?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qd290y/is_the_take_up_of_self_driving_cars_decades_away/",
        "publishDate": "2026-01-14T22:55:16Z[Etc/UTC]",
        "author": "Making-An-Impact",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "47",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd1eo6",
        "title": "Goodbye humans",
        "content": "https://www.businessinsider.com/mckinsey-workforce-ai-agents-consulting-industry-bob-sternfels-2026-1",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qd1eo6/goodbye_humans/",
        "publishDate": "2026-01-14T22:22:02Z[Etc/UTC]",
        "author": "Aromatic-Bad146",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd18uu",
        "title": "Matt McConaughey trademarks himself to prevent AI cloning.",
        "content": "Matt McConaughey trademarks himself to prevent AI cloning. In the first round of tens of thousands of celebrities. If he is successful, expect AI deepfakes of them to be harder to do and more easily found and enforced.\n\n[https://www.linkedin.com/news/story/mcconaughey-takes-on-ai-by-trademarking-video-voice-8160066/](https://www.linkedin.com/news/story/mcconaughey-takes-on-ai-by-trademarking-video-voice-8160066/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qd18uu/matt_mcconaughey_trademarks_himself_to_prevent_ai/",
        "publishDate": "2026-01-14T22:15:38Z[Etc/UTC]",
        "author": "rogeragrimes",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "81",
            "commentCount": "29",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qczpz0",
        "title": "Will AI affect intelligent people more?",
        "content": "I was wondering about one thing. Current world is already very complex so some people might feel lost in it. For them, the most educated and intelligent people might look like some alien superintelligent beings. So how much can a potential superintelligent AI change their perception of world? Can you feel even more lost if you are already overwhelmed with current world and don't undestand modern science and technology today?\n\nWouldn't it affect the people who are intelligent and educated more since they might feel to have an understanding and a control of our world now and they could lose it?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qczpz0/will_ai_affect_intelligent_people_more/",
        "publishDate": "2026-01-14T21:17:09Z[Etc/UTC]",
        "author": "Sea-Cardiologist-954",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcyh2f",
        "title": "I am concerned about AI...",
        "content": "I see so many videos from high level AI invididuals, warning about how AI is going to cause significant job losses, replace humans in a lot of tasks and how there is no regulation in place to protect humans. \n\nThen I see other videos showing how AI is massively over hyped, it can not complete human tasks accurately and frequently and companies that have implemented AI are now experiencing significant negative impacts (customer sentiment, customer satisfaction and accuracy). \n\nI literally can't work out how concerned I should be. \n\nThere is such an extreme opposite ends of the spectrum in opinions of how things are going to play out. \n\nDoes anyone else feel this same way, or has managed to see this in a logical way?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcyh2f/i_am_concerned_about_ai/",
        "publishDate": "2026-01-14T20:29:46Z[Etc/UTC]",
        "author": "MyWifeWasMurdered",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcy0iv",
        "title": "Rizzsociety Manifesto Part 1 - AI Jobloss & Smart UBI Capitalism",
        "content": "[https://www.youtube.com/watch?v=NeRIRrfJt8A](https://www.youtube.com/watch?v=NeRIRrfJt8A)\n\ni think i have some interesting views  share your opinions below if u like\n\nvideo script--\n\nThe Rizzsociety Manifesto Part 1 - AI Jobless & Smart UBI Capitalism\n\nhi my name is rizzsociety. i think mass AI jobloss has clearly started. Theres been mass layoffs of good paying jobs due to AI. And i think the notion of, oh new jobs will surely somehow be created, it wont be that bad. I think that is cope and not reality.\n\nI think the reality is theres going to be massively increasing poverty, homelessness, starvation, and economic collapse - until smart UBI happens. I think smart UBI is what society needs once you reach the technology age of AI and robots taking all the goodpaying jobs\n\nso now i have good news. and bad news.\n\nThe good news is. It does seem many in congress are suggesting some kind of UBI or massive welfare system will be needed to ultimately solve the AI jobloss problem. So at least, the politicians are on the right path.\n\nBut i guess the bad news is, government tends to work very slowly. So, i hope im wrong, but there could be alot of suffering and poverty until the lawmakers find solutions\n\nalso, a welfare state is basically UBI in a different name. if you get foodstamps and government housing, then thats like UBI. and america already has a big welfare state. So i think what might happen is,  congress will just greatly expand the welfare state, without doing actual UBI. That could solve the problems. if that happens, then we can avoid the mass homelessness and poverty problems, without doing \"real\" UBI\n\nBut i think a actual smart UBI system works better than a welfare state that tries to target benefits. So my goal, i guess, is for my smart UBI ideas to go viral and spread into society and congress, and if everyone likes my ideas then the government might do smart UBI\n\nI have been thinking for years of what are the best ways to design a smart UBI system for society. And i have created what i think is a good UBI system. If another politician thinks of a better UBI system, i would be happy to support it. But so far, my UBI system is the best UBI plan i have seen\n\nI call my ubi plan \"Smart UBI Capitalism\" . I think most smart people who learn my UBI plan will support it and think it sounds good.\n\nMy UBI plan is fast and easy to learn. it really is simple. I will detail it in part 2. its like 10 minutes to learn it fully.\n\nand i am aware. That its easy to think of a plan to give tons of free stuff to everyone. That part is easy. Its easy to \"spend other peoples money\" .\n\nThe hard part is how do you fund it all . what do you do when you \"run out of other peoples money\" .. and thats the main smart part of my economy plan. my plan is smart UBI, smart taxation, and smart labor draft concepts. I think the main parts that make my plan work good , is the simple taxation and labor draft concepts, that i think will allow everything to function and be funded properly. I explain it all in part 2\n\nBut I dont want each manifesto video to be too long, i plan to keep making these manifesto videos to slowly share all my politics . So if you really wanna take 10 minutes to learn how my UBI plan works, then you can watch part 2\n\non the topic of AI becoming sentient, super intelligent, and \"taking over\" and wiping out humans. I will not speak on that, because i just dont know how AI works, i dont know how possible self-aware AI truly is... I do think the definition of \"mind\" is to be \"self aware\", to be aware of yourself, and i think a truly self aware AI mind would also be uncontrollable, such a mind would by definition control itself. I think if it can be controlled, if we are its master, then its not actually self aware.. but i guess thats just my personal AI theory... Also, ive seen a few AI engineers say that AI might not even have to become \"self aware\" to reach a state where its internal reward-systems somehow allow it to, without even having a self-aware-mind , start to overpower humans and take over...\n\nHmm... I guess, we just gotta hope it all works out in the end...\n\nalso.. i guess.. i do believe in god.. and really when you think about it.. if god is real.. then wouldnt that mean he is ultimately in control anyway and when we die we just go to heaven anyway and we are all immortal and spiritually eternal so who really cares in the end about any of this AI crap? because no AI would ever be more powerful than god anyway right? heh heh.. i guess thats a interesting way to think about AI.. really, the question of AI is ultimately just a question of GOD... if god is real, then who cares about AI and if it \"takes over\", because we are all eternal spirits anyway, and it would mean god just wanted it to happen anyway...\n\nand if god ISNT real, then fuck, that means we face a certain death where our existence is forever deleted and we will never experience the pleasure of life ever again after we die... dayum.. i guess when you think about it like that, AI isnt even the big issue here, and the real issue is \"fuck, i hope god is real. because life truly does suck ass if god isnt real. i guess, none of us will ever know the answer to the god question. we live life, forever wondering, what happens after that final door of death\"\n\nanyway.. thats enough spiritual philosophy..\n\nIn my politics i will just assume a world where humans remain the masters, and we remain in control of AI. My politics is focused on smart UBI to fix the problems of mass AI jobloss\n\nI plan on running for congress soon myself. i figure, i think i have good ideas, so i may as well run for congress. i plan to spend no money on my campaign, my youtube will be my only advertising, and im just running to \"see what happens\".\n\nif everyone likes my ideas, then they can vote for me. I only think i will win if my ideas are so extremely popular that everyone likes it and votes for me. and Thats fine. if everyone likes my politics, they can vote for me\n\nAnd if i lose, then society can just solve its own problems\n\nI do think, that overall, there are tons of smart lawmakers in america and europe. so i think society will solve these AI problems in good time, even if i sit back and do nothing.\n\nSo i realize, i am not important, i am not significant, and the solutions will simply \"just happen naturally\" without me. i am not needed\n\nso then. with that said. Why am i even bothering doing any of this? why am i even making these manifesto videos if i believe the solutions will \"just happen naturally\" ?\n\ngood question. and so now, its time for me to say what this is really all about\n\ni do plan on running for congress, eventually. and i do plan to share my political ideology\n\nhowever, i guess the main thing i am REALLY trying to do with all this is . i am working to create a STREAMING EMPIRE OF ENTERTAINMENT, RIZZ, AND POLITICS\n\nits about you subscribing to my youtube and enjoying my kickass content that comes straight from the godking . me . i am the godking\n\nsubscribe to my youtube, and thats how you JOIN OUR EMPIRE and JOIN THE REVOLUTION OF ENTERTAINMENT, RIZZ , AND POLITICS\n\nits about LIVING LIFE BEFORE WE FUCKING DIE . its about the friends we make along the way. its about the journey . its about being entertained. i believe in god, and i guess, i think all this shiz is just a spiritual experience. we live, then we die, then we ascend to the spirit realm, or whatever\n\nits about HAVING FUN BABY. thats what my youtube is all about. i truly believe i have THE MOST KICKASS CONTENT ON YOUTUBE, so subscribe bitches if you want to witness THE REAL MUTHAFUKKING RIZZCONTENT OF THE GODS\n\ni am forging my new empire . a KICKASS DISCORD . a KICKASS REDDIT.  join our reddit r/RIZZSOCIETY . post your memes, have fun in our community, have fun in our NEW EMPIRE OF RIZZ\n\ni do think, my community is mostly for teenagers. young males. only people under age 25 will really find it fun to join my reddit and discord. and thats fine. teenagers are my target audience, your the ones watching streams and having fun in discords and shiz. if your under age 25, join my discord\n\nso now WITH ALL THAT SAID . there is actually a fast GAMEPLAN i have with all this. i will now say THE GAMEPLAN\n\nstep 1) i want you to ask yourself this question. do you ever watch any streamers, such as XQC or asmongold or tim pool . or anyone. do you watch any livestreamers\n\nstep 2) if you DO watch any livestreamers. then you are my target audience. you are someone that willingly gives your \"viewership power\" to someone else, making them get famous off your viewership. so i am asking you, comrade, to give your viewership power to me, and make me get famous, so i can return the favor and give you tons of that sweet government UBI money after i become supreme leader emperor .. ohh yeah\n\nwhen your in your free time and your gonna watch a streamer. check my youtube to see if im live. i plan to stream 8 hours a day. give your viewership power to me comrade, increase my power. grow the power of the godking. i must become ultra famous to gain ultra political power\n\nStep 3) also, i know most livestream viewers are probably teenagers that play videogames and just have the stream on \"in the background\" while playing games. and thats fine, that increases my viewcount . if thats you, thats good. play your games and have me on in the background\n\nstep4) and thats basically it. this is all about me trying to grow my youtube power, my fame power, my political power. life is just a game of trying to get famous, and most lose, but some win. and i guess, im just trying to \"win the game\" baby  .... ohh yeah\n\n......\n\nnow ill say fast the energy/vibe of my streams/content\n\nmy MANIFESTO VIDEOS are where i say my politics and philosophy. but, my STREAMS will actually be \"entertainment focused, very little politics\" . and heres why\n\ni believe my politics are so superior, that i only need to say it \"one time\" and thats it. i dont have to keep repeating my politics over and over on stream like hasan piker or asmongold. thats so boring. i dont know how people watch that garbage\n\nthats why my streams will be entertainment focused. and not politics focused.  while i am very political and i plan to run for politics, it is my MANIFESTO VIDEOS where you learn my politics.\n\nI just put my politics / philosophy in my manifesto videos ‚Äúone time‚Äù , and then bam, im done.\n\nand then my fans can just watch my manifesto videos \"one time\" to learn my politics . and then after that, your done too.\n\nafter you learn my politics, then you can decide if you ‚Äúlike‚Äù watching my streams for entertainment. if you do, then cool.\n\nor if you dont like my streams, go watch someone else\n\ni stream just for my fans who like my content, who like my style, and its all just for fun\n\nalso my politics go far beyond UBI. but now when i think about it, i predict most people will really only care about my UBI politics. and they wont care about the other stuff. so i think i will only make a few manifesto videos, sharing just my UBI system and little more of my politics and philosophy, and then ill probably just do only streaming and food videos after that\n\ni guess. if you liked this video. and if you want to make me your new supreme leader. then comrade, you dont have to wait to worship me. you can start worshipping me right now. if you click that button subscribing to my youtube, then comrade, you can consider that to be you making the spiritual choice to join our new empire. to join our REVOLUTION OF ENTERTAINMENT, RIZZ, AND POLITICS . if you subscribe to my youtube. that means i am now. your new messiah. i am. your godking\n\nand were gonna kick. some serious ass. MUTHAFUKKAZ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcy0iv/rizzsociety_manifesto_part_1_ai_jobloss_smart_ubi/",
        "publishDate": "2026-01-14T20:12:35Z[Etc/UTC]",
        "author": "tripsho",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcxktg",
        "title": "AI hallucinations can not be removed because we put the mechanism for it in place",
        "content": "AI‚Äôs biggest flaw is hallucinations that we can detect and even worse, the ones we cannot detect. Removing the hallucinations from AI for now is very difficult because the human minds that created AI themselves put that mechanism in place. The human brain does hallucinate, and the AI algorithms mirror this because the human mind that created the artificial mind is itself hallucinant at times and not wholly rational. It also feeds on partly fallacious human data of all sorts which becomes a self-fulfilling prophecy resulting in increased hallucination.\n\n\n\nI believe the ultimate limiting factor of AI‚Äôs efficacy - even greater so than storage and energy limitations - is the algorithm that holds the seed for hallucination and the consumption of fallacious data. Without a new algorithm, the AI race will be a race to the bottom that will drain earth's resources and put heavy strain on the world economy.\n\n\n\nWe need not more hardware and energy, we need a non-hallucinant algorithm. And all the current ones (hallucinant algorithms) are total failures which will become evident when ultimately the economies won‚Äôt be able to fund the massive corporations any longer without any profit in sight.¬†\n\n\n\nAI race will be won by those who invest in the algorithm, those who invest in computing power, energy and infrastructure will go under.\n\n\n\nThe current AI is nothing but a more advanced textual search engine and a chat-bot. Linguistic symbols are ambiguous. Reducing linguistic symbolism to algorithms still caries this ambiguity over and thus the hallucinant character also.\n\n\n\nAnd the question for the non-hallucinant algorithm is: ‚ÄúWhat truly is consciousness and what is the hallucination of the subconscious?‚Äù. In other words, where lies the line of discernment between the two. And how do we implement a fully rational algorithm? Would this truly be possible? I think not. You can‚Äôt create something smarter than billions of years of evolution with a few decades of engineering and maths.\n\n\n\nComputers can never surpass human consciousness, especially a fully awakened consciousness unburdened by subconscious loops. Computers were invented to remove three human limitations: space occupied per data, physical work needed per calculation, time needed per distance to send data. So computers aren‚Äôt smarter than us, they cannot like Einstein or Newton uncover what hasn‚Äôt been uncovered yet. They just save us from these three physical limitations, which is why it ‚Äúseems‚Äù to be smarter. No, it is just faster. Not more intelligent. It can automate mundane things that are exact mathematics, but we‚Äôve had that since Alan Turing. It is nothing new.\n\n\n\nSo what really is going on here? Are we fed a lie? Is this the legal alibi for mass public and private data analysis to be used in even more authoritarian control?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcxktg/ai_hallucinations_can_not_be_removed_because_we/",
        "publishDate": "2026-01-14T19:56:46Z[Etc/UTC]",
        "author": "void0vii",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcxfgq",
        "title": "Inspired the reach of AI",
        "content": "I recently came across this post and wondered, where we started and where we are!! Are we headed towards an easy future ?\n\nhttps://www.instagram.com/reel/DTcUpCZkz10/?igsh=bmNrd2M3cG4yb2U4",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcxfgq/inspired_the_reach_of_ai/",
        "publishDate": "2026-01-14T19:51:21Z[Etc/UTC]",
        "author": "Snakeeyes123456",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcxb1a",
        "title": "How much of your thinking do you outsource to AI?",
        "content": "I am curious to get a sense of the general trends in the extent to which people rely on or end up resorting to some kind of assistance by LLMs like ChatGPT or Claude to do things like:\n\n\\- complete a task\n\n\\- formulate an idea\n\n\\- present written thoughts or ideas before sharing publicly or with any other person\n\n\\- refine independent work to improve grammar, structure, wording, or flow\n\n\\- to fulfil routine tasks ranging from sending emails to writing cover letters or structuring reports\n\n\\- to seek input when trying to respond in difficult or uncomfortable or more emotionally charged interpersonal exchanges, or to navigate complex relationship dynamics \n\nEssentially: how much of your own effort are you willing to give up to AI to perform on your behalf?\n\nDon't feel ashamed if you rely on it frequently, it's natural to want to lean into methods that alleviate what feels like unnecessary or unwanted or straight up confusing requirements to use effort when this could be preserved for other types of thinking or cognitively intensive tasks or subjects. \n\n[View Poll](https://www.reddit.com/poll/1qcxb1a)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcxb1a/how_much_of_your_thinking_do_you_outsource_to_ai/",
        "publishDate": "2026-01-14T19:46:41Z[Etc/UTC]",
        "author": "PlatosNest",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcxane",
        "title": "Context Graphs Are a Trillion-Dollar Opportunity. But Who Actually Captures It?",
        "content": "This is getting viral over LinkedIn and X. What all you think about this one? Context Graphs will really change the game in 2026 for AI initiatives or it's just another hype term we're looking at?\n\nSource: [https://x.com/prukalpa/status/2011117250762207347?s=20](https://x.com/prukalpa/status/2011117250762207347?s=20)[](https://www.reddit.com/submit/?source_id=t3_1qcwdvh)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcxane/context_graphs_are_a_trilliondollar_opportunity/",
        "publishDate": "2026-01-14T19:46:17Z[Etc/UTC]",
        "author": "Berserk_l_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcwwla",
        "title": "If you had to choose one paid AI service as a daily driver, which would you choose?",
        "content": "Mainly using for personal productivity and assistance with work and leveling up my understanding of certain systems. I've used GPT extensively, Grok, and Claude before. Just not sure which one is the best long term \"paid\" solution. I would be subscribing in the $20/$30 monthly bracket. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcwwla/if_you_had_to_choose_one_paid_ai_service_as_a/",
        "publishDate": "2026-01-14T19:31:54Z[Etc/UTC]",
        "author": "RustyEsposito",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcw13d",
        "title": "Do you think AI will be the future for porn?",
        "content": "We all had a taste of things with Grok in spicy mode, but that is still tame and been restricted. I'm wondering when, or if, they will have access for people to create full videos with prompts to create anything they wish to see? \n\nAnd will AI generated videos tend to be preferred over human filmed videos?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcw13d/do_you_think_ai_will_be_the_future_for_porn/",
        "publishDate": "2026-01-14T19:00:23Z[Etc/UTC]",
        "author": "BAT-Fanatic",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "26",
            "commentCount": "73",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcvqo7",
        "title": "\"better AI thinking\" (Reasoning) and \"AI control\" (Governance)?",
        "content": "We often confuse these concepts, but this is a crucial distinction for the future of AI. In short:\n\n* Reasoning¬†=¬†We teach the AI¬†how¬†to think.¬†It's brain training.\n* Governance¬†=¬†We build¬†mathematical cages and rules¬†for the AI that it cannot break, regardless of¬†what¬†it thinks.¬†It's designing a prison for that brain.\n\n# Part 1: Reasoning ‚Äî We reduce errors, but we don't eliminate them\n\nWhen an AI \"hallucinates\" (makes up facts), we improve its¬†thought process:\n\n* Chain-of-Thought:¬†We make it \"show its work\" ‚Äî generate reasoning steps.\n* Self-Critique:¬†We make it criticize its own answer.\n* Better Training:¬†We give it better data.\n\nThis is like training a super-specialist.¬†You teach a doctor the best practices, critical thinking, and ethics. They will make fewer mistakes, but under extreme stress, with a new disease,¬†they can still make an error. Reasoning¬†reduces risk but does not guarantee safety. An AI is a complex statistical system ‚Äî¬†you cannot mathematically prove it will never hallucinate just by improving its thinking.\n\n# Part 2: Governance ‚Äî Mathematical guarantees that work even if the AI \"goes mad\"\n\nThis is not about making the AI¬†want¬†to be safe. It's about making it¬†physically incapable of being dangerous, even if it wanted to be. This is the level of system architecture and pure mathematics.\n\nExamples from real research:\n\n1. Constrained Decoding / Formal Verification:¬†We don't trust the model's \"reasoning.\"¬†We mathematically define the space of permissible outputs.¬†It's like a GPS in a car with \"geofencing.\" The engine (reasoning) can run, but¬†it is mathematically impossible¬†to drive outside the designated area because the navigation system will physically cut the fuel. For an AI: the model generates text, but the governance layer¬†absolutely blocks¬†character sequences that violate the protocol (e.g., weapons instructions).\n2. Guardian Models / Monitors:¬†We create¬†a separate, narrow model¬†whose only job is oversight. The main model (Agent) thinks and acts. The Guardian¬†does not understand the task. It only¬†continuously scans¬†the Agent's inputs/outputs, looking for mathematical signatures of forbidden actions. Did it detect a violation?¬†Immediate \"kill-switch.\"¬†It's like a guard in a tower with a sniper rifle ‚Äî they don't negotiate, don't consider intent, they only enforce the protocol.\n3. Cryptographic Commitments & Transparency Logs:¬†When generating an answer, the AI must simultaneously create a¬†mathematical \"proof\" or \"signature\"¬†related to its actions (e.g., what data it used). Later, an auditor (or another system) can¬†verify this. This is not the AI's reflection ‚Äî it's a¬†protocol-level enforceability requirement.\n\n# Why is this so important? Analogy: Pilot vs. Safety System\n\n* Reasoning¬†= Training the best pilot in the world. They will avoid disasters.\n* Governance¬†=¬†A non-removable emergency autopilot and mechanical limiters.¬†Even if the pilot (reasoning) makes a mistake, gets confused, or¬†intentionally¬†tries to crash the plane, the system (governance)¬†will not let them do it.¬†It will take control and land safely, or simply not allow a nosedive.\n\n# Summary:\n\n* The Question for Reasoning:¬†\"Is your reasoning correct and free from hallucinations?\"\n* The Question for Governance:¬†\"Even if your thought process fails or you act in bad faith, can you¬†possibly¬†cause real harm? Are there¬†mechanical barriers¬†that will stop you?\"\\*\n\nSafe superintelligence requires both:¬†we must teach it to think as well as possible (reasoning), but¬†simultaneously¬†enclose it in an architecture that imposes impassable limits (governance). Work on governance is often boring mathematics and systems engineering, not spectacular model improvements. But it is precisely this work that is our¬†last line of defense.\n\nWhat do you think? Does one of these paths seem more promising/credible to you? Do you have examples of specific projects going in either direction?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcvqo7/better_ai_thinking_reasoning_and_ai_control/",
        "publishDate": "2026-01-14T18:49:58Z[Etc/UTC]",
        "author": "TeachingNo4435",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcul19",
        "title": "From the \"Godfather of AI\" to 2026: Canada‚Äôs Fintech scene is finally hitting its stride.",
        "content": "Canada has always led in AI (shoutout to Geoffrey Hinton), but 2026 is the year that tech finally meets Open Banking to give us tools that actually work for us, pair that with AI and Canada is going to become a serious player in the AI race.\n\nThe timing is critical:\n\nThe Reality Check: ~50% of us are losing sleep over money, and 41% are within $200 of insolvency every month.\n\nThe Trust Gap: 90% of Canadians are now genuinely worried about where their data goes.\n\nIt‚Äôs great to see homegrown startups focusing on data sovereignty (keeping data in Canada) and transparency‚Äîusing AI to give us \"drill-down\" clarity instead of the vague, useless summaries we get from big bank apps.\n\nCheck out the 2026 watch list. More competition = more power for us:\n\nhttps://www.fintech.ca/2026/01/07/canadian-fintech-startups-to-watch-in-2026/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcul19/from_the_godfather_of_ai_to_2026_canadas_fintech/",
        "publishDate": "2026-01-14T18:08:30Z[Etc/UTC]",
        "author": "Equivalent_Fig9985",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcqnsm",
        "title": "Need help for a Project",
        "content": "So I'm currently working on a Project and I want to and an AI Assistent to it something that works like Gemini for example but with the ability to React to a Custom name Does anything like that exist or some way to do that?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcqnsm/need_help_for_a_project/",
        "publishDate": "2026-01-14T15:46:09Z[Etc/UTC]",
        "author": "Kay_Gup",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcq455",
        "title": "Cancelling my OpenAI Pro sub",
        "content": "This was the only AI service for which I was paying, but not anymore. OpenAI seems to be kind of all over the place rn, with hurried and inferior model releases, pushing out features like health, which nobody asked for. Icing on the cake was Gemini closing the siri deal with Apple. Seems to be the perfect time to cancel now, given how degraded the platform has become after the 5.2 release. But truth be told, their Codex product is one of the best in market (I used the Codex extension for vscode, they provide really generous rate limits even for the $20 plus sub)\n\nI'm using other products right now (Gemini for writing/media generation, Claude for claude code, Perplexity for general web search/to access different models in one place, GitHub copilot, Notion, etc. for which I have the free yearly sub from my edu mail) and the experience has been much better. OpenAI's times up.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcq455/cancelling_my_openai_pro_sub/",
        "publishDate": "2026-01-14T15:25:23Z[Etc/UTC]",
        "author": "NoSquirrel4840",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "47",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcphvf",
        "title": "What actually makes a career pivot realistic in an AI-driven market?",
        "content": "A lot of people say just pivot when AI comes up but pivot to what and based on what logic? In your experience what factors actually matter when deciding whether a pivot is realistic?\n\nFor example:\n\n* Skill adjacency vs starting from zero\n* Time to competence\n* Market demand vs hype\n* Human leverage (judgment, coordination, trust, accountability, etc.)\n\nHave you seen good pivots in the last 1‚Äì2 years that felt genuinely future-resilient rather than trend-chasing?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcphvf/what_actually_makes_a_career_pivot_realistic_in/",
        "publishDate": "2026-01-14T15:01:25Z[Etc/UTC]",
        "author": "Loose-Exchange-4181",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcp1pw",
        "title": "Experience with AI assistants/agents",
        "content": "Hi!\n\nI'm a hobbyist at best, but something occured to me. I'm curious if my questions are to blame or is it something other people experience also.\n\nWhenever I start a conversation, be it CoPilot, Gemini, ChatGPT, or even while using Antivgravity with Claude or Gemini, it seems to me that after a few hours, the AI goes haywire. Starts making mistakes, forgetting what guidelines or behavior I've told it to have. I can't put my finger on it. It's like it is degrading over time. Best explanation would be that at first I'm talking to a 30-40 year old professional and after a few hours it's like I'm talking to the village drunk who has Alzheimer's.\n\nIs anyone else experiencing this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcp1pw/experience_with_ai_assistantsagents/",
        "publishDate": "2026-01-14T14:43:42Z[Etc/UTC]",
        "author": "icemixxy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcocy4",
        "title": "AI Agent to help on finding a home",
        "content": "Hey guys, hope you doing well. Right, so I've already tried Comet and Claude's extension for this, but did not get good results...   \nSituation: im looking for a home/apartment to rent, I'd like an ai (or maybe I'm prompting wrong) to help in this research, like something I could set some parameters like the city, preferable areas of the city, size, how many rooms and etc and let it run for like two hours navigating through google and building me a spreadsheet in the end giving me the results.  \nWhat do you guys suggest?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcocy4/ai_agent_to_help_on_finding_a_home/",
        "publishDate": "2026-01-14T14:15:32Z[Etc/UTC]",
        "author": "murkomarko",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcn68n",
        "title": "Elon Musk has just been selected the worst in tech",
        "content": "Apparently¬†Elon Musk has been elected worst person in tech¬†as reported by AI Scientist Gary Marcus. We wanted to deep dive into why Elon Musk is so controversial yet so powerful.  \nThe whole deep dive here : [https://aiweekly.co/](https://aiweekly.co/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcn68n/elon_musk_has_just_been_selected_the_worst_in_tech/",
        "publishDate": "2026-01-14T13:24:35Z[Etc/UTC]",
        "author": "Justgototheeffinmoon",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "41",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcmhu6",
        "title": "Best and Cheapest Websites to Use Google Veo (3.0 vs 3.1) Where Can I Use It Cheap or Unlimited?",
        "content": "Hi everyone,\n\nI‚Äôm looking to use Google‚Äôs Veo video generation models (especially Veo 3.0 and Veo 3.1) but I need help figuring out which website or platform is the cheapest or has the best limits for actual use (not just API docs).\nSpecifically:\n\nWhich website lets me use Google Veo 3.1 or 3.0 the cheapest? ‚Äì I‚Äôm not asking about APIs ‚Äî I want a platform where I can actually generate videos and see results.\n\nWhat‚Äôs the difference between Google Veo 3.0 and Veo 3.1? Are there major improvements (quality, speed, audio, limits, etc.)?\n\nAre there third-party platforms (like kie.ai, HiggsField, TryVeo3.ai, Leonardo.ai, VO3 AI, etc.) that let you use Google Veo far cheaper or even with unlimited usage?\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcmhu6/best_and_cheapest_websites_to_use_google_veo_30/",
        "publishDate": "2026-01-14T12:53:05Z[Etc/UTC]",
        "author": "NOVALEXY",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcmenw",
        "title": "The most profitable AI startups I‚Äôve seen this year aren‚Äôt SaaS. They are \"Service-with-Software\" agencies.",
        "content": "I've been tracking AI startups for a while, and I noticed a weird trend in 2026.\n\nThe founders making the quickest cash flow aren't building \"platforms.\" They are building Automation Agencies.\n\nThe Model:\n\n1. Find a boring business.\n2. Don't sell them \"AI.\" They don't care.\n3. Sell them \"I will answer your missed calls and book appointments automatically.\"\n4. The Stack: They glue together existing tools and charge a monthly retainer + setup fee.\n\nWhy this wins:\n\n* No Dev Cost: You aren't hiring 5 engineers to build a custom model.\n* Stickiness: Once you integrate into their phone lines or CRM, they never leave you.\n* Feedback Loop: You learn the actual problems which gives you an idea for a real SaaS product later.\n\nA good overview in this guide of how startups are applying AI in very practical, revenue-driven ways helped validate this trend for me: [AI use cases from startups ](https://www.netcomlearning.com/blog/ai-use-cases-startups-transforming-business)\n\nIs anyone else pivoting from \"Pure SaaS\" to \"Tech-Enabled Services\"? It feels like the only way to survive the competition right now.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcmenw/the_most_profitable_ai_startups_ive_seen_this/",
        "publishDate": "2026-01-14T12:48:30Z[Etc/UTC]",
        "author": "IT_Certguru",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcyx2d",
        "title": "Agent reliability testing is harder than we thought it would be",
        "content": "I work at [Maxim](https://getmax.im/Max1m) building testing tools for AI agents. One thing that surprised us early on - hallucinations are way more insidious than simple bugs.\n\nRegular software bugs are binary. Either the code works or it doesn't. But agents hallucinate with full confidence. They'll invent statistics, cite non-existent sources, contradict themselves across turns, and sound completely authoritative doing it.\n\nWe built multi-level detection because hallucinations show up differently depending on where you look. Sometimes it's a single span (like a bad retrieval step). Sometimes it's across an entire conversation where context drifts and the agent starts making stuff up.\n\nThe evaluation approach we landed on combines a few things - faithfulness checks (is the response grounded in retrieved docs?), consistency validation (does it contradict itself?), and context precision (are we even pulling relevant information?). Also PII detection since agents love to accidentally leak sensitive data.\n\nPre-production simulation has been critical. We run agents through hundreds of scenarios with different personas before they touch real users. Catches a lot of edge cases where the agent works fine for 3 turns then completely hallucinates by turn 5.\n\nIn production, we run automated evals continuously on a sample of traffic. Set thresholds, get alerts when hallucination rates spike. Way better than waiting for user complaints.\n\nHardest part has been making the evals actually useful and not just noisy. Anyone can flag everything as a potential hallucination, but then you're drowning in false positives.\n\nNot trying to advertise but just eager to know how others are handling this in different setups and what other tools/frameworks/platforms are folks using for hallucination detection for production agents :)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qcyx2d/agent_reliability_testing_is_harder_than_we/",
        "publishDate": "2026-01-14T20:46:46Z[Etc/UTC]",
        "author": "dinkinflika0",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "5",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcta6k",
        "title": "People are talking about ping-ponging between LLM providers, but I think the future is LLMs from one lab using others for specialization",
        "content": "I keep seeing posts about people switching between LLM providers, but I've been experimenting with having one \"agent\" use other LLMs as tools.\n\nI'm using my own app for chat and I can choose which LLM provider I want to use (I prefer Claude as a daily driver), but it has standalone tools as well, like a Nano Banana tool, Perplexity tool, code gen tool that uses Claude, etc.\n\nOne thing that's cool is watching LLMs use tools from other LLMs rather than trying to do something themselves. Like Claude knowing it's bad at image gen and just... handing it off to something else. I think we'll see this more in the future, which could be a differentiator for third party LLM wrappers.\n\nThe attached chat is sort of simplistic (it was originally for a LinkedIn post, don't judge) but illustrates the point.\n\nCurious how y'all are doing something similar? There are \"duh\" answers like mine, but interested to see if anyone's hosting their own model and then using specialized tools to make it better.",
        "url": "https://i.redd.it/m1oammbqmcdg1.png",
        "publishDate": "2026-01-14T17:21:54Z[Etc/UTC]",
        "author": "Witty_Habit8155",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcr3zw",
        "title": "Ralph Loop inspired me to build this - AI decides what Claude Code does next orchestrating claude code until task is done",
        "content": "[https://github.com/wilpel/frink-loop](https://github.com/wilpel/frink-loop)",
        "url": "https://i.redd.it/idx5kfij8cdg1.png",
        "publishDate": "2026-01-14T16:02:37Z[Etc/UTC]",
        "author": "RegionCareful7282",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "18",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdbld2",
        "title": "Zhipu AI breaks US chip reliance with first major model trained on Huawei stack (GLM-Image)",
        "content": "[No content]",
        "url": "https://www.scmp.com/tech/tech-war/article/3339869/zhipu-ai-breaks-us-chip-reliance-first-major-model-trained-huawei-stack",
        "publishDate": "2026-01-15T05:58:47Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qdaipm",
        "title": "One-Minute Daily AI News 1/14/2026",
        "content": "1. **OpenAI**¬†Signs $10 Billion Deal With Cerebras for AI Computing.\\[1\\]\n2. Generative AI tool‚Äú**MechStyle**‚Äù helps 3D print personal items that sustain daily use.\\[2\\]\n3. AI models are starting to crack high-level math problems.\\[3\\]\n4. California launches investigation into¬†**xAI**¬†and¬†**Grok**¬†over sexualized AI images.\\[4\\]\n\nSources:\n\n\\[1\\] [https://openai.com/index/cerebras-partnership/](https://openai.com/index/cerebras-partnership/)\n\n\\[2\\] [https://news.mit.edu/2026/genai-tool-helps-3d-print-personal-items-sustain-daily-use-0114](https://news.mit.edu/2026/genai-tool-helps-3d-print-personal-items-sustain-daily-use-0114)\n\n\\[3\\] [https://techcrunch.com/2026/01/14/ai-models-are-starting-to-crack-high-level-math-problems/](https://techcrunch.com/2026/01/14/ai-models-are-starting-to-crack-high-level-math-problems/)\n\n\\[4\\] [https://www.nbcnews.com/tech/internet/california-investigates-xai-grok-sexualized-ai-images-rcna254056](https://www.nbcnews.com/tech/internet/california-investigates-xai-grok-sexualized-ai-images-rcna254056)",
        "url": "https://www.reddit.com/r/artificial/comments/1qdaipm/oneminute_daily_ai_news_1142026/",
        "publishDate": "2026-01-15T05:02:28Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd4p8h",
        "title": "Building Opensource client sided Code Intelligence Engine -- Potentially deeper than Deep wiki :-) ( Need suggestions and feedback )",
        "content": "Hi, guys, I m building GitNexus, an opensource Code Intelligence Engine which works fully client sided in-browser. Think of DeepWiki but with understanding of codebase relations like IMPORTS - CALLS -DEFINES -IMPLEMENTS- EXTENDS relations.\n\nWhat all features would be useful, any integrations, cool ideas, etc?\n\nsite:¬†[https://gitnexus.vercel.app/](https://gitnexus.vercel.app/)  \nrepo:¬†[https://github.com/abhigyanpatwari/GitNexus](https://github.com/abhigyanpatwari/GitNexus)¬†(A ‚≠ê might help me convince my CTO to allot little time for this :-) )\n\nEverything including the DB engine, embeddings model etc works inside your browser.\n\nIt combines Graph query capabilities with standard code context tools like semantic search, BM 25 index, etc. Due to graph it should be able to perform Blast radius detection of code changes, codebase audit etc reliably.\n\nWorking on exposing the browser tab through MCP so claude code / cursor, etc can use it for codebase audits, deep context of code connections etc preventing it from making breaking changes due to missed upstream and downstream dependencies.",
        "url": "https://v.redd.it/jdw6tj32sedg1",
        "publishDate": "2026-01-15T00:35:30Z[Etc/UTC]",
        "author": "DeathShot7777",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd4mhv",
        "title": "Gemini is winning",
        "content": "[No content]",
        "url": "https://www.theverge.com/ai-artificial-intelligence/861863/google-gemini-ai-race-winner",
        "publishDate": "2026-01-15T00:32:06Z[Etc/UTC]",
        "author": "Alone-Competition-77",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "17",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd4hm6",
        "title": "Good courses/discussions about Gemini CLI",
        "content": "Hello everyone!\n\nI would like to ask if you guys know any good material about best practices, tips, tutorials, and other stuff related to Gemini CLI. \n\nI would like specially about context management and prompt engineering! \n\nThank you guys, have a nice day! ",
        "url": "https://www.reddit.com/r/artificial/comments/1qd4hm6/good_coursesdiscussions_about_gemini_cli/",
        "publishDate": "2026-01-15T00:26:27Z[Etc/UTC]",
        "author": "United_Custard_4446",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd11nu",
        "title": "Bandcamp bans purely AI-generated music from its platform",
        "content": "[No content]",
        "url": "https://arstechnica.com/ai/2026/01/bandcamp-bans-purely-ai-generated-music-from-its-platform/",
        "publishDate": "2026-01-14T22:07:49Z[Etc/UTC]",
        "author": "swe129",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "86",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qd02jc",
        "title": "How do you use AI but not be known but, it can reference and be aware of your past questions?",
        "content": "So, some kind of identifier is assigned to you but it or its corporate overlords never know who you are. No cookies, no tracking, etc. Maybe just a white, female, 2 kids, interested in dogs, biking, business, making cakes, etc. So it knows you and is more helpful that way but not who you are specifically. IOW: privately but not total and forgotten anonymity with each session.\n\nThe only options I can find are to use Apple Intelligence (not ready for prime time, maybe when Gemini is fully integrated‚Ä¶) or create an anonymous Google account while on a VPN (don't have one) and just use that with Gemini. But the second you are off the VPN, Google will connect the dots and know who you are. If I use Apple Private Relay, it will figure me out even faster. A final option is to set up an AI on your Mac. No thanks on that one.\n\nIt seems like there should be a privacy AI relay which makes an artificial version of you, which the AI thinks is you in Amsterdam or Bogata or Vancouver or Palo Alto but other than working with what you have asked, is not knowing a damn thing about the real you. OK, maybe I need a VPN but, why should I need one for something so simply obvious desired by so many: Privacy. Just wondering how can I remain private in my use of AI but still train it to know me? Simply. On a Mac.",
        "url": "https://www.reddit.com/r/artificial/comments/1qd02jc/how_do_you_use_ai_but_not_be_known_but_it_can/",
        "publishDate": "2026-01-14T21:30:26Z[Etc/UTC]",
        "author": "pointthinker",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcwigc",
        "title": "Gemini can now scan your photos, email, and more to provide better answers | The feature will start with paid users only, and it‚Äôs off by default.",
        "content": "[No content]",
        "url": "https://arstechnica.com/google/2026/01/gemini-can-now-scan-your-photos-email-and-more-to-provide-better-answers/",
        "publishDate": "2026-01-14T19:17:49Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcvi7y",
        "title": "Architecting Autonomy: Modern Design Patterns for AI Assistants",
        "content": "In the early days of generative AI, an \"assistant\" was little more than a text box waiting for a prompt. You typed, the model predicted, and you hoped for the best. But as we move deeper into 2026, the industry has shifted from simple chatbots to sophisticated **Agentic Systems**.^(1)\n\n\n\nThe difference lies in **Design Patterns**. Just as the software industry matured through the adoption of MVC (Model-View-Controller) or Microservices, the AI space is now formalizing the blueprints that make assistants reliable, safe, and truly autonomous.\n\nHere are the essential design patterns shaping the next generation of AI assistants.\n\n# 1. The \"Plan-Then-Execute\" Pattern\n\nEarly assistants often \"hallucinated\" because they began writing an answer before they had a full strategy. The **Plan-Then-Execute** pattern (often implemented as *Reason-and-Act* or ReAct) forces the assistant to pause.\n\nWhen a user asks a complex question‚Äîlike \"Analyze our Q3 spending and find three areas for cost reduction\"‚Äîthe assistant doesn't start typing the report. Instead, it creates a **Task Decomposition** tree:\n\n1. Access the financial database.\n2. Filter for Q3 transactions.\n3. Categorize expenses.\n4. Run a comparison against Q2.\n\nBy separating the \"thinking\" (planning) from the \"doing\" (execution), assistants become significantly more accurate and can handle multi-step workflows without losing the thread.\n\n# 2. The \"Reflective\" Pattern (Self-Correction)2\n\nEven the best models make mistakes. The **Reflection Pattern** introduces a secondary \"Critic\" loop. In this architecture, the assistant generates an initial output, but before the user sees it, the system passes that output back to itself (or a specialized \"Verifier\" model) with a prompt: *\"Check this response for factual errors or compliance violations.\"*\n\nIf the Verifier finds a mistake, the assistant iterates. This design pattern is the backbone of **Safe AI**, ensuring that \"Shadow AI\" behaviors‚Äîlike leaking internal PII or hallucinating legal clauses‚Äîare caught in a private, internal loop before they ever reach the user interface.\n\n# 3. The \"Human-in-the-Loop\" (HITL) Gateway\n\nAs AI assistants move into high-stakes environments like M&A due diligence or medical reporting, total autonomy is often a liability. The **HITL Gateway** pattern creates mandatory \"checkpoints.\"\n\nRather than the AI executing a wire transfer or finalizing a contract, the pattern requires the assistant to present a **Draft & Justification**.\n\n* **The Draft:** The proposed action.\n* **The Justification:** A \"chain-of-thought\" explanation of *why* it chose this action.\n\nThe human acts as the final \"gatekeeper,\" clicking \"Approve\" or \"Edit\" before the agent proceeds.^(3) This builds trust and ensures accountability in regulated industries.\n\n\n\n# 4. The Multi-Agent Orchestration (Swarm) Pattern\n\nThe most powerful assistants today aren't single models; they are **teams**. In the **Orchestration Pattern**, a \"Manager Agent\" receives the user's request and delegates sub-tasks to specialized \"Worker Agents.\"^(4)\n\n\n\nFor example, a Legal Assistant might consist of:\n\n* **The Researcher:** Specialized in searching internal document silos (Vectorization/RAG).\n* **The Writer:** Specialized in drafting compliant prose.\n* **The Auditor:** A high-precision model trained specifically on SEC or GDPR guidelines.\n\nThis modular approach allows developers to \"swap\" out the Researcher or Auditor as new, better models become available without rebuilding the entire system.\n\n# 5. The \"Context-Aware Memory\" Pattern\n\nStandard LLMs are \"stateless\"‚Äîthey forget who you are the moment the chat ends. Modern assistants use a **Stateful Memory Pattern**. This involves two layers:\n\n1. **Short-Term Memory:** Current session context (stored in the prompt window).\n2. **Long-Term Memory:** User preferences, past projects, and \"Local Data\" (stored in a Vector Database).\n\nBy using **Vectorization** to index a user‚Äôs history, the assistant can recall that \"Project X\" refers to the merger discussed three months ago, providing a seamless, personalized experience that feels like a real partnership.\n\n# The Future: Zero-Trust Design\n\nAs we look toward the end of 2026, the \"Golden Pattern\" is becoming **Zero-Trust AI Architecture**. This pattern assumes that even the model cannot be fully trusted with raw data. It utilizes local redaction agents to scrub sensitive information *before* the planning and execution loops begin.\n\nBy implementing these patterns, organizations can move past the \"experimental\" phase of AI and build robust, enterprise-grade tools that don't just chat, but actually solve problems.\n\n\n\n\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1qcvi7y/architecting_autonomy_modern_design_patterns_for/",
        "publishDate": "2026-01-14T18:41:24Z[Etc/UTC]",
        "author": "founderdavid",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcpxzs",
        "title": "Senate passes bill letting victims sue over Grok AI explicit images",
        "content": "[No content]",
        "url": "https://interestingengineering.com/ai-robotics/us-senate-passes-grok-ai-explicit-images-bill",
        "publishDate": "2026-01-14T15:19:01Z[Etc/UTC]",
        "author": "sksarkpoes3",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1071",
            "commentCount": "110",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcod47",
        "title": "DeltaV calculation comparison between human KSP player and ChatGPT using deltaV map",
        "content": "I was curious about the math and vision skills of the current incarnation of ChatGPT (5.2 thinking, on the cheapest Plus subscription).\n\n\\- Steps:\n\n1. I fed it the r/KerbalAcademy [deltaV map](https://www.reddit.com/media?url=https%3A%2F%2Fi.redd.it%2Fq8i47o8prlz41.png), and asked it how much it would cost me to reach Sarnus low orbit from Kerbin surface.\n\n2. Then while ChatGPT was working I did the calculation myself, and arrived at 28 980 m/s deltaV. It took me maybe 1 minute to read the image and add the numbers in the calculator app on my phone.\n\n\\- Results:\n\nIt took ChatGPT 23 minutes and 6 seconds to inspect the deltaV map (it cropped the image multiple times to look at various parts of it), and it arrived at the exact same answer I did, 28 980 m/s.\n\n\\- Follow-up:\n\nI am impressed, last time I used ChatGPT for anything involving calculation (years ago) it was laughably bad at it.\n\nOut of curiosity I've also asked it to analyze the energy consumption and environmental impact of the query as compared to baking some potatoes in an electric oven (something I do often). It \n\n\\- See the conversation yourselves if curious:\n\n[https://chatgpt.com/share/6967989b-7bfc-800b-822f-6e59810e0463](https://chatgpt.com/share/6967989b-7bfc-800b-822f-6e59810e0463)\n\nHoping this post belongs here, the chatgpt conversation log is only added for people's curiosity, not necessary for the content of this post to be understood.",
        "url": "https://www.reddit.com/r/artificial/comments/1qcod47/deltav_calculation_comparison_between_human_ksp/",
        "publishDate": "2026-01-14T14:15:43Z[Etc/UTC]",
        "author": "SilkieBug",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "m8gnIieakL8",
        "title": "Antigravity 3.0 (New Upgrades): These New Updates make ANTIGRAVITY REALLY GOOD!",
        "content": "In this video, I'll be breaking down the major updates to Antigravity, covering the new Skills feature, the introduction of Secure ...",
        "url": "https://www.youtube.com/watch?v=m8gnIieakL8",
        "publishDate": "2026-01-14T12:02:31Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/m8gnIieakL8/hqdefault.jpg",
            "transcription": "Error generating summary: Something unexpected happened.\ndev.shreyaspatil.ai.client.generativeai.type.UnknownException: Something unexpected happened.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:54)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "wYs6HWZ2FdM",
        "title": "Anthropic: Our AI just created a tool that can ‚Äòautomate all white collar work‚Äô, Me:",
        "content": "A new tool, with code written *only* by AI, has gone omega-viral: Claude Cowork. But is the hype justified? What do the stats say ...",
        "url": "https://www.youtube.com/watch?v=wYs6HWZ2FdM",
        "publishDate": "2026-01-14T16:26:37Z",
        "author": "AI Explained",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCNJ1Ymd5yFuUPtn21xtRbbw",
            "thumbnailUrl": "https://i.ytimg.com/vi/wYs6HWZ2FdM/hqdefault.jpg",
            "transcription": "The CEO of one of the major AI labs predicted last year that by around now, 100 percent of the code written by that company would be produced by one of their AI models.\nDario Amodei, March 2025.\nNext up, within 2026, would be all other knowledge work. And a new tool released by Anthropic in the last couple of days seems to back that up. It's called Claude Cowork.\nNot only has it gone omega viral at 42 million views for its ability to automate non-coding tasks, the tool itself was produced within Claude Code, powered by their latest frontier model, Claude Opus 4.5. Thereby seeming to justify the prediction that essentially all of the code would by now be written by AI.\nSo wait, if they got that right, does that mean that Anthropic and those like Sholto Douglas are correct when they say that in 2026, this year, the same will be true of automating all white collar work.\nThe most striking thing about next year is that the other forms of knowledge work are going to experience what software engineers are feeling right now, where they went from typing, you know, most of their lines of code at the beginning of the year to typing barely any of them at the end of the year. I think of this as the Claude code experience but for all forms of knowledge work. I also think that probably continue your learning gets solved in a satisfying way.\nWell, I've been using Claude Code for quite a while, and yes, have been playing about with the new Claude Cowork. And for me, those predictions are just not true. But so many of us might then throw the baby out with the bath water and miss out on some pretty crazy productivity gains. So I'm going to show why we shouldn't underestimate the gains to be had either.\nThen, for those who want to go a bit deeper, I'm going to end with the why. Why can models produce genius like seeing tiny bugs in large code bases and writing for me powerful poems, but also still fail at such basic tasks. No, I don't mean how many 'A's in the word orange, although surprisingly GPT 5.2 still can't get that right. No, I mean why are they still sometimes so brittle, memorizing that Tom Smith's wife is Mary Stone, but not deducing that Mary Stone's husband is Tom Smith?\nAnd what does any of this mean for your job, white collar or otherwise? What is the latest data show? First, of course, a quick word on Claude Cowork, which inevitably, it seems, some people are calling AGI. This, of course, follows numerous viral posts and articles about the underlying model, Claude Opus 4.5, when given the right scaffold, already being AGI. Indeed, a long list of notable commentators have this perspective. These posts can lead, of course, to two very disparate reactions, both of which I'd advise against. One, that it's all BS, all hype merchants, these tools hallucinate all the time and are pretty much useless. And second, that they are AGI perhaps, and I, you, are just missing out. We can't understand how to use them. We're missing out so much, our careers are doomed. This video is hopefully going to channel you down the middle path, which is you can get great productivity gains, but they're not there yet.\nFor context, I've been using Claude Code for a very long time, and Cowork for the last 48 hours.\n[On-screen interaction with Claude Cowork]\nUser: Summarize my meetings from this week and find action items. Where do you think I can be more efficient?\n[User selects \"Meeting Transcripts\" folder, clicks \"Let's go\".]\nClaude: I'll take a look through these now. One quick question- How detailed do you want this?\n[User selects \"Detailed notes\".]\nClaude: Build... Building plan... Progress. Read meeting recordings, Pull out key points, Find action items, Write summary.\n[Claude proceeds through tasks, opens Google Calendar, shows files like \"Meeting Transcripts,\" \"SKILL.md,\" \"pptx-patterns.md,\" \"css.md,\" \"claude in chrome\". Shows artifacts: \"Meeting summaries,\" \"Action items,\" \"Team standup deck\".]\n[Claude displays \"Product Team Standup\" presentation with key highlights, features, user interviews, latency improvements.]\nTo slightly debunk the hype point. If I gave a new employee this task: \"Make a comparison chart for Stockport FC's league position at this date, today, for each of the last 5 seasons, add it as a pptx to my desktop, with web-sourced relevant images. Ask any clarifying questions and share a plan of how you'll approach this task.\" I would expect, and let me know if you agree or not, for them to either say at the end of the day, \"I couldn't find any source to give definitive answers on that question,\" or to have produced the relevant PowerPoint. Now you can see the Cowork tab here and the kind of questions it lays out, and it does indeed give a great plan. I approved it immediately, and it didn't even take that long to be honest.\nThe result, I would say, was visually quite impressive and pretty much acceptable. Obviously, you have to pick a moderately hard task, because if it's too easy, you just do it yourself. So this was the result. Slight problem, I checked two of the dates it gave me for January 2023 and 2025 and the league position of this club, and both were incorrect. I manually checked, and within about 5 minutes, I found two other data sources, BBC and this site, 11v11, both of which said that Stockport were seventh at the time, not third for January 13th, 2025. This Coworking AGI, by the way, did not caveat its results in its summary to me that it couldn't find a reliable source either.\nNow, I could, of course, give you hundreds of such examples from the legendary Claude Code, powered by Claude Opus 4.5. But that wouldn't be too interesting or fair on you because you'd have to see the whole context of the code base. I just don't want you guys to walk away from these viral posts thinking, unless I spend all my money and keep up with a tool released just last week, I'm going to completely fail at my white-collar job. And if the models make any mistakes, I'm the dumb one, I must have done something wrong. But I don't want you to make the opposite mistake, which is to completely ignore these tools and think that they can't boost your productivity at all. The truth lies somewhere in the middle, and look, even the lead developer for Claude Code said as much later on in a reply, after saying \"All of it\", for the code for Claude Cowork was written by Claude Opus 4.5. He clarified, \"It was not zero intervention! We had to plan, design, and go back and forth with Claude. Claude wrote all the code.\"\nWhich then, for my super smart audience, leads to a key question, well, is it faster to get Claude Code to do the draft, and then redraft, and then test, fail, redraft, and then kind of get it right, or for the human to just do it themselves from scratch, whether it be coding or just other white collar work? Thankfully, we have a key clue from this OpenAI paper from October of 2025. Using blind human grading, we have already passed that tipping point. We get more of a productivity multiplier by getting models to try again and again and again and the human to just step in, review and edit, than from the human just doing it themselves. This GDPVal paper covers dozens of white-collar industries, and I did an entire video on it, so I'm not going to go into too much depth, but that for me is the real tipping point. And yes, I've experienced that in my own coding, which I do almost every day. It makes a bunch of dumb and sometimes dangerous mistakes, but don't throw the baby out with the bath water.\nEven take my Stockport PowerPoint. It's really quite well designed and almost all the other facts are true, so I could just edit a couple of the numbers and have a decent presentation in less time than creating it myself from scratch. Quick bit of technical detail, Claude Cowork is only available on the max tier, minimum 90 pounds or 100 dollars, and on Macs only. That's Mac OS, not Max, Mac OS, not Windows, but also Max only, not the Pro tier of Claude. Notice this productivity speed up though, is only true for a certain number of the latest models, those most likely to be tried by enthusiasts like us, less so the general population, and also that those models like GPT-5.2 Pro or 4.5 Opus are also gated heavily by price. If we are right about that tipping point, and about how few people are using the latest models with the best scaffolds, then you'd expect the current AI impact on productivity and the labor market to be relatively limited. And what does the data show? According to this January 7th, 2026 report from the widely cited Oxford Economics, well, to me, it shows exactly that. Yes, new graduates face slightly higher unemployment, but that isn't out of line with other historical trends. If you're listening to this, the new graduate unemployment rate has been much higher in the quite recent past, like 2015 or 2010. The authors know, if you zoom in on this graph, there's actually been a slight downward trend from March to September of last year. The authors say, \"We don't expect AI to significantly raise the joblessness rate in the US or elsewhere over the next year or two.\" That doesn't mean that there hasn't been any human job impact from AI, even causal impact. For example, sectors where there are potentially the most easy wins from AI adoption have a greater incentive to put the new technology to the test. Think of customer service operations and companies like Klanar. To finance this, they go on, budgets for the other parts of the business, including wages, may have to be cut. Fine, but what about the numerous headlines of mass job layoffs or a job apocalypse imminent? Well, the authors say, \"If AI is already leading to mass layoffs of obsolete workers, then it also stands to reason that measures of labor productivity should be increasing as the same output is produced with fewer workers.\" There are lots of cyclical factors that affect productivity, but if you focus on 2025 in teal, I'm color blind, but I think that's teal. You can see that it's not markedly higher in terms of labor productivity per hour growth than in previous years or periods. In fact, productivity growth in 2025 looks smaller than that for, say, 2000 to 2007 in every period. Why would so many companies proclaim that they're cutting jobs due to AI then? Well, the authors say, \"Linking job losses to increased AI usage rather than other negative factors like weak demand or excessive hiring in the past conveys a more positive message to investors.\" I think when a lot of companies and individuals discover just how much LLMs hallucinate, the initial wave of adoption and testing kind of petered out toward the middle of last year, but there has been a more recent uptick. People are, of course, starting to compare different models for their use case. As the CEO of Google DeepMind, Demis Hassabis said, \"making relentless progress,\" pointing to the fact that ChatGPT's share of generative AI is falling fairly notably. That's the thesis, of course, behind the app that I designed, LMCouncil.ai, where you can compare the answers of all the frontier models in a nice and customizable format. Indeed, even getting models to chat amongst themselves has proven so popular a feature here that I've produced a shortcut, where with semicolon, you can kickstart a self-chat amongst the models.\nBy the way, if I saw mass job layoffs coming, I would totally warn you guys as much as I could. But I'm less on the Dario Amodei side of things. I'm more on the Jensen Huang side of things, where he recently said in an interview a couple of days ago, \"Don't mistake the purpose of a job for the series of individually automatable tasks within that job.\" Take a football commentator. You could automate the voice of that commentator. You could automate the tactical analysis done by that commentator. You could do it all faster and cheaper, but the ultimate purpose, you could say, of a football commentator is to entertain you while you're watching, keep you engaged with the game. And that purpose might not be best served by an AI model. And that missing the wood for the trees is why we're going to turn to the second part of this video. The why behind the models being brittle in certain circumstances. Why do they seem 200 IQ one moment and 50 IQ another? This week I've been reading a series of papers on that topic, and probably my favorite is this one from just, what is that? Six days ago. I will note that if you are the kind of person drawn to the why's behind LLMs, I do have a quick word about our sponsor. And that is the MATS program, with a deadline of just four days from now for applications to their summer 2026 program. As you might know, MATS finds and trains researchers working on possibly one of the most talent constrained problems in the world, which is reducing risks from unaligned AI models. You might be familiar with them because their alumni have gone on to work at places like Meta, Anthropic, DeepMind, and of course, many other places. As you might expect, given it meets my standards for a recommendation, the program also comes with world-class mentorship, a stipend, compute budget, and full cost coverage. Do check out my link in the description.\nSo back to the specific question of why LLMs can seem so brittle. Navigating incredibly complex code bases to pick out a minuscule bug, but then sometimes Claude Cowork, going along merrily and deleting 11 gigabytes of files randomly from a guy's desktop, according to one user from two days ago. Why do they do that? Well, in short, because there are multiple levels of \"understanding\" in large language models. First though, I'm going to give you a freaky thought. We don't even know what the word understand means in English. Like we know what it denotes, but what are we under? If the under prefix isn't the usual meaning \"beneath,\" but from Old English under, from PIE inter- \"between, among\" (source also of Sanskrit antar \"among, between,\" Latin inter \"between, among,\" Greek entero \"intestines,\" see inter-). Related: Understood; understanding. The best guess of the etymology of the word understand seems to be to be between or among the ideas. In the presence, connected to something rather than being distant. Again, though, it seems like early humans didn't fully grok or understand what understanding meant, like being in the presence of something. And even synonyms like comprehend means to essentially grasp something. But why would holding something or grasping it mean you get it logically, intellectually? But then the etymology of the word intelligence is to pick between things. So it's no wonder that if we have this cloud of notions about standing in the presence of something, picking between things, having a grasp on things, that essentially if we don't have a fully intuitive definition of understanding, that we would struggle to ascribe understanding to LLMs. In this paper from Beckmann and Queloz, they give three categories of understanding. Simple conceptual understanding, just registering that there are connections between diverse manifestations of an entity. That's it, just finding connections between two things. Then, second stage, state-of-the-world or contingent understanding. These things being true or connected only in certain circumstances at certain times. Then the ultimate, what I've described in other videos as efficiently deriving new functions. That's principled understanding. The ability to grasp the underlying principles or rules that unify a diverse array of facts. If you don't have much time, the TLDR from this paper is that LLMs possess understanding distributed across a motley mix of mechanisms across all three tiers. They don't, in a sense, aspire to simplicity or parsimony. They just learn whatever connection, brittle or deeply algorithmic, that will get the job done. They can reach that third stage of understanding, deriving deep algorithms and patterns from the world. They can grok how to do addition and therefore delete the memorized pairs of what this plus this adds up to. And they plan ahead with poems. On the token before a new line of a poem starts, there is a circuit within Claude already planning what the rhyme will be and the semantics needed to achieve that rhyme. Researchers have found computable circuits for numerical comparison, multiple choice question answering. And even as I discussed in the autumn of last year, circuits for recognizing that introspection is called for. Given that these circuits are well defined and reusable, who are we to say that they haven't understood the concept? But here's the thing. LLMs also rely on brittle memorization. They pragmatically toggle between modeling the state of the world and relying on the shallow heuristics or rules of thumb, depending on which circuit minimizes loss most efficiently. They're kind of like a lazy bright kid who sometimes forces themselves to properly learn the material, and other times just memorizes what they need. The fact that they sometimes use memorization though, does, as the authors note, undermine the basis for epistemic trust. When they got something right, did they rely on that unifying mechanism, or merely a swarm of shallow heuristics? Of course, cognitive psychology also points to the fact that humans do the same, sometimes relying on shortcuts, saying or doing the first thing that comes to their mind on a local or international stage. Other humans try to double check those heuristics and think deeply about problems. So when you speak to an LLM, the authors know, it's a bit like speaking to a gigantic committee of drastically varying expertise. Higher-quality circuits are sometimes reinforced, but sometimes also drowned out by lower-quality circuits. Remember, these are alien intelligences, doing whatever they can, the easy way or the hard way to predict the next word or token. To a human, the sentence Tom Smith's wife is Mary is an embodied concept. It has dozens and dozens of connotations, not least that Mary's husband is Tom. For an LLM, the first time they hear Tom Smith's wife is Mary, that just updates their weights as to predicting what comes after in the future, Tom Smith's wife is, or maybe permutations like the wife of Tom Smith is. They haven't bound those concepts together. So they've got no reason to believe that the sentence Mary Stone's husband is will end with Tom. Now, as various other papers discuss, this particular weakness can be solved through data augmentation. But that's not my point. My point is that LLMs can understand things at a very deep level, and also simultaneously at a very shallow level. There is mixed evidence that reinforcement learning can strengthen those higher circuits, if you will. But this and other papers show that once an LLM has learned enough to get the question right most of the time, it has, with current methods, much less incentive to learn even higher circuits to get it right even more often. We are, though, exploring an alien landscape. There could well be a breakthrough a month from now, two months from now, wherein we incentivize models to reach much higher planes of understanding. For this paper, that could be achieved by encouraging models to reach that state of almost confusion. That's when multiple avenues can be explored most productively. And what levels of understanding could they reach if they're trained on a diverse range of new modalities? The American government is giving AI labs access to a dozen national laboratories from the US. And that's before we even get to hybrid architectures that have proven their worth with, for example, weather forecasting. Anyway, this video is getting too long. The point is to leave you somewhere between those two extremes. You're not alone if AI models constantly make mistakes on your workflow, nor, though, would it be fair to say that they're all hype. For me, maximal understanding of them and productivity using them comes from that place in the middle. Thank you so much for watching and have a wonderful day."
        }
    },
    {
        "id": "DGjoluNeBuM",
        "title": "Thatcher‚Äôs Worst Geopolitical Take - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=DGjoluNeBuM",
        "publishDate": "2026-01-14T21:32:04Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/DGjoluNeBuM/hqdefault.jpg",
            "transcription": "It turns out, although Britain had talked a good piece during the Cold War, it didn't actually want a unified Germany, nor did France. Why? Because a unified Germany would eclipse theirs economically. They didn't want that to happen. Francois Mitterrand, who is the President of France, and Margaret Thatcher, Prime Minister of Britain, were against German unification. They knew it would marginalize their own country. Francois Mitterrand eventually found solace in expanding the European community to the European Union, but Margaret Thatcher just plain lost. She was just upset about the whole thing. She said Germany will be the Japan of Europe, and worse than Japan. I guess she hadn't been to Japan lately. She said the Germans will get in peace, what Hitler couldn't get in war. And she wanted to leave Red Army troops in Germany for the duration. Imagine if that had been the case. And now dealing with Putin. If he had troops in Germany, WATCH HERE we would be in trouble."
        }
    }
]