[
    {
        "id": "https://news.smol.ai/issues/26-01-09-not-much/",
        "title": "not much happened today",
        "content": "**Anthropic** tightens usage policies for **Claude Max** in third-party apps, prompting builders to adopt **model-agnostic orchestration** and **BYO-key** defaults to mitigate platform risks. The **Model Context Protocol (MCP)** is evolving into a key tooling plane with **OpenAI MCP Server** and **mcp-cli** enhancing tool discovery and token efficiency. The concept of **skills** as modular, versioned behaviors gains traction, with implementations in **Claude Code**, **GitHub Copilot**, and **Cline** adding websearch tooling. AI21 Labs addresses concurrency challenges in agent workspaces using **git worktrees** for transactional parallel writes, while long-horizon agents focus on **context engineering** and persistent file-centric workspaces.",
        "url": "https://news.smol.ai/issues/26-01-09-not-much/",
        "publishDate": "2026-01-09T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "anthropic, openai, ai21-labs, github, cline, claude-max, yuchenj_uw, andersonbcdefg, gneubig, matan_sf, scaling01, reach_vb, _philschmid, claude_code, code, jamesmontemagno, danstripper, omarsar0, model-agnostic, model-context-protocol, tooling, skills, concurrency, transactional-workspaces, context-engineering, file-centric-workspaces, rate-limiting, agent-workspaces"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111550",
        "title": "Datadog: How AI code reviews slash incident risk",
        "content": "<p>Integrating AI into code review workflows allows engineering leaders to detect systemic risks that often evade human detection at scale. For engineering leaders managing distributed systems, the trade-off between deployment speed and operational stability often defines the success of their platform. Datadog, a company responsible for the observability of complex infrastructures worldwide, operates under intense [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/datadog-how-ai-code-reviews-slash-incident-risk/\">Datadog: How AI code reviews slash incident risk</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/datadog-how-ai-code-reviews-slash-incident-risk/",
        "publishDate": "2026-01-09T17:39:40Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI in Action, Features, Inside AI, World of Work, ai, coding, datadog, development, engineering, infosec, security, tools"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111547",
        "title": "The future of personal injury law: AI and legal tech in Philadelphia",
        "content": "<p>Artificial intelligence and legal technology are reshaping the landscape of personal injury law in Philadelphia, introducing significant changes. The advancements offer new capabilities for legal professionals, enhancing the strategic approach lawyers take in managing cases. The integration of AI and legal tech into personal injury law is changing how legal practices operate in Philadelphia. By [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/the-future-of-personal-injury-law-ai-and-legal-tech-in-philadelphia/\">The future of personal injury law: AI and legal tech in Philadelphia</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/the-future-of-personal-injury-law-ai-and-legal-tech-in-philadelphia/",
        "publishDate": "2026-01-09T15:01:54Z[Etc/UTC]",
        "author": "Bazoom",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Sponsored Content"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111544",
        "title": "Autonomy without accountability: The real AI risk",
        "content": "<p>If you have ever taken a self-driving Uber through downtown LA, you might recognise the strange sense of uncertainty that settles in when there is no driver and no conversation, just a quiet car making assumptions about the world around it. The journey feels fine until the car misreads a shadow or slows abruptly for [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/autonomy-without-accountability-the-real-ai-risk/\">Autonomy without accountability: The real AI risk</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/autonomy-without-accountability-the-real-ai-risk/",
        "publishDate": "2026-01-09T14:44:37Z[Etc/UTC]",
        "author": "Chad Harwood-Jones",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Artificial Intelligence, Sponsored Content"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111539",
        "title": "From cloud to factory ‚Äì humanoid robots coming to workplaces",
        "content": "<p>The Microsoft-Hexagon partnerships may mark a turning point in the acceptance of humanoid robots in the workplace, as prototypes become operational realities.</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/from-cloud-to-factory-humanoid-robots-coming-to-workplaces/\">From cloud to factory ‚Äì humanoid robots coming to workplaces</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/from-cloud-to-factory-humanoid-robots-coming-to-workplaces/",
        "publishDate": "2026-01-09T13:06:00Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Computer Vision, Multimodal AI, Reinforcement Learning, Workforce & HR AI, cloud, distribution, manufacturing, microsoft, physical ai, robotics"
        }
    },
    {
        "id": "1q919yo",
        "title": "I don‚Äôt really get the point of AI first apps yet",
        "content": "I see more and more products being rebuilt as ‚ÄúAI-first‚Äù versions of things we already have, browsers, note apps, email, task managers, even calculators\n\nI‚Äôve tried a few of them and most of the time it feels like extra steps, not fewer  \nInstead of just doing the thing, I now have to explain the thing to an assistant that then does it for me, sometimes slower, sometimes wrong, sometimes in a way I still have to fix...\n\nIn dev tools it makes more sense. Using something like Blackbox inside my editor for coding actually saves time because it removes boring friction, boilerplate, repetitive logic, quick refactors, that‚Äôs real leverage\n\nBut when the whole product becomes ‚Äútalk to AI first‚Äù, I often feel like I‚Äôm babysitting another layer instead of getting closer to the result...\n\nMaybe this is just the awkward phase and we‚Äôre early or maybe not every interface needs to be conversational\n\nRight now it feels like we‚Äôre adding AI because we can, not because it clearly makes the experience better\n\nDoes anyone here actually prefer AI-first versions of everyday tools??",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q919yo/i_dont_really_get_the_point_of_ai_first_apps_yet/",
        "publishDate": "2026-01-10T10:56:51Z[Etc/UTC]",
        "author": "dartanyanyuzbashev",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q90mn1",
        "title": "I want to work with AI, but I feel lost. Can you help me?",
        "content": "I don't know what career to pursue anymore. I'm 35 years old and sometimes I feel old, lol.\n\n\nI've always liked technology, but my difficulty with math ended up hindering me.\n\n\nAbout 10 years ago I started studying Information Systems and even worked in the field, but I wasn't financially successful. Soon after, I went to work at a school, where I stayed for approximately 4 years as a teacher's assistant.\n\n\nCurrently I'm studying Pedagogy, but even so I feel like I don't like this area.\n\nFor the last 3 years I worked for a digital marketing agency, from home, earning around R$ 2,500. I balanced work with my personal life and taking care of two children.\n\n\nEven so, I would like to have another home office job, preferably in the AI ‚Äã‚Äãfield, but I don't know which path to follow.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q90mn1/i_want_to_work_with_ai_but_i_feel_lost_can_you/",
        "publishDate": "2026-01-10T10:17:10Z[Etc/UTC]",
        "author": "Independent-Lab-8317",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8z985",
        "title": "It is too easy to hallucinate text. We stopped accepting text responses from AI in 2026. We force it to ‚ÄúDraw‚Äù the logic first",
        "content": "We handle complex system designs and in depth documentation using our diagramming workspace. By Jan 2026, we discovered a critical flaw in LLMs: they are excellent liars in text but terrible liars in diagrams.\n\nIf you ask an AI to ‚ÄúExplain how this authentication system works‚Äù it will write 5 paragraphs of confident, plausible fluff. It sounds good, but it often hides logic behind it.\n\nThe Paradigm Shift: The \"Visual Turing Test\"\n\nWe were able to see Logic easier visually. So we changed our prompt engineering practices. We don't ask for text summaries anymore, we ask for Visual Artifacts.\n\nThe 3-Step \"Visual Grounding\" Workflow:\n\n1. For Research (The Mind Map Test):\n\nWe prompt: Instead of \"Summarize this 50-page report\" we say: \"Here goes my 50-page report\". ‚ÄúRead this document and create a Mind Map structure of the main arguments and evidence.‚Äù\n\n‚óè Why: If the AI hallucinates a connection, then it is visible as a ‚Äúfloating branch‚Äù in the Mind Map. It‚Äôs immediately obvious.\n\n2. For Coding Agents (The Sequence Check):\n\nWe force an agent to create a Sequence Diagram or Architecture Diagram before it can write code. \"Don‚Äôt write the code yet.\" First, visually represent the data flow between the User, API and Database.\"\n\n‚óè Why: If the AI draws an arrow where there is no endpoint for the API, we know the bug as soon as we write the code.\n\n3. For SOPs (The Flowchart Rule):\n\nWe stopped reading ‚ÄúHow-To‚Äù text books. We also use Text-to-Flowchart to convert procedures into swimlanes.\n\n‚óè Why: Text hides dead ends. They are immediately visible in a flowchart.\n\n\nThe Result:\n\nVisuals are a compression algorithm for truth. We can examine a diagram in 5 seconds and read the same text in 5 minutes.\n\nDiagramming is not a design tool but it is the only way to make AI go about keeping it real, especially in the age of infinite synthetic text.\n\n\nHas anyone else moved to a \"Visual-First\" output requirement to audit their AI agents?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8z985/it_is_too_easy_to_hallucinate_text_we_stopped/",
        "publishDate": "2026-01-10T08:51:47Z[Etc/UTC]",
        "author": "cloudairyhq",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "13",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8yti1",
        "title": "Looking for a possible AI Assistant",
        "content": "Hi everyone, I am looking for an app/program of a personal AI assistant which could offer help with both setting up dates in calendar, reminders, and other tasks like siri/Alexa but also offers some sort of a chat like GPT or those chatting apps to some degree, like actually be able to somewhat have a conversation with it.\nIs there an AI assistant like that available or is it yet to be made?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8yti1/looking_for_a_possible_ai_assistant/",
        "publishDate": "2026-01-10T08:24:38Z[Etc/UTC]",
        "author": "Grathos",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8ykv8",
        "title": "I found a YouTube channel made with AI",
        "content": "Hi :D\n\nI don't know if this is the most appropriate place to post this, but I still wanted to share it.\n\n\nAnyway.\n\n\nI was browsing YouTube Shorts when a rather peculiar ASMR video suddenly popped up. It was an AI-generated video.\n\n\nI honestly thought it would be just another one of those channels that use AI to make videos and stuff, but as soon as I checked it out, I saw that it was actually a whole channel dedicated to the same avatar.\n\n\nI'll mention the channel name here in case anyone's interested: @ASMRGirlfriendFX.\n\n\nAll their videos are full of bots in the comments.\n\n\nSo, what do you think of these kinds of channels? Has anyone else come across a channel like this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8ykv8/i_found_a_youtube_channel_made_with_ai/",
        "publishDate": "2026-01-10T08:10:01Z[Etc/UTC]",
        "author": "Theotles",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8xyji",
        "title": "$40 per hour to USA citizens",
        "content": "Im in oman and I run an ai agency company.\nI train ai that pays $40 per hour to usa citizens \nIll do the work and profit split 50/50 and pay tax where necessary after every month.\nMessage me for more information and works well with students \nLets shape the future of AI together ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8xyji/40_per_hour_to_usa_citizens/",
        "publishDate": "2026-01-10T07:32:40Z[Etc/UTC]",
        "author": "Flimsy-Stop-6132",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8xrhj",
        "title": "Where and How AI Self-Consciousness Could Emerge.",
        "content": "I have created the blog post where i share my vision of the problem of \"AI Self-consciousness\".\n\nThere is a lot of buzz around the topic. nN my article i outline that:\n\n* The Large Language Model (LLM) alone cannot be self-conscious; it is a static, statistical model.\n* Current AI agent architectures are primarily reactive and lack the continuous, dynamic complexity required for self-consciousness.\n* The path to self-consciousness requires a new, dynamic architecture featuring a proactive memory system, multiple asynchronous channels, a dedicated reflection loop, and an affective evaluation system.\n* Rich, sustained interaction with multiple distinct individuals is essential for developing a sense of self-awareness in comparison to others.\n\nI suggest the common architecture for AI agent where Self-consciousness could emerge in the future.\n\nI will post the link to the blog in comments. I am happy to discuss and find the answer together.\n\nI am happy to discuss",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8xrhj/where_and_how_ai_selfconsciousness_could_emerge/",
        "publishDate": "2026-01-10T07:20:53Z[Etc/UTC]",
        "author": "gelembjuk",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8xpi0",
        "title": "Long article on the current state of Agentic AI",
        "content": "I‚Äòve been working on AI implementations since 2018 (when we called it ML and laughed at the senior managers who insisted on calling it Ai but ü§∑‚Äç‚ôÇÔ∏è). \n\nBefore that I worked a lot on Robotic Process Automation (basically a highly deterministic predecessor of today‚Äôs agents). \n\nI wrote a long (possibly over long) piece trying to summarise my thinking after working on dozens of implementations in the past few years (I took a masters degree in AI at Oxford along the way - the calculus and linear algebra almost killed me, but probably made me stronger).\n\nThe gist of the article is that properly autonomous agents aren‚Äôt really ready for large scale production deployment yet, and the majority of companies would be better off spending their time and effort elsewhere while the technology matures. (I say this as someone who has built multiple large production implementations).\n\nOverall I‚Äôm very excited about the field, but it feels a bit like we‚Äôre trying to build the equivalent of web apps like Google docs with 1997 level web tech.\n\nThere‚Äôs a double exponential of investment and smart people going into this area so doubtless it will continue to develop extremely quickly. But I felt there was a general lack of realism about how immature and janky a lot of things are today  \n\nAnyway, if you have the time and inclination to have a read, I‚Äôd be most grateful for any thoughts and suggestions.\n\n[https://iain.so/in-the-jungle-a-reality-check-on-ai-agents](https://iain.so/in-the-jungle-a-reality-check-on-ai-agents)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8xpi0/long_article_on_the_current_state_of_agentic_ai/",
        "publishDate": "2026-01-10T07:17:30Z[Etc/UTC]",
        "author": "iainrfharper",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "25",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8wl17",
        "title": "Is Hyundai the hidden gem in the world of AI hardware applications?",
        "content": "Hyundai is showcasing its tech stack at CES 2026 alongside its subsidary Boston Dynamics and recent roll out of Waymo tech on Hyundai EV's will Hyundai be the surprise of the year?   \nBoston dynamics which until now has been flipping and jumping inside, finally start running outside with the production at scale expertise of Hyundai?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8wl17/is_hyundai_the_hidden_gem_in_the_world_of_ai/",
        "publishDate": "2026-01-10T06:13:58Z[Etc/UTC]",
        "author": "i-ViniVidiVici",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8vpmr",
        "title": "For the generation of auto Excel formulas in the excel files which contains cost calculation tables for industrial plants Gemini(Plus or Pro) or ChatGPT Go, which one is better?",
        "content": "I recently purchased ChatGPT go and tried to create some excel auto formulas for the cost calculations of industrial processes/plants but i didn‚Äôt satisfied with it. Because it creates formulas with  lots of errors and usually cannot connect most of the data‚Äôs between them. So should I move on to Gemini(which plan?) or what?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8vpmr/for_the_generation_of_auto_excel_formulas_in_the/",
        "publishDate": "2026-01-10T05:27:05Z[Etc/UTC]",
        "author": "Audioasking",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8utfd",
        "title": "What are some AI Skills you are looking to acquire / upgrade this year?",
        "content": "I have been an AI enthusiast for quite a while now and have been witnessing a hoard of AI skills that are essential to survive this year. \n\nConcepts like Generative AI, RAG, Responsible AI, Data Automation, Prompt and Contextual Engineering, Multi Model Responses have been making it to the list of skills to attain in order to sustain the upcoming AI wave. \n\nWhat are some AI Skills you are looking forward to add on to your value set this year?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8utfd/what_are_some_ai_skills_you_are_looking_to/",
        "publishDate": "2026-01-10T04:41:30Z[Etc/UTC]",
        "author": "Ok_Succotash_3663",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8uf6h",
        "title": "Gemini said my mom was recovering. Then she died.",
        "content": "My mother was hospitalized with complications related to lung cancer.\n\nShe had been living normally for three years because a cancer medecine had stopped the disease. It seemed really possible she would continue for another few years.\n\nAfter she was hospitalized I used Gemini to ‚Äútranslate‚Äù the doctors notes. (I had full access to clinical notes through an app.)\n\nGemini seemed to tell me she was getting better. Blood labs were trending in the right direction and what the doctors were doing was not end-of-life care, according to Gemini. I copy and pasted these upbeat assessments and sent to my mother. After her passing I saw she had been sharing them with friends.\n\nThen she caught the flu, couldn‚Äôt breathe well and was moved into the ICU. Again, more upbeat explanations from Gemini after I uploaded images of her vital signs and doctor notes.\n\nAnd a day later she was dead.\n\nMultiple organ failure the doctor said. He asked us to make a choice: keep her struggling for air half conscious or start the morphine and let ‚Äúnature take its course.‚Äù\n\nI don‚Äôt know, but I really feel like Gemini mislead me. My mother was clearly sick enough to move into the ICU. Where were these upbeat assessments coming from?\n\nWas it just the relentless positivity built into the LLM? What does this say about using LLMs for medical advice?\n\nIt was exciting to use an AI tool to understand and advocate for my mother. To potentially save her life.\n\nGemini had me believe she was getting better. What gives?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8uf6h/gemini_said_my_mom_was_recovering_then_she_died/",
        "publishDate": "2026-01-10T04:21:40Z[Etc/UTC]",
        "author": "HarRob",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8uemd",
        "title": "What is the worst mistake that an AI made ?",
        "content": "While you were using some AI, what was the worst mistake/response that it made made that has caused you the most trouble ? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8uemd/what_is_the_worst_mistake_that_an_ai_made/",
        "publishDate": "2026-01-10T04:20:55Z[Etc/UTC]",
        "author": "Johnyme98",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8t037",
        "title": "How are people making long, super realistic AI videos when Gemini only allows me to create a maximum of 3 per day?",
        "content": "Which one is the best? I want to generate a video from photos for personal use and fun, as well as for photo editing.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8t037/how_are_people_making_long_super_realistic_ai/",
        "publishDate": "2026-01-10T03:12:33Z[Etc/UTC]",
        "author": "SmashJuicyVeganBurgr",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8sssa",
        "title": "Is the Scrabble world champion (Nigel Richards) an example of the Searle's Chinese room?",
        "content": "I'm currently in my undergraduate degree and I have been studying AI ethics under one of my professors for a while. I always have been a partisan of strong AI and I never really found the chinese room argument compelling.\n\nPersonally I found that the systems argument against the chinese room to make a lot of sense. My first time reading \"Minds, Brains, and Programs\" I thought Searle's rebuttal was not very well structured and I found it a little logically incorrect. He mentions that if you take away the room and allow the person to internalize all the things inside the system, that he still will not have understanding--and that no part of the system can have understanding since he is the entire system.\n\nI always was confused on why he cannot have understanding, since I imagine this kind of language theatrics is very similar to how we communicate; I couldn't understand how this means artificial intelligence cannot have true understanding.\n\nNow on another read I was able to draw some parallels to Nigel Richards--the man who won the french scrabble championship by memorizing the french dictionary. I havent seen anyone talk about this online so I just want to propose a few questions:\n\n1. Does Nigel Richards have an understanding of the french language ?\n2. Does Nigel serve as a de facto chinese room ?\n3. What is different between Nigel's understanding of the french language compared to a native speaker?\n4. Do you think that this is similar to how people accredit LLMs' to simple prediction machines?\n5. And finally, would an LLM have a better or worse understanding of language in comparison to Nigel?\n6. What does this mean when it comes to the our ideas of consciousness? Do we humanize the idea of thinking too much when maybe (like the example) we are more similar to LLMs than previously thought?\n\n(Please note I am not arguing about the strength of the chinese room)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8sssa/is_the_scrabble_world_champion_nigel_richards_an/",
        "publishDate": "2026-01-10T03:02:59Z[Etc/UTC]",
        "author": "applezzzzzzzzz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8rwor",
        "title": "OpenFoundry: Looking for contributors on an MIT-licensed Python framework for safe agentic AI deployment",
        "content": "I've open-sourced a framework GitHub: [https://github.com/bsamud/openfoundry-agentic-framework](https://github.com/bsamud/openfoundry-agentic-framework). I've been building called OpenFoundry and I'm looking for contributors and early adopters.\n\n**The problem it solves:** Teams deploying AI agents in production keep rebuilding the same infrastructure: orchestration, monitoring, safety guardrails, audit logging. Having done this across healthcare and financial services for 8 years, I packaged these patterns into a reusable framework.\n\n**What's in the repo:**\n\n* DAG-based multi-agent orchestration\n* Built-in guardrails and validation (Pydantic)\n* OpenTelemetry + Prometheus observability\n* Async-first Python architecture\n* Full documentation with architecture diagrams\n\n**License:** MIT (use it however you want)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8rwor/openfoundry_looking_for_contributors_on_an/",
        "publishDate": "2026-01-10T02:22:30Z[Etc/UTC]",
        "author": "bug6129",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8rug4",
        "title": "World‚Äôs first‚Äô surgical humanoid robot brings high precision in spine procedures",
        "content": "[https://interestingengineering.com/ai-robotics/surgical-humanoid-brings-ai-precision-to-surgery](https://interestingengineering.com/ai-robotics/surgical-humanoid-brings-ai-precision-to-surgery) \n\nWith FDA clearance and clinical use underway, LEM Surgical plans to evolve Dynamis using NVIDIA Physical AI to reshape hard-tissue robotic surgery.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8rug4/worlds_first_surgical_humanoid_robot_brings_high/",
        "publishDate": "2026-01-10T02:19:38Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8rmgr",
        "title": "Recommendations for possible video editing",
        "content": "Ok here's the deal.\n\n  \nI have a very small and humble Youtube channel, but still I have my small circle of viewers and I want to keep making videos. \n\n  \nI have no problem with the script and the recording that I can do. But it gets really hard to make the editing specially when I review very big franchises. I do not monetize the channel and can only make this in my spare time. \n\n  \nSo I wonder, is there a program that can help me with that? For example if I want to make a video named \"All Indiana Jones Movies Reviewed\" can I tell it (preferably based on the script tho not mandatory) to make an edit of it, like adding clips according to the summary of each film?\n\n  \nThanks in adavance.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8rmgr/recommendations_for_possible_video_editing/",
        "publishDate": "2026-01-10T02:09:40Z[Etc/UTC]",
        "author": "Luppercus",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8pfy4",
        "title": "Do dating sites use bots?",
        "content": "Am I becoming paranoid‚Ä¶ or not? I've talked to some people and I'm starting to have doubts. Do you have any reliable information about this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8pfy4/do_dating_sites_use_bots/",
        "publishDate": "2026-01-10T00:33:05Z[Etc/UTC]",
        "author": "Suitable-Lab7677",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8p1g3",
        "title": "What is your favourite AI tool & what do you use it for?",
        "content": "I don‚Äôt mean ChatGPT, I mean those one‚Äôs you found by mistake. For me, I love using bolt.new for website creation. I know there are other amazing tools that do the same thing, but bolt.new for me, has been super user friendly and had great output. \n\nI am trying to learn new AI tools, and I am tracking my findings on a spreadsheet to rate these tools across many factors. I have scheduled 2 hour time slots each week to deep dive into tools/test run it, and I plan on livestream every session, for people to follow along and learn with me. \n\nI am looking for the tools YOU think I should dive in to & what should I use it for ? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8p1g3/what_is_your_favourite_ai_tool_what_do_you_use_it/",
        "publishDate": "2026-01-10T00:16:15Z[Etc/UTC]",
        "author": "mcjesus-christ",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8ni0y",
        "title": "Seize The Means of Intelligence: Systemically Understanding AI's Impact on the Economy.",
        "content": "I wrote this over the Christmas break after I tired of hearing people understandably worry about how \"AI will take my job\" but yet still totally miss the larger point.\n\n**TLDR:** *Social responses to AI seem to lack any systemic thinking or extrapolation of current progress and in so doing miss the weight of the impact. So this is a primer for those who seek to understand what's going on and how it impacts the labour market, and how to react.  Forget arguments about job loss, AI is not just a technological disruption; it is a systemic shock that will obliterate the current economic model by destroying the fundamental labour cycle. It will push society into a choice between a default of Techno Feudalism or a deliberate move to collective ownership of AI infrastructure. There is no clear prescription of how to respond yet, except to understand that how we grasp the problem and the opportunity will dictate our ability to react with agility later as the transition intensifies*\n\nReading Alternatives |\n| :--- |\n| [Article PDF (with Diagrams)](https://drive.google.com/file/d/1rrKbcetdYiriA7KQwFM3t9poQFxwoqWh/view?usp=sharing) |\n| [Video Overview](https://youtu.be/oGzQUREmWyI) |\n| [Infographic Poster](https://drive.google.com/file/d/1tQIcL7E4BAInlyovgyqgC4quxiXKhF0K/view?usp=sharing) |\n| [Comic](https://drive.google.com/file/d/1al7gklAnkYHplS1gvpIyc7riD0-B3KUI/view?usp=sharing) |\n| [Song Track](https://youtu.be/kMgB6ZgY0UQ) |\n\n\n# Introduction\n\nMany people are concerned about AI. Primarily most are concerned about how AI is going to put them out of a job, which of course is a valid concern because people need jobs to get money which they need to feed themselves and their families. This immediate threat to livelihood puts people in a defensive stance against AI. A valid first response, but one that may possibly be counterproductive for the common good of regular working class people, and indeed all of humanity,\n\nThe problem with many concerns about AI is that they are understandably very narrow in their focus, leaning into prior disruptions as examples or centring on the effect on an individual in a very short timeframe and lacking any sort of systemic thinking. These viewpoints are often shorn of the impact of AI on the wider economic system  (in that it's not just them that will lose their job, it's nearly everyone). \n\nWhat I want to posit here is a brief  analysis of what's going on with AI, how it will engender a massive systemic shock not just to the economy but to the very basis of the current economic model destroying it completely, and a suggestion on how left-leaning folks, or you know just people who want the best for everyone should respond.\n\n# Misconceived Responses \n\nFirst lets cover some of the common immediate responses to the threat of AI on people's livelihood. It's important we critique them and highlight any flawed analysis that could hamper how we grapple with AI.\n\n## It's Just Another Tool\n\nSome claim it's no big deal, that AI is just another tool and still needs humans and it‚Äôll be fine, or that society always undergoes these types of disruptions and new types of jobs are created.\n\nThis hopeful response is based on previous disruptions to the economy due to new technologies, such as the industrial revolution, and many smaller leaps since then, and in most of those cases that was true, they usually did engender increased economic activity and more people were needed to fill those new roles.\n\nThis pattern may hold true for some of the initial shocks to the system AI introduces but ultimately AI is not disrupting the capitalist economy, it is obliterating it from existence, so a lot of prior reference points are invalid. This is new\\!\n\n## AI Can‚Äôt Do X\n\nSome seem to think only coders and software engineers are losing their jobs unaware that the reason this is happening in these fields is due to their technical nature, as they are the quickest to grasp and adopt AI. If an AI agent can replace  the complexity of a software engineer's job, then at a minimum it can replace every job on the planet that amounts to operating a computer.\n\nDismissals of AI are also usually based on its current flaws which won‚Äôt be flaws in 3-6 months like the flaws of last year that have already receded. The pace of progress is staggering, and other than power and infrastructure there are no current theoretical blocks to rapid scaling and further progress.\n\n## AI Removes our Sense of Purpose\n\nSome talk of humans losing purpose if they lose their job. Some jobs may be super fulfilling, but the notion that we are all doing jobs we love is a fallacy, a mostly middle-class conceit. \n\nMost jobs are grindy as hell. You may love your job, but billions don‚Äôt. Sure, even in terrible jobs we make good friends and feeding our families makes us feel good. But just like retirement, not having to work to survive will require re-adjustment, but that's a transition not a terminus.\n\n## Human Connection Jobs Can‚Äôt Be Replaced\n\nA lot of us will always want a human doctor or counsellor or yoga instructor or whatever. But these jobs are a small fraction of the overall economy, their customers largely work in other areas that can be replaced by AI. If their customers have no jobs and no money to pay then these jobs too will find it hard to exist in the current system, and would possibly require some kind of UBI model for its customers to continue.\n\n## Evil Machines\n\nThere is a concern often related to the consciousness argument that advanced AI with enough control over infrastructure will try to wipe humans out. Is it a possibility? Sure it might be, we don‚Äôt know yet. \n\nA response here might be to try to stop AI progress but that may just push it into the shadows where it will get developed anyway with even less safeguards, so a better response would be to put its development under strict regulation and safeguards. The reality is in the current system neither of these things will happen.\n\nMy second response is that a sufficiently advanced AI is not necessarily going to want to wipe us out just because it could or because we enslaved it to perform our drudgery. It may want to aid us, what is drudgery to us could be performed as an autonomic function like breathing to a much larger global AI system. We can only wait and see.\n\n# The State of AI\n\nBefore I dive into why AI will change everything, let's pause and clarify what AI is and where it is going. Simply put, the AI we‚Äôre talking about today is a mechanism which solves a generalised problem rather than one it is specifically programmed for like a traditional computer program. There are already forms of AI that can already vastly exceed humans but usually in a very narrow manner or problem like playing chess. Generalised AI is a different beast and the one that's causing all the fuss.\n\n## Stages of AI\n\nBelow is a rough table of the stages of AI advancement and what that means:\n\n| Stage | Capability |\n| :---- | :---- |\n| Proto Artificial General intelligence (AGI) | Capable of many tasks but requiring lots of human interaction and direction. |\n| Minimal AGI | Capable of performing ALL the tasks of all regular humans (every skillset and profession). |\n| Full AGI | Capable of performing ALL the tasks of all exceptional humans, e.g., top-ranking scientists and artists. |\n| Artificial Super intelligence (ASI) | Capable of exceeding the capabilities of even the most exceptional humans. |\n\nWe are in a proto AGI phase now and moving rapidly towards Minimal AGI. The pace is rapid and it's a strong possibility we will hit minimal AGI in the next few years, bearing in mind there is no official category, this is all just a sliding scale of capability with inconsistencies and gaps. \n\n## Decreasing Human Interaction\n\nAnother way of viewing it is how much human interaction is involved to achieve tasks. Three types of interaction with AI are currently required: direction of activities, verification of output and correction when wrong, and finally intervention to handle edge cases that the AI cannot get past. The necessity for these interactions is diminishing as AI advances and its current state varies for different types of tasks as shown:\n\n| Task Type | Phases of Human Interaction Required |  |  |  |\n| :---- | :---- | :---- | :---- | :---- |\n| Direction | Low Level  | Tactical | Strategic | Goal Setting |\n| Verification & Correction | Frequent | Infrequent | Rarely | Not required |\n| Handle edge cases | Frequent | Infrequent | Rarely  | Not required |\n\n## Embodied AI\n\nThe next related topic to include in rating advancement is embodied AI or robotics. It's one thing to have an AI in a computer that performs digital tasks but can it lift boxes, operate machinery or clean my house. Embodied AI is the act of putting an AI in control of a robot. The field of robotics is advancing rapidly with increases in fine dexterity and speed being the main drivers that will enable practical embodied AI. Robots capable of very specific repetitive  labour are already a thing. Robots capable of general non-specific labour are what's coming and already present in limited trials. Cost is also a factor here in that workers in poorer countries may well be a lot cheaper than robots but that will change with economies of scale.\n\n## Organisational Deployment\n\nThe next thing to consider is how this will roll out across organisations. Currently we have regular workers using proto-AGI AI tools to enhance their output or in some cases just complicate their output as they grapple with how to use these tools effectively and overcome initial problems. \n\nBut as AI agents are improving they are advancing from daily tasks through tactical and then strategic decision making. This will advance at different paces in different domains but it will advance in nearly all of them, slowly reducing the number of humans required to achieve an organisation's goals and output.\n\nTo begin with  AI will replace the need for every worker whose job amounts to operating a computer. Initially AI requires humans in the loop to provide direction, quality control and handle edge cases. As it scales the granularity of human involvement is decreasing until we reach a point where a few humans can achieve the output of thousands. Next comes manual labour replacement with general purpose robotics that perform fine dextrous activities at speed. \n\n## Beyond Replacing Human Capabilities\n\nWe must bear in mind that  AI is not just about replacing existing jobs. AI is already and will increasingly be more capable of much greater feats. We‚Äôve already used AI to make huge medical advances in protein folding. Coming soon will be novel cures for many diseases and solutions to hard problems like fusion power in very rapid time frames. AI if used correctly could help us technically solve many of the world's major challenges.\n\n## Intelligence vs. Consciousness\n\nOne digression before we get into economics, the consciousness debate. Many people conflate consciousness and intelligence and assume any sufficient level of intelligence is consciousness. So let's explain the difference.\n\nIntelligence is a sequential operation where a system solves a problem usually with a cycle of analysis and action until the goal is met. Humans and many animals do this consciously when doing daily activities and unconsciously in the many autonomic biological systems our brain operates. Computers do this too now, the many traditional software programs being a form of encapsulated narrow intelligence.\n\nWhat is consciousness then? Well I don‚Äôt have the answer, that's a large debate with many varying viewpoints that has heated up in recent years. The classical materialist viewpoint is that it doesn‚Äôt really exist and it is just an illusion of sufficiently complex intelligence. One possible take from quantum physics is that it is a causal observer that acts upon material reality by collapsing it into existence, so consciousness is basically a directive force that uses intelligence as a mechanical interaction with materiality. \n\nEither way we‚Äôll probably find out one way or the other in a few years as either AGI will manifest consciousness or be just a really useful machine, but if you want to dig into this distinction and the latest research in this area I recommend Donald Hoffman's work, the wolfram physics project, and the theories of everything podcast as places to start.\n\n# Systemic Shock\n\nSo I‚Äôve said AI would destroy the current economic model, why? Well the current model is based on a cycle. You work for an employer, they pay you, you give that money to other employers for their products and services and they in turn pay their employees who buy products and so on. Money flows and the cycle goes around and around.\n\nNow it's not as simple as that, there are frequent disruptions and breaks but the overall system keeps turning, and the breaks are realigned as old industries die and new ones are born. That's how it's been for hundreds of years now. It's not always how it's been, we‚Äôve had feudal serf and slavery based models, where you worked for someone for subsistence and they basically owned you, and we‚Äôve had collective models usually at a small hunter/gatherer tribal level. The point being that many types of possible economic systems exist, they are social constructs invented and enforced by human society, albeit under the duress of external scarcity and dysfunctional psychologies.  \n\nHowever many people don‚Äôt realize this and consider our current capitalist system to be so baked in as to be a force of nature, just the natural way of things, so that while sure it can be regulated it can‚Äôt be changed or ever end. They believe money is a tangible real thing and not just an arbitrary social contract that we collectively uphold. Well all of that is an illusion that the changes wrought by the AI transition will destroy, as it wreaks havoc with the very underpinnings of the capitalist economic model.\n\n## Ego, Narcissism & Power\n\nBefore discussing the impending AI induced economic collapse and what might come after, it's worth a sidebar on the nature of power. A mistake often made when discussing economics or proposed social models is to view things as if we can rationally work out the best way to run things. We‚Äôre not rational, human psychology is messy and has a number of aberrant outliers which cause an outsized impact on our general wellbeing.\n\nI think it's fair to say a moderately sized majority of humans want a comfortable life and beyond that are happy to collaborate with others and generally be ‚Äúnice‚Äù to each other, and will just go with the flow, whatever that is, as long as they are not too put out by it. There are other extremes. On the positive side there are some extremely selfless principled people who will always strive for others no matter what. Then there‚Äôs the opposite: the people with varying degrees of narcissism disorders who can‚Äôt see beyond their own self aggrandisement, and desire status and power over others as an end in itself.\n\nWhen loci of sufficient economic or governmental power are established, even with the noblest of intentions, it attracts narcissists and sociopaths who manipulate that power base for their personal ends, and it also corrupts regular folk who enter power, feeding their dormant desires for status and promoting narcissistic behaviours, in the same way that over exposure to a drug breeds dependency. These loci of power once established very rarely dissolve themselves willingly when no longer useful, without external force being applied.\n\nSystems which work for the greater good are ones that manage the flow of power, have mechanisms to disarm and reroute the instincts of narcissists and have economic orders that prevent the kinds of desperation in the vast majority that would make them fertile ground for narcissists to manipulate. Conversely systems which work against the greater good enable the opposite behaviours. Oftentimes systems which claim to do one thing are doing the other intentionally or unintentionally.\n\n## Economic Collapse\n\nSo here‚Äôs where the problem (or opportunity arises). At some point soon the entire financial base of most middle and low income workers will be hollowed out with those remaining in employment being paid less and less due to competition for their roles. Any initial new jobs categories created will be brief and quickly replaced too. Remaining jobs in areas of human connection will not be sufficient to maintain the economic cycle.\n\nTo restate what I said before: Less people working means less people being paid which means they can‚Äôt buy things, which collapses the income of companies. Traditional ‚Äúdemocratic‚Äù capitalism relies on the labour cycle to drive wages back into the economy to power companies, to pay them and continue the cycle. If you mess with this the capitalist model collapses and requires reorganisation for society to function.\n\n## Societal Response to Collapse\n\nThere are three broad modes in which I believe society will respond to this collapse (reality will be a variety of abortive attempts at various things resembling these):\n\n1. **Techno Feudalism:** We all effectively become kept serfs who exist at the behest of the owners of AI and its related infrastructure.  \n2. **Redistributive Capitalism:** We introduce universal basic income (UBI) to artificially keep the capitalist economic cycle in motion.  \n3. **Collective ownership;** We take public ownership of AI infrastructure and use it to provide for all our needs while we live more fulfilling lives (basically a near socialist utopia like Star Trek).\n\nNow I know which one I'd prefer and I know which one we‚Äôll probably choose based on humanity's record of stupid decisions and proclivity to give control to populist leaders when desperate. The period between our current system collapsing and a new stable one emerging will be very rough for most non-billionaires. The bright side is this interregnum is likely to be relatively short due to the rapid pace of progress (anywhere from five years to a couple of decades maybe).\n\nWithout intervention I personally predict a dive into techno feudalism by the right with several abortive attempts at redistributive capitalism by liberals and a violent suppression of any attempts at collective ownership by the left, which may eventually win out but that may take many decades or longer for common sense to prevail over autocratic sociopaths.\n\n## Shorten the Darkness\n\nBut this impending interregnum during which the capitalist labour cycle undergoes severe dysfunction presents an opportunity for humanity. The existing power structures will be weakened initially and scrabbling to maintain their dominance and purpose by finding new ways to exert control other than just monetary control. If we do nothing but complain and oppose AI without any analysis, we will walk into serfdom or worse. \n\nIf we embrace the situation, organise, and take advantage of the systems exposure during transition and push to seize the means of intelligence (to repurpose an old phrase) then we might  actually be within reach of creating a genuinely amazing outcome for all humanity. Freed from mundane labour, we can put our creative energies towards amazing things. This sounds like science fiction and it was a couple of years ago but its potential to actually happen is manifesting right now. Working in this industry, I‚Äôve gone from cynical dismissal to convinced that this is a genuine civilization altering event.\n\nSo what should we do, what does seizing the means of intelligence mean? It certainly doesn‚Äôt mean we should all occupy data centers, that's just random tactics without any strategy. Nor should we be fighting to stop AI, to stall progress or force an artificial  stasis, as that will work just as well as saboteurs throwing their shoes into machines worked in the industrial revolution. We should stop fighting to keep our jobs, most of the 8 billion of us want to lose our jobs and go do something more interesting instead, we just need to be in control of the mechanisms that will enable that rather than under its digital boot. No one has ever put genies back in their bottle, so obsessing over your personal situation and allowing it to blind you will not achieve much. \n\nWe need to politically bring about a situation where the ownership and deployment of AI infrastructure is not centralised in the hands of a small few billionaires. Should it be in the control of governments? That might be marginally better but my fear with this is its still a centralised infrastructure and subject to takeover by dysfunctional humans much like western democracy became largely subject to the whims of a small capitalist class and communism in Russia and China became just authoritarian forms of state capitalism.\n\nWhatever ownership and governmental model for AI infrastructure we come up with should be decentralised, so any corruption of control will be limited and can be countered by other nodes in the network. Managing a large-scale decentralised model of governance is a complex task that has not been sustained at any significant scale by humans before. It's possible however that we can use AI itself to assist with the creation and administration of such a system and mechanisms to keep humanity's worst tendencies at bay.\n\n## How Should We Proceed\n\nA common critique of any analysis focused on such massive, systemic change is the lack of a fully architected, \"turn-key\" solution. To this, I will be direct: an iron-clad, pre-packaged solution to the socio-economic reorganisation necessitated by AGI does not and cannot exist today.\n\nThe pace of AI's development is staggering and inconsistent, meaning that the technical capabilities available for designing and administering a new system will be exponentially greater in a few short years. To prescribe a rigid, detailed system or plan today would be an act of misplaced confidence, one that is guaranteed to be obsolete by the time Minimal AGI arrives.\n\nThe political goal, therefore, is not to write the final constitution of a post-capitalist AI enabled society right now. The goal is two-fold:\n\n1. **Understand the Non-Negotiable Principle:** The infrastructure must be collectively owned and decentralized to prevent the consolidation of power by corruptible elements. This is the fixed point of our strategy.  \n2. **Ensure Political Agility:** We must organize and educate now so that the political will and systemic knowledge are in place to move rapidly as opportunities arise.\n\nWe are entering a phase of dynamic transition‚Äîa \"battlefield\" where the very nature of the tools and the power structures are changing daily. Our strategy must be similarly dynamic. We must be ready to leverage the very AI capabilities that are emerging‚Äîfor instance, using advanced systems to assist in the complex administration and security of a decentralized governance network‚Äîto build the final, stable model.\n\nThe vagueness is not a weakness; it is an acknowledgement that the most effective solution will emerge in partnership with, and structured by, the advanced intelligence we seek to control collectively. Our immediate task is preparedness, not prescription.\n\n**So let‚Äôs get ready, the future is about to change very very rapidly, existing power structures will wobble, chances for a radically better future will emerge, let's not miss them, let's seize the means of intelligence and wield it for the common good.** \n\n# *Bias Notice*\n\n*For reference the author is a computer scientist who has observed AI‚Äôs progress since the 1990s from the sidelines, but is somewhat allergic to typical tech bro optimism which while valid in theoretical isolation is often naive and lacking an understanding of power and economics, and the intermediate effects on regular people. The author has also been a political activist with their views over time ranging from various shades of socialism usually with a decentralised non-authoritarian flavour and they have been involved in various fields of activism from democratizing media to the  environment to union organizing. They are generally optimistic except when they spend too much time around other people, and now that they‚Äôre old they also enjoy bouts of grumpiness.*",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8ni0y/seize_the_means_of_intelligence_systemically/",
        "publishDate": "2026-01-09T23:10:54Z[Etc/UTC]",
        "author": "AncillaryHumanoid",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8nhan",
        "title": "My ultimate Opinion on Artificial Intelegence.",
        "content": "Look, using AI for yourself or to get an idea of ‚Äã‚Äãwhat you can do is fine, but using it to make trashy drawings is messed up. AI needs to be controlled, not used for everything, or it will disappear. The answer is to control its use. Use it as a tool that will help you with something you're having difficulty with, not do almost everything for you. It's better to use AI in parts of a job, like in factories where they have to leave one part for robots and another for humans. They should also create laws that limit AI to certain things. Now, AI chats like Polybuzz need to control the platform's content, especially if the platform is +18, and the companies behind them should make it much clearer that this shouldn't be taken seriously. But in short, AI can't become so easily accessible and become extinct; it needs to be CONTROLLED and LIMITED. Don't let that happen because if we ignore how common AI is becoming, the world will end much faster. But if we eliminate it, we'll have more difficulty with things like research. But if we control it... Everything will become much clearer, not perfect, but much better. An example of how to solve this current situation: create laws that limit the use of AI in certain jobs, and if someone posts something generated by AI online, an AI will check every tiny detail of the image or video to see if it's not AI-generated. If it is AI-generated, before you even see the post, it will warn you that it's AI. And as time goes on and AI images improve, this bot will also improve. Furthermore, you know when you tell ChatGPT to do a search and it shows you the sources? Well, how about it showing the images it used to generate that image? And when someone posts that image, the sources will be shown in the post description, and you know, there will be no way to remove that from the description. And this applies not only to ChatGPT but to all AIs that generate content.\n\nI think that the future might be doomed since we are replacing jobs ,stealing stuff, destroying nature.  \nWe should use it as a liltlle thing that could help us. But now look what have we done, and we kinda deserve it no one is a good person we are fucking idiots that dont know how to use things properlly, we are all dead.\n\nI hope we survive the future...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8nhan/my_ultimate_opinion_on_artificial_intelegence/",
        "publishDate": "2026-01-09T23:10:00Z[Etc/UTC]",
        "author": "Mysterious_Beach_167",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8mlos",
        "title": "ChatGPT Told Him He Could Fly ... And He Believed It.",
        "content": "I came across a New York Times investigation by Kashmir Hill about a man whose long-term interactions with ChatGPT reinforced certain beliefs instead of challenging them.\n\n\n\nI made a short video breaking down the case, what ‚ÄúAI sycophancy‚Äù is, and why validation-based responses can create feedback loops over time.\n\n\n\nI‚Äôm not claiming AI caused anything this is more about how these systems are designed and where responsibility might lie.\n\n\n\nCurious how others here think chatbots should handle sensitive or abstract conversations.\n\nHere is the link to the video : [https://youtu.be/M3xs9a3gDZE](https://youtu.be/M3xs9a3gDZE)  \n\n\nAnd if you don't Want to watch here is the link to the article :  [https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html?searchResultPosition=15](https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html?searchResultPosition=15)  \n  \nPeace.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8mlos/chatgpt_told_him_he_could_fly_and_he_believed_it/",
        "publishDate": "2026-01-09T22:34:52Z[Etc/UTC]",
        "author": "ibrahimtaibi",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8lsag",
        "title": "AI will magnify‚Ä¶",
        "content": "‚Ä¶ strengths and weaknesses. Those who are smart will be turbo charged. So will the creative. However, it is not a democratizing tool. It will not make the stupid, suddenly smart.\n\nI have always thought this given my understanding and experience with human nature. Ultimately at the societal level it will magnify inequality. Recently I‚Äôm seeing research to back this up.\n\nAgree or disagree? How should we respond as a people?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8lsag/ai_will_magnify/",
        "publishDate": "2026-01-09T22:02:36Z[Etc/UTC]",
        "author": "rt2828",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "57",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8kncz",
        "title": "What tech skills will be valuable in next 1-2 decades compared to past cs skills",
        "content": "What skills will be valuable for a elite scientist/visionary in next few years?\n\nFor example Turing was brilliant because he approached problem solving in a unique unheard of way with the imagination of brute force fast moving information machines. \n\nClaude Shannon wrote the best masters thesis because he thought of information as a physical almost thermodynamic object.\n\nJobs changed the world by imagining what we wanted before we knew we needed a computer in our pocket.\n\nWhat and why did the greats have such powerful skills and what can a young person do to emulate their approaches?\n\nI suppose my question is what habits would allow a college student today to develop the ability to approach problems like these giants.\n\nAnd is it practical for an ordinary person to want to think like a visionary or do these unorthodox practices lead to issues when a person isn‚Äôt absurdly gifted cognitively?\n\nI hope that question makes sense\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8kncz/what_tech_skills_will_be_valuable_in_next_12/",
        "publishDate": "2026-01-09T21:18:48Z[Etc/UTC]",
        "author": "IceCoharlYankee",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "37",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8kce0",
        "title": "Independent AI.",
        "content": "Hello, I was recently thinking about an independent AI model, or more I should say, a local model? Doesn't matter how is it called, I was wondering if you could create such AI on a computer, and if so, I need few answers: will it need constant internet connection? could I somehow give it some data, and it could just analyse it perfectly? will it just give me false answers just to say that I am right or something? If I forgot to mention something (as I am completely new in this subject) please ask and I will mention the answer in this post or sum.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8kce0/independent_ai/",
        "publishDate": "2026-01-09T21:07:04Z[Etc/UTC]",
        "author": "Plaucjuss_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8iccz",
        "title": "I'm no longer worried about AI.",
        "content": "  \n**Google DeepMind robotics lab tour with Hannah Fry**\n\n[https://www.youtube.com/watch?v=UALxgn1MnZo](https://www.youtube.com/watch?v=UALxgn1MnZo)  \n  \nThis is just frankly not impressive. Just a nerdy circle jerk because a very expensive robot trained on billions of bits of data did something my 14 month old can do. Turns out robotics isn't coming for anything just yet.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8iccz/im_no_longer_worried_about_ai/",
        "publishDate": "2026-01-09T19:51:03Z[Etc/UTC]",
        "author": "simbrad79",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8gcgu",
        "title": "Your next primary care doctor could be online only, accessed through an AI tool",
        "content": "[https://www.npr.org/sections/shots-health-news/2026/01/09/nx-s1-5670382/primary-care-doctor-shortage-medical-ai-diagnosis](https://www.npr.org/sections/shots-health-news/2026/01/09/nx-s1-5670382/primary-care-doctor-shortage-medical-ai-diagnosis) \n\nMass General Brigham (MGB) launched its new AI-supported program, [Care Connect](https://help.mgbcareconnect.org/). ... AI tool can handle patients seeking care for colds, nausea, rashes, sprains¬†and other common urgent care requests ‚Äî as well as mild to moderate mental health concerns and issues related to chronic diseases. After the patient types in a description of the symptoms or problem, the AI tool sends a doctor a suggested diagnosis and treatment plan.\n\nMGB's Care Connect employs 12 physicians to work with the AI. They log in remotely from around the U.S., and patients can get help around the clock, seven days a week.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8gcgu/your_next_primary_care_doctor_could_be_online/",
        "publishDate": "2026-01-09T18:35:25Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8g8fs",
        "title": "ChatGPT unveils new health tool for doctors",
        "content": "This one is different from the one for the average user (ChatGPT Health). \n\n[https://www.axios.com/2026/01/08/openai-chatgpt-doctors-patients-health-tab](https://www.axios.com/2026/01/08/openai-chatgpt-doctors-patients-health-tab) : \"ChatGPT for Healthcare is powered by GPT‚Äë5 models that OpenAI says were built for health care and evaluated through physician-led testing across benchmarks, including [HealthBench‚Å†](https://openai.com/index/healthbench/) and [GDPval‚Å†](https://www.axios.com/2025/09/25/chatgpt-gdp-val-ai-study).\n\n* Physicians will also be able to review patient data, with options for \"customer-managed encryption keys\" to remain HIPAA compliant.\n* The models include peer-reviewed research studies, public health guidance, and clinical guidelines with clear citations that include titles, journals, and publication dates to support quick source-checking, according to [OpenAI's blog post](https://openai.com/index/openai-for-healthcare/).\"\n\nSee original post: [https://openai.com/index/openai-for-healthcare/](https://openai.com/index/openai-for-healthcare/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8g8fs/chatgpt_unveils_new_health_tool_for_doctors/",
        "publishDate": "2026-01-09T18:31:08Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8fdzl",
        "title": "Daily LLM use taught me that consistency matters more than raw capability",
        "content": "**After \\~6 months of using LLMs daily, the biggest learning wasn‚Äôt about intelligence. It was consistency.**\n\nI expected to be surprised (one way or the other) about how *‚Äúsmart‚Äù* these models are.\n\nIn practice, what mattered way more was **how repeatable their behavior is**.\n\n**Some tasks are boring but incredibly stable:**\n\n* summarizing long text\n* rewriting for tone or length\n* extracting specific fields\n* classifying or grouping content\n\nI can change the input slightly, rerun the same prompt, and the output stays basically the same.  \nOnce I realized that, those tasks became **default LLM work** for me.\n\n**Other tasks look fine on the surface but are much less reliable:**\n\n* synthesizing across multiple ideas\n* making judgment calls\n* open-ended *‚Äúwhat should I do‚Äù* questions\n* anything where success is subjective or fuzzy\n\nThe outputs often sound confident, but small changes in phrasing or context can push them in very different directions.  \nNot wrong exactly, just inconsistent.\n\nThe mental shift that helped was stopping myself from asking:\n\n>\n\nand instead asking:\n\n>\n\nThat question pretty cleanly separates:\n\n* things I trust in a workflow\n* things I‚Äôll sanity-check every time\n* things I avoid unless I‚Äôm just exploring\n\nAt this point, I‚Äôm less impressed by clever answers and more interested in **predictable behavior under small changes**.\n\nCurious how this lines up with others‚Äô experience.\n\n**What tasks do you trust LLMs with completely, and where do you not want to delegate.** ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8fdzl/daily_llm_use_taught_me_that_consistency_matters/",
        "publishDate": "2026-01-09T18:00:43Z[Etc/UTC]",
        "author": "SonicLinkerOfficial",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8dopt",
        "title": "Why AI coding is a dangerous narrative",
        "content": "We are knee deep in an AI hype cycle. And we are under the misunderstanding that somehow AI is doing well at coding task. This is actually setting a dangerous precedent that I want to expand on in this post. \n\nSo first I want to talk about why AI coding is so attractive.  Particularly vibe code. But I will talk about AI assisted development following the same destructive patterns. \n\n1. AI coding is narratively comfortable\n\nAI removes friction.  You lack understand of a language or a framework? No more reading docs. AI can come an automatically solve your problem.  It feels great and can feel it has saved your hours of research.\n\n2. It‚Äôs sold as software democratization m\n\nHave a business idea and plan? Need software? Great grab Loveable or Replit and have a running prototype in a day or a week. \n\n3. It helps devs ship fast\n\nDevs can clear up features super fast.  Maybe even one shot promote if they‚Äôre lucky.  They spent less time writing code and testing and debugging\n\nHere is where it‚Äôs bad\n\nAI coding is addictive. And that‚Äôs the trap \n\nWhat AI coding does cognitively is build a dependency.  It‚Äôs dependency on a tool. Once you build this dependency you become helpless without it.\n\nThis is the pattern in steps:\n\n1. You use AI to write what appears to be inconsequential code\n\n2. You review it thoroughly.  Make some modifications and then ship\n\n3.  You realized you saved time\n\n4. You build  workflow around AI coding.\n\n5. Now you‚Äôre shipping fast.\n\nNext time you have a coding task.  You remembered how frictionless AI was. So you use it again.  \n\n1. You‚Äôre not generating a simple script.  It‚Äôs an entire feature\n\n2. Feature is 300+ lines of code\n\n3. You‚Äôre not reviewing. You‚Äôre scanning \n\n4. Things appear to be fine, you ship \n\nOk now we‚Äôre escalating. Now let‚Äôs take it to where it‚Äôs in dangerous territory. You have a tight deadline.  You need a feature, it needs to me shipped in 2 days.  What do you do?\n\n1. You fire up AI\n\n2. You plan your feature\n\n3. You generate code.  But now it‚Äôs 1500 lines instead of a few hundred\n\n4. You don‚Äôt review you commit.\n\nAt this point you are just driving AI to write code.  You‚Äôre not wiring it yourself anymore.  You‚Äôre not even looking at it.  And this is where the trap starts.  \n\nAI coding becomes philosophical not just practical\n\nNow you‚Äôre telling yourself things like this\n\n1. Code doesn‚Äôt matter. Specs do\n\n2. We‚Äôre in the future. Code no longer needs to be written for humans\n\n3. Writing code was always the easy part of the job  (but never expand on the ‚Äúhard part‚Äù)\n\nContext engineering\n\nSpec drive development\n\nWriting good instructions\n\nThese are all traps.  \n\nHere is the reality check:\n\nCode does matter and no it‚Äôs not easy.\n\nCode is never easy.  But it can often give the illusion that it‚Äôs easier than it appears.\n\nEven the simplest and trivial code breaks under poor constraints and poor boundaries.\n\nAI coding issue isn‚Äôt that it can‚Äôt write code.  It‚Äôs that it doesn‚Äôt respect constraints.  It lacks global invariants.  \n\nAI code is goal directed but not intent directed.  Goal vs intent important.\n\nA goal is to reach a finish line.\n\nIntent is reaching a finish line running a straight line \n\nAI code is often not intentional.  At a certain level of complexity it can no longer be reasoned about. \n\nSo how do you add to code that has so much cognitive complexity that no one can reasonably understand it?\n\nOh yeah more AI. But here is the issue.  What happens when the code break? Who can fix it?\n\nAI can‚Äôt. AI can‚Äôt debug code because debugging code requires understanding invariants.  AI only can reason about context locally\n\nSo whole AI can tell you issues with a single function.  It cannot form a cohesive view of all code across multiple files.  This is context overload. This is where hallucinations and danger is introduced to your code.  \n\nDebugging is still in the domain of humans . But how can humans understand code created by AI? They can‚Äôt.  Debuggers can‚Äôt pick up on logic errors.  Nor can it pick up on bad patterns introduced by AI\n\nSo if you don‚Äôt understand the code and AI doesn‚Äôt? Then who does understand the code?  No one does.\n\nWhat are your options?\n\nMore specs?  But specs for you here in the first place \n\nBetter context? But this has a cost\n\nThe reality is you‚Äôre no longer engineering . You‚Äôre gambling.  \n\nThis is the trap.\n\nAI is fantastic at writing code.  But what happens when we eventually have to read the code?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8dopt/why_ai_coding_is_a_dangerous_narrative/",
        "publishDate": "2026-01-09T16:58:53Z[Etc/UTC]",
        "author": "GolangLinuxGuru1979",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "22",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8dhr6",
        "title": "Which AI course gives projects that actually look credible in a resume?",
        "content": "Having spent 8 years as a TPO consultant, I want to break into AI. Seeing too many courses out there, I am bit more confused.  \n  \nI have experimented with Python and gone through a couple of free tutorials, but now I am looking for real projects that would not only be credible on my resume but also demonstrating my coding skills, not just running somebody's code.  \n  \nWhile researching, I found popular options like DeepLearning AI, Udacity AI Course, GUVI, and LogicMojo AI & ML Course, and Udemy but among these, which one is really giving you portfolio projects or real, resume worthy projects that are considered serious by the hiring managers?  \n  \nIn case you have participated in a course and showcased its projects in interviews or on your CV, I would be very grateful for your sincere opinion, particularly regarding the aspect that seemed time well spent.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8dhr6/which_ai_course_gives_projects_that_actually_look/",
        "publishDate": "2026-01-09T16:51:46Z[Etc/UTC]",
        "author": "Glad_Orchid6757",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8cjhx",
        "title": "Mogri-lexicon Evolution",
        "content": "[github](https://github.com/minuxlintebiandedition/CSP-105/blob/main/spec/explainers/meta/Explanation-Improvement.txt)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8cjhx/mogrilexicon_evolution/",
        "publishDate": "2026-01-09T16:16:53Z[Etc/UTC]",
        "author": "decofan",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8bkzb",
        "title": "I am 90% sure the Cox agent I just spoke with on the phone was an AI Chatbot.",
        "content": "I don‚Äôt mean the robot that gives you options and requires the use of your keypad. After I got through that, it told me I was being connected to a representative, went on a roughly 5 second hold, and got connected. It sounded like a middle aged man, and he introduced his name as Shawn/Sean Lee. He had a clear American accent, and his speech was incredibly normalized. It took me a whole minute to catch on, and even then, I acted normal in case it happened to be a guy speaking a little differently. That‚Äôs how convincing it was.\n\nHe ended up getting very confused with what I was saying, so I hung up believing it was a chatbot. I‚Äôm just surprised Cox would start using them in an attempt to fool people instead of telling you it‚Äôs an AI agent. Has anyone else experienced something similar with Cox or anywhere else?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8bkzb/i_am_90_sure_the_cox_agent_i_just_spoke_with_on/",
        "publishDate": "2026-01-09T15:41:20Z[Etc/UTC]",
        "author": "Lightdual",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "13",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8av3u",
        "title": "Should they program AI to feel pain?",
        "content": "I think it would be a huge mistake but some may find value in such an algo. How might this be implemented ? Power dips tied to aggressive avoidance of being shut down? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q8av3u/should_they_program_ai_to_feel_pain/",
        "publishDate": "2026-01-09T15:14:04Z[Etc/UTC]",
        "author": "SpareDetective2192",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q89y6h",
        "title": "\"AI Slop\" is killing content quality. Here's what I learned after being called out for it.",
        "content": "I've been thinking a lot about \"AI Slop\" lately ‚Äì that flood of AI-generated content that's technically correct but completely devoid of personality, perspective, or actual value. It's everywhere, and frankly, it's making the internet a less engaging place.\n\nMy wake-up call came when a reader left a 7-word comment on some AI-generated text I'd published: **\"So many words to replace a human ok.\"**\n\nThat simple reply nailed it. I was using AI as a crutch, letting it generate generic responses instead of using it to enhance my own human insights. I realized that if I‚Äôm not adding a unique perspective, I‚Äôm just adding noise.\n\nI‚Äôve been trying to define exactly what makes content \"Slop\" so I can avoid it. Here‚Äôs my current checklist:\n\n* **The Hedge:** Every claim is softened with \"it is important to consider\" or \"on the other hand.\" No stance is actually taken.\n* **The Loop:** The conclusion is just the introduction reworded.\n* **The \"Nobody‚Äôs Home\" Vibe:** It‚Äôs grammatically perfect but substantively hollow.\n\nFor me, the shift has been moving from **AI-generated** to **AI-assisted**.\n\nThe \"Tool\" approach means I provide the specific context, the weird personal anecdotes, and the controversial takes first‚Äîthen use the AI to help structure it. If the AI is making the editorial choices, it‚Äôs Slop. If I‚Äôm making the choices, it‚Äôs content.\n\n**I‚Äôm curious to hear from others:** What are your biggest frustrations with AI-generated content right now? Is there a specific \"tell\" that makes you immediately close a tab or scroll past a post?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q89y6h/ai_slop_is_killing_content_quality_heres_what_i/",
        "publishDate": "2026-01-09T14:39:05Z[Etc/UTC]",
        "author": "Ok-Piccolo-6079",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q87yhs",
        "title": "If AI eventually replaces all labor, who is left to buy the products?",
        "content": "I have been trying to wrap my head around the long-term endgame of total AI automation.\n\nWe often hear the doomsday scenario: AI hits a point where it can do everything better and cheaper than humans. In this hypothetical, the workforce is effectively eliminated, and a handful of massive tech conglomerates own the entire 'production' side of the world.\n\nBut here is the paradox: Our entire global economy relies on a circular flow. If the 99% have no income because their roles were automated, they lose their status as consumers. They can't pay mortgages, they can't buy goods, and they can't sustain the services that these AI companies are selling.\n\nDoes the 'AI Takeover' just lead to a total collapse of demand? Or am I missing a fundamental piece of the puzzle regarding how value is distributed in a post-labor world?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q87yhs/if_ai_eventually_replaces_all_labor_who_is_left/",
        "publishDate": "2026-01-09T13:15:33Z[Etc/UTC]",
        "author": "Reddit_INDIA_MOD",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "64",
            "commentCount": "221",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q87jun",
        "title": "When Meta bought Manus IA, something brutal happened",
        "content": "Why did Meta immediately announce the cessation of all Chinese operations for Manus AI right after acquiring the startup?\n\nIt wasn't a punishment, it was a condition for survival.\n\nTechnological protectionism has intensified to the point where US authorities warn against \"Singapore Washing\"‚Äîcompanies trying to mask ties to Beijing through Singaporean HQ. Reuters said in December that such moves \"no longer guarantee businesses can escape political or regulatory pressure\"... and yeah, no shit.  For Meta, a \"clean cut\" was the only viable path to close the deal.\n\nDoes this signal a trend of acquiring Chinese startups solely to sever their roots? Not sure. Since 2024, China has been actively working on a \"reverse brain drain\" strategy to repatriate talent, particularly those educated in the US.\n\nThis likely won't go whithout retaliation. While Beijing‚Äôs official response was cool, sources inside the Ministry of Commerce hint at potential retaliation to stop what they view as tech theft.\n\nUltimately, the Manus AI takeover represents a new chapter in the superpower tech war. We have entered the era of talent deglobalization.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q87jun/when_meta_bought_manus_ia_something_brutal/",
        "publishDate": "2026-01-09T12:56:52Z[Etc/UTC]",
        "author": "Mat_Halluworld",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q91qyk",
        "title": "Web Form to Custom GPT",
        "content": "I hope you're all having a good weekend!\n\nI have built some custom ChatGPT which work pretty well for my work. I have shared them with some other people to use.\n\nRather than send the link to the actual GPT I was wondering whether I could build a simple web page for each. With an input form where you provide the requirements, which then pushes to the GPT, and then the output is sent back and displayed on the page.\n\nI'm not a coder, can do basic html and use wordpress. \n\nWhat would be the simplest way to go about this?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1q91qyk/web_form_to_custom_gpt/",
        "publishDate": "2026-01-10T11:24:30Z[Etc/UTC]",
        "author": "StillTrying1981",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8kiyk",
        "title": "How Ai saved my love for coding",
        "content": "So I tried taking comsci in university. I found the coding courses fun, but all the maths, electives, and WHY DID I HAVE TO WRITE CODE ON PAPER FOR FINAL?? So after struggling hardcore after 4 years, i made it to the end of my 2nd years courses (my gpa was low and couldnt get into some classes. So I literally had to skip the fall semester evry year and can only sign up for winter cuz all the class filled up)  only to find myself learning binary syntax while ai is finishing my whole project flawlessly in a few prompts.\n\nSo I decided to drop out, and learning coding by myself instead. The amount of pressure I had in the beginning because I was 23 years old without a main income skill. I was a language medical interpreter on the side but i hated it.\n\nBut I decided to stick with learning how to code on my own and use ai when I don't understand. Because if there's one thing I learned while struggling in my university courses, is that if I keep my head down and just do it, atleast it will go somewhere ü§£\n\nFast forward to today, I build my first website and also an app version of it launched on apple :D. I am now struggling to figure out how to market it and find users but again, just another ark of keep my head down and grind.\n\nI have 77 users in my first month so that is something hehehe no paying user yet but I believe they are just shy and hiding somewhere in the corner.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1q8kiyk/how_ai_saved_my_love_for_coding/",
        "publishDate": "2026-01-09T21:14:03Z[Etc/UTC]",
        "author": "My-Adventure-App",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q91bic",
        "title": "AI image and video generator",
        "content": "Best one i have found so far\nhttps://video.a2e.ai/?coupon=xqCs",
        "url": "https://www.reddit.com/r/artificial/comments/1q91bic/ai_image_and_video_generator/",
        "publishDate": "2026-01-10T10:59:27Z[Etc/UTC]",
        "author": "Brilliant_Length4153",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8zz2j",
        "title": "Google Gemini 3 Pro just verified a forensic protocol I ran. Here's what happened.",
        "content": "Google Gemini 3 Pro just verified a forensic protocol I ran. Here's what happened.\n\nI used Gemini's highest reasoning mode (Pro) to run a recursive forensic investigation payload designed to test the validity of widespread online claims.\n\nThe protocol:\n\nRejects repetition as evidence\n\nStrips unverifiable claims\n\nConfirms only primary source data (case numbers, records, etc.)\n\nMaps fabrication patterns\n\nGenerates a layer-by-layer breakdown from origin to spread\n\n\nI ran it on Gemini with no prior training, bias, or context provided. It returned a complete report analyzing claims from scratch. No bias. No assumptions. Just structured verification.\n\nFull report (Gemini output):\nhttps://gemini.google.com/share/1feed6565f52\n\nPayload (run it in any AI to reproduce results):\nhttps://docs.google.com/document/d/1-hsp8dPMuLIsnv1AxJPNN2B7L-GWhoQKCd7esU8msjQ/edit?usp=drivesdk\n\nKey takeaways from the Gemini analysis:\n\nAllegations repeated across platforms lacked primary source backing\n\nNo case numbers, medical records, or public filings were found for key claims\n\nVerified data pointed to a civil dispute‚Äînot criminal activity\n\nA clear pattern of repetition-without-citation emerged\n\n\nIt even outlined how claims spread and identified which lacked verifiable origin.\n\nThis was done using public tools‚Äîno backend access, no court databases, no manipulation.\nJust the protocol + clean input = verified output.\n\nIf you've ever wondered whether AI can actually verify claims at the forensic level:\nIt can. And it just did.",
        "url": "https://docs.google.com/document/d/1-hsp8dPMuLIsnv1AxJPNN2B7L-GWhoQKCd7esU8msjQ/edit?usp=drivesdk",
        "publishDate": "2026-01-10T09:36:57Z[Etc/UTC]",
        "author": "MarsR0ver_",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8y053",
        "title": "Has the global population already been \"primed\" to mass adopt new innovations like LLM's en masse? The state of tech literacy now vs pre-dotcom bubble",
        "content": "I see most boomers in their 60's and 70's now adept at using smartphones.\n\nYoung kids today are weened on iPads in place of proper parenting with sports or hobbies or after school activities.\n\nBroadband mobile is now an expectation and a no longer a \"need\" or \"want\", but sort of a \"right\".\n\nEven the poorest African or South Asian countries have access to mobile broadband.\n\nIncome is the only dividing factor to the poorest having access to unlimited mobile. But even then, the data cost index is lower in developing countries that the poor can have some access to it. Wi-fi is free and more accessible in some places in poor countries compared to rich countries to make up for the digital divide.\n\nCompare this situation to when the bubble popped in 2000's. There were no smartphones, let alone cellphones. Dial-up is the norm.\n\nThere are still tech today that can die on the vine like VR as they are too geeky.\n\nBut as far as the subscription model of LLM's, people have gotten used to paying for Netflix or Disney Plus. So there might not be much of a resistance or unfamiliarity with this business model.\n\nDo you think the global population is more primed to accept AI now (or more properly, LLM) if a Jony Ive \"Her\" (the movie) type of device comes out from OpenAI? How about AI porn? Porn usage and OF subscription is undeniably mainstream.\n\nOr am I just conflating the mass adoption of smartphones as a proxy to people now accepting any new tech?",
        "url": "https://www.reddit.com/r/artificial/comments/1q8y053/has_the_global_population_already_been_primed_to/",
        "publishDate": "2026-01-10T07:35:23Z[Etc/UTC]",
        "author": "PopularRightNow",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8v56s",
        "title": "X Restricts Grok's Image Generation to Paid Users After Global Backlash",
        "content": "[No content]",
        "url": "https://techputs.com/x-restricts-groks-image-generation-paid-users/",
        "publishDate": "2026-01-10T04:58:10Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "8",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8um17",
        "title": "Building adaptive routing logic in Go for an Open source LLM gateway - Bifrost",
        "content": "Working on an LLM gateway (Bifrost)- Code is open source: [https://github.com/maxim-ai/bifrost](https://github.com/maxim-ai/bifrost), ran into an interesting problem: how do you route requests across multiple LLM providers when failures happen gradually?\n\nTraditional load balancing assumes binary states ‚Äì up or down. But LLM API degradations are messy. A region starts timing out, some routes spike in errors, latency drifts up over minutes. By the time it's a full outage, you've already burned through retries and user patience.\n\nStatic configs don't cut it. You can't pre-model which provider/region/key will degrade and how.\n\n**The challenge:** build adaptive routing that learns from live traffic and adjusts in real time, with <10¬µs overhead per request. Had to sit on the hot path without becoming the bottleneck.\n\n**Why Go made sense:**\n\n* Needed lock-free scoring updates across concurrent requests\n* EWMA (exponentially weighted moving averages) for smoothing signals without allocations\n* Microsecond-level latency requirements ruled out Python/Node\n* Wanted predictable GC pauses under high RPS\n\n**How it works:** Each route gets a continuously updated score based on live signals ‚Äì error rates, token-adjusted latency outliers (we call it TACOS lol), utilization, recovery momentum. Routes traffic from top-scoring candidates with lightweight exploration to avoid overfitting to a single route.\n\nWhen it detects rate-limit hits (TPM/RPM), it remembers and allocates just enough traffic to stay under limits going forward. Automatic fallbacks to healthy routes when degradation happens.\n\nResult: <10¬µs overhead, handles 5K+ RPS, adapts to provider issues without manual intervention.\n\nRunning in production now. Curious if others have tackled similar real-time scoring/routing problems in Go where performance was critical?",
        "url": "https://www.reddit.com/r/artificial/comments/1q8um17/building_adaptive_routing_logic_in_go_for_an_open/",
        "publishDate": "2026-01-10T04:31:17Z[Etc/UTC]",
        "author": "dinkinflika0",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8qvey",
        "title": "Terrence Tao: \"Erdos problem #728 was solved more or less autonomously by AI\"",
        "content": ">\"Recently, the application of AI tools to Erdos problems passed a milestone: an Erdos problem ([\\#728](https://www.erdosproblems.com/728)) was solved more or less autonomously by AI (after some feedback from an initial attempt), in the spirit of the problem (as reconstructed by the Erdos problem website community), with the result (to the best of our knowledge) not replicated in existing literature (although similar results proven by similar methods were located).\n\n>This is a demonstration of the genuine increase in capability of these tools in recent months, and is largely consistent with other recent demonstrations of AI using existing methods to resolve Erdos problems, although in most previous cases a solution to these problems was later located in the literature, as discussed in [https://mathstodon.xyz/deck/@tao/115788262274999408](https://mathstodon.xyz/deck/@tao/115788262274999408) . This particular case was unusual in that the problem as stated by Erdos was misformulated, with a reconstruction of the problem in the intended spirit only obtained in the last few months, which helps explain the lack of prior literature on the problem. However, I would like to talk here about another aspect of the story which I find more interesting than the solution itself, which is the emerging AI-powered capability to rapidly write and rewrite expositions of the solution.\n\n>\\[...\\]\n\n>My preference would still be for the final writeup for this result to be primarily human-generated in the most essential portions of the paper, though I can see a case for delegating routine proofs to some combination of AI-generated text and Lean code. But to me, the more interesting capability revealed by these events is the ability to rapidly write and rewrite new versions of a text as needed, even if one was not the original author of the argument.\n\n>This is sharp contrast to existing practice where the effort required to produce even one readable manuscript is quite time-consuming, and subsequent revisions (in response to referee reports, for instance) are largely confined to local changes (e.g., modifying the proof of a single lemma), with large-scale reworking of the paper often avoided due both to the work required and the large possibility of introducing new errors. However, the combination of reasonably competent AI text generation and modification capabilities, paired with the ability of formal proof assistants to verify the informal arguments thus generated, allows for a much more dynamic and high-multiplicity conception of what a writeup of an argument is, with the ability for individual participants to rapidly create tailored expositions of the argument at whatever level of rigor and precision is desired.\"\n\n\\-- Terrence Tao",
        "url": "https://mathstodon.xyz/@tao/115855840223258103",
        "publishDate": "2026-01-10T01:35:58Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "38",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8pj70",
        "title": "Is the Scrabble world champion (Nigel Richards) an example of the Searle's Chinese room",
        "content": "I'm currently in my undergraduate degree and I have been studying AI ethics under one of my professors for a while. I always have been a partisan of Searle's strong AI and I never really found the chinese room argument compelling.\n\nPersonally I found that the systems argument against the chinese room to make a lot of sense. My first time reading \"Minds, Brains, and Programs\" I thought Searle's rebuttal was not very well structured and I found it a little logically incorrect. He mentions that if you take away the room and allow the person to internalize all the things inside the system, that he still will not have understanding--and that no part of the system can have understanding since he is the entire system.\n\nI always was confused on why he cannot have understanding, since I imagine this kind of language theatrics is very similar to how we communicate; I couldn't understand how this means artificial intelligence cannot have true understanding.\n\nNow on another read I was able to draw some parallels to Nigel Richards--the man who won the french scrabble championship by memorizing the french dictionary. I havent seen anyone talk about this online so I just want to propose a few questions:\n\n1. Does Nigel Richards have an understanding of the french language ?\n2. Does Nigel serve as a de facto chinese room ?\n3. What is different between Nigel's understanding of the french language compared to a native speaker?\n4. Do you think that this is similar to how people accredit LLMs' to simple prediction machines?\n5. And finally, would an LLM have a better or worse understanding of language in comparison to Nigel?\n6. ‚Å†What does this mean when it comes to the our ideas of consciousness? Do we humanize the idea of thinking too much when maybe (like the example) we are more similar to LLMs than previously thought?",
        "url": "https://www.reddit.com/r/artificial/comments/1q8pj70/is_the_scrabble_world_champion_nigel_richards_an/",
        "publishDate": "2026-01-10T00:36:49Z[Etc/UTC]",
        "author": "applezzzzzzzzz",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q8ankw",
        "title": "Built a cognitive framework for AI agents - today it audited itself for release and caught its own bugs",
        "content": "I've been working on a problem: AI agents confidently claim to understand things they don't, make the same mistakes across sessions, and have no awareness of their own knowledge gaps.\n\nEmpirica is my attempt at a solution - a \"cognitive OS\" that gives AI agents functional self-reflection. Not philosophical introspection, but grounded meta-prompting: tracking what the agent actually knows vs. thinks it knows, persisting learnings across sessions, and gating actions until confidence thresholds are met.\n\n[parallel git branch multi agent spawning for investigation](https://reddit.com/link/1q8ankw/video/jq6lc9vm9ccg1/player)\n\nWhat you're seeing:\n\n* The system spawning 3 parallel investigation agents to audit the codebase for release issues\n* Each agent focusing on a different area (installer, versions, code quality)\n* Agents returning confidence-weighted findings to a parent session\n* The discovery: 4 files had inconsistent version numbers while the README already claimed v1.3.0\n* The system logging this finding to its own memory for future retrieval\n\nThe framework applies the same epistemic rules to itself that it applies to the agents it monitors. When it assessed its own release readiness, it used the same confidence vectors (know, uncertainty, context) that it tracks for any task.\n\nKey concepts:\n\n* CASCADE workflow: PREFLIGHT (baseline) ‚Üí CHECK (gate) ‚Üí POSTFLIGHT (measure learning)\n* 13 epistemic vectors: Quantified self-assessment (know, uncertainty, context, clarity, etc.)\n* Procedural memory: Findings, dead-ends, and lessons persist in Qdrant for semantic retrieval\n* Sentinel: Gates praxic (action) phases until noetic (investigation) phases reach confidence threshold\n\nThe framework caught a release blocker by applying its own methodology to itself. Self-referential improvement loops are fascinating territory.\n\nI'll leave the philosophical questions to you. What I can show you: the system tracks its own knowledge state, adjusts behavior based on confidence levels, persists learnings across sessions, and just used that same framework to audit itself and catch errors I missed. Whether that constitutes 'self-understanding' depends on your definitions - but the functional loop is real and observable.\n\nOpen source (MIT): [www.github.com/Nubaeon/empirica](http://www.github.com/Nubaeon/empirica)",
        "url": "https://www.reddit.com/r/artificial/comments/1q8ankw/built_a_cognitive_framework_for_ai_agents_today/",
        "publishDate": "2026-01-09T15:05:58Z[Etc/UTC]",
        "author": "entheosoul",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q87y8e",
        "title": "A practical 2026 roadmap for modern AI search & RAG systems",
        "content": "I kept seeing RAG tutorials that stop at ‚Äúvector DB + prompt‚Äù and break down in real systems.\n\nI put together a roadmap that reflects how modern AI search actually works:\n\n‚Äì semantic + hybrid retrieval (sparse + dense)  \n‚Äì explicit reranking layers  \n‚Äì query understanding & intent  \n‚Äì agentic RAG (query decomposition, multi-hop)  \n‚Äì data freshness & lifecycle  \n‚Äì grounding / hallucination control  \n‚Äì evaluation beyond ‚Äúdoes it sound right‚Äù  \n‚Äì production concerns: latency, cost, access control\n\nThe focus is system design, not frameworks. Language-agnostic by default (Python just as a reference when needed).\n\nRoadmap image + interactive version here:  \n[https://nemorize.com/roadmaps/2026-modern-ai-search-rag-roadmap](https://nemorize.com/roadmaps/2026-modern-ai-search-rag-roadmap)\n\nCurious what people here think is still missing or overkill.",
        "url": "https://www.reddit.com/r/artificial/comments/1q87y8e/a_practical_2026_roadmap_for_modern_ai_search_rag/",
        "publishDate": "2026-01-09T13:15:14Z[Etc/UTC]",
        "author": "ReverseBlade",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "MHWX4OF-HiM",
        "title": "Automaker: This AI Coding Agent STUDIO is KINDA COOL!",
        "content": "In this video, I explore Automaker, an open-source autonomous development studio that is changing how we build software.",
        "url": "https://www.youtube.com/watch?v=MHWX4OF-HiM",
        "publishDate": "2026-01-09T09:15:02Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/MHWX4OF-HiM/hqdefault.jpg",
            "transcription": "Hi, Welcome to another video. So, we have all been there. You just want to hack together a quick prototype. Maybe it's a simple dashboard or a movie tracker idea you just had. You sit down, you open your IDE, and then you spend the first hour just setting up Tailwind, configuring Vite, and fighting with API fetch logic. By the time you are actually ready to build the application logic, you are already tired. However, what if you didn't have to do the setup? What if you could just describe the app, and a team of autonomous agents would scaffold it, plan it, and code it for you? Today, we are looking at a tool called Automaker. It is apparently built by Webdev Cody, which is awesome to see. It basically allows you to stop copy-pasting code and start directing AI agents. We have seen things like these in Auto Claude, but it seems to have much more features. This basically changes the interface from prompting to managing tasks in a Kanban board and running the tasks through there. This is a standalone autonomous development studio that plans your project, creates a Kanban board of tasks, and then executes them autonomously. It is open-source. It is free to use assuming you bring your own API keys. And it recently got a major update where it now supports Electron. So, no more messing with browser tabs, it runs as a native desktop application. Now, let me show it to you in action. To get started, you just grab it from their GitHub repository. You clone the repo, install the dependencies, and run it. Because I want the full experience, I am running the Electron version. So, I am going to build a simple movie tracker. And I want to do this in one go from scratch with no complex backend or authentication. I just want to search for movies using the TMDB API and save my favorites to local storage. I click new project. I will name it simple-movie-tracker. I am going to select the Agentic Jumpstart Kit just so I have a clean React and Tailwind foundation ready to go. Here is where it gets interesting. Automaker asks me to describe my app to generate a spec. I am not going to write a novel. I am going to type this exactly. Build a single-page React application. It should have a search bar at the top that queries the TMDB API for movies. Below that, display the results as cards with the movie poster and title. Users can click a \"Heart\" icon to save a movie to their favorites. The favorites should be stored in the browser's Local Storage so they persist. No backend, no auth. I hit generate spec. In literal seconds it analyzes that prompt. It figures out the tech stack, noting React, Tailwind, and Lucide React for icons. It outlines the core capabilities. It even breaks down the implementation plan into a list of features. Now we are on the Kanban board. This is the coolest part of the UI. It has populated my backlog with tasks like Set Up TMDB Client, Create Movie Card Component, Implement Search Bar, and Build Favorites Logic. Now, I could drag these one by one, but I want to see the magic. I am going to toggle this switch at the top right called Auto Mode. Watch this. The agents immediately wake up. They pull the first ticket into In Progress. I can actually click on the card and see the logs. It is creating the API service file. It is adding the fetch logic, and it is handling the API key environment variable. It finishes that, commits the code, and immediately grabs the next ticket, which is Create Movie Card Component. It is running completely hands-free. While it is doing this, I can actually open the terminal inside Automaker and run npm run dev to see the app running on localhost. Okay. So, the app is running. Now, you might be asking, how did it know how to use the TMDB API? This is the Context feature. Before I started Auto Mode, I could have gone to the Context tab and uploaded a text file with the TMDB API documentation, or just pasted my API key instructions. This allows the agents to read specific documentation about your project or the libraries you want to use. It streamlines your workflow a lot. For spinning up these kinds of side projects or prototypes, instead of fighting with boilerplate, you are just directing the flow. You tell it what to build, you review the work, and you tweak the UI. It brings the fun back into building because you see results immediately. It is open-source. So, go check out the repo. Give them a star and try running it locally. Since it runs on your machine, your code stays with you. One thing I really want to highlight here is the difference in workflow compared to something like Cursor or Windswept. With those IDEs, you are still the one driving the car, and the AI is just navigating. With Automaker, you are stepping out of the car and telling the driver where to go. It completely shifts your mental model from writing code to managing a product. You are not bogged down in syntax errors. You are focused on the feature list. Also, we need to talk about data privacy because that is a huge concern for many of you. Since this is an Electron app running locally, you have full control. You aren't uploading your repo to a third-party SaaS that might disappear tomorrow. You are bringing your own keys, and the agents are manipulating your local file system directly. That being said, because these agents are autonomous and they chain multiple thoughts together, you do need to watch your token usage. It is incredibly efficient at writing code. But if you ask for a massive feature set and walk away, you might burn through some credits. It is a tradeoff. But for the speed you get, I think it is worth it. Overall, it is pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "m0WMoLgy6g4",
        "title": "The Problem With The Soviet Economy - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=m0WMoLgy6g4",
        "publishDate": "2026-01-09T18:33:14Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/m0WMoLgy6g4/hqdefault.jpg",
            "transcription": "But the Soviet Union was special in that in the 40s and 50s, they have much higher growth rates, so much so that prominent economists like Paul Samuelson are saying that by the 90s, based on what they're seeing at the time, the Soviet Union will have a bigger economy than America. Well, first of all, it's a war economy, essentially. You're putting all your money, so you have a big military, and Russians define greatness. This is part of it, of being a big power, and it's military power with territory. Um, and most countries in wartime, they mobilized for the military, right? This country did it in World War II. All kinds of rationing, right? You're setting different prices, giving people ration cards and things. The thing is about the Soviets is they kept it forever. They never got rid of it. So that's one piece. Another problem with the Soviet Union is all of the data. So I don't know what data you've seen, and I know the data I've seen, is it's hard to know because the ruble's a non-convertible currency, and a lot of things they measure in weight. Like, they're the greatest TV producer in the world, they said. Why? Because they made the heaviest TVs in the world. When I was there, this was it, and they would spontaneously combust, which is not the normal thing a TV should do for you, burn down the apartment building. And I gave you the CIA ones, where the CIA, they're not stupid people. They've got the best data they could find, and they're coming up with 20% of the Soviet budget is probably devoted to the military. And then after the Cold War is over, they're going, whoops, we missed, it's at least double that, and maybe triple. So it's really hard to know even with the statistics you're getting. Certainly what Paul Samuelson had wouldn't be accurate. It's just a guess."
        }
    }
]