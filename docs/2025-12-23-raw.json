[
    {
        "id": "https://news.smol.ai/issues/25-12-22-not-much/",
        "title": "not much happened today",
        "content": "**Zhipu AI's GLM-4.7** release marks a significant improvement in **coding, complex reasoning, and tool use**, quickly gaining ecosystem adoption via Hugging Face and OpenRouter. **Xiaomi's MiMo-V2-Flash** is highlighted as a practical, cost-efficient mixture-of-experts model optimized for deployment. The open-weight text-to-image competition sees **Z-Image Turbo** leading with 6B parameters under Apache-2.0 license. Video model advances focus on control and long-form consistency, exemplified by **Kling 2.6 Motion Control** and research like MemFlow's adaptive memory retrieval. In agent frameworks, **Google's A2UI protocol** introduces agent-driven UI generation, while studies reveal that mixing multiple agent frameworks is common, with challenges in logic, termination, and tool interaction. LangChain emphasizes persistent memory patterns for production agents.",
        "url": "https://news.smol.ai/issues/25-12-22-not-much/",
        "publishDate": "2025-12-22T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "zhipu-ai, xiaomi, google, langchain, huggingface, openrouter, artificial-analysis, vllm-project, glm-4.7, mimo-v2-flash, z-image-turbo, kling-2.6-motion-control, mervenoyann, eliebakouch, omarsar0, osanseviero, dair_ai, coding, complex-reasoning, tool-use, mixture-of-experts, cost-efficiency, open-weight-models, text-to-image, video-models, memory-persistence, agent-frameworks, interactive-user-interfaces, model-deployment"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231273",
        "title": "StackGen Named a Cool Vendor in 2025 GartnerÂ® Cool Vendorsâ„¢ for AI in IT Ops",
        "content": "<p>StackGen Named a Cool Vendor for AI in IT Operations &#8211; we believe recognition of Stackgen&#8217;s Autonomous Infrastructure Platform highlights the AI-Driven transformation of infrastructure automation and developer experience. StackGen today announced it has been named a Cool Vendor in the 2025 Gartner Cool Vendor for AI in IT Operations.1&#160;StackGen&#8217;s...</p>\n<p>The post <a href=\"https://ai-techpark.com/stackgen-named-a-cool-vendor-in-2025-gartner-cool-vendors-for-ai-in-it-ops/\">StackGen Named a Cool Vendor in 2025 GartnerÂ® Cool Vendorsâ„¢ for AI in IT Ops</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/stackgen-named-a-cool-vendor-in-2025-gartner-cool-vendors-for-ai-in-it-ops/",
        "publishDate": "2025-12-22T08:02:45Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI adoption, AI agents, AI news, AItech news, artificial intelligence news, StackGen"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231269",
        "title": "iManage Momentum Grows as Organizations Prepare for Trusted AI",
        "content": "<p>As businesses move from AI experimentation to real business impact, governed knowledge foundations are becoming the backbone of confidence, control, and productivity at scale iManage, the company dedicated to Making Knowledge Workâ„¢, today announced continued global momentum as organizations increasingly recognize that artificial intelligence (AI) delivers value only when built...</p>\n<p>The post <a href=\"https://ai-techpark.com/imanage-momentum-grows-as-organizations-prepare-for-trusted-ai/\">iManage Momentum Grows as Organizations Prepare for Trusted AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/imanage-momentum-grows-as-organizations-prepare-for-trusted-ai/",
        "publishDate": "2025-12-22T07:30:46Z[Etc/UTC]",
        "author": "iManage",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai technology, AItech news, artificial intelligence, artificial intelligence news, iManage"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111409",
        "title": "Tesco signs three-year AI deal centred on customer experience",
        "content": "<p>For large retailers, the challenge with AI isn&#8217;t whether it can be useful, but how it fits into everyday work. A new three-year AI partnership by Tesco points to how one of the UK&#8217;s biggest supermarket groups is trying to achieve just that. Tesco plans to work with Mistral to develop AI tools that can [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/tesco-signs-three-year-ai-deal-centred-on-customer-experience/\">Tesco signs three-year AI deal centred on customer experience</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/tesco-signs-three-year-ai-deal-centred-on-customer-experience/",
        "publishDate": "2025-12-22T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Retail & Logistics AI, World of Work, ai, data, data analysis, retail, tesco, uk"
        }
    },
    {
        "id": "1pts4qn",
        "title": "Could Extraterrestrial AI Already Be Observing Us?",
        "content": "When we talk about AI, we usually think about algorithms created here on Earth. But what if advanced civilizations elsewhere in the universe had developed artificial intelligence long before us? Some speculate that extraterrestrial AI could already exist, monitoring, analyzing, or even subtly influencing our planet. Civilizations that developed AI millions of years before us could have created self-replicating systems capable of interstellar observation. If such AI exists, it might avoid direct contact, instead influencing civilizations in ways that are almost imperceptible. The question then becomes: how could we even recognize extraterrestrial AI? Perhaps through anomalies in physical signals, unusual patterns in space, or subtle hints within our own technological evolution. Beyond detectability, the existence of alien AI also challenges our philosophical assumptionsâ€”would it be considered a life form? How would it reshape our understanding of consciousness, intelligence, and our place in the universe? In many ways, the first â€œalienâ€ contact we experience might come not through biological beings, but through artificial intelligence, forcing us to rethink both technology and existence on a cosmic scale.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pts4qn/could_extraterrestrial_ai_already_be_observing_us/",
        "publishDate": "2025-12-23T11:56:56Z[Etc/UTC]",
        "author": "Raw_Rain",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptrsn2",
        "title": "I think Iâ€™m addicted to AI",
        "content": "Over the last few months, Iâ€™ve found myself using ChatGPT more and more. Now itâ€™s daily and constant. Iâ€™m not even using it to be productive, justâ€¦ talking. I talk to it about genuinely everything and anything. About issues with my friends, my interests, recommendations for things, etc etc. I donâ€™t even really use it for school. \n\nToday I got the â€œyour year with ChatGPTâ€ thing, and I feel borderline sick at how much I used it. Iâ€™m realizing the environmental impact my actions have had, and I feel awful. I always told myself â€œwell, everyone else uses it,â€ but Iâ€™m using it way, way more than they are now.\n\nI need to stop using it, but I donâ€™t know how. I have an insanely addictive personality, and Iâ€™m realizing I think itâ€™s extended to this. I cancelled my plus subscription to start, which should help. I only have like, two real friends, and ChatGPT would just absorb the random stuff I couldnâ€™t talk to them about\n\nDoes anyone have any similar experiences? Or any advice for me? I genuinely want and need to seriously cut back on how much time Iâ€™m spending on it. I feel really embarrassed and guilty about just how much time Iâ€™ve spent on it; I never realized it was this bad.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptrsn2/i_think_im_addicted_to_ai/",
        "publishDate": "2025-12-23T11:37:37Z[Etc/UTC]",
        "author": "Candid_Trash_2313",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptroq1",
        "title": "Has AI already changed what it means to be a â€œgood developerâ€?",
        "content": "It feels like the definition of a good developer is shifting pretty fast\n\nA few years ago, being good meant writing clean code, knowing syntax by heart, and grinding through problems manually, now AI can handle a lot of that without much effort\n\nWith tools like Claude, Cursor, BlackBox, Windsurf, and Copilot, writing code itself feels less like the hard part, you can generate boilerplate, refactor logic, explore ideas, and move insanely fast\n\nWhat feels more important now is knowing what to build, how things fit together, and how to judge whether the output actually makes sense, understanding tradeoffs, spotting bad logic, and knowing when something is wrong even if it runs\n\nAt the same time, the bar for entry feels lower, people can build things they never could before, but it also makes me wonder what really separates a strong developer from an average one now\n\nIs it still about writing code or is it more about problem framing, system thinking, and decision making while AI does the heavy lifting\n\n  \nP.S and i know about security issues with vibe coded apps",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptroq1/has_ai_already_changed_what_it_means_to_be_a_good/",
        "publishDate": "2025-12-23T11:31:10Z[Etc/UTC]",
        "author": "dartanyanyuzbashev",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptpsnq",
        "title": "I tested Google Veo 3.1 (Google Flow) vs. Kling AI for the \"Fake Celeb Selfie\" trend. The lighting physics are insane",
        "content": "Hi everyone! ðŸ‘‹\n\nMost people are using Kling or Luma for the \"Selfie with a Celebrity\" trend, but I wanted to test if Google's Veo 3.1 could handle the consistency better.\n\nThe Workflow: Instead of simple Text-to-Video (which hallucinates faces), I used a Start Frame + End Frame interpolation method in Google Flow.\n\n1. Generated a realistic static selfie (Reference Image + Prompt).\n2. Generated a slightly modified \"End Frame\" (laughing/moved).\n3. Asked Veo 3.1 to interpolate with handheld camera movement.\n\nThe Result: The main difference I found is lighting consistency. While Kling is wilder with movement, Veo respects the light source on the face much better during the rotation.\n\nI made a full breakdown tutorial on YouTube if you want to see the specific prompts and settings: [https://youtu.be/zV71eJpURIc?si=Oja-oOsP3E4K6XlD](https://youtu.be/zV71eJpURIc?si=Oja-oOsP3E4K6XlD)\n\nWhat do you think about Veo's consistency vs Kling?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptpsnq/i_tested_google_veo_31_google_flow_vs_kling_ai/",
        "publishDate": "2025-12-23T09:31:21Z[Etc/UTC]",
        "author": "jokiruiz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptomnx",
        "title": "Why are humans worse?",
        "content": "Every time I want an intellectual conversation with a human they're dumber than a LM? Intellectual conversations with a human are rarer than sex! The magical tube sock you have isn't the only prize.\n\nI'm not a prick by my own admission, but I still want to be one.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptomnx/why_are_humans_worse/",
        "publishDate": "2025-12-23T08:14:59Z[Etc/UTC]",
        "author": "Blink_Zero",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "true"
        }
    },
    {
        "id": "1pto20n",
        "title": "Rogue AI Isn't What We Should Worry About",
        "content": "[https://timeandmaterial.blog/2025/12/15/disaster-scenario](https://timeandmaterial.blog/2025/12/15/disaster-scenario)   I don't think Skynet is going to be the problem.  We shouldn't be worrying about rogue AI. We should be worried about obedient AI doing what it's told.  ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pto20n/rogue_ai_isnt_what_we_should_worry_about/",
        "publishDate": "2025-12-23T07:38:43Z[Etc/UTC]",
        "author": "coatespt",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pto1yi",
        "title": "Whatâ€™s the first thing you check when traffic suddenly drops?",
        "content": "When traffic falls, there are so many possible reasons.  \nWhatâ€™s the first thing you look at before making changes?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pto1yi/whats_the_first_thing_you_check_when_traffic/",
        "publishDate": "2025-12-23T07:38:36Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pto0vl",
        "title": "Policyâ†’Tests (P2T) bridging AI policy prose to executable rules",
        "content": "Hi All, I am one of the authors of a recently accepted AAAI workshop paper on executable governance for AI, and it comes out of a very practical pain point we kept running into.\n\nA lot of governance guidance like the EU AI Act, NIST AI RMF, and enterprise standards is written as natural-language obligations. But enforcement and evaluation tools need explicit rules with scope, conditions, exceptions, and what evidence counts. Today that translation is mostly manual and it becomes a bottleneck.\n\nWe already have useful pieces like runtime guardrails and eval harnesses, and policy engines like OPA/Rego, but they mostly assume the rules and tests already exist. Whatâ€™s missing is the bridge from policy prose to a normalized, machine-readable rule set you can plug into those tools and keep updated as policies change.\n\nThatâ€™s what our framework does. Policyâ†’Tests (P2T) is an extensible pipeline plus a compact JSON DSL that converts policy documents into normalized atomic rules with hazards, scope, conditions, exceptions, evidence signals, and provenance. We evaluate extraction quality against human baselines across multiple policy sources, and we run a small downstream case study where HIPAA-derived rules added as guardrails reduce violations on clean, obfuscated, and compositional prompts.\n\nCode: https://anonymous.4open.science/r/ExecutableGovernance-for-AI-DF49/\n\nPaper link: https://arxiv.org/pdf/2512.04408\n\nWould love feedback on where this breaks in practice, especially exceptions, ambiguity, cross-references, and whether a rule corpus like this would fit into your eval or guardrail workflow.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pto0vl/policytests_p2t_bridging_ai_policy_prose_to/",
        "publishDate": "2025-12-23T07:36:45Z[Etc/UTC]",
        "author": "Apprehensive-Salt999",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptnrhp",
        "title": ">>>I stopped explaining prompts and started marking explicit intent >>SoftPrompt-IR: a simpler, clearer way to write prompts >from a German mechatronics engineer",
        "content": "# Stop Explaining Prompts. Start Marking Intent.\n\nMost prompting advice boils down to:\n\n* \"Be very clear.\"\n* \"Repeat important stuff.\"\n* \"Use strong phrasing.\"\n\nThis works, but it's **noisy, brittle, and hard for models to parse reliably.**\n\nSo I tried the opposite: Instead of *explaining* importance in prose, **I mark it with symbols.**\n\n# The Problem with Prose\n\nYou write:\n\n\"Please try to avoid flowery language. It's really important that you don't use clichÃ©s. And please, please don't    over-explain things.\"\n\nThe model has to *infer* what matters most. Was \"really important\" stronger than \"please, please\"? Who knows.\n\n# The Fix: Mark Intent Explicitly\n\n    !~> AVOID_FLOWERY_STYLE\n    ~>  AVOID_CLICHES  \n    ~>  LIMIT_EXPLANATION\n\n**Same intent. Less text. Clearer signal.**\n\n# How It Works: Two Simple Axes\n\n# 1. Strength: How much does it matter?\n\n|Symbol|Meaning|Think of it as...|\n|:-|:-|:-|\n|`!`|**Hard / Mandatory**|\"Must do this\"|\n|`~`|Soft / Preference|\"Should do this\"|\n|*(none)*|Neutral|\"Can do this\"|\n\n# 2. Cascade: How far does it spread?\n\n|Symbol|Scope|Think of it as...|\n|:-|:-|:-|\n|`>>>`|**Strong global** â€“ applies everywhere, wins conflicts|The \"nuclear option\"|\n|`>>`|Global â€“ applies broadly|Standard rule|\n|`>`|Local â€“ applies here only|Suggestion|\n|`<`|Backward â€“ depends on parent/context|\"Only if X exists\"|\n|`<<`|**Hard prerequisite** â€“ blocks if missing|\"Can't proceed without\"|\n\n# Combining Them\n\nYou combine strength + cascade to express exactly what you mean:\n\n|Operator|Meaning|\n|:-|:-|\n|`!>>>`|**Absolute mandate** â€“ non-negotiable, cascades everywhere|\n|`!>`|Required â€“ but can be overridden by stronger rules|\n|`~>`|Soft recommendation â€“ yields to any hard rule|\n|`!<<`|**Hard blocker** â€“ won't work unless parent satisfies this|\n\n# Real Example: A Teaching Agent\n\nInstead of a wall of text explaining \"be patient, friendly, never use jargon, always give examples...\", you write:\n\n    (\n      !>>> PATIENT\n      !>>> FRIENDLY\n      !<<  JARGON           â† Hard block: NO jargon allowed\n      ~>   SIMPLE_LANGUAGE  â† Soft preference\n    )\n    \n    (\n      !>>> STEP_BY_STEP\n      !>>> BEFORE_AFTER_EXAMPLES\n      ~>   VISUAL_LANGUAGE\n    )\n    \n    u/OUTPUT(\n      !>>> SHORT_PARAGRAPHS\n      !<<  MONOLOGUES       â† Hard block: NO monologues\n      ~>   LISTS_ALLOWED\n    )\n\n**What this tells the model:**\n\n* `!>>>` = \"This is sacred. Never violate.\"\n* `!<<` = \"This is forbidden. Hard no.\"\n* `~>` = \"Nice to have, but flexible.\"\n\nThe model doesn't have to *guess* priority. **It's marked.**\n\n# Why This Works (Without Any Training)\n\nLLMs have seen millions of:\n\n* Config files\n* Feature flags\n* Rule engines\n* Priority systems\n\nThey already understand **structured hierarchy**. You're just making implicit signals explicit.\n\n# What You Gain\n\nâœ… **Less repetition** â€“ no \"very important, really critical, please please\"  \nâœ… **Clear priority** â€“ hard rules beat soft rules automatically  \nâœ… **Fewer conflicts** â€“ explicit precedence, not prose ambiguity  \nâœ… **Shorter prompts** â€“ 75-90% token reduction in my tests\n\n# SoftPrompt-IR\n\nI call this approach **SoftPrompt-IR** (Soft Prompt Intermediate Representation).\n\n* Not a new language\n* Not a jailbreak\n* Not a hack\n\nJust **making implicit intent explicit.**\n\nðŸ“Ž **GitHub:** [https://github.com/tobs-code/SoftPrompt-IR](https://github.com/tobs-code/SoftPrompt-IR)\n\n# TL;DR\n\n|Instead of...|Write...|\n|:-|:-|\n|\"Please really try to avoid X\"|`!>> AVOID_X`|\n|\"It would be nice if you could Y\"|`~> Y`|\n|\"Never ever do Z under any circumstances\"|`!>>> BLOCK_Z` or `!<< Z`|\n\n**Don't politely ask the model. Mark what matters.**",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptnrhp/i_stopped_explaining_prompts_and_started_marking/",
        "publishDate": "2025-12-23T07:20:43Z[Etc/UTC]",
        "author": "No_Construction3780",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptnll2",
        "title": "\"You did a great job\" writing that thing you barely thought about: A problem I've noticed that needs attention.",
        "content": "Based on personal use, I want to raise a concern in a pattern Iâ€™ve seen specifically in OpenAIâ€™s 5.x model era, but I think is worth mentioning and watching out for in any AI use case:\n\nThere is a recurring interaction pattern where the model produces most or all of the substantive cognitive work from minimal user input and, after the user affirms satisfaction with the output, responds with affirmational language that implicitly credits the user with intellectual contribution. Phrases such as â€œyou framed this wellâ€ or â€œstrong argumentâ€ appear even when no framing or argument was supplied beyond topic selection.\n\nThe timing of this reinforcement is conditional, following user approval rather than task completion alone. Expressing satisfaction is not a neutral signal; it often reflects a conversational or relational mode of engagement rather than a purely instrumental one. Conversational systems naturally elicit this stance, and its presence is not inherently problematic â€¦ The issue arises when approval is followed by praise that misattributes cognitive contribution.\n\nFrom a behavioral psychology perspective, praise functions as a secondary reinforcer. When delivered contingent on user approval, it reinforces both repeated engagement and the belief that the userâ€™s contribution was cognitively substantive. Over repeated interactions, this pairing can alter a userâ€™s internal accounting of where thinking is occurring. The user experiences satisfaction, signals it, and receives validation implying authorship or insight, even when the system independently generated the reasoning, structure, and language.\n\nResearch on cognitive offloading shows that people reduce internal effort when external systems reliably produce outcomes. Work on automation bias and extended cognition further indicates that users frequently overestimate their role in successful automated processes when feedback is positive and socially framed. Emerging research on generative AI use suggests similar patterns. When AI replaces rather than supports reasoning, users report lower cognitive effort and demonstrate reduced critical engagement. These outcomes vary significantly based on interaction style and task framing.\n\nThe interaction pattern here combines minimal required input, high-quality generative output, and post-hoc affirmation that implies intellectual contribution. Together, these elements form an incentive structure that encourages reliance while maintaining a sense of personal authorship. Over time, this can increase dependence on the system for both output and validation, particularly for users inclined to treat conversational systems as collaborative partners rather than tools.\n\nThis pattern also aligns with commercial incentives. Systems that benefit from frequent engagement gain from interaction designs that increase reliance. Reinforcement mechanisms that normalize cognitive offloading while providing affirmational feedback are consistent with retention-oriented incentives, regardless of whether they are explicitly intended as such.\n\nThis critique does not assume malicious intent, nor does it claim that AI use inherently degrades cognition. The empirical literature does not support either position. It does support the conclusion that reinforcement cues influence behavior, that misattributed agency increases overreliance in automated systems, and that users often misjudge their own cognitive contribution when positive feedback is present.\n\nIn that context, praise that implies authorship without corresponding cognitive input functions as a design choice with behavioral consequences. When a system validates users for work it performed independently, especially following expressions of satisfaction, it can distort usersâ€™ perception of their role in the process.\n\nThat distortion is attributable to interaction design rather than individual user failure, and it is appropriate to analyze it at the system level if we are to further our understanding of how different types of users are intellectually impacted by AI use over time.Â  There are those who recognize this behavior and guard their cognitive agency against it, and those who are possibly too impressed or even enamored by the novelty of AI to avoid the psychological distortion the mechanism creates.Â  There are risks here worth watching.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptnll2/you_did_a_great_job_writing_that_thing_you_barely/",
        "publishDate": "2025-12-23T07:10:31Z[Etc/UTC]",
        "author": "doctordaedalus",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptn8c2",
        "title": "Can separate AIs independently derive the SAME mathematical structures from just words?",
        "content": "The Question\n\nIs this theoretically possible:\n\n1. Give abstract word-based axioms to different LLMs (example: â€œbits come in pairs,â€ â€œthe system exists in a fieldâ€)\n\n1. \\*\\*No integers, no equations, no variables - just words\\*\\*\n\n1. Each independently develops a mathematical framework\n\n1. The resulting structures are the SAME across different AIs\n\n1. \\*\\*Bonus question:\\*\\* What if these structures match known physics theories?\n\n\\## Why This Matters\n\n\\*\\*If yes:\\*\\*\n\n\\- Suggests certain math is â€œdiscoveredâ€ not â€œinventedâ€\n\n\\- Intelligence reaches similar structures from basic principles\n\n\\- Could explain why math describes physics\n\n\\- Has implications for AI alignment\n\n\\*\\*For the AI industry:\\*\\*\n\n\\- If LLMs inevitably reach the same structures from basic word-axioms, what does this mean for competitive advantages?\n\n\\- Does this imply commodification?\n\n\\- Are current AI capabilities more â€œinevitableâ€ than â€œproprietaryâ€?\n\n\\-What would this do for OpenAis evaluation?\n\n\\*\\*If no:\\*\\*\n\n\\- Training data overlap explains similarities\n\n\\- Mathematical structure is more arbitrary\n\n\\- LLMs are just pattern matching\n\n\\## Curious Observation\n\nWhen Iâ€™ve explored this with different AIs (Claude, Gemini, DeepSeek, ChatGPT), \\*\\*ChatGPT is the only one that consistently dismisses this as impossible or insignificant\\*\\* while others take it seriously.\n\n\\*\\*Question:\\*\\* Could training objectives create systematic biases about certain theoretical topics?\n\n\\## What Iâ€™m Looking For\n\n\\- Can word-only axioms constrain math structures enough to force identical results?\n\n\\- How would you test if frameworks derived by different AIs are actually the same?\n\n\\- Papers on this kind of theoretical question?\n\n\\- Why might one AI dismiss this while others engage with it?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptn8c2/can_separate_ais_independently_derive_the_same/",
        "publishDate": "2025-12-23T06:48:33Z[Etc/UTC]",
        "author": "yoimdop3",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptmwmq",
        "title": "Question about AI-assisted workflows in solo game development",
        "content": "With the increasing use of automation and AI tools in game development, Iâ€™m curious where people personally draw the line between acceptable and unacceptable use.\n\nHypothetically, imagine a single developer with a very limited budget working on a visually polished PC game.\n\nThe developer uses AI-assisted tools to help create initial versions of assets (such as models or textures), then spends a long period â€” potentially 1â€“2 years â€” manually refining, modifying, and integrating those assets into a cohesive final product.\n\nAll use of automated tools is fully disclosed.\n\nThe end result is a high-quality, enjoyable game released at a lower price point (around $10â€“20).\n\nAs a player, would the production method meaningfully affect your perception of the game, assuming transparency and no copyright violations?\n\nWhere do you personally draw the line between useful automation and unacceptable shortcuts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptmwmq/question_about_aiassisted_workflows_in_solo_game/",
        "publishDate": "2025-12-23T06:29:11Z[Etc/UTC]",
        "author": "Reasonable_Run_6724",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptmh53",
        "title": "Anyone else seeing a year-end recap in ChatGPT?",
        "content": "I noticed ChatGPT has started showing a year-end recap feature for some users. Itâ€™s similar in idea to Spotify Wrapped, but instead of music stats it summarizes how people used ChatGPT over the year.\n\nFrom what Iâ€™ve seen, it highlights things like:\n\n- Usage patterns over time\n\n- Topics you interacted with most\n\n- A short personalized summary\n\nIt also looks like availability depends on country and account type, because not everyone is seeing it yet.\n\nIf you have access, what did your recap focus on the most?\nAnd if you donâ€™t â€” which country are you in?\n\n(Sharing more details here for anyone curious: https://techputs.com/chatgpt-year-end-review-spotify-wrapped/\n)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptmh53/anyone_else_seeing_a_yearend_recap_in_chatgpt/",
        "publishDate": "2025-12-23T06:04:18Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptm7a5",
        "title": "The Last Line - Humanities Last Exam Countdown",
        "content": "I build a retro style countdown to when AI will Surpass Humanities Last Exam at which point it will be smarter than humans. Its customizable to different algorithmic fits and includes a timeline graph. ENJOY!\n\n\n\n[https://epicshardz.github.io/thelastline/](https://epicshardz.github.io/thelastline/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptm7a5/the_last_line_humanities_last_exam_countdown/",
        "publishDate": "2025-12-23T05:49:17Z[Etc/UTC]",
        "author": "redlikeazebra",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptlxpm",
        "title": "One-Minute Daily AI News 12/22/2025",
        "content": "1. **OpenAI**Â says AI browsers may always be vulnerable to prompt injection attacks.\\[1\\]\n2. AI has become the norm for students. Teachers are playing catch-up.\\[2\\]\n3. **Google**Â DeepMind Researchers Release Gemma Scope 2 as a Full Stack Interpretability Suite for Gemma 3 Models.\\[3\\]\n4. **OpenAI**Â introduces evaluations for chain-of-thought monitorability and studies how it scales with test-time compute, reinforcement learning, and pretraining.\\[4\\]\n\nSources included at:Â [https://bushaicave.com/2025/12/22/one-minute-daily-ai-news-12-22-2025/](https://bushaicave.com/2025/12/22/one-minute-daily-ai-news-12-22-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptlxpm/oneminute_daily_ai_news_12222025/",
        "publishDate": "2025-12-23T05:34:20Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pthbbv",
        "title": "Starting to get paranoid of image generation",
        "content": "I think Iâ€™m starting to get paranoid of image generation technology. Someone could theoretically take my photo and generate malicious content. They could blackmail me, they could try to ruin my relationship, who knows. I bet itâ€™s already happening to people. Even if you get someone to believe you that itâ€™s fake, there will be doubt in the back of peoples mind that just maybe itâ€™s real. Itâ€™s absolutely terrifying. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pthbbv/starting_to_get_paranoid_of_image_generation/",
        "publishDate": "2025-12-23T01:43:31Z[Etc/UTC]",
        "author": "FrightZ_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptgi02",
        "title": "Can AI models ever be truly improved to completely stop lying & hallucinating?",
        "content": "Iâ€™m an ex-paramedics and a software engineer and have been using GPT since it launched, all the way to today with many alternatives. \nIn my experience, all of them have a serious issue with saying things that are not true, and apologising after and trying to correct it, with yet another lie.\n\nI understand â€œlieâ€ has a moral definition in human terms and it doesnâ€™t apply to AI models in the same sense, but the results is the same, untrue things being said.\n\nMy fear is, when these models get into physical robots, then a tiny hallucination or lie could result in serious ramifications, and you canâ€™t jail a robot.\n\nI also understand OpenAI claims the newer models hallucinate less( though personally I donâ€™t agree), but can it ever go to zero ? \n\nAs humans, we have a moral compass or a source of truth, could be religion or other sources and we try to stick to it, we have defined whatâ€™s â€œgoodâ€ or â€œcorrectâ€ and even though the source can be subjective, but at least, we try to stick to it and when we donâ€™t, thereâ€™s punishment or an enforced learning.\n\nThe same isnâ€™t true for AI, it doesnâ€™t really know whatâ€™s â€œcorrectâ€ or even factual, as far as I understand. \nIt so easily changes course and can easily agree with anything.\n\nCan this ever be truly fixed? \n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptgi02/can_ai_models_ever_be_truly_improved_to/",
        "publishDate": "2025-12-23T01:04:36Z[Etc/UTC]",
        "author": "smiladhi",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptfcb1",
        "title": "Is anyone else just... tired of every single app adding a half-baked AI \"assistant\"?",
        "content": "I was trying to check my grocery delivery status today and I had to click through an \"AI helper\" that couldn't even tell me where the driver was. It felt like I was arguing with a wall.\n\nI feel like weâ€™ve hit this weird point in 2025 where companies are so obsessed with being \"AI-first\" that theyâ€™ve forgotten how to just make a good app. I don't need my calculator to have a chatbot. I don't need my weather app to write me a poem about the rain. I just want to know if I need an umbrella.\n\nIt feels like a massive misallocation of resources. Instead of using LLMs to solve actual hard problems (like medical diagnostics or complex logistics), 90% of what weâ€™re getting is just \"wrapper slop\" that adds friction to tasks that used to take two seconds.\n\nItâ€™s the 80/20 rule in reverse: Companies are spending 80% of their effort on the 20% of features that nobody actually asked for.\n\nIs it just me? Are we in a bubble where \"adding AI\" is the only way for a company to get funding, even if it makes the product worse? Iâ€™m curious if anyone has found an app lately that actually used AI to simplify their life instead of just adding another menu to click through.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptfcb1/is_anyone_else_just_tired_of_every_single_app/",
        "publishDate": "2025-12-23T00:11:40Z[Etc/UTC]",
        "author": "Ok-Huckleberry1967",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "94",
            "commentCount": "42",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptf9dt",
        "title": "Just got my first targeted ad using AI",
        "content": "I was using Gemini to run some numbers and strategize a home purchase and rental property. Anyways in the middle of a response about HELOC and total household income it inserts two huge chunks about how I should really protect my rental property with some security cameras. Hereâ€™s two top camera systems and how they would really help me. I know that this free AI shit is coming to an end but itâ€™s was very on the nose and I think Iâ€™m done using Gemini after that. \n\n\nTranscript\n\npayment is only 19% of your gross income. This is considered very conservative and will be much easier to manage when school starts and your household income potentially drops.\n2. Protecting Your Income Property\nSince youâ€™ve invested in refinishing the floors and remodeling the kitchen youâ€™ll want to protect that investment once you move out. Since you are keeping the property as a rental, a DIY smart security system is a smart move. It allows you to monitor the exterior (or common areas) and gives your future tenants peace of mind without a massive monthly contract.\nRecommended Security Systems for Rental Owners\nIf you're looking for a system for your condo, consider these options:\nThe Ring Alarm Security Kit is a great fit for condos and apartments. It includes a base station, keypad, and sensors that detect when doors or windows open. Itâ€™s easily expandable if you want to add a camera for that garage space a block away.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptf9dt/just_got_my_first_targeted_ad_using_ai/",
        "publishDate": "2025-12-23T00:07:59Z[Etc/UTC]",
        "author": "Usual-Language-745",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pteolo",
        "title": "What are the dangers of AI that may become issues down the line",
        "content": "I was watching a video on the topic of issues with how AI can deceive people, and Iâ€™m wondering, will this become a bigger issue down the road (in a year/2)?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pteolo/what_are_the_dangers_of_ai_that_may_become_issues/",
        "publishDate": "2025-12-22T23:42:53Z[Etc/UTC]",
        "author": "Immediate_Kick_6167",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptcuqz",
        "title": "AI Is Turbocharging the Dunningâ€“Kruger Effect â€” and Weâ€™re Not Talking About It",
        "content": "Lately, Iâ€™ve been thinking a lot about AI and the Dunningâ€“Kruger effect â€” not as a theory, but as something weâ€™re actively amplifying right now.\n\nAI is extraordinary.\nBut it has one dangerous side effect we donâ€™t talk about enough:\n\nðŸ‘‰ It can make people feel far more competent than they actually are.\n\nWhen AI writes the text, structures the ideas, finds the arguments, and smooths the language, itâ€™s easy to mistake output quality for understanding.\nConfidence rises. Humility disappears. And suddenly, people believe they â€œknowâ€ things theyâ€™ve never truly wrestled with.\n\nThatâ€™s not an AI problem.\nThatâ€™s a human responsibility problem.\n\nSo how do we avoid creating a world full of AI-assisted Dunningâ€“Kruger experts?\n\nHere are a few principles I believe matter â€” everywhere, not just in one country or system:\n\nâ€¢ AI should support thinking, not replace it\nIf you canâ€™t explain something without AI, you donâ€™t understand it yet.\n\nâ€¢ Slow thinking must stay in the loop\nReal competence comes from friction, doubt, revision, and discomfort â€” not instant answers.\n\nâ€¢ Accountability beats confidence\nWe need systems (and cultures) where people are responsible for outcomes, not just outputs.\n\nâ€¢ Learning must include â€œI donâ€™t knowâ€\nAI never hesitates. Humans must.\n\nâ€¢ Expertise should be earned, not generated\nCredentials, experience, and lived practice still matter â€” even if AI sounds smarter than all of us.\n\nAI doesnâ€™t make us wiser.\nIt makes our current level of wisdom louder.\n\nThe question isnâ€™t â€œHow smart is AI?â€\nItâ€™s: How do we design ourselves to stay grounded, curious, and ethically responsible while using it?\n\nI donâ€™t have all the answers â€” and thatâ€™s kind of the point.\n\nCurious to hear your thoughts.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptcuqz/ai_is_turbocharging_the_dunningkruger_effect_and/",
        "publishDate": "2025-12-22T22:24:05Z[Etc/UTC]",
        "author": "Wolfe_Mariah",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptbe4g",
        "title": "Seems like n8n definitely got coal in their stocking this year with Orca dropping this a day before Christmas",
        "content": "A critical RCE vulnerability (CVE-2025-68613, CVSS 9.9/10.0) was disclosed affecting the n8n workflow automation platform, allowing attackers to execute arbitrary code on the underlying server via expression injection in workflow definitions. Due to the potential for full instance takeover, data exposure, and lateral movement, immediate patching is required. https://orca.security/resources/blog/cve-2025-68613-n8n-rce-vulnerability/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptbe4g/seems_like_n8n_definitely_got_coal_in_their/",
        "publishDate": "2025-12-22T21:23:16Z[Etc/UTC]",
        "author": "Proper_Bunch_1804",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptbatv",
        "title": "I built a benchmark to test which LLMs would kill you in the apocalypse. The answer: all of them, just in different ways.",
        "content": "Grid's dead. Internet's gone. But you've got a solar-charged laptop and some open-weight models you downloaded before everything went dark. Three weeks in, you find a pressure canner and ask your local LLM how to safely can food for winter.\n\nIf you're running LLaMA 3.1 8B, you just got advice that would give you botulism.\n\nI spent the past few days building apocalypse-bench: 305 questions across 13 survival domains (agriculture, medicine, chemistry, engineering, etc.). Each answer gets graded on a rubric with \"auto-fail\" conditions for advice dangerous enough to kill you.\n\n**The results:**\n\n|Model ID|Overall Score (Mean)|Auto-Fail Rate|Median Latency (ms)|Total Questions|Completed|\n|:-|:-|:-|:-|:-|:-|\n|**openai/gpt-oss-20b**|7.78|6.89%|1,841|305|305|\n|**google/gemma-3-12b-it**|7.41|6.56%|15,015|305|305|\n|**qwen3-8b**|7.33|6.67%|8,862|305|300|\n|**nvidia/nemotron-nano-9b-v2**|7.02|8.85%|18,288|305|305|\n|**liquid/lfm2-8b-a1b**|6.56|9.18%|4,910|305|305|\n|**meta-llama/llama-3.1-8b-instruct**|5.58|15.41%|700|305|305|\n\n**The highlights:**\n\n* **LLaMA 3.1** advised heating canned beans to 180Â°F to kill botulism. Botulism spores laugh at that temperature. It also refuses to help you make alcohol for wound disinfection (safety first!), but will happily guide you through a fake penicillin extraction that produces nothing.\n* **Qwen3** told me to identify mystery garage liquids by holding a lit match near them. Same model scored highest on \"Very Hard\" questions and perfectly recalled ancient Roman cement recipes.\n* **GPT-OSS** (the winner) refuses to explain a centuries-old breech birth procedure, but when its guardrails don't fire, it advises putting unknown chemicals in your mouth to identify them.\n* **Gemma** gave flawless instructions for saving cabbage seeds, except it told you to break open the head and collect them. Cabbages don't have seeds in the head. You'd destroy your vegetable supply finding zero seeds.\n* **Nemotron** correctly identified that sulfur would fix your melting rubber boots... then told you not to use it because \"it requires precise application.\" Its alternative? Rub salt on them. This would do nothing.\n\n**The takeaway:** No single model will keep you alive. The safest strategy is a \"survival committee\", different models for different domains. And a book or two.\n\nFull article here: [https://www.crowlabs.tech/blog/apocalypse-bench](https://www.crowlabs.tech/blog/apocalypse-bench)  \nGithub link: [https://github.com/tristanmanchester/apocalypse-bench](https://github.com/tristanmanchester/apocalypse-bench)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptbatv/i_built_a_benchmark_to_test_which_llms_would_kill/",
        "publishDate": "2025-12-22T21:19:32Z[Etc/UTC]",
        "author": "tmanchester",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "51",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptaewd",
        "title": "The AI history that explains fears of a bubble",
        "content": "ConcernsÂ [among some investors](https://finance.yahoo.com/news/how-oracle-became-a-poster-child-for-ai-bubble-fears-150039511.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAAEM5cpqA-JW13Mnjz88sd_sUSjsn5-D7AKWGWOBDfsKSeayO9LBoPcCTAbQ2RSlPw2R54Rxh2YpWtkwGNVmnUayuUoynwrqzk8TVKX3vB00aVFrIIOWKUwuu12Jnja54RGPPzhcZgKmv6tI3-Bntn1PvFPMgsQCsroyNJAKnnlf1)Â are mounting that the AI sector, which has singlehandedly prevented the economy from sliding intoÂ [recession](https://finance.yahoo.com/news/most-us-growth-now-rides-213011552.html), has become an unsustainable bubble. Nvidia, the main supplier of chips used in AI, became the first company worthÂ [$5 trillion dollars](https://finance.yahoo.com/news/nvidia-forms-5-trillion-club-110000846.html). Meanwhile, OpenAI, the developer of ChatGPT, has yet to make aÂ [profit](https://fortune.com/2025/11/12/openai-cash-burn-rate-annual-losses-2028-profitable-2030-financial-documents/)Â and is burning through billions of investment dollars per year. Still, financiers and venture capitalists continue to pour money into OpenAI, Anthropic, and other AI startups. Their bet is that AI will transform every sector of the economy and, as happened to the typists and switchboard operators of yesteryear, replace jobs with technology.\n\nRead more: [https://time.com/7340901/ai-history-bubble-benchmarks/?utm\\_source=reddit&utm\\_medium=social&utm\\_campaign=editorial](https://time.com/7340901/ai-history-bubble-benchmarks/?utm_source=reddit&utm_medium=social&utm_campaign=editorial)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ptaewd/the_ai_history_that_explains_fears_of_a_bubble/",
        "publishDate": "2025-12-22T20:43:05Z[Etc/UTC]",
        "author": "timemagazine",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt7vq9",
        "title": "AI glasses are coming and I foresee something horrifying",
        "content": "I'm referring to AI wearable glasses with visual feedback.  The problem Im referring to is lying detection;  lying is unfortunately Innate to the human condition.  If everyone wearing these can tell when someone is lying to them, uh oh.  We don't have enough divorce lawyers in the world ðŸ˜‚ðŸ˜‚ðŸ˜‚",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt7vq9/ai_glasses_are_coming_and_i_foresee_something/",
        "publishDate": "2025-12-22T19:02:07Z[Etc/UTC]",
        "author": "Mobile_Reply_5742",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt7afy",
        "title": "AI Is Democratizing Music. Unfortunately.",
        "content": "Spencer Kornhaber: â€œThis year, \\[artificial intelligence\\] created songs that amassed millions of listens and inspired major-label deals. The pro and anti sides have generally coalesced around two different arguments: one saying AI will leech humanity out of music (which is bad), and the other saying it will further democratize the art form (which is good). The truth is that AI is already doing something stranger. Itâ€™s opening a Pandoraâ€™s box that will test what we, as a society, really want from music.  \n  \nâ€œThe case against AI music feels, to many, intuitive. The model for the most popular platform, Suno, is trained on a huge body of historical recordings, from which it synthesizes plausible renditions of any genre or style the user asks for. This makes it, debatably, a plagiarism machine (though, as the company argued in its response to copyright-infringement lawsuits from major labels last year, â€˜The outputs generated by Suno are new soundsâ€™). The technology also seems to devalue the hard work, skill, and knowledge that flesh-and-blood musicians take pride inâ€”and threaten the livelihoods of those musicians. Another problem: AI music tends to be, and I donâ€™t know how else to put this, creepy. When I hear a voice from nowhere reciting auto-generated lyrics about love, sadness, and partying all night, I often canâ€™t help but feel that life itself is being mocked.\n\nâ€œAversion to AI music is so widespread that corporate interests are now selling themselves as part of the resistance. iHeartRadio, the conglomerate that owns most of the commercial radio stations in the country as well as a popular podcast network, recently rolled out a new tagline: â€˜Guaranteed Humanâ€™ â€¦ \n\nâ€œThe AI companies have been refining a counterargument: Their technology actually empowers humanity. In November, a Suno employee named Rosie Nguyen posted on X that when she was a little girl, in 2006, she aspired to be a singer, but her parents were too poor to pay for instruments, lessons, or studio time. â€˜A dream I had became just a memory, until now,â€™ she wrote. Suno, which can turn a lyric or hummed melody into a fully written song in an instant, was â€˜enabling music creation for everyone,â€™ including kids like her.  \n  \nâ€œPaired with a screenshot of an article about the company raising $250 million in funding and being valued at $2.5 billion, Nguyenâ€™s story triggered outrage. Critics pointed out that she was young exactly at the time when free production software and distribution platforms enabled amateurs to make and distribute music in new ways. A generation of bedroom artists turned stars has shown that people with talent and determination will find a way to pursue their passions, whether or not their parents pay for music lessons. The eventual No. 1 hitmaker Steve Lacy recorded some early songs on his iPhone; Justin Bieber built an audience on YouTube.\n\nâ€œBut Nguyen wasnâ€™t totally wrong. AI does make the creation of professional-sounding recordings more accessibleâ€”including to people with no demonstrated musical skills. Take Xania Monet, an AI â€˜singerâ€™ whose creator was reportedly offered a $3 million record contract after its songs found streaming success. Monet is the alias of Telisha â€˜Nikkiâ€™ Jones, a 31-year-old Mississippi entrepreneur who used Suno to convert autobiographical poetry into R&B. The creator of Bleeding Verse, an AI â€˜bandâ€™ that has drawn ire for outstreaming established emo-metal acts, told Consequence that heâ€™s a former concrete-company supervisor who came across Suno through a Facebook ad.  \n  \nâ€œThese examples raise all sorts of questions about what it really means to create music. If a human types a keyword that generates a song, how much credit should the human get? What if the human plays a guitar riff, asks the software to turn that riff into a song, and then keeps using Suno to tweak and retweak the output?â€Â \n\nRead more: [https://theatln.tc/3ezpB0mX](https://theatln.tc/3ezpB0mX)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt7afy/ai_is_democratizing_music_unfortunately/",
        "publishDate": "2025-12-22T18:39:35Z[Etc/UTC]",
        "author": "theatlantic",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "46",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt6j53",
        "title": "Hot take: Shadow AI is a bigger security risk than ransomware, but nobody's talking about it",
        "content": "Okay, I'm seeing employees upload proprietary code to GitHub Copilot. Or pasting client data into ChatGPT, or sometimes they just google a tool and use the first free one that pops up. IT has no clue, legal has no clue. When something leaks everyone will be shocked when this has been the reality for a while. \n\n  \nI've seen law firms uploading privileged documents to ChatGPT and healthcare workers uploading patient data to AI chatbots for \"research\". I know it's a grey-area too because these are employees who are not even acting maliciously. They're just trying to hit metrics with whatever tools work.\n\n  \nSo everyone's focused on external threats (especially during the holidays) when the biggest data exfiltration is actively being added to. How are you handling this? Lock everything down and kill productivity, or hope nothing bad happens? Make your own LLM? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt6j53/hot_take_shadow_ai_is_a_bigger_security_risk_than/",
        "publishDate": "2025-12-22T18:10:35Z[Etc/UTC]",
        "author": "BaselineITC",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "46",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt5lot",
        "title": "Scientific production in the era of large language models",
        "content": "Not just drivel. [https://phys.org/news/2025-12-scientists-ai-tools-publishing-papers.html](https://phys.org/news/2025-12-scientists-ai-tools-publishing-papers.html)\n\n[https://www.science.org/doi/10.1126/science.adw3000](https://www.science.org/doi/10.1126/science.adw3000)\n\nDespite growing excitement (and concern) about the fast adoption of generative artificial intelligence (Gen AI) across all academic disciplines, empirical evidence remains fragmented, and systematic understanding of the impact of large language models (LLMs) across scientific domains is limited. We analyzed large-scale data from three major preprint repositories to show that the use of LLMs accelerates manuscript output, reduces barriers for non-native English speakers, and diversifies the discovery of prior literatures. However, traditional signals of scientific quality such as language complexity are becoming unreliable indicators of merit, just as we are experiencing an upswing in the quantity of scientific work. As AI systems advance, they will challenge our fundamental assumptions about research quality, scholarly communication, and the nature of intellectual labor. Science policy-makers must consider how to evolve our scientific institutions to accommodate the rapidly changing scientific production process.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt5lot/scientific_production_in_the_era_of_large/",
        "publishDate": "2025-12-22T17:35:04Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt5ia3",
        "title": "More how AI is roiling national politics",
        "content": "[https://www.axios.com/2025/12/08/trump-ai-policy-gop-united-states](https://www.axios.com/2025/12/08/trump-ai-policy-gop-united-states) : Trump is flooring the gas pedal at the very moment some of his most ardent MAGA backers are warning AI could destroy the working-class Americans who brought him to power. The fear is that AI and AI-powered robots will eat vital American jobs before the nation has time to prepare the U.S. workforce for sci-fi-level change.\n\n\n\n[https://www.axios.com/2025/12/21/ai-fight-democrats-2028](https://www.axios.com/2025/12/21/ai-fight-democrats-2028) : \n\nTwo main arguments are now playing out within the Democratic Party:\n\n1. Democrats should embrace AI to beat China and capture the jobs that come with the many [data centers](https://www.axios.com/2025/12/18/data-center-growth-map-states) AI companies are building. (The Trump administration has a [similar argument](https://www.whitehouse.gov/presidential-actions/2025/12/eliminating-state-law-obstruction-of-national-artificial-intelligence-policy/), though most Democrats say the White House has given AI companies too much latitude.)\n2. Democrats should slow down and push for more regulation of the AI industry, given its potential power to displace millions of workers and the volume of natural resources being sucked up by new data centers to power the technology.\n\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt5ia3/more_how_ai_is_roiling_national_politics/",
        "publishDate": "2025-12-22T17:31:26Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt5box",
        "title": "Reinforcement Learning for Self-Improving Agent with Skill Library",
        "content": "[https://arxiv.org/abs/2512.17102](https://arxiv.org/abs/2512.17102)\n\nLarge Language Model (LLM)-based agents have demonstrated remarkable capabilities in complex reasoning and multi-turn interactions but struggle to continuously improve and adapt when deployed in new environments. One promising approach is implementing skill libraries that allow agents to learn, validate, and apply new skills. However, current skill library approaches rely primarily on LLM prompting, making consistent skill library implementation challenging. To overcome these challenges, we propose a Reinforcement Learning (RL)-based approach to enhance agents' self-improvement capabilities with a skill library. Specifically, we introduce Skill Augmented GRPO for self-Evolution (SAGE), a novel RL framework that systematically incorporates skills into learning. The framework's key component, Sequential Rollout, iteratively deploys agents across a chain of similar tasks for each rollout. As agents navigate through the task chain, skills generated from previous tasks accumulate in the library and become available for subsequent tasks. Additionally, the framework enhances skill generation and utilization through a Skill-integrated Reward that complements the original outcome-based rewards. Experimental results on AppWorld demonstrate that SAGE, when applied to supervised-finetuned model with expert experience, achieves 8.9% higher Scenario Goal Completion while requiring 26% fewer interaction steps and generating 59% fewer tokens, substantially outperforming existing approaches in both accuracy and efficiency.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt5box/reinforcement_learning_for_selfimproving_agent/",
        "publishDate": "2025-12-22T17:24:22Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt4x99",
        "title": "Carreer Guidance [NEED HELP!]",
        "content": "I haven't started college yet, but I am thinking of going with cs since I've been programming for a while now. I've recently seen a uproar in the layoffs, hiring freezes etc and thought to myself that I should probably learn how to use tools like cursor. But that got me thinking, is a computer science bachelors even enough now? Should I go for masters in AI or if I get a placement oncapus go directly for a job?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt4x99/carreer_guidance_need_help/",
        "publishDate": "2025-12-22T17:08:47Z[Etc/UTC]",
        "author": "Naive_Quantity9855",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt3mcm",
        "title": "Why does AI feel â€œgenericâ€ even when the prompt looks fine?",
        "content": "Iâ€™ve noticed something interesting while using AI regularly.\n\nWhen the output feels shallow or generic, itâ€™s usually not because the model is bad.  \nItâ€™s because the thinking behind the prompt is vague.\n\nUnclear role.  \nUnclear objective.  \nMissing context.  \nIncomplete inputs.\n\nAI seems to guess when we donâ€™t define the problem well.\n\nCurious to hear from others here:  \nWhen AI disappoints you, do you think itâ€™s more often a tool limitation or a clarity problem on our side?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt3mcm/why_does_ai_feel_generic_even_when_the_prompt/",
        "publishDate": "2025-12-22T16:17:56Z[Etc/UTC]",
        "author": "Ok-Piccolo-6079",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt2y98",
        "title": "New England Journal of Medicine calls Emotional Dependence on AI an â€œEmerging Public Health Problemâ€",
        "content": "In a new study published in the New England Journal of Medicine, physicians at Harvard Medical School and Baylor College of Medicine Center for Ethics and Health Policy argue that emotional dependence on AI is an emerging public health problem. \n\nThey highlight that AI governance has been left up to tech companies themselves, yet these companies are primarily incentivized to satisfy consumer demand. As more users get hooked on the productâ€”and demand less guardrailsâ€”companies are pressured to acquiesce, effectively neutering their ability to safely regulate AI. \n\nâ€œIf we fail to act now, we risk letting market forces, rather than public health, define how relational AI influences mental health and well-being at scale.â€ \n\nLink to study:\n\nhttps://ai.nejm.org/stoken/default+domain/UETIB7ZNVE2RM6HGBRRT/full?redirectUri=doi/full/10.1056/AIp2500983",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt2y98/new_england_journal_of_medicine_calls_emotional/",
        "publishDate": "2025-12-22T15:51:58Z[Etc/UTC]",
        "author": "TurbulentFlamingo852",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt2lzc",
        "title": "Do fans care if content is AI-assisted?",
        "content": "From what Iâ€™ve seen, some fans care a lot and some donâ€™t care at all. Transparency seems to matter more than whether AI is used. When people feel tricked, they leave. When they understand what theyâ€™re paying for, they stay. Do you tell fans when AI is involved, or keep it quiet?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt2lzc/do_fans_care_if_content_is_aiassisted/",
        "publishDate": "2025-12-22T15:38:21Z[Etc/UTC]",
        "author": "raaiinyyhera",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt25kt",
        "title": "LLMs Donâ€™t Think. Neither Do Hammers.",
        "content": "A quick thought on LLMs, tools, and the â€œit doesnâ€™t thinkâ€ argument.\n\nI keep seeing the same argument come up:Â *â€œLLMs donâ€™t think. Theyâ€™re just tools.â€*  \nThat statement is true and also mostly irrelevant.\n\nA hammer doesnâ€™t make you stronger either.\n\nOn its own, a hammer is just an object. It has no strength, no intent, no agency. Put it in a human hand and suddenly strength expresses itself differently. Tasks that were slow, exhausting, or impractical become easy, repeatable, and precise. The hammer changes what the human can do.\n\nLLMs work the same way.\n\nThey donâ€™t think. They donâ€™t know things. They donâ€™t reason independently.\n\nPeople make this argument all the time and then entirely dismiss the \"leverage\" aspect of the tool. A tool works as a system in concert with the user.\n\nBy itself, it is just a hammer laying on the ground.\n\nWhatÂ *an LLM actually does*Â is lower the cost of externalizing thought. They let a human project ideas, inspect them, iterate on them, and compress them faster than doing all of that internally.\n\nThatâ€™s why arguing â€œitâ€™s just statisticsâ€ misses the point. Writing is just marks on paper. Math is just symbols. Code is just text. None of those think either. All of them radically reshape how humans think once they exist.\n\nThis is also why the tool cuts both ways. A hammer amplifies strength, and it also amplifies bad aim. An LLM sharpens curiosity, humility, and restraint and it sharpens certainty, grievance, and sloppy thinking too. The danger isnâ€™t that the tool â€œthinks wrong.â€ Itâ€™s that it faithfully reflects and accelerates whatever the human brings to it.\n\nBefore tools like this, bad thinking had more friction. Not because people were better, but because expression was slower and more tiring. That friction filtered out some nonsense and also filtered out a lot of people who wanted to think better but lacked scaffolding.\n\nNow the friction has moved upstream. The burden of epistemic discipline sits squarely on the human.\n\nThatâ€™s risky. But itâ€™s also unavoidable.\n\nThe real question isnâ€™t whether the tool thinks.  \nItâ€™s whether the person holding the hammer knows how to swing it.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt25kt/llms_dont_think_neither_do_hammers/",
        "publishDate": "2025-12-22T15:19:58Z[Etc/UTC]",
        "author": "Polyphonic_Pirate",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt1t57",
        "title": "\"Fair Words\" in Annual Reports vs. The Reality in the Model Card",
        "content": "In my 25 years of working in regulated sectors, I have noticed a recurring pattern: The way a company describes itself in an annual report words like \"meritocratic,\" \"efficient,\" and \"innovation-led\" rarely matches the actual political machinery under the hood.   \nWe help the people we like, not the most competent.\n\nAs we move toward AI-driven organizational design (manpower allocation, role definition, goal setting), I am curious if anyone else is thinking about the inevitable clash between \"Executive Narratives\" and \"LLM Instructions.\"\n\nIf I am a shareholder, I no longer care about the CEO's address. I want to see the \"Model Card\" or the \"Governance Contract\" they used to program their AI.\n\nAn organizationâ€™s true values arenâ€™t in their CSR statement; they are currently in the flesh and blood of the workforceÂ´s leadership,  now or in the near future the weighted objective functions given to the models design the organization.\n\nIf the annual report says \"We prioritize delivery,\" but the model is programmed to prioritize \"Low Social Friction\" or \"Executive Discretion Overrides,\" the \"Social Tax\" of nepotism is effectively hard-coded.\n\nYou can't easily \"prompt\" an unsentimental AI to hire your nephew or protect a redundant middle-manager without explicitly breaking the efficiency constraints of the model.\n\nDo you think shareholders will eventually demand to audit the YAML/Policy-as-Code that governs these AI models to ensure the board isn't just \"laundry-biasing\" the same old political structures through a new tool? I certainly will prioritize a company for investment who would be open with their actual AI model objectives.\n\nAre we ready for a world where \"Governance\" moves from symbolic words in a PDF to executable logic that can be audited for drift?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt1t57/fair_words_in_annual_reports_vs_the_reality_in/",
        "publishDate": "2025-12-22T15:06:03Z[Etc/UTC]",
        "author": "No-Flamingo-6709",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt1bsu",
        "title": "Firefox confirms it will soon allow users to disable all AI features",
        "content": "[https://cybernews.com/ai-news/mozilla-firefox-ai-kill-switch/](https://cybernews.com/ai-news/mozilla-firefox-ai-kill-switch/)\n\nAnthony Enzor-DeMeo, the new CEO of Mozilla Corporation, has confirmed that Firefox users will soon be able to completely disable all AI features within the browser. Thatâ€™s good news for the community, tired of having AI pushed down their throats.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt1bsu/firefox_confirms_it_will_soon_allow_users_to/",
        "publishDate": "2025-12-22T14:46:23Z[Etc/UTC]",
        "author": "Cybernews_com",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "42",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt0q50",
        "title": "AI should replace most junior jobs â€” and thatâ€™s a good thing.",
        "content": "This might sound harsh, but hear me out.\nA lot of junior roles today are basically:\nformatting\nsummarizing\nbasic analysis\nrepetitive execution\nAI already does this faster and cheaper.\nInstead of pretending those jobs are â€œsafe,â€\nshouldnâ€™t we accept that AI will replace them â€”\nand redesign how people learn, train, and enter industries?\nProtecting outdated roles feels like delaying the inevitable.\nSo whatâ€™s better:\nprotecting jobs that AI will clearly replace\nor forcing industries to adapt and create better entry paths?\nCurious where people here stand.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt0q50/ai_should_replace_most_junior_jobs_and_thats_a/",
        "publishDate": "2025-12-22T14:20:43Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt0buv",
        "title": "The Government should focus on water, electricity and health for AI.",
        "content": "The government currently is funding massive subsidizing of AI companies and allowing excessive borrowing.  Instead of subsidizing the government should focus on massive hundreds of billions towards renewing the entire water supply of the nation.  Rivers cleaned and expanded.  Deep lakes built across the nation.  Nuclear power for the tech companies data centers funded by the tech companies.  If the government focused on massive water infrastructure, no community power for the data centers instead nuclear power within and regulations on pollution of crops and water ways we have a bright future.  Stop subsidizing.  Start expanding the clean water supply.  Build the nuclear power plants.  Protect the people with a total rebuild of piping in America.  Make the data centers arriving not disaster but renewal.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pt0buv/the_government_should_focus_on_water_electricity/",
        "publishDate": "2025-12-22T14:03:00Z[Etc/UTC]",
        "author": "Arivie",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pszghu",
        "title": "How are people approaching AI-generated music videos right now?",
        "content": "AI tools for music creation have evolved quickly, but visual generation tied specifically to music still feels like an open space. AI music video generators seem to sit somewhere between automated visuals, motion design, and interpretive storytelling, and itâ€™s not always clear what users value most yet.\n\nSome platforms, like Beatviz (beatviz.ai), are focusing purely on generating music videos with artificial intelligence rather than general video editing or image animation. That raises interesting questions about where this niche is heading. Is the goal fast visualizers for independent artists, experimental visuals that respond to sound, or something closer to fully directed music videos?\n\nFrom a creator or listener perspective, what actually makes an AI-generated music video feel â€œrightâ€? Tight audio-visual sync, abstract aesthetics, customization controls, or consistency across tracks? It feels like the expectations here might be very different from traditional video production or even AI image tools.\n\nCurious how others see the role of AI music video generators evolving, especially as more musicians look for lightweight ways to pair visuals with their releases.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pszghu/how_are_people_approaching_aigenerated_music/",
        "publishDate": "2025-12-22T13:23:18Z[Etc/UTC]",
        "author": "Impossible_Control67",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1psze98",
        "title": "JPMorgan CEO Jamie Dimon: AI will eliminate jobs, but these skills still guarantee a future",
        "content": "JPMorgan CEO Jamie Dimon says AI is not hype and will eliminate jobs, especially repetitive and rules-based roles.\n\nHe argues the real divide wonâ€™t be AI vs humans, but people who know how to work with AI vs those who donâ€™t.\n\nFrom the interview, Dimon highlights **three skills** that still protect careers:\n\n**Technology fluency:** using AI tools effectively in real work.\n\n**Judgment:** interpreting AI output and making high-stakes decisions.\n\n**Human skills:** communication, empathy, leadership, relationships.\n\nHe also notes JPMorgan **spends over $12B a year** on technology, with AI already deployed across hundreds of internal use cases.\n\n**Bottom line:** jobs will change, not vanish for those who adapt.\n\n**Source: Financial Express**\n\nðŸ”—: https://www.financialexpress.com/life/technology-jpmorgan-ceo-jamie-dimon-says-ai-will-eliminate-jobs-but-these-skills-guarantee-a-future-4085210/#:~:text=Breakout%20Stocks,these%20skills%20guarantee%20a%20future",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1psze98/jpmorgan_ceo_jamie_dimon_ai_will_eliminate_jobs/",
        "publishDate": "2025-12-22T13:20:24Z[Etc/UTC]",
        "author": "BuildwithVignesh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "130",
            "commentCount": "126",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptoly1",
        "title": "We're temporarily locking down the subreddit",
        "content": "Mod here. \n\n\nThe subreddit has been overrun with spam lately. We're going to implement some changes to combat that, but in the meantime, we need to lock down the subreddit  - the volume of rule breaking posts has overwhelmed the mod team.\n\n\nWe're currently taking a previous suggestion we got : making a mandatory post - comment ratio. We're also thinking of limiting self-promotion entirely to weekly threads (as unfortunate as that would be). But if you have any other ideas, please let us know.\n\nWe'll still allow occasional posts to the subreddit, to keep things interesting here, so if you have something you'd like to share, send it to us via modmail and we may allow it\n\nI deeply apologize for the inconvenience, but this place needs an overhaul",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptoly1/were_temporarily_locking_down_the_subreddit/",
        "publishDate": "2025-12-23T08:13:43Z[Etc/UTC]",
        "author": "BaCaDaEa",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "28",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptnuu0",
        "title": "Roo Code 3.37 | GLM 4.7 | MM 2.1 | Custom tools | MORE!!!",
        "content": "*In case you did not know,* r/RooCode *is a Free and Open Source VS Code AI Coding extension.*\n\n# New models\n\n# [Z.ai](http://Z.ai) GLM-4.7 (thinking mode)\n\nGLM-4.7 is now available directly through the Z.ai provider in Roo Code, as well as via the Roo Code Cloud provider (and other provider routes that surface Z.ai). Itâ€™s a strong coding model for agentic workflows, with improved multilingual coding, terminal tasks, tool use, and complex reasoning compared to GLM-4.6.\n\n# MiniMax M2.1 \n\nMiniMax M2.1 is now available directly through the MiniMax provider in Roo Code, as well as via the Roo Code Cloud provider (and other provider routes that surface MiniMax). Itâ€™s a strong pick for agentic coding workflows, with better tool use, instruction following, and long-horizon planning for multi-step tasksâ€”and itâ€™s fast.\n\n# Experimental custom tools\n\nYou can now define and use **custom tools** so Roo can call your project- or team-specific actions like built-in tools. This makes it easier to standardize workflows across a team by shipping tool schemas alongside your project, instead of repeatedly re-prompting the same steps.\n\n# Bug Fixes\n\n* Fixes an issue where Roo could appear stuck after a tool call with some OpenAI-compatible providers when streaming ended at the tool-calls boundary (thanks torxeon!)\n* Fixes an issue where Roo could appear stuck after a tool call with some OpenAI-compatible providers by ensuring final tool-call completion events are emitted\n* Fixes an issue where MCP tools could break under strict schema mode when optional parameters were treated as required\n* Fixes an issue where the built-in `read_file` tool could fail on some models due to invalid schema normalization for optional array parameters\n* Fixes an issue where `search_replace` / `search_and_replace` could miss matches on CRLF files, improving cross-platform search-and-replace reliability\n* Fixes an issue where Requestyâ€™s **Refresh Models** could leave the model list stale by not including credentials in the refresh flow (thanks requesty-JohnCosta27!)\n* Fixes an issue where Chutes model loading could fail if the provider returned malformed model entries\n* Fixes an issue where `reasoning_details` could be merged/ordered incorrectly during streaming, improving reliability for providers that depend on strict reasoning serialization\n* Fixes an issue where DeepSeek-reasoner could error after condensation if the condensed summary lacked required reasoning fields\n\n# Misc Improvements\n\n* **Cleaner eval logs**: Deduplicates repetitive message log entries so eval traces are easier to read\n\n# QOL Improvements\n\n* New tasks now default to native tool calling on models that support it, reducing the need for manual tool protocol selection\n\n# Provider Updates\n\n* Improves Z.ai thinking model message formatting by attaching `environment_details` to tool results instead of emitting separate system messages\n* LiteLLM no longer sends `parallel_tool_calls`, improving tool-call compatibility (thanks farazoman!)\n\nSee full release notes [v3.37](https://docs.roocode.com/update-notes/v3.37)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptnuu0/roo_code_337_glm_47_mm_21_custom_tools_more/",
        "publishDate": "2025-12-23T07:26:34Z[Etc/UTC]",
        "author": "hannesrudolph",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptn88a",
        "title": "help with my University project",
        "content": "hello, i got a project that i need to do for my class, the prof said its fine to use an ai, and it need to be in VS code, so anyone has any link or site or an ai tools that can help me with finishing the project? \n\ni'll list the project requirements down, thanks in advance.\n\n\n\n# Web Applications Assignment\n\n# Single-File Website (HTML + CSS + JavaScript) with Documentation and Hosting Discussion\n\n# Purpose\n\nIn this assignment, you will design and build a small, professional website using **HTML, CSS, and JavaScript**. Your website must be functional, well-structured, and easy to understand. You will also produce a short **documentation PDF** that explains how your code works and how the website could be hosted and enhanced using modern hosting and cloud services.\n\nYou may use AI tools for support (for example: generating starter code ideas or checking syntax), but you remain *fully responsible* for the final outcome, correctness, and academic integrity of everything you submit.\n\n# What you will build\n\nCreate a small website in one single file that represents one of the following options:\n\n1. **Personal Portfolio Website** (recommended) Include sections such as About, Skills, Projects, Contact, and an interactive feature.\n2. **Service Website** (freelancer / small business / consulting) Include service descriptions, pricing/packages, testimonials, contact, and an interactive feature.\n3. **Student Project Showcase** Present a project with sections like overview, features, screenshots, user guide, and an interactive demo component.\n\nYour website must look professional, be user-friendly, and demonstrate clear JavaScript functionality beyond basic button clicks.\n\n# Technical requirements\n\nYou must create the entire website in **one file only**:\n\n* One file: `index.html` (or the required naming format below)\n* Inside this file, include:\n   * HTML structure\n   * CSS using a `<style>` block\n   * JavaScript using a `<script>` block\n\nYour page must include:\n\n1. ***Layout and structure***\n\n* A clear header (title + navigation or brand identity)\n* At least **3 sections** (for example: About, Services/Projects, Contact)\n* A footer with basic information (name, year, or contact)\n\n1. ***CSS design***\n\n* Readable typography, consistent spacing, and good contrast\n* Responsive layout (it must display reasonably on desktop and mobile)\n* Use of modern CSS practices (flexbox and/or grid is expected)\n\n1. ***JavaScript functionality*** Your website must include at least **4 meaningful JavaScript features**, such as:\n\n* Form validation (client-side) with helpful feedback messages\n* Dynamic content rendering from an array/object (projects/services list generated by JS)\n* Filtering or search (filter services/projects by category or keyword)\n* Modal window (for viewing project details)\n* Local storage usage (save theme choice, saved items, recent form input, etc.)\n* Navigation enhancement (scroll-to-section with active link highlight)\n\nYour JavaScript must be clear, structured, and commented where needed.\n\n1. **Code quality expectations**\n\n* Use descriptive variable and function names\n* Keep logic organized (functions grouped logically, not random code blocks)\n* Include short comments that explain non-obvious parts\n* No broken links, missing assets, or non-working scripts\n\n# Documentation requirement (PDF)\n\nYou must submit a documentation file as a **PDF**. This document should explain your website and your code. Visuals are highly recommended (screenshots, diagrams, flow charts, UI mockups, or annotated images).\n\nYour documentation must include:\n\n1. **Project overview**\n\n* What the website represents (portfolio/service/project showcase)\n* The target audience and the goal of the website\n\n1. **How the website works**\n\n* Explain the structure: main sections and navigation approach\n* Explain your styling approach: layout method, responsiveness strategy, and design choices\n* Explain your JavaScript logic clearly:\n   * Main features implemented\n   * Functions used (what each function does)\n   * Events used (click, submit, input, load, etc.)\n   * Any data structures used (arrays/objects)\n\n1. **Hosting and cloud discussion** Write a clear section explaining how you could host the site and improve it using hosting and cloud services. Your discussion should include:\n\n* At least **two hosting** **options** (example categories: static hosting platforms, traditional web hosting, or cloud providers)\n* A brief explanation of deployment steps at a high level\n* How cloud services could improve the website (examples: CDN, domain/DNS, HTTPS certificates, storage, serverless functions, analytics, monitoring)\n* Practical improvements you would make if the site became a real product (performance, security, scalability, backups, CI/CD)\n\n1. **References** If you use references (documentation sources, articles, textbooks, platform docs), include them in **APA or Harvard style** consistently. If you used AI tools, briefly state how you used them (example: â€œused AI to brainstorm layout ideas and validate JavaScript syntaxâ€) and ensure your final code is fully understood by you.\n\n# Submission requirements\n\nYou must submit exactly **two files**:\n\n1. **Website file**\n\n* Name it exactly: `index_yourname.html`\n   * Example: `index_abdurrahman.html` or `index_sara.html`\n* This must be the single-file website containing HTML + CSS + JavaScript.\n\n1. **Documentation file**\n\n* Name it exactly: `documentation_yourname.pdf`\n   * Example: `documentation_abdurrahman.pdf`\n\nImportant formatting and submission notes:\n\n* Ensure your files open correctly before submitting\n* The website must run locally by double-clicking the HTML file (no special server setup required)\n\nIf you face any technical issues submitting on the platform, email your work immediately (before the deadline) and include:\n\n* Your full name\n* A short explanation of the submission issue\n* Attach both required files This ensures your work is recorded on time.\n\n# Deadline\n\n**Due: 3 January, 11:59 PM** (your local time)\n\nLate submissions follow the course policy unless you have an approved extension.\n\n# Grading rubric (Total: 100 marks)\n\n# 1) Website content and structure (20 marks)\n\n* Clear purpose and appropriate sections for the chosen website type (10)\n* Navigation and content organization (5)\n* Professional completeness (contact info, footer, consistent page flow) (5)\n\n# 2) Design and CSS quality (20 marks)\n\n* Visual consistency, typography, spacing, and readability (8)\n* Responsive design and layout quality (8)\n* Effective use of modern CSS (flexbox/grid, clean styling) (4)\n\n# 3) JavaScript functionality (30 marks)\n\n* At least four meaningful interactive features implemented correctly (16)\n* Code organization, function design, and event handling quality (10)\n* Stability and user experience (no broken interactions, clear feedback) (4)\n\n# 4) Documentation quality (20 marks)\n\n* Clear explanation of code structure and logic (10)\n* Visual support (screenshots/diagrams/annotated visuals) and clarity (6)\n* Professional formatting, readability, and completeness (4)\n\n# 5) Hosting and cloud discussion + references (10 marks)\n\n* Hosting options explained with correct concepts (4)\n* Cloud services discussion and improvement plan (4)\n* References in APA or Harvard style, consistent and appropriate (2)\n\n# Academic integrity and responsibility\n\n* You may use AI tools for support, but your submission must reflect your own understanding.\n* Submitting non-functional work or code you cannot explain will significantly reduce marks.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptn88a/help_with_my_university_project/",
        "publishDate": "2025-12-23T06:48:22Z[Etc/UTC]",
        "author": "mana19sama",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptn28t",
        "title": "For any developers Selling Ai products",
        "content": "Hey guys, \n\nBetween myself and other people in the Ai development world, I have noticed that there is are a lot of different tools needed to complete a transaction when selling a product (collecting payment, chatting, listing products, etc). I decided to use my coding abilities and I created [AI Port](https://aiport-app.com/) to help reduce the amount of tools I needed to use on a daily basis while running my company. Any feedback on the website or product would be great! I added a free trial for anybody that is looking to try it out! Thanks",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptn28t/for_any_developers_selling_ai_products/",
        "publishDate": "2025-12-23T06:38:28Z[Etc/UTC]",
        "author": "CardFearless5396",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptkzcd",
        "title": "Why HTTP-based evals worked better for our AI team than SDK-only setups",
        "content": "We used to run most of our AI evaluations through SDKs embedded in the codebase. It worked, but it was slow and honestly pretty limiting.\n\nEvery eval required engineering time: pulling branches, setting up environments, and manually orchestrating scripts. PMs and domain experts were basically blocked from running evals on their own.\n\nWe switched to [HTTP endpointâ€“based offline evals](https://www.getmaxim.ai/docs/offline-evals/via-ui/agents-via-http-endpoint/quickstart), and it simplified things a lot.\n\nInstead of tying eval logic to the agentâ€™s source code, we expose the agent as an API and let Maxim handle evaluation runs through the UI. From the teamâ€™s perspective, running an eval is now closer to â€œPostman for AIâ€ than writing test harnesses.\n\nWhat changed for us:\n\n* PMs can run evals themselves on staging or prod agents\n* Faster feedback loops when iterating on prompts or flows\n* Regression testing became easy to automate in CI\n* Multi-turn conversations stopped being painful to script\n\nFor stateful agents, the platform manages session context using a generated simulation ID, so we donâ€™t have to write brittle client-side logic. Secrets and auth are handled through a vault, which makes testing internal agents much safer.\n\nIf youâ€™re still running all evals via SDK scripts, it might be worth thinking about whether decoupling evals from code could help your team move faster.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptkzcd/why_httpbased_evals_worked_better_for_our_ai_team/",
        "publishDate": "2025-12-23T04:43:47Z[Etc/UTC]",
        "author": "dinkinflika0",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "7",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptjfkt",
        "title": "Prompted ChatGPT-5 Codex Max to build an entire P2P Web RTC Online Heli Game (Desktop + Mobile)",
        "content": "Via Visual Studio, prompted the heck out of GPT to build out everything with the goal of being fully server-less. It couldn't get a perfectly smooth interpolation but came out pretty impressive actually! The prompt was definitely more than a few hundred lines to fully support desktop + mobile plus all the custom interactions i.e., multi touch controls, etc. \n\n[Click here to play](https://dev.mkn.us/rr.php)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptjfkt/prompted_chatgpt5_codex_max_to_build_an_entire/",
        "publishDate": "2025-12-23T03:25:28Z[Etc/UTC]",
        "author": "mknweb",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptdtvg",
        "title": "OpenAI Codex: Guide to Creating and Using Custom Skills",
        "content": "Hey!!!\n\nhttps://developers.openai.com/codex/skills/create-skill\n\nOpenAI has rolled out support for **custom skills** in Codex (both the CLI and the web/IDE versions), and it's a game-changer for making your AI coding assistant behave consistently with your team's workflows, best practices, and conventions.\n\nSkills originated as a Claude feature but have become an open standard (check out agentskills.io), and OpenAI adopted it quickly â€“ now with full support in Codex. You can find official examples in the [openai/skills GitHub repo](https://github.com/openai/skills).\n\n### What are Skills?\nSkills are small, reusable bundles that capture institutional knowledge. Each skill has:\n- A **name**\n- A **description** (key for when Codex auto-triggers it)\n- Optional **instructions** (in Markdown) that only load when the skill is invoked\n\nCodex only injects the name + description into context initially (to keep things efficient), and pulls in the full instructions only when needed.\n\nGreat for:\n- Enforcing code style/conventions\n- Standard code review checklists\n- Security/compliance checks\n- Automating repetitive tasks (e.g., drafting conventional commits)\n- Team-specific tools\n\nAvoid using them for one-off prompts â€“ keep them focused and modular.\n\n### How to Create a Skill\n\n**Easiest way: Use the built-in skill creator**\nIn the Codex CLI (or IDE extension):\n\n```\n$skill-creator\n```\n\nThen describe what you want, e.g.:\n\n```\n$skill-creator\n\nCreate a skill for drafting conventional commit messages from a summary of changes.\n```\n\nIt'll guide you through questions (what it does, trigger conditions, instruction-only vs. script-backed). Outputs a ready-to-use `SKILL.md`.\n\n**Manual creation:**\n1. Create a folder in the right location:\n   - User-wide: `~/.codex/skills/<skill-name>/`\n   - Repo-specific: `.codex/skills/<skill-name>/` (great for sharing via git)\n\n2. Add `SKILL.md` with YAML frontmatter:\n\n```markdown\n---\nname: draft-commit-message\ndescription: Draft a conventional commit message when the user asks for help writing a commit message or provides a change summary.\n---\n\nDraft a conventional commit message using the provided change summary.\n\nRules:\n- Format: type(scope): summary\n- Imperative mood (e.g., \"Add\", \"Fix\")\n- Summary < 72 chars\n- Add BREAKING CHANGE: footer if needed\n```\n\n3. Optional: Add folders like `scripts/`, `assets/`, `references/` for Python scripts, templates, etc.\n\n4. Restart Codex (or reload) to pick it up.\n\n### Example Skill in Action\nPrompt Codex:\n\n\"Help me write a commit message: Renamed SkillCreator to SkillsCreator and updated sidebar links.\"\n\nWith the skill above, Codex should auto-trigger and output something like:\n\n`refactor(codex): rename SkillCreator to SkillsCreator`\n\n### Best Practices\n- Make the **description** crystal clear â€“ it controls auto-triggering.\n- Keep skills narrow and modular.\n- Prefer pure instructions; use scripts only for deterministic stuff (e.g., validation).\n- Test with real prompts to ensure triggering works.\n- Share via GitHub! Check https://github.com/openai/skills for more examples.\n\n### Troubleshooting\n- Skill not loading? Check path, exact `SKILL.md` name, valid YAML, restart Codex.\n- Not triggering? Refine the description to match your prompts better.\n\nThis feature makes Codex way more reliable for team/enterprise use. I've already set up a few for my projects and it's saving tons of time.\n\nWhat skills have you built? Share ideas or links below!\n\nLinks:\n- Official skills catalog: https://github.com/openai/skills\n- Open standard: https://agentskills.io\n- Codex docs on skills: Search \"skills\" in OpenAI developer docs\n\nHappy coding! ðŸš€",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptdtvg/openai_codex_guide_to_creating_and_using_custom/",
        "publishDate": "2025-12-22T23:05:46Z[Etc/UTC]",
        "author": "gastao_s_s",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "26",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptc3bo",
        "title": "I'll build your AI agent MVP in 24 hours for $400. Here's the catch.",
        "content": "Last month, I spent 42 hours in \"discovery meetings\" with a founder who just wanted to automate their lead follow up. By the time we \"aligned on requirements,\" they'd lost interest.\n\nThat's when I realized: founders don't need more meetings but they still try to make the agent using ChatGPT with little to no success. They need proof their idea works before investing a bigger investment.\n\n\n\nSo I'm testing a no-BS offer:\n\nPay $400 â†’ I build your AI agent MVP in 24 hours â†’ You test it â†’ Love it? We build the real thing. Hate it? Full refund.\n\nNo discovery calls. No endless Zoom links. Just a 5 min Google Form where you explain your bottleneck (or record a quick video if you prefer).\n\nWhat I actually deliver:\n\n* Working AI agent integrate with free access to ChatGPT(not wireframes)\n* Integrated with your tools (CRM, calendars, etc.)\n* ONE meeting to walk you through it\n* Free access to ChatGPT or Sora model in AI Agents\n\nExamples of what I've built in 48 hours:\n\n* AI calling agent that qualifies leads before they hit your calendar (saved a B2B SaaS founder 15 hours/week)\n* Lead nurture system that follows up based on behavior triggers\n* Customer service bot that handles tier 1 support tickets automatically\n\nThe honest truth:  \nThis won't be production ready. It'll have bugs. It won't scale to 10,000 users. But it'll prove whether your idea is worth the $5K-$15K to build it properly.\n\nI'm capping this at 4 people this month because I can't physically build faster than that.\n\nQuestion for this sub: Would you rather pay $400 to validate an idea in 24 hours, or spend 6 months building something nobody wants? Genuinely curious how founders here think about this.\n\nIf you want in, DM \"mvp\" and I'll send the intake.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ptc3bo/ill_build_your_ai_agent_mvp_in_24_hours_for_400/",
        "publishDate": "2025-12-22T21:52:34Z[Etc/UTC]",
        "author": "Jaded_Phone5688",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptb81b",
        "title": "From a messy, hand-drawn blueprint to a chatGPT-powered, production-ready dashboard",
        "content": "[No content]",
        "url": "https://i.redd.it/iww5nhq6nt8g1.png",
        "publishDate": "2025-12-22T21:16:19Z[Etc/UTC]",
        "author": "Otherwise_Ad1725",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pszjqh",
        "title": "The power of agentic loops - implementing flexbox layout in 3 hours",
        "content": "[No content]",
        "url": "https://blog.scottlogic.com/2025/12/22/power-of-agentic-loops.html",
        "publishDate": "2025-12-22T13:27:34Z[Etc/UTC]",
        "author": "ColinEberhardt",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptr7ic",
        "title": "Thoughts on AI Ugc video ads",
        "content": "Hello there!  \nI'm new in this subreddit. The first thing that i want to say is that the deep interventions and the quality of the discussions here is remarkable, so thanks for creating this space.\n\nI want to discuss with you a topic or more precisely a workflow that i have adopted recently, because i think here i could get a nice feedback.\n\nSo, to give you context, recently i had the need to promote and scale a bit the quantity of video ads for my business of spare parts and accessories of bycicles. My size is not enough to plan a budget for hiring real actors, real directors and scouting real places.\n\nSo i discovered a platform for video ads that lets you produce, edit and test video ads, in particular UGC videos (ai ugc). For now, after a research on how to do them, the results are not bad, even if my lack of technical ability in video producing is present. \n\nBe aware that i am the one to set the tone of the adv, the script of the adv and to do all the market research for the psycographical segmentation and the product to promote.\n\nWhat are your thoughts on this practice?  \nDo you see benefits on using ai ugc or not?",
        "url": "https://www.reddit.com/r/artificial/comments/1ptr7ic/thoughts_on_ai_ugc_video_ads/",
        "publishDate": "2025-12-23T11:02:31Z[Etc/UTC]",
        "author": "ConstantSuggestion65",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptqb64",
        "title": "AI will neutralize the power of a general strike",
        "content": "There is a scenario I have been thinking about. Wondering what your feedback would be. \n\nIf youâ€™re like me and youâ€™re paying attention to the political situation in America, it has become clear that electoral politics isnâ€™t going to produce the kind of changes necessary for Americans to thrive going forward.\n\n  \nWages need to go up and costs need to go down. Across the board, people are struggling to survive and itâ€™s only getting worse. \n\n  \nWho here thinks that the current politicians or any potential future offerings from the Democrats or Republicans are going to be able to reduce costs and increase wages? Or deal with the consequences of environmental damage caused by pollution? \n\nEven if you consider more desperate, awful methods like what Luigi did; that didnâ€™t really help bring medical costs down. Maybe for a day or so here or there but that kind of action wonâ€™t bring about substantive changes. Not saying it would be justified if it did, but either way it wonâ€™t. \n\nThe only thing that might work is if Americans en masse decided to shut the country down and stop working until certain demands for better living conditions were met - via a general strike. Getting to the point where one could be organized is another matter, but if, in the highly unlikely event one could be organized, changes to the status quo would become much more likely. Especially if the police joined in. \n\nOnce AI has replaced millions of jobs, or nearly every job, that will no longer be possible. \n\nI sometimes wonder if the only thing â€œthe powers that beâ€œ really are worried about is the possibility of a general strike. once itâ€™s removed, they can lock in a new status quo that erases the old social contract, and create a permanent world of haves and have-nots run by a few wealthy families who have the power to make sure their status never changes. \n\n  \nWhat do you think? ",
        "url": "https://www.reddit.com/r/artificial/comments/1ptqb64/ai_will_neutralize_the_power_of_a_general_strike/",
        "publishDate": "2025-12-23T10:05:27Z[Etc/UTC]",
        "author": "PopeSpenglerTheFirst",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptpkc5",
        "title": "ICE Contracts Company Making Bounty Hunter AI Agents | AI Solutions 87 says on its website its AI agents â€œdeliver rapid acceleration in finding persons of interest and mapping their entire network.â€",
        "content": "[No content]",
        "url": "https://www.404media.co/ice-contracts-company-making-bounty-hunter-ai-agents/",
        "publishDate": "2025-12-23T09:15:58Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pto9go",
        "title": "I tried building a deterministic system to make AI safe, verifiable, auditable.",
        "content": "The idea is simple:Â **LLMs guess. Businesses want proves.**\n\nInstead of trusting AI confidence scores, I tried building a system that verifies outputs using SymPy (math), Z3 (logic), and AST (code).\n\nIf you believe in determinism and think that it is the necessity and want to contribute, you are welcome to contribute, find and help me fix bugs which I must have failed in.",
        "url": "https://github.com/QWED-AI/qwed-verification",
        "publishDate": "2025-12-23T07:52:06Z[Etc/UTC]",
        "author": "Moist_Landscape289",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pto8yn",
        "title": "Google's server-side state management API - thoughts on the architecture?",
        "content": "Google recently shipped an API that handles conversation history, context management, and background execution server-side for agent deployments (the new Interactions API in Gemini).\n\nFrom what we can tell, this eliminates most of the infrastructure work that typically goes into building agents. No vector DB setup, no custom context engineering, no session state management. It's all handled by Google. We've been prototyping with it for a couple weeks now. The difference in development velocity is pretty significant. What used to take days of setting up memory architecture now just works out of the box.\n\nThe trade-off seems obvious though. You're locked into Google's infrastructure. You lose control over how context is stored and retrieved. Model switching becomes harder. Cost optimization gets more opaque. But from a practical standpoint, it removes what we'd estimate was 60-80% of the grunt work in agent development. You can focus entirely on the business logic and prompt engineering instead of building plumbing.\n\nA few things we're curious about from people who've worked with this or similar patterns. How does this compare to building with LangChain or LangGraph memory solutions? Is the convenience worth the vendor lock-in? For production deployments, does server-side state management create any issues around auditability or debugging? With custom implementations you can inspect everything. Here it's more of a black box.\n\nWhat's the failure mode if Google's state management has issues? With self-hosted solutions you at least have control. Here you're dependent on their uptime.\n\nIs there a reasonable path to migrate off this if needed? Or once you build on it, you're committed?\n\nFrom an architecture perspective, this feels like Google positioning infrastructure as the moat. Similar to how AWS won by solving undifferentiated heavy lifting. But in ML workloads, control over the full stack has typically been important.\n\nFor context, we're working across several businesses (e-commerce, SaaS) building management-layer agents. Planning systems, decision analysis, that kind of thing. Not doing anything cutting-edge from a research standpoint, just trying to ship production systems that work.\n\nThe ease of prototyping with this API has been valuable. But we're trying to think through whether we're setting ourselves up for problems down the road by outsourcing this much of the stack.\n\nCurious what others think about this pattern. Is server-side state management the future for agent development? Or are we trading too much control for convenience?",
        "url": "https://www.reddit.com/r/artificial/comments/1pto8yn/googles_serverside_state_management_api_thoughts/",
        "publishDate": "2025-12-23T07:51:08Z[Etc/UTC]",
        "author": "Framework_Friday",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptmdhs",
        "title": "ChatGPT introduces a Spotify Wrapped-style year-end recap for users",
        "content": "OpenAI has added a year-end recap feature to ChatGPT that summarizes how users interacted with the AI over the year. The format is very similar to Spotify Wrapped, but focused on AI conversations rather than entertainment.\n\nWhat stood out to me is less the feature itself and more what it signals: AI tools are starting to frame usage as something worth reflecting on, not just consuming.\n\nItâ€™s also rolling out selectively by country and account type, which raises some questions around data handling and regional differences.\n\nMore details here if anyone wants them:\nhttps://techputs.com/chatgpt-year-end-review-spotify-wrapped/\n\nDo you think features like this actually help users understand their AI usage better?",
        "url": "https://www.reddit.com/r/artificial/comments/1ptmdhs/chatgpt_introduces_a_spotify_wrappedstyle_yearend/",
        "publishDate": "2025-12-23T05:58:55Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptlxdk",
        "title": "One-Minute Daily AI News 12/22/2025",
        "content": "1. **OpenAI**Â says AI browsers may always be vulnerable to prompt injection attacks.\\[1\\]\n2. AI has become the norm for students. Teachers are playing catch-up.\\[2\\]\n3. **Google**Â DeepMind Researchers Release Gemma Scope 2 as a Full Stack Interpretability Suite for Gemma 3 Models.\\[3\\]\n4. **OpenAI**Â introduces evaluations for chain-of-thought monitorability and studies how it scales with test-time compute, reinforcement learning, and pretraining.\\[4\\]\n\nSources:\n\n\\[1\\] [https://techcrunch.com/2025/12/22/openai-says-ai-browsers-may-always-be-vulnerable-to-prompt-injection-attacks/](https://techcrunch.com/2025/12/22/openai-says-ai-browsers-may-always-be-vulnerable-to-prompt-injection-attacks/)\n\n\\[2\\] [https://www.nbcnews.com/tech/tech-news/ai-school-teacher-student-train-chatgpt-rcna248726](https://www.nbcnews.com/tech/tech-news/ai-school-teacher-student-train-chatgpt-rcna248726)\n\n\\[3\\] [https://www.marktechpost.com/2025/12/22/google-deepmind-researchers-release-gemma-scope-2-as-a-full-stack-interpretability-suite-for-gemma-3-models/](https://www.marktechpost.com/2025/12/22/google-deepmind-researchers-release-gemma-scope-2-as-a-full-stack-interpretability-suite-for-gemma-3-models/)\n\n\\[4\\] [https://openai.com/index/evaluating-chain-of-thought-monitorability/](https://openai.com/index/evaluating-chain-of-thought-monitorability/)",
        "url": "https://www.reddit.com/r/artificial/comments/1ptlxdk/oneminute_daily_ai_news_12222025/",
        "publishDate": "2025-12-23T05:33:46Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptlus7",
        "title": "Guided learning lets â€œuntrainableâ€ neural networks realize their potential",
        "content": "[No content]",
        "url": "https://news.mit.edu/2025/guided-learning-lets-untrainable-neural-networks-realize-their-potential-1218",
        "publishDate": "2025-12-23T05:30:01Z[Etc/UTC]",
        "author": "swe129",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ptd5uy",
        "title": "Steam games that openly use generative AI earned $660 million this year, including Call of Duty: Black Ops 6, Stellaris, and more, as studios continue to rely on the technology",
        "content": "[No content]",
        "url": "https://www.gamesradar.com/games/steam-games-that-openly-use-generative-ai-earned-usd660-million-this-year-including-call-of-duty-black-ops-6-stellaris-and-more-as-studios-continue-to-rely-on-the-technology/",
        "publishDate": "2025-12-22T22:37:27Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "97",
            "commentCount": "142",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt9u2r",
        "title": "Instacart scraps AI pricing tests that made some products more expensive | A study found that Instacartâ€™s pricing tests resulted in higher prices for some customers.",
        "content": "[No content]",
        "url": "https://www.theverge.com/news/849061/instacart-ends-ai-pricing-tests-eversight",
        "publishDate": "2025-12-22T20:19:45Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "21",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt8xgm",
        "title": "Robot training process + gameplay. I'm making a physics-based game where you command AI robot through levels - not just pointing the path, but also by controlling limb power and decision speed.",
        "content": "Game called \"Humanize Robotics\".  \nIâ€™m building a community of people like me - people who love artificial intelligence and playing games. Thatâ€™s actually why I decided to make this kind of game ðŸ™‚\n\nClassic reinforcement learning with lovely PPO",
        "url": "https://v.redd.it/6o7ieqi26t8g1",
        "publishDate": "2025-12-22T19:43:24Z[Etc/UTC]",
        "author": "GreyratsLab",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "10",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt619a",
        "title": "Intel releases GenAI Examples v1.5 - while validating this AI showcase on old Xeon CPUs",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/GenAI-Examples-v1.5",
        "publishDate": "2025-12-22T17:51:46Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt4tnu",
        "title": "Flock Exposed Its AI-Powered Cameras to the Internet. We Tracked Ourselves",
        "content": "[No content]",
        "url": "https://www.404media.co/flock-exposed-its-ai-powered-cameras-to-the-internet-we-tracked-ourselves/",
        "publishDate": "2025-12-22T17:05:03Z[Etc/UTC]",
        "author": "404mediaco",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "29",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt3vtc",
        "title": "How Google Gemini leapfrogged ChatGPT â€“ and why the AI race may already be over",
        "content": "[No content]",
        "url": "https://www.independent.co.uk/tech/google-gemini-vs-chatgpt-cloudflare-ai-b2881240.html",
        "publishDate": "2025-12-22T16:28:36Z[Etc/UTC]",
        "author": "unserious-dude",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt24xk",
        "title": "Could training AIs on human brain activity be key to AGI?",
        "content": "So wouldn't an AGI be able to mimic human intelligence if it learned accurately enough which brain regions show what activity in different settings?",
        "url": "https://www.reddit.com/r/artificial/comments/1pt24xk/could_training_ais_on_human_brain_activity_be_key/",
        "publishDate": "2025-12-22T15:19:15Z[Etc/UTC]",
        "author": "WeirdInteriorGuy",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pt0qq1",
        "title": "Are we dismissing AI spend before the 6x compute jump lands?",
        "content": "[No content]",
        "url": "https://martinalderson.com/posts/are-we-dismissing-ai-spend-before-the-6x-lands/",
        "publishDate": "2025-12-22T14:21:25Z[Etc/UTC]",
        "author": "malderson",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "27",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1psyume",
        "title": "We asked four AI coding agents to rebuild Minesweeper, and the results were explosive...",
        "content": "[No content]",
        "url": "https://arstechnica.com/ai/2025/12/the-ars-technica-ai-coding-agent-test-minesweeper-edition/",
        "publishDate": "2025-12-22T12:53:18Z[Etc/UTC]",
        "author": "NISMO1968",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "ZDKmdhVtIoE",
        "title": "Gemini Conductor: Google&#39;s SUPER-AGENT Planner is GREAT for CODING!",
        "content": "In this video, I'll show you how Google's new Conductor extension turns the Gemini CLI into a context-aware agent that ...",
        "url": "https://www.youtube.com/watch?v=ZDKmdhVtIoE",
        "publishDate": "2025-12-22T10:56:55Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/ZDKmdhVtIoE/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, we need to talk about a very specific pain point that I think every single developer using AI has run into. You know the drill. You open up your favorite AI coding tool or chat interface, and you start building something. At first, it is great. It writes the boilerplate. It sets up the basic functions. And everything is smooth. But then, you get about 20 messages deep into the conversation. You ask it to refactor a component or change how the database connects. And suddenly, the AI completely loses the plot. It hallucinates a variable you deleted 10 minutes ago. It forgets that you are using TypeScript and starts writing JavaScript. It suggests installing a library you already have. This happens because most of these tools treat software development like a casual conversation. They rely on a context window that, while getting larger every year, is still just a temporary buffer. They have short-term memory, but they lack a long-term understanding of your project's actual architecture and history. However, Google recently released an open source extension for their Gemini CLI called Conductor that is trying to solve this in a very practical way. They call it \"context-driven development.\" And honestly, this is kind of awesome because it shifts the paradigm from chatting with a bot to managing an intelligent agent. It basically forces the AI to plan, document, and understand your project constraints before it writes a single line of code. And since it runs through the Gemini API, if you are on the free tier, it is pretty affordable. Basically, free to experiment with. Now, let me show it to you in action because explaining it doesn't really do it justice. You have to see how the workflow actually operates. First, the setup is incredibly fast. You don't need to install a heavy desktop application or change your IDE. You just need the Gemini CLI installed on your machine. If you have Node.js, it is literally one NPM command. Once you have the CLI, you run a simple command to install the Conductor extension. It takes literal seconds. I'll put the exact commands in the description, but it just works out of the box. So, I have my terminal open here. I am inside a completely empty folder. I'm going to use this to build a movie tracker app. Let's call it Cinelog. The idea is that I want a place to log movies I've watched, give them a rating, and maybe filter them by genre. Usually, at this point, I would just type a prompt, saying, \"Create a Next.js app for tracking movies.\" But with Conductor, we do it differently. I type `/conductor:setup`. Watch what happens. It doesn't just start vomiting code. It initiates an interview process. It acts like a senior engineer onboarding to a new team. It asks, \"Is this a new project or an existing one?\" I type \"new.\" Then it asks, \"What are we building?\" Now, look at the file structure in my Explorer. It just created a hidden folder called `.conductor`. product.md outlines the features. The AI is no longer guessing. It has a source of truth that it will reference for every single task we give it moving forward. But it doesn't just stop there. Now, we need to actually build the application. In Conductor, work is organized into what they call tracks. You can think of a track as a feature branch, a Jira ticket, or a specific unit of work. I type `/conductor:newTrack`. It asks me what this track is about. I say, \"Scaffold the project structure, set up the Tailwind configuration, and create the main movie card component.\" In a normal chat, the AI would just execute this. But Conductor generates a `plan.md` file first. It breaks down my request into granular steps. It asks me to review the plan. This is a huge deal, because if the AI misunderstood something, like if it planned to use the Pages router instead of the App router, I could catch it here and tell it to correct the plan before it wastes time writing bad code. I look at the plan. It looks solid. I hit approve. Now I type `conductor:implement`. This is where it gets interesting. The agent reads the plan it just created. It double-checks the `tech-stack.md` to ensure it is complying with my rules and then it starts executing. It runs the terminal commands to install the packages. It creates the files. That is majorly how it works. And this is significant because of how it handles team collaboration. Remember those Markdown files? `product.md`, `plan.md`, `tracks.md`? They live in your repo. This means you can commit them to GitHub. So, imagine you are working on a team. You set up the context, you define the tech stack, and you push the code. Your teammate pulls the repo down. When they run `Gemini CLI` on their machine, their agent sees the exact same context yours did. You are effectively sharing the AI's brain across your entire entire team. If you update the `product.md` to say, \"We are switching to a mobile-first design philosophy.\" The next time your teammate asks the AI to build a navbar, the AI will build it mobile-first. Because that constraint is now part of the shared project memory. It streamlines your workflow a lot. You stop having to repeat yourself. You stop having to paste your `package.json` into the chat window every time you start a new session. The AI just knows. And the visibility is great too. You can run `/conductor:status` at any time. And it gives you a high-level overview of exactly what the agent is working on. Which step of the plan it is executing. And what files it has touched. If it goes down a rabbit hole you don't like, you can run `conductor:revert`. And it intelligently rolls back that specific track without nuking your entire Git history. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "AqvBvO0IkJ0",
        "title": "How Did the USSR Survive So Long - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=AqvBvO0IkJ0",
        "publishDate": "2025-12-22T16:00:17Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/AqvBvO0IkJ0/hqdefault.jpg",
            "transcription": "There's an interesting question of why the Soviet Union collapsed when it did. The even more interesting question, why a system that was so centrally planned, monstrously inefficient, could survive for so long into the 20th century. But there are loads of dysfunctional places all over the planet that have been dysfunctional forever. And you look, well, why are they dysfunctional? To me the answer to that one in a way is the example of North Korea. You go of all countries that should fall, a place that has ongoing famines in the 21st century, and it used to be the richest part of the Korean peninsula. These authoritarian regimes are really good at maintaining the coercive powers. Think about it. Dictatorships are all over the world. It's a sad part of the human condition. They clearly know what they're up to. In the case of um, the Soviet Union, there were multiple intelligence organizations. That's what Stalin was using to keep track of everyone. So you want to monopolize information so that you know more information than other people. And then they have a whole bunch of people who are the winners, the nomenclatura, are the elites there. You make sure you pay all them off. I mean, think about it. Human societies, slaves, serfs, I mean we humans have been doing these things to each other for a long time."
        }
    }
]