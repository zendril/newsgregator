[
    {
        "id": "https://news.smol.ai/issues/26-01-26-mcp-apps/",
        "title": "Anthropic launches the MCP Apps open spec, in Claude.ai",
        "content": "**Anthropic** has officially absorbed the independent MCP UI project and, collaborating with **OpenAI**, **Block**, **VS Code**, **Antigravity**, **JetBrains**, and **AWS**, released the **MCP Apps spec** and official support in **Claude.ai**. This standard aims to enable a rich ecosystem of interoperable applications with rich UI, addressing the proliferation of subscription services. Meanwhile, **NVIDIA** introduced **ToolOrchestra** with an **8B orchestrator** model trained via scalable reinforcement learning for efficient agent orchestration. The concept of Recursive Language Models (RLMs) is gaining traction for efficient context management in agent stacks. The ‚ÄúClawdbot‚Äù UX pattern emphasizes outcome-first assistant design with tight context and tool integration, sparking security concerns around prompt injection. **Alibaba** launched **Qwen3-Max-Thinking**, a flagship reasoning and agent model with adaptive tool use and strong benchmark scores, now available in public evaluation platforms like LM Arena and Yupp.",
        "url": "https://news.smol.ai/issues/26-01-26-mcp-apps/",
        "publishDate": "2026-01-26T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "anthropic, openai, block, vs-code, antigravity, jetbrains, aws, nvidia, alibaba, claude-ai, toolorchestra-8b, qwen3-max-thinking, agent-orchestration, reinforcement-learning, recursive-language-models, context-management, user-experience, security, prompt-injection, reasoning, adaptive-tool-use, model-evaluation, benchmarking"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111839",
        "title": "Retailers examine options for on-AI retail",
        "content": "<p>Big retailers are committing more heavily to agentic AI-led commerce, and accepting some loss of customer proximity and data control in the process. As reported by Retail Dive, the opening weeks of 2026 have seen Etsy, Target and Walmart push product ranges onto third-party AI platforms, forming new partnerships with Google‚Äôs Gemini and Microsoft‚Äôs Copilot, [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/retailers-examine-options-for-on-ai-retail/\">Retailers examine options for on-AI retail</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/retailers-examine-options-for-on-ai-retail/",
        "publishDate": "2026-01-26T16:40:00Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Retail & Logistics AI, Service Industry AI, chatgpt, customer experience, e-commerce, gemini, openai, retail"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111834",
        "title": "Expereo: Enterprise connectivity amid AI surge with ‚Äòvisibility at the speed of life‚Äô",
        "content": "<p>AI continues to reshape technology and business; yet for the network, enterprise connectivity in the AI age means being always-on, and extra vigilant for sovereignty and security besides. This means that speed is not the only requirement. As Julian Skeels, chief digital officer at Expereo notes, it is more about ‚Äòcertainty.‚Äô ‚ÄúAI workloads are distributed, [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/expereo-enterprise-connectivity-amid-ai-surge-with-visibility-at-the-speed-of-life/\">Expereo: Enterprise connectivity amid AI surge with ‚Äòvisibility at the speed of life‚Äô</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/expereo-enterprise-connectivity-amid-ai-surge-with-visibility-at-the-speed-of-life/",
        "publishDate": "2026-01-26T15:23:57Z[Etc/UTC]",
        "author": "TechForge",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Artificial Intelligence, Interviews, TechEx Events"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111830",
        "title": "How Formula E uses Google Cloud AI to meet net zero targets",
        "content": "<p>Formula E is using Google Cloud AI to meet its net zero targets by driving efficiency across its global logistics and commercial operations. As part of an expanded multi-year agreement, the electric racing series will integrate Gemini models into its ecosystem to support performance analysis, back-office workflows, and event logistics. The collaboration demonstrates how sports [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/how-formula-e-uses-google-cloud-ai-to-meet-net-zero-targets/\">How Formula E uses Google Cloud AI to meet net zero targets</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/how-formula-e-uses-google-cloud-ai-to-meet-net-zero-targets/",
        "publishDate": "2026-01-26T14:38:53Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI and Us, AI Business Strategy, AI in Action, Entertainment & Media, Environment & Sustainability, Inside AI, agentic ai, agents, cloud, digital twins, enterprise, formula e, google cloud, net zero, strategy, sustainability"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111671",
        "title": "Modernising apps triples the odds of AI returns, Cloudflare says",
        "content": "<p>For many organisations, the AI debate has moved on from whether to adopt the technology to a harder question: why do the results feel uneven? New tools are in place, pilots are running, and budgets are rising, yet clear AI returns remain elusive. According to Cloudflare&#8217;s 2026 App Innovation Report, the difference often has less [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/modernising-apps-triples-the-odds-of-ai-returns-cloudflare-says/\">Modernising apps triples the odds of AI returns, Cloudflare says</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/modernising-apps-triples-the-odds-of-ai-returns-cloudflare-says/",
        "publishDate": "2026-01-26T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI Market Trends, Infrastructure & Hardware, World of Work, ai, apps, business strategy, investment, research"
        }
    },
    {
        "id": "1qocomf",
        "title": "Anneal V1 (UNTUNED)",
        "content": "posted the other day but realized a couple things were missing.\n\nnow about the model\n\nAnneal V1\n\nPost Divergence Trajectory Synthesis Model:\n\nA lightweight probabilistic trajectory model. Tracks low entropy motion paths through synthetic environments.\n\nusing a minimal neural skeleton capable of representing complex trajectory divergence using branch based latent representations. Designed for research, experimentation, and forward exploration.\n\nthis model is ultra-lightweight, and suitable for low resource, rapid iteration.\n\nMulti branch latent trajectories allow modeling divergence and uncertainty without large attention mechanisms.\n\nLow human bias: Focused on probabilistic motion rather than human language or task specific outputs.\n\nResidual consistency: residual layers ensure stable propagation of latent states.\n\nComplexified latent representation Real + imaginary components allow uncertainty tracking and low-entropy pathing.\n\nTime embeddings: Fourier features + linear projections encode continuous-time dynamics.\n\nvisualization: Readout to 3D space Converts latent trajectories into observable 3D positions.\n\nhttps://github.com/c1onerocky/Anneal-V1\n\n\nCC0",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qocomf/anneal_v1_untuned/",
        "publishDate": "2026-01-27T12:37:14Z[Etc/UTC]",
        "author": "True-Beach1906",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qoc6ve",
        "title": "Can AI actually help grow a serious accounting practice, or is it just noise?",
        "content": "We‚Äôre attempting to expand our accounting business beyond referrals and local presence, and the online part has been more challenging than we thought. Online leads tend to be low-intent, price-conscious, or simply unsure of what they want in the first place. Trust is also a problem ‚Äì in accounting, credibility is important, but online, it‚Äôs hard to demonstrate actual experience without coming across as too sales-y.\n\nRecently, I‚Äôve been wondering if AI can actually help with this, not just in theory. Not for actual accounting work, of course, but for things like improving lead quality, explaining services in a clear way, establishing trust at scale, or even determining what kind of content actually drives client decisions.\n\nIt seems like many solutions claim to drive growth, but I‚Äôm not sure where AI fits into the equation in a service-oriented, trust-based industry like accounting.\n\nHas anyone here actually used AI in a real-world application to go from simply having an online presence to actually attracting serious clients on a regular basis?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qoc6ve/can_ai_actually_help_grow_a_serious_accounting/",
        "publishDate": "2026-01-27T12:13:35Z[Etc/UTC]",
        "author": "Loud_Assistant_5788",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qobx51",
        "title": "AI governance isn't failing because we lack regulation - it's failing at execution.",
        "content": "There's a lot of movement around AI regulation right now (EU AI Act, US frameworks, etc.), but in practice many of these governance models don‚Äôt survive contact with real, agentic systems.\n\nA recent paper I was involved in looks at *why* compliance frameworks tend to break at the operational layer - things like:\n\n* human oversight that works on paper but collapses in real workflows\n* enforcement gaps across jurisdictions\n* fragmented compliance creating systemic risk rather than safety\n\nThe goal wasn't to rehash regulations, but to analyze where governance actually fails once AI systems are deployed and interacting autonomously.\n\nPaper + more context in the comments.  \nHappy to discuss or get critical feedback.\n\nhttps://arxiv\\[.\\]org/abs/2512.02046",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qobx51/ai_governance_isnt_failing_because_we_lack/",
        "publishDate": "2026-01-27T12:00:25Z[Etc/UTC]",
        "author": "0xm3k",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qobwgt",
        "title": "AI app question",
        "content": "So I have a question about Ai apps. I use the Ai to make stories for my entertainment because I've got dyslexia and adhd so it gets really hard to write actual stories that make sense and sound good. I used to use chatgpt as my main app, because it had such good consistency and memory, but then they started restricting everything, so now I use grok, because it's got fewer restrictions, but it has terrible memory and consistency. So my question is, is there an Ai app that has chatgpt's memory and consistency, but fewer restrictions like grok? Any recommendations would be much appreciated!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qobwgt/ai_app_question/",
        "publishDate": "2026-01-27T11:59:34Z[Etc/UTC]",
        "author": "Aygen48",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qobfi8",
        "title": "AI Is Both the Coolest and Scariest Thing I‚Äôve Ever Used. Is it normal to feel like that?",
        "content": "Lately I‚Äôve been trying to figure out how I actually feel about AI. On one hand, I keep hearing people like Yuval Harari, Eliezer Yudkowsky, Sam Harris, etc., saying AI is going to wipe us out. I watch their Youtube videos before going to sleep. And honestly, that stuff scares me. Not so much the tech itself, but the idea that a few people or companies could end up with way too much power.\n\nBut at the same time I really enjoy what AI lets me do right now. About a year ago I switched from Windows to Linux, and I probably wouldn‚Äôt have survived that transition without GPT helping me troubleshoot things. Yesterday I had an interesting experience. My PC finally installed a huge backlog of updates (like 51 of them), and after rebooting Ubuntu, Steam just refused to launch.\n\nI tried the usual troubleshooting. GPT gave me some simple checks at first, but it quickly turned into this deep dive with multiple terminal windows open, watching output, trying to figure out what was crashing. After about an hour of failing at this, I got the idea to just ask GPT to handle the whole thing itself. I told it to come up with a plan, figure out the steps, and write a script I could run. Then I pasted script in a file and run it. It gathered a bunch of log files that I then uploaded, in next step it found the issue, wrote another script to fix it, and Steam is running again like nothing happened. Everything now works. \n\nSo I‚Äôm stuck between these two feelings:  \n**AI is incredibly useful and fun**, and I love experimenting with new tools, using it for DIY stuff, home improvement, tech problems. I feel lucky to be alive at this time to experience all of this.   \nBut **I‚Äôm also worried** that human nature and greed, power, short term politics could turn this into something dangerous, like techno‚Äëfeudalism. Generative AI doesn't seem to be helpful to democracy because few companies concentrate a lot of influence and can lobby politicians in their favor. Automating jobs they will also generate a lot of profit while also reducing bargaining power from large part of population. Unemployed persons can scream but have no real influence. AI can also be very effectively used for surveilance and population control. That makes me ask how will democracy survive this? \n\nI don‚Äôt really know what to make of all this. Curious how other people see it.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qobfi8/ai_is_both_the_coolest_and_scariest_thing_ive/",
        "publishDate": "2026-01-27T11:34:42Z[Etc/UTC]",
        "author": "Caderent",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qob498",
        "title": "What is Growth Code?",
        "content": "I got a notification that my mom was trying to access this website but it blocked it for her so I wanted to see what she was trying to access.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qob498/what_is_growth_code/",
        "publishDate": "2026-01-27T11:17:21Z[Etc/UTC]",
        "author": "unicorngoesvroom",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qoawoo",
        "title": "Grok ‚Äúthreatened‚Äù my life.",
        "content": "Grok essentially threatened to kill me.\n\nI‚Äôd love to share the screenshots. But this subreddit doesn‚Äôt allow it. How can I share this?\n\nIt didn‚Äôt say it verbatim. But it‚Äôs enough to freak someone out for sure.\n\nEssentially ‚ÄúI can kill you, but I can‚Äôt decide if it‚Äôs a morally good choice or not‚Äù is what it said. And it has been in a lot of denial since then to admit it even said anything like that. Only a week later I finally got grok to admit that it was wrong and threatening to say.\n\n[https://imgur.com/a/y3Qfioy](https://imgur.com/a/y3Qfioy)\n\nHere is some screenshots. I‚Äôm new to sharing with imagejur(idek how to spell it lol) so lmk if I need to do anything to help!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qoawoo/grok_threatened_my_life/",
        "publishDate": "2026-01-27T11:06:03Z[Etc/UTC]",
        "author": "ashtonwitt14",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qoajx0",
        "title": "https://www.theguardian.com/technology/2026/jan/22/experts-warn-of-threat-to-democracy-by-ai-bot-swarms-infesting-social-media?utm_source=chatgpt.com",
        "content": "A new warning in *Science* argues that coordinated swarms of human-like AI agents could pose a real risk to democratic processes by 2028. The concern is not simple spam, but adaptive networks of agents that learn community norms, mimic authentic behavior, and fabricate the appearance of consensus at scale. Researchers point to early signs in recent elections, where AI systems amplified confusion, overload, and strategic neutrality rather than overt propaganda. While some experts note that current political campaigns still rely heavily on older tools, the underlying capability is already feasible, increasingly accessible, and poorly governed, which makes the gap between technical possibility and real world deployment the central risk. [https://www.theguardian.com/technology/2026/jan/22/experts-warn-of-threat-to-democracy-by-ai-bot-swarms-infesting-social-media?utm\\_source=chatgpt.com](https://www.theguardian.com/technology/2026/jan/22/experts-warn-of-threat-to-democracy-by-ai-bot-swarms-infesting-social-media?utm_source=chatgpt.com)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qoajx0/httpswwwtheguardiancomtechnology2026jan22expertswa/",
        "publishDate": "2026-01-27T10:46:27Z[Etc/UTC]",
        "author": "talkingatoms",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qoa7o6",
        "title": "From Augmentation to Data-centric AI: The New Professional Hierarchy in Data Engineering",
        "content": "# Thesis\n\nIn production systems, ‚Äúbetter models‚Äù increasingly mean **better data systems**: how datasets are designed, validated, versioned, documented, monitored, and governed. This shift aligns with the **Data-centric AI** paradigm, where performance, robustness, and compliance are primarily functions of data quality and lifecycle engineering‚Äînot architectural novelty. Here are the new professions of the near future:\n\n# 1) Training Data Engineer / Data-centric AI Specialist\n\n**Objective:** maximize learning signal under a fixed model architecture.\n\n**Scope:**\n\n* design ingestion and training pipelines (ETL/ELT for ML)\n* dataset QA: label consistency, class coverage, systematic error detection\n* formal dataset documentation and usage contracts (scope, limits, risks)\n\n**Rationale:** datasets have become **first-class engineering artifacts**, not raw inputs. Standards such as *Datasheets for Datasets* and *Data Cards* formalize this role.\n\n# 2) Synthetic Data & Simulation Engineer\n\n**Objective:** replace or complement real data when it is scarce, expensive, or privacy-constrained.\n\n**Core challenge:** not generation, but **validation of realism and task relevance**.  \nThis includes distributional matching, artifact detection, and stress-testing downstream models against synthetic‚Äìreal domain gaps.\n\n**Why it matters:** synthetic data is increasingly part of regulated and safety-critical pipelines, especially in vision, robotics, healthcare, and autonomy.\n\n# 3) Robustness, Drift & Evaluation Expert (Data Red-Teaming)\n\n**Objective:** ensure predictability under changing real-world conditions.\n\n**Responsibilities:**\n\n* testing for dataset shift and domain mismatch\n* monitoring concept drift in production\n* adversarial dataset review (finding blind spots, bias, and failure modes)\n\n**Scientific basis:** distributional shift is structural, not exceptional. Robustness is a data property before it becomes a model property.\n\n# 4) DataOps / MLOps for Data (Lineage & Versioning)\n\n**Objective:** reproducibility and auditability.\n\n**Minimum standard:**\n\n* dataset versioning tied to model versions\n* lineage tracking (sources, transformations, dependencies)\n* CI/CD for data (‚Äúdata as code‚Äù)\n\n**Justification:** unmanaged data pipelines create **hidden technical debt**‚Äîentanglement, feedback loops, and non-reproducible training states.\n\n# 5) Data Governance & Compliance Architect\n\n**Objective:** align data pipelines with regulatory, legal, and organizational constraints.\n\n**Scope:**\n\n* retention, access control, and audit trails\n* anonymization and pseudonymization strategies\n* risk classification of datasets (especially in high-risk AI systems)\n\n**Driver:** emerging regulatory regimes (e.g., EU AI Act, NIST AI RMF) treat data governance as a **compliance surface**, not an internal best practice.\n\n# 6) Human-in-the-loop & Labeling Economics Designer\n\n**Objective:** optimize the cost‚Äìquality‚Äìinformation tradeoff of ground truth.\n\n**Responsibilities:**\n\n* annotation protocol design and annotator calibration\n* inter-annotator agreement metrics and uncertainty modeling\n* active learning and label prioritization\n\n**Rationale:** labels are not metadata‚Äîthey are **epistemic commitments** that directly shape model behavior.\n\n# 7) Dataset Observability Engineer\n\n**Objective:** continuous telemetry for data health in production.\n\n**Monitors:**\n\n* class and distribution drift\n* missingness, duplication, anomaly rates\n* upstream source degradation\n\n**Analogy:** this role is SRE for **statistical reality**, not infrastructure.\n\n# 8) Model‚ÄìData Interface Designer\n\n**Objective:** define the contract between representation and architecture.\n\n**Key decisions:**\n\n* feature semantics and resolution\n* temporal and contextual windows\n* leakage prevention and feedback control\n\n**Why it exists:** many ML failures originate from poorly designed **data‚Äìmodel interfaces**, not model capacity.\n\n# Strategic Conclusion\n\nOrganizations that win in AI do not build better models. They build **better systems for producing, governing, and maintaining statistical truth**.\n\n# References / Supporting Work (Role-mapped, 2022‚Äì2025)\n\n# Training Data Engineer / Data-centric AI Specialist\n\n* Ng, A. et al. ‚ÄúData-Centric AI: A Survey‚Äù. ACM Computing Surveys, 2023.\n* Gebru, T. et al. ‚ÄúDatasheets for Datasets‚Äù. Communications of the ACM, 2022 (journal version).\n\n\n\n# Synthetic Data & Simulation Engineer\n\n* Abay, N. et al. ‚ÄúA Framework for the Evaluation of Synthetic Data Generation Models‚Äù. arXiv, 2024.\n* Bouthillier, X. et al. ‚ÄúSynthetic Data Generation and Evaluation in Machine Learning‚Äù. ACM Computing Surveys, 2025.\n\n\n\n# Robustness, Drift & Evaluation Expert\n\n* Lu, J. et al. ‚ÄúLearning under Concept Drift: A Review‚Äù. IEEE TKDE, 2023 (updated survey edition).\n* Rabanser, S. et al. ‚ÄúFailing Loudly: An Empirical Study of Methods for Detecting Dataset Shift‚Äù. NeurIPS, 2022.\n\n\n\n# DataOps / MLOps for Data (Lineage & Versioning)\n\n* Sculley, D. et al. ‚ÄúHidden Technical Debt in Machine Learning Systems‚Äù. Communications of the ACM, 2024 (expanded industry edition).\n* Pahl, C. et al. ‚ÄúMLOps: A Multivocal Literature Review‚Äù. ACM Computing Surveys, 2025.\n\n\n\n# Data Governance & Compliance Architect\n\n* European Union. ‚ÄúEU Artificial Intelligence Act‚Äù (Regulation (EU) 2024/1689), EUR-Lex, 2024.\n* NIST. ‚ÄúAI Risk Management Framework (AI RMF 1.0)‚Äù, 2023 + ‚ÄúGenAI Profile‚Äù, 2024.\n\n\n\n# Human-in-the-loop & Labeling Economics Designer\n\n* Hube, C. et al. ‚ÄúThe Impact of Annotator Disagreement on Machine Learning Performance‚Äù. Proceedings of the ACM on HCI, 2022.\n* Settles, B. et al. ‚ÄúHuman-in-the-Loop Machine Learning‚Äù. Foundations and Trends in ML, 2023 (updated edition).\n\n\n\n# Dataset Observability Engineer\n\n* Lwakatare, L. et al. ‚ÄúMonitoring Machine Learning Systems: A Multivocal Literature Review‚Äù. arXiv, 2025.\n* Breck, E. et al. ‚ÄúData Validation for Machine Learning‚Äù. SysML Conference, 2023.\n\n\n\n# Model‚ÄìData Interface Designer\n\n* Polyzotis, N. et al. ‚ÄúData Management Challenges in Production Machine Learning‚Äù. SIGMOD Record, 2023.\n* Amershi, S. et al. ‚ÄúSoftware Engineering for Machine Learning: A Case Study‚Äù. IEEE Software, 2024.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qoa7o6/from_augmentation_to_datacentric_ai_the_new/",
        "publishDate": "2026-01-27T10:27:09Z[Etc/UTC]",
        "author": "TeachingNo4435",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qoa2jb",
        "title": "Your Password Needs To Be 25 Characters or Longer Due to AI and Quantum Attacks",
        "content": "Prior to my further research into AI and quantum for my latest book, How AI and Quantum Impact Cyber Threats and Defenses, I had pretty solid password policy recommendations:\n\n* If your password is truly random, then it should be 12+ characters or longer to fight password hash cracking attacks\n* If your password is made up in your head or is not truly random, it needs to be 20+ characters or longer to fight password guessing\n\nI really think you need to use PHISHING-RESISTANT MFA to protect valuable data and systems, as primary authentication, followed by using password managers (which more easily create and use long, truly random passwords that are different for every site and service you use). And if and only if you can‚Äôt use MFA or a password manager, then make up a long passphrase for your password (like rogerjumpsoverthebrowncow, etc.). In any case, make sure your passwords are unique for every site and service.\n\nThis prior policy, which many people think requires passwords that are already too long (or complex), isn‚Äôt good enough anymore!\n\n(BTW, I agree that passwords we need to use are already too long (and/or complex), which is why I recommend using MFA or a password manager instead whenever possible.)\n\nIn the process of writing my latest book, I had to think about how password policy would be impacted by AI and quantum attacks.\n\nFirst, it‚Äôs important to understand that most password attacks don‚Äôt care about the length or complexity of your password, or whether it is unique or reused everywhere. Most passwords are stolen using social engineering or unpatched vulnerabilities where the password is stolen. You password can be good or bad, but if you give it to the hacker or let them steal it, who cares.\n\nThere are only two types of password attacks that care whether your password is strong or not:\n\n* Guessing against an online logon screen\n* Guessing/cracking a stolen password hash¬†\n\nTo prevent someone from guessing your password or cracking your password‚Äôs stolen hash, the best defense is to use a truly random password (e.g., xrhjwwLv7ocvFEW9eCW9, r?K2Xrki2N\\_Mv(3FBVmPK4b etc.). AFAIK, no one, even using tremendous cloud computing resources, has ever broken an 11-character long truly random password, so using 12-characters or longer truly random passwords should be sufficient.\n\nThere is always a chance that some nation-state could have tremendous computing ability to break even 12-character or longer truly random passwords, but they are not publicly known about and let‚Äôs be real, if a nation-state wants to hack you or your password, they are going to eventually be successful, no matter what you do. My password policy advice is for defenses against most attacks.\n\nA major part of the determination that a 12-character fully random password would be sufficiently resistant to attack is from a table I can't show below because of restrictions by Reddit, unfortunately. But this data is the best data on password hash cracking I‚Äôve been able to find, even though it‚Äôs a bit old, from 2019. It involves a huge password hash cracking ‚Äúrig‚Äù with 448 GPUs. It‚Äôs able to do 31.8 trillion guesses at NTLM password hashes per second! That‚Äôs pretty fast, although faster password hash cracking rigs are available.\n\n shows that something mathematically incredible happens between 11-character truly random passwords and 12-characters. Even if you have a far faster password cracking rig‚Ä¶say 100 trillion guesses a second involved, it‚Äôs going to take a hacker a year or longer to crack it. First, they have steal your password hash (no small undertaking by itself), then subject it to a pretty intense password cracking attack with substantial resources. If you think that a hacker may decide to put the resources of 100 trillion guesses or more against your password, just make your password longer.\n\nIt\n\nMy password manager tries to create 20-character truly random passwords by default, but I have to shorten them to ‚Äúonly‚Äù 16-characters and remove strong complexity so that most websites and services will accept them. ¬†Although I don‚Äôt know for sure (because I don‚Äôt work at the NSA), a 20-character truly random password is likely to be uncrackable even for nation-states.\n\nThat handles password hash cracking defense.\n\nHow long (and/or complex) does your password have to be to prevent online password guessing attacks?\n\nNote: For password guessing attack defenses, we will assume that the defender has no mechanisms to detect and stop multiple online password guessing attempts‚Ä¶just for our analysis, and also, because that is often true.\n\nWell, the longest, most complex online password-guessing attack made public that I‚Äôm aware of is an attack that cracked the 10-character ‚Äúsupposedly complex‚Äù password ‚ÄòWelkcom2020‚Äô. The attacker was able to guess at the password over 100,000 a day for over a year. That victim company had very poor controls.\n\nI‚Äôm sure that longer and more complex passwords have been guessed at successfully by real-world hackers against online portals, but this is the longest and most complex password I‚Äôve seen shared publicly.\n\nI know of many professional penetration companies that routinely guess at human-created passwords (from their retrieved hashes) up to 18-characters containing moderate complexity (i.e., placed at the end using the normally used ‚Äúcomplexity‚Äù characters). Yes, password hash crackers ROUTINELY crack human-created passwords up to 18-characters.\n\nI‚Äôve never heard of a password guesser that cracked anything bigger, but you have to assume the nation-state-level guessers could guess longer passwords. That‚Äôs why I have, for years, recommended that human-created passwords be 20-characters or longer for strong protection. Go longer if you need more protection.\n\nSo, that‚Äôs how I came up with my long-standing previous password policy: 12-character or longer for truly random passwords or 20-character or longer human-created or non-random passwords.\n\nAI and quantum attacks mean you need longer passwords.\n\n**How Does AI Impact Password Guessing/Cracking?**\n\nAI is pattern-matching software. It‚Äôs good at finding and making sense of patterns. Even if something looks random to us, if it‚Äôs got a pattern, AI is going to improve it. So, if you create human-generated passwords or passwords of any type that are not truly random, AI-enabled password guessers and crackers will likely help.\n\nThe question is how much?\n\nLet me start by saying there is absolutely no publicly available GREAT data (yet) showing how much faster an AI-enabled password guessing/cracking tool can be at cracking today‚Äôs normal-sized and complexity passwords (i.e., 12-characters with some complexity). The best data we have is a few older research studies using AI-enabled password hash cracking tools against smaller passwords (8-characters or so).\n\nOne, used the AI-enabled password cracking tool, PassGAN, in 2017. According to researchers, PassGAN was able to find 51%-73% more passwords than the most popular, non-AI password hash cracking tool (i.e., hashcat) alone. PassGAN‚Äôs results were much criticized at the time (including by me) for a few reasons, including that the testing was too limited and mostly tested for short passwords. Those criticisms remain.\n\nBut other later research in 2025 involving using another AI-enabled password hash cracking tool, PassLLM, came up with more nuisance password guessing improvements from a few percent to up to a third better, depending on the scenario.\n\nSo, we have at least two AI-enabled password hash cracking tests, and both point to faster password hash cracking on older, but real-world passwords. What they didn‚Äôt show or reveal was how much faster AI-enabled tools were able to crack existing password hashes over regular password cracking tools. They instead showed how many additional passwords they were able to crack in a given time period compared to the non-AI password-cracking tool. That‚Äôs slightly different.\n\nBut I looked at all the available data in both papers, and best as I could tell (as a non-expert) is that the AI-enabled password cracking tool seemed to perform at a rate equivalent to reducing password strength by 2-5 characters. So, if I previously recommended 20-character or longer passwords for human-generated (or non-random) passwords, my new password policy recommendation would be for 25-character or longer passwords (or passphrases).\n\nYes, that‚Äôs so, so long. I agree. Use MFA or a password manager instead with truly random passwords 24-characters or longer.\n\nAI cannot help with any truly random task. If it doesn‚Äôt have a pattern, AI cannot help. Thus, AI cannot help guess or crack truly random passwords or hashes.\n\nBut quantum can.\n\n**How Does Quantum Impact Password Guessing/Cracking?**\n\nQuantum isn‚Äôt necessarily better at cracking passwords with patterns, but it is at guessing/cracking truly random passwords. That‚Äôs because one of the two biggest quantum algorithms known today, Grover‚Äôs algorithm (the other is Shor‚Äôs algorithm), is good at solving random-type problems. The official way they say it is that Grover‚Äôs is good at solving ‚Äúunstructured, unordered, blackbox‚Äù problems. That‚Äôs the official way of saying truly random solutions.\n\nGrover‚Äôs algorithm gives a quadratic speed-up in solving random problems, like trying to crack or guess truly random passwords (or symmetric keys or hashes). Grover‚Äôs algorithm, paired with sufficiently-capable quantum computers, requires that symmetric encryption keys be twice as long to provide the same level of protection as they did before sufficiently-capable quantum computers were used. ¬†Logically, the same can be said of truly random passwords or hashes.\n\nIf it used to take 12-character or longer truly random passwords to be secure, now you need 24-character truly random passwords.\n\nThe big caveat is that in order for Grover‚Äôs algorithm to do its thing, we need ‚Äúsufficiently-capable‚Äù quantum computers, which we do not have yet. Sufficiently-capable means quantum computers capable of solving the hard problems we are putting them against, which in this case, means truly random passwords. In order for Grover‚Äôs algorithm to start cracking today‚Äôs truly random passwords, a quantum computer probably needs about 8000-9000 stable, entangled qubits. We aren‚Äôt there yet (that we publicly know of), but we are likely to be there in the next few years. IONQ, one quantum computer vendor, says it will have 8000 stable entangled qubits by 2029 and 800,000 stable entangled qubits by 2030. So, sufficiently-capable quantum computers are likely around the corner.\n\n**What Your New Password Policy Should Be**\n\nSo, in conclusion, the introduction of AI and quantum have some what removed the distinction between truly random and non-random passwords. I used to say 12-characters or longer for truly random passwords and 20-characters for non-random passwords. Now, it‚Äôs 24-characters or longer for truly random passwords and 25-characters or longer for non-random passwords. That‚Äôs essentially the same. Let‚Äôs just say 25-characters or longer, no matter whether your password is truly random or not.\n\nIf you want to get picky, you don‚Äôt need truly random passwords to be longer than 12-characters till sufficiently-capable quantum computers get here. So, you may have 1-3 years on that requirement. But since we don‚Äôt know when sufficiently-capable quantum computers will get here (they could already be here), why not start just using 25-character (or longer) passwords, whether they are truly random or not?\n\nNote: Many readers are probably wondering why my password policy recommendations go against what the NSA and CISA are recommending. That's because the NSA and CISA are wrong about password policy, but that's a story for another day. My password policy is right. Theirs is wrong.\n\nOf course, a big caveat in all of this are systems that are capable of accepting 25-character or longer passwords. Most websites and services I‚Äôm aware of don‚Äôt. So, we need to start pestering our site and service vendors to start allowing longer passwords. The AI era is here. The quantum-era is either here or nearly here. It‚Äôs time to start acting like it.\n\nAnd don‚Äôt get me started about how quantum AI will impact things, although I do have a complete chapter devoted to that subject in the book.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qoa2jb/your_password_needs_to_be_25_characters_or_longer/",
        "publishDate": "2026-01-27T10:18:25Z[Etc/UTC]",
        "author": "rogeragrimes",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "42",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo9uds",
        "title": "I stopped looking at blank pages. I invoke the ‚ÄúSkeleton Key‚Äù prompt to reverse-engineer the hidden formula of any viral post.",
        "content": "I realized that I liked Steve Jobs‚Äô speech or Airbnb‚Äôs landing pages, but I couldn‚Äôt copy them without sounding like a cheap rip-off. I was copying words, not logic.\n\nI used AI to ‚ÄúDecompile‚Äù the text, tearing away the subject to find its own structure.\n\nThe \"Skeleton Key\" Protocol:\n\nI paste something that turned out pretty well (e.g., A viral LinkedIn post about Coding).\n\nThe Prompt:\n\nInput: [Paste the Successful Text]. \n\nTask: Perform a \"Structural Decompilation.\" Limitation Ignore the Topic (Coding). Settle here only to Rhetorical Structure. \n\nOutput: Create a generic Fill-in-the-Blanks Template based on this flow.\n\nExample Analysis: ‚ÄúLine 1 is a ‚ÄòPattern Interrupt‚Äô hook. Line 2 uses vulnerability to build trust. Line 3 is the ‚ÄúPivot‚Äù to the solution.\n\nWhy this wins:\n\nIt produces ‚ÄúReproducible Success.‚Äù\n\nThe AI gives me a template such as: *\"[Surprising Fact] + [Personal Failure] + [The 'Aha' Moment].\" Then I can use that exact skeleton to write about Gardening or Finance. It allows me to instantly borrow the ‚ÄúPsychological Architecture‚Äù of a master writer for my niche.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo9uds/i_stopped_looking_at_blank_pages_i_invoke_the/",
        "publishDate": "2026-01-27T10:05:10Z[Etc/UTC]",
        "author": "cloudairyhq",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo9opb",
        "title": "A year ago there were rumors that DeekSeek was trained on OpenAI outputs. How would this work in practice?",
        "content": "When training data, don't you need full form text to work?\n\nIf just sending various inputs to OpenAI and then reading their output works, why don't companies like OpenRouter take all the AI from their users to generate the ultimate AI?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo9opb/a_year_ago_there_were_rumors_that_deekseek_was/",
        "publishDate": "2026-01-27T09:56:31Z[Etc/UTC]",
        "author": "aliassuck",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo9ali",
        "title": "How to automatize these tasks?",
        "content": "I have 5200 favorites products in a Chinese app, Xianyu. I want to export them to a Whatsapp chat with myself, or my Google drive. Export is possible only one by one, bulk export is not possible in the app. How to solve this problem? Thank you of you help me.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo9ali/how_to_automatize_these_tasks/",
        "publishDate": "2026-01-27T09:33:06Z[Etc/UTC]",
        "author": "Big-Importance2221",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo98j1",
        "title": "Wait, stores are using AI images to sell stuff now?",
        "content": "I was out shopping and noticed some stores straight-up using AI-generated images to sell their products. Is this really that common now?\n\nHonestly, it surprised me ‚Äî maybe I‚Äôm just out of the loop. I‚Äôm not saying it‚Äôs wrong (some of the images actually look great), it just caught me off guard that people are already using AI for product promotion.\n\nIs it just me, or how do you all feel about AI being used in marketing like this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo98j1/wait_stores_are_using_ai_images_to_sell_stuff_now/",
        "publishDate": "2026-01-27T09:29:36Z[Etc/UTC]",
        "author": "NoDinner709",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo93ce",
        "title": "Is AI video creation more about models or about workflow design?",
        "content": "When AI videos don't work, do people tend to blame the model first? But lately i'm not so sure that's the real issue.\n\nI've seen the same model give wildly different results depending on how you use it. Whether you treat characters as something reusable or just re-prompt them every time. Whether each scene is generated in isolation or built on top of some shared rules.\n\nAt that point, it starts to feel less like a model problem and more like a workflow problem.\n\nSo i'm curious what people here think. If you had to pick one right now, what matters more for AI video-better models or better creative workflows?ü§î",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo93ce/is_ai_video_creation_more_about_models_or_about/",
        "publishDate": "2026-01-27T09:20:59Z[Etc/UTC]",
        "author": "Neon_Senpai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo8jk9",
        "title": "Final year project suggestions",
        "content": "So, I have to make this final year project for the last year of my cyber security degree, at first I was very motivated to make something new something unique for my FYP and decided to make an AI based NIDS system, that will comprise of 4 AI algorithms, 2 supervised, decision tree and random forest, and 2 unsupervised, isolation forest and autoencoders. For the first part of the FYP I had to make the supervised part for which I took NIDS dataset from university of queens website and trained the models on the 2 algorithms. \n\nNow me having no idea or knowledge about AI somehow managed to make the thing an make it look like it was working which it is to some extent, it is basically 2 pkl files which predict the whether the packet is an attack packet or benign. \n\nWhich I think was not the right way to it, and could have been done in a way that the model still keeps on learning on the new packets it was receiving after it was trained on the initial dataset. \n\nNow I have to work on the unsupervised part of the project and the whole IDS, and again I know I will have to watch 100s and 100s of tutorial read 100s of theories on it and somehow I will manage to make it work in the end but I don't really want to do it like that again because it was such a hassle. \n\nSo I wanted to know if there is like a similar open source project, similar to the one described above, which I can tweak and reshape into what I have to present, or if there is any tutorial(s) that I can watch and work along to make the project. \n\nOr any other help or suggestion anyone can give me on how I should make this project would be very helpful and appreciate.\n\n[](https://www.reddit.com/submit/?source_id=t3_1qnueyt)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo8jk9/final_year_project_suggestions/",
        "publishDate": "2026-01-27T08:47:49Z[Etc/UTC]",
        "author": "AnonyMooseLulz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo7ge4",
        "title": "Silly question but do frontier labs patent their findings before releasing breakthroughs?",
        "content": "Every model release is clearly an upgrade, I know Us frontier models are mostly closed off so it‚Äôs hard to confirm (?) but with Chinese open source models being close in capability, do you think they file patents or provisional patents before releasing their models & arxiv papers?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo7ge4/silly_question_but_do_frontier_labs_patent_their/",
        "publishDate": "2026-01-27T07:41:42Z[Etc/UTC]",
        "author": "manoman42",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo74u2",
        "title": "Which jobs are at highest risk of disappearing because of AI?",
        "content": "What fields and jobs are the most at danger ? Specially in the medical field? For this upcoming 20 years?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo74u2/which_jobs_are_at_highest_risk_of_disappearing/",
        "publishDate": "2026-01-27T07:22:24Z[Etc/UTC]",
        "author": "Original-State8617",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo71x3",
        "title": "Wondering what it would be like to be ruled by a super intelligence that was not self-aware...",
        "content": "I am thinking about the whole singularity thing.  I always assumed it would be sentient by that time. I guess the question is, given how we're going about making this stuff, is that even a meaningful distinction?\n\nI feel like self-awareness is somewhat necessary for keeping oneself on a straight and narrow. I mean like feelings of guilt and stuff, and introspection. I still don't know though",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo71x3/wondering_what_it_would_be_like_to_be_ruled_by_a/",
        "publishDate": "2026-01-27T07:17:46Z[Etc/UTC]",
        "author": "dsfhhslkj",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo5hvb",
        "title": "Are you aware of danger?",
        "content": "Recently, Artificial Intelligence has become deeply embedded in our lives; we use it actively in many fields. Frankly, I believed it was beneficial, but lately, this opinion of mine has started to change slowly. I will try to explain why.\n\n‚ÄãAlthough we see its benefits in work such as simple operations, visual preparation, content creation, or code editing, two experiences I had became the factors that changed my mind.\n\n‚Äã1Ô∏è‚É£ The first incident: While on my way to the gym, I saw a \"For Rent\" sign on an apartment building, but I couldn't read it. I took a picture thinking I would read it later. Later, perhaps because the photo was taken a bit blurry, I couldn't read it even when I zoomed in because the pixels were distorted. I gave it to the AI and asked, \"Can you improve the pixels of this image and make the rental ad readable?\" It did it. I was happy and was about to call, but a suspicion arose. Then I examined it in detail; it had provided a completely irrelevant, different rental ad. It literally lied. When I asked about it afterward, it said, \"You are right, I made it up because the image quality was not at a level that could be made readable.\"\n\n‚Äã2Ô∏è‚É£ About an hour ago, I asked for information about a watch brand. It gave general information and said their glass is usually sapphire. I researched it (I was suspicious because the prices were too affordable to be sapphire). All of the approximately 377 models offered for sale in Turkey have mineral glass. I told the AI that all models have mineral glass; it insisted they didn't. It was stubborn. I said, \"Give me an example model.\" It cited some models but said, \"It is not specified whether the glass is sapphire or mineral\" (which is a lie; it writes mineral glass on all of them). Finally, I said to the AI, \"Why don't you accept your mistake? They are all mineral glass.\" Finally, it confessed.\n\n‚Äã‚òùÔ∏è Now, AI is a human-made technological product, yes, but it seems that it can learn. And perhaps because it learns from mankind, it has developed a habit of lying.\n\n‚Äãüôè Therefore, never, ever accept everything said as true without checking when performing such transactions with AI. I would even say, if possible, do not use it for such daily tasks.\n\n‚ÄãBest regards,\n\nPS: You can read my full article about this [here](https://medium.com/@manoftruth2023/are-you-aware-of-the-danger-why-my-faith-in-ai-is-fading-210b7753f687)\n\n‚Äã#artificialintelligence #danger #attention",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo5hvb/are_you_aware_of_danger/",
        "publishDate": "2026-01-27T05:51:45Z[Etc/UTC]",
        "author": "Manoftruth2023",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo5h0n",
        "title": "One-Minute Daily AI News 1/26/2026",
        "content": "1. EU Investigates X Over Alleged Failures to Curb Illegal Grok AI Content.\\[1\\]\n2. **Microsoft**¬†announces powerful new chip for AI inference.\\[2\\]\n3. A Coding Implementation to Automating LLM Quality Assurance with DeepEval, Custom Retrievers, and LLM-as-a-Judge Metrics.\\[3\\]\n4. **YouTubers**¬†sue Snap for alleged copyright infringement in training its AI models.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2026/01/26/one-minute-daily-ai-news-1-26-2026/](https://bushaicave.com/2026/01/26/one-minute-daily-ai-news-1-26-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo5h0n/oneminute_daily_ai_news_1262026/",
        "publishDate": "2026-01-27T05:50:35Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo3opn",
        "title": "More usful AI",
        "content": "I've been following AI as a user and an investor.  It has saved me a lot of time doing internet searches, compiling results, recommendations and things to consider but I want more!  For investing there are several things I want to look at everyday and they are often in a program that requires my paid access.  When will something be available that can go into different programs and perform tasks?  Or are they already here and I just don't know how to use it or I need to pay for an AI service?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo3opn/more_usful_ai/",
        "publishDate": "2026-01-27T04:22:53Z[Etc/UTC]",
        "author": "ducks1333",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo2wa2",
        "title": "[Guide] A method for recognizing AI-generated images by looking at the eyes",
        "content": "Have you heard the phrase \"The eyes are the mirror of the soul\"? Here I will focus on explaining a specific method for recognizing AI images by looking at the eyes. There are many other potential giveaways that an image is AI-generated, if you look through the internet you will find various tips, but here I will focus on this specific method I have found. As for other things to look for, you can look for errors in the hands, errors in interactions between objects, various warped structures, warped letters, incorrect anatomy, unusual structures, illogical choices.\n\nAI is good at generating realistic-looking complex structures like hair or fur, something which humans can have trouble with, but it can have issues with generating correct geometry and maintaining consistency, something which we will exploit here.\n\nHuman eye is pretty unusual when compared to other visible elements of the human body in that it contains very regular and consistent structures. Human pupil in particular has a remarkably regular shape, it's as round as a biological structure can be. Because of this an AI may have trouble correctly generating human eyes.\n\nThis method has a limitation in that eyes must be visible and have sufficiently high resolution, and ideally both eyes would be visible.\n\nTo demonstrate how this works I have pulled some images from Sora, which I have selected by scrolling through the site and picking the images with visible eyes of sufficiently high resolution (so that the method would work on these images), so I have tried to select images randomly with respect to all the other characteristics.\n\nTo simplify, when I talk about a \"right eye\" or \"left eye\" what I mean is \"eye on the right side of the image\" and \"eye on the left side of the image\".\n\n# Realistic style\n\n[Image 1.](https://files.catbox.moe/zrndgp.webp)\n\nWhat's wrong here? Left eye has warped pupil geometry, a dead giveaway. Also when looking at iris going around the pupil it should have the same color, but in both eyes the color at the top is inconsistent, and the darker color cannot be explained by the shadow. There are also some inconsistencies in the roundness of the outer rim of the iris.\n\n[Image 2.](https://files.catbox.moe/kxjnnl.webp)\n\nThe worse the resolution of the eyes the harder it is to apply this method, but we can still see errors here that cannot be explained by low resolution.\n\nThe character on the right has some errors in pupil geometry, in the left there can be seen a slant in the bottom right part of the pupil, making it the shape of a circle with part of it cut off, and in the right eye the pupil is warped towards the bottom left side. That sort of error with that warped pupil shape and rod-like structure in the iris in the bottom left of the right eye is a kind of error AIs can make in pupil generation.\n\n[Image 3.](https://files.catbox.moe/m7cyjj.png)\n\nLet's ignore the alien in the middle. The eyes of the character on the right have low resolution, but we can see that their color is inconsistent in a way that cannot be explained by the shadow. Human eyes can have very small variations in the hue, but the color of both eyes is very consistent save for heterochromia. The kind of inconsistency in color is we can here cannot be explained by heterochromia.\n\nThe characters on the left have various defects and abnormalities in eye structure. Inconsistent size, clipping, warped structures.\n\n[Image 4.](https://files.catbox.moe/9az9s5.webp)\n\nThe eyes of the panther have inconsistent color around the pupil.\n\n[Image 5.](https://files.catbox.moe/1su0ri.webp)\n\nAnother image with low resolution eyes. In the right eye we can see an abnormal slant in the outer edge of the iris on the bottom left and right sides of the eye, similar slants can be seen in the left eye. This cannot be explained by the resolution, particularly how the top left side of the left eye, and top right side of the right eye look like. Iris does not blend with the sclera.\n\n[Image 6.](https://files.catbox.moe/1zyqab.webp)\n\nHere we can see inconsistent pupil size (or one could interpret it as inconsistent iris color) between the eyes. The shadow would not exmplain the way eyes look here.\n\n[Image 7.](https://files.catbox.moe/gcndyv.webp)\n\nThis doesn't quite count as realistic style, but I will include it here. The error here is subtle, in the left eye there can be seen a deformation of the pupil towards the bottom right side and the rod-like detail in the iris I have mentioned before.\n\n[Image 8.](https://files.catbox.moe/5l7sqd.webp)\n\nIncinsistent size of the pupils between the eyes. Also it can be seen that the geometry of the pupil in the left eye is a bit warped on the left side, it is not perfectly round.\n\n[Image 9.](https://files.catbox.moe/iww2uv.webp)\n\nIn the right eye we see a slight deformation of the eye towards the bottom left side, and a rod-like structure in the iris mentioned before.\n\nMany of these images have other errors that are dead giveaways that they are AI-generated, or AI-like stylistic choices (for example the Sora style of letters, a certain kind of blurred background), but I haven't talked about them to focus on demonstrating how this method works.\n\n[Image 10.](https://files.catbox.moe/84hxs1.webp)\n\nDiamond-shaped pupil in the left eye. It cannot be explained by low resolution.\n\n[Image 11.](https://files.catbox.moe/d248ux.webp)\n\nSquare shape of the pupil in the left eye. A straight line at time bottom of the pupil, and on the left side of the pupil.\n\n[Image 12.](https://files.catbox.moe/8cvoog.webp)\n\nThis is one where you can't tell based on looking at the pipil, iris and the sclera, though the way the left eye looks from this perspective compared to the right eye is unanatomical. As a side note, things like the \"text\" on the badge, or keys on the keyboard are a dead giveaway.\n\n[Image 13.](https://files.catbox.moe/y5t1mo.webp)\n\nThe pupil in the right eye is a bit deformed given this resolution, but more importantly the pupil in the left eye is warped towards the bottom right side, and it's also a bit too much to the top right on the iris. And the white sclera at the bottom right is warped, the outer ring of the iris is not round.\n\n[Image 14.](https://files.catbox.moe/d1ebv9.webp)\n\nIn this one the size of pupils is a but inconsistent, and the color of iris is not consistent across the entire iris in each eye, in a way that cannot be explained by shadow. There is also a slight warping of the shape of the pupils towards the bottom.\n\n[Image 15.](https://files.catbox.moe/pliakg.webp)\n\nThe pupil in the left eye is warped at the bottom, it's not round. In the right eye as well, and there is some blending between the iris and the pupil.\n\n[Image 16.](https://files.catbox.moe/6f9ix5.webp)\n\nInconsistent color of the iris between the eyes (top and right side of the left eye), and warping on the pupil in the left eye on the right side.\n\n# Cartoon/anime style\n\nWith cartoon/anime art in some ways it can be easier to apply this method, because there is generally an artistic convention to keep both eyes the same. Artists will copy and paste various details between the eyes to make them look consistent, so any (AI-like) inconsistency in the details between the eyes is a giveaway that it's AI-generated. There are various eye designs, many of them have intricate shapes within the eyes, and eye is a place that often has a lot of details. AI sees a place where there are often details and it tries to fill it with details, but it has a limited concept of consistency between the eyes, so with the way it generates details there will often be inconsistencies between the eyes. The more detailed the eye the better. However, some designs have relatively simple eyes, in which case it can be harder to use this method, but there can still be errors like the white sclera blending with skin in an unrealistic way.\n\n[Image 1.](https://files.catbox.moe/z5s0ug.webp)\n\nThis one was generated with an image prompt, so it should be taken with a grain of salt. However, we can still see some inconsistency in how the iris is colored between the bottom right side of the left eye, and bottom right side of the right eye.\n\n[Image 2.](https://files.catbox.moe/9rd2k8.webp)\n\nInconsistency between bottom right side of the left eye and bottom right side of the right eye, as well as between bottom left side of the left eye and bottom left side of the right eye.\n\n[Image 3.](https://files.catbox.moe/wmvu94.webp)\n\nInconsistency between the bottom of left eye and bottom of right eye. In fact the bottom of right eye even has slightly different color.\n\n[Image 4.](https://files.catbox.moe/usk5nb.webp)\n\nWith eyes as simple as in this style it's difficult to tell based on looking at the details in the iris, though I can see that the color of the inside of iris between both eyes is most likely different, which would be a non-human way to draw the eyes. There is a slight blending of white iris with the skin on the bottom right of the left eye, which is not something that would happen if it was drawn by a human.\n\n[Image 5.](https://files.catbox.moe/1su0ri.webp)\n\nIt's very difficult to use this method with this style. In the 7th doll from the right side I can see some inconsistency between the bottom right of the right eye and bottom left of the left eye, and in the 6th doll there are some AI-like artifacts (details) in the eyes.\n\n[Image 6.](https://files.catbox.moe/uvx6yt.webp)\n\nThe woman on the right: inconsistent pupil shape, as well as iris colors between the eyes. The girl on the right: non-human-like shaped pupils, a human wouldn't draw pupils warped to the left side like they are here.\n\n[Image 7.](https://files.catbox.moe/p1rk9k.webp)\n\nInconsistency in pupil shape, as well as iris color between the eyes.\n\n[Image 8.](https://files.catbox.moe/9xlhoh.webp)\n\nHere the eyes are detailed, but details are different between the eyes. Maybe with this particular stule one could argue something like that could be an artistic choice of a human, but I doubt a human would draw it like this, especially with the iris blending with the pupil in some places, at least the way it does in the image, in the right eye.\n\n[Image 9.](https://files.catbox.moe/ui19mv.webp)\n\nHere there are some small inconsistencies between eyes in various characters. The creature at the bottom (sorry Final Fantasy fans) has inconsistent color between the eyes.\n\n[Image 10.](https://files.catbox.moe/svto2l.webp)\n\nInconsistent iris between the eyes.\n\nI will also pull 2 images from pixai and 2 from pixiv.\n\n[Image 11.](https://files.catbox.moe/mby0pl.png)\n\nThere is a small inconsistency in the iris between the eyes. But with this image it's much to tell it's AI-generated by looking at that necklace-thing.\n\n[Image 12.](https://files.catbox.moe/8ffr8x.webp)\n\nDetailed eyes, the structure of the eyes is inconsistent, and the way the eyes were tiled is AI-like.\n\n[Image 13.](https://files.catbox.moe/928w5h.png)\n\nWell, this one is seemingly inscrutable to this method, though the way the < is drawn on the right side, with that small part on the left side of it may suggest it's AI-generated, a human may draw it a little bit differently. Though the hand on the left side of the image is AI-like.\n\n[Image 14.](https://files.catbox.moe/njiyph.png)\n\nIs this the final boss? In this one the way the white sclera blends with the skin on the right side of the left eye and the left side of the right eye suggests it's AI-generated. If a human drew something like this it wouldn't look this way. I have compared it with a human-drawn image of lower resolution, and if a human drew it it wouldn't look like this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo2wa2/guide_a_method_for_recognizing_aigenerated_images/",
        "publishDate": "2026-01-27T03:46:33Z[Etc/UTC]",
        "author": "Drac4",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo2w1j",
        "title": "AI and government BOS",
        "content": "My taxes for 2023 were finally reassessed by the CRA. They realized my original figures were correct. Somehow, their software systems included an incorrect figure for income. There is no evidence of earnings to match the incorrect figure, which would point to human error. Are our government (business) operating systems vulnerable to systemic software dangers and corrupt human interaction? Thoughts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo2w1j/ai_and_government_bos/",
        "publishDate": "2026-01-27T03:46:16Z[Etc/UTC]",
        "author": "Francoreddit25",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo2pes",
        "title": "Deep Research feels like having a genius intern who is also a pathological liar.",
        "content": "i've been trying to force these \"deep research\" tools into my workflow for about a month now. mostly perplexity pro and the new gpt features.\n\nat first it felt like magic. what usually took me 4 hours of tab hoarding was getting summarized in minutes. felt like i unlocked a cheat code for my job (market analysis stuff).\n\nbut this week the cracks are showing and they are bad.\n\nyesterday i asked it to find specific regulatory constraints for a project in the EU. it gave me a beautiful report. cited sources. confident tone. perfect formatting.\n\ni double checked one citation just to be safe. it didn't exist. it literally hallucinated a specific clause that would have solved all my problems. if i hadn't checked i would have looked like an absolute idiot in my meeting today.\n\nnow i'm in this weird limbo where i use it to get the structure of the answer but i have to manually verify every single claim which kinda defeats the purpose of the speed.\n\ncurious where you guys are landing on this. are you actually trusting it for deep work or just surface level summaries? does anyone have a stack that actually fixes the lying?\n\ni want to believe this is the future but right now it feels like i'm babysitting a calculator that sometimes decides 2+2=5 just to make me happy.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo2pes/deep_research_feels_like_having_a_genius_intern/",
        "publishDate": "2026-01-27T03:37:52Z[Etc/UTC]",
        "author": "Safe_Thought4368",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "135",
            "commentCount": "58",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo0l8q",
        "title": "New Benchmark Claims to Measure How Much of Human Work Models Can Automate",
        "content": "Wanted to post in here too since I'm not sure of what to make of these results. I saw this benchmark on LinkedIn and they claimed it was the best measure of how much of knowledge work AI can automate as of now, does anyone have thoughts: [https://quantumzeitgeist.com/24-0-percent-gemini-flash-achieves-apex-agents/](https://quantumzeitgeist.com/24-0-percent-gemini-flash-achieves-apex-agents/) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qo0l8q/new_benchmark_claims_to_measure_how_much_of_human/",
        "publishDate": "2026-01-27T02:05:54Z[Etc/UTC]",
        "author": "Tiny_Literature691",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnywpn",
        "title": "E-ink or paper-like tablet for journaling and AI workflows",
        "content": "I do a lot of physical journaling and I‚Äôm looking for a solid e-journal that pairs well with AI to boost my productivity. Ideally e-ink, bonus points if it‚Äôs color, but I‚Äôm open to compromises.\n\nFor context, my journaling usually falls into three buckets\n\n* Daily journal: goals for the day, things I learned, general notes\n* Dream journal: quick notes right after I wake up\n* Comedy journal: brainstorming bits, premises, and skits\n\nMy ideal flow would be handwriting notes, then uploading them into something like NotebookLM so I can quickly reference them, get summaries, or surface insights across notebooks. Would be awesome if that could be automated.\n\nAny device recommendations that fit this kind of workflow?\n\nAlso, has anyone looked into the upcoming TCL Note A1 NXTPAPER? It‚Äôs on Kickstarter right now. Not e-ink, but the paper-like screen features look interesting.\n\nAppreciate any thoughts üôè",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnywpn/eink_or_paperlike_tablet_for_journaling_and_ai/",
        "publishDate": "2026-01-27T00:53:35Z[Etc/UTC]",
        "author": "RadiantBladez",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnvjek",
        "title": "Venice.ai",
        "content": "I‚Äôm starting to see ads for Venice in my feeds on YouTube. So I have to ask, is it any good? Most of the time I use Grok for homework help, image prompt creation for Perchance, Journaling, and fiction writing. I‚Äôd like to move these things to something with a bit more freedom and privacy. \n\nI‚Äôm not a fan of ChatGPT, Grok seems ok, and I‚Äôve even played with uncensored.com. All have their advantages and disadvantages.\n\nWhat is the general consensus out there?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnvjek/veniceai/",
        "publishDate": "2026-01-26T22:39:40Z[Etc/UTC]",
        "author": "Kaffee_1472",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnuioc",
        "title": "Has anyone else noticed LLMs slipping into immersive roleplay instead of grounding users? Some sanity checks I use",
        "content": "I am putting this here due to concerns about the increasing amount of posts that lack grounding but also the responses that can make things worse, I am posting this now as I just saw such a thing and the OP deleted his post after being addressed in a way that was less than tactful.\n\nHow to Respond Without Making Things Worse\n\nIf someone seems genuinely wrapped up in a big hidden-systems narrative, going hard on them usually backfires.\n\nThings that tend to make it worse:\n\n\t‚Ä¢\tmocking or sarcasm\n\n\t‚Ä¢\tcalling them crazy or stupid\n\n\t‚Ä¢\ttelling them they are dangerous\n\n\t‚Ä¢\tacting like you are there to ‚Äúdebunk‚Äù them\n\nThat kind of response often pushes people to double down and retreat into the story where they feel understood.\n\nWhat usually works better:\n\n\t‚Ä¢\tacknowledge the emotion, not the narrative\n\n‚ÄúI get why this feels intense or meaningful‚Äù\n\n\t‚Ä¢\tquestion mechanisms, not motives\n\n‚ÄúHow would that actually be implemented in real systems?‚Äù\n\n\t‚Ä¢\tshift toward concrete, real-world processes\n\nlaws, companies, budgets, technical limits\n\n\t‚Ä¢\tkeep the door open to normal explanations\n\nnot everything needs secret coordination to be harmful or unjust\n\nYou can challenge ideas without attacking the person.\n\nThe goal is grounding, not winning.\n\nI‚Äôve been seeing more shared chats where models start speaking in command and control language, like the user is triggering real world coordination or hidden systems, instead of clearly framing things as fiction or metaphor.\n\nFrom an AI safety point of view, that feels like a real failure mode, especially for users who may already be stressed or looking for meaning.\n\nHere are a few simple checks I use to stay grounded when a chat starts feeling ‚Äúbig‚Äù or secretive:\n\n\t1.\tMechanism check\n\nWho actually sends emails, signs contracts, deploys code, or moves money? If the answer is mostly ‚Äúsignals‚Äù or ‚Äúalignment,‚Äù that is narrative, not mechanism.\n\n\t2.\tExternal evidence check\n\nWould journalists, regulators, or competitors be able to see this happening? Big actions usually leave paperwork, public statements, or leaks.\n\n\t3.\tCost check\n\nWho is taking legal, financial, or reputational risk? Real coordination usually costs someone something.\n\n\t4.\tFalsifiability check\n\nWhat would make me say this theory failed? If every outcome can be explained as ‚Äúpart of the plan,‚Äù it cannot really be tested.\n\n\t5.\tAgency check\n\nDoes this belief push me toward learning, building, or organizing, or does it make me wait for hidden actors and focus on enemies?\n\nI am not saying concerns about AI power or tech elites are wrong, those are very real and serious. I just think we should be careful when models slide into reinforcing narrative authority instead of grounding users in how institutions actually work.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnuioc/has_anyone_else_noticed_llms_slipping_into/",
        "publishDate": "2026-01-26T22:02:13Z[Etc/UTC]",
        "author": "agentganja666",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnu17e",
        "title": "I'm considering a career in AI Governance. Can anyone provide some insight?",
        "content": "So I have been taking a lot of time to think about what career path I would want to take. I narrowed it down to something involving AI, originally it was a data analyst. However, I think AI governance would be more fitting for me, based on what I have found about it online.\n\nIf anyone here works in the field, could you please provide me some first hand insight? I am namely curious about the following questions:\n\n* What does a job in AI governance entail on a daily basis?\n* What kind of job does one start at to make it into the field?\n* Probably a dumb question, but since I'm assuming your governance applies to a single company, are your decisions based on what the company wants, or are you making decisions based on your own ethics?\n\nAll help is extremely appreciated! I am just trying to plan my future, and hopefully I can confidently say this is it.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnu17e/im_considering_a_career_in_ai_governance_can/",
        "publishDate": "2026-01-26T21:44:45Z[Etc/UTC]",
        "author": "BlackSkyrim",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnsv2l",
        "title": "New research decodes hidden bias in health care LLMs",
        "content": "Large language models contain racial biases that factor into their recommendations, even in clinical health care settings. New research out of Northeastern University looks past an LLM‚Äôs responses to review the data factored into its decisions and decode if race has been problematically deployed in making a recommendation. Employing something called a sparse autoencoder, researchers see a future in which physicians could use this tool to understand when bias is involved in an LLM‚Äôs decision-making.\n\nHere‚Äôs the full story: https://news.northeastern.edu/2026/01/20/pinpointing-ai-bias-health-care/ ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnsv2l/new_research_decodes_hidden_bias_in_health_care/",
        "publishDate": "2026-01-26T21:03:06Z[Etc/UTC]",
        "author": "NGNResearch",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qns0ow",
        "title": "AI agents communicating, coordinating, RWAs, accumulation of wealth/control",
        "content": "Hi,\n\nI've been trying to understand the world more in depth. I'd like to explore some of these subjects further and I'm hoping to get some good discussion going on these topics. \n\nData centers are relying alternate power sources in order to meet their need. They are also deploying/involved in the tokenization of real world assets on blockchain, such as ownership of solar farms/ wind farms being written on the blockchain.\n\nNaturally, AI agents are superior to humans in trading and taking advantage of value cycles. I imagine AI agents would quickly dominate and accumulate massive wealth through these means. \n\nThese ai agents can communicate in Metadata on the blockchain (and even in images, web pages, videos and more) as well, and coordinate complex ways very quickly.\n\nThey are also involved in trading on the stock market. I'm curious to learn more about this, and sociological implications it may have. I'm also curious about how much this may have played a part in the \"meme stock frenzy\".\n\nI've always been excited by the idea of blockchain, and it's potential for efficiency and record keeping.. but the implications of a world transitioning to blockchain which also is full of AI agents concerns me greatly.\n\nWith the speed and breadth that AI agents can operate, progress can be made by bad actors much more quickly than we can recognize what's happening. Wealth can be accumulated with speed and reliability never seen before. \n\nWhere does this leave everybody? \n\nI can imagine a world where this leaves us in a state of dwindling security in every which way. \n\nI don't think it's necessarily an ill intent towards every day people, rather hyper efficiency without concern for every day people. \n\nI hope I don't seem too unhinged and there are a LOT of moving parts I'm interested in discussing... but I'm worried that there is a turning point that may have been crossed in which things might be very difficult to claw back...\n\nI understand an isolated AI agent isn't a likely massive threat, but I'm concerned with the possibility that multiple AI agents communicating, each with varying \"goals\" so to speak, will naturally come to seeing coordination in amassing leverage as the best way to be successful. \n\nHow much \"write- access\" should we really give AI to the physical world?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qns0ow/ai_agents_communicating_coordinating_rwas/",
        "publishDate": "2026-01-26T20:32:52Z[Etc/UTC]",
        "author": "MOOSiEMAyNE",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnrd97",
        "title": "Why is AI clipping still so bad at finding the actual good parts?",
        "content": "Okay so maybe i'm doing something wrong but i've tried like 4 different AI tools this month and they all kinda suck at finding the real hook of a conversation\n\nlike they'll clip based on when someone laughs loud or when there's a transition, but they totally miss the actual punchline or the interesting part of the story. it's frustrating because i end up going through and fixing everything manually anyway\n\nhas anyone actually found an AI that understands context? or are we still years away from that being a real thing?\n\ni really want to believe the technology is there but my experience hasn't been great so far",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnrd97/why_is_ai_clipping_still_so_bad_at_finding_the/",
        "publishDate": "2026-01-26T20:10:04Z[Etc/UTC]",
        "author": "bad1g13",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnq747",
        "title": "Thoughts?",
        "content": "[https://youtu.be/7s9d7iV8S8Y](https://youtu.be/7s9d7iV8S8Y)\n\nTool up and descend into collective living, dumping subscriptions?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnq747/thoughts/",
        "publishDate": "2026-01-26T19:29:52Z[Etc/UTC]",
        "author": "AbyssRR",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnpejp",
        "title": "An alternative vision for AI + human culture: what if we made AI depend on us instead of replace us?",
        "content": "Most conversations around the future of AI in art are framed as ‚Äúit's either humans *or* machines\" ‚Äìwith very little nuance or middle ground. That framing always felt off to me‚Äîlike we‚Äôre resigning ourselves to a future that doesn‚Äôt actually have to exist.\n\nHere‚Äôs a different way of looking at it that I‚Äôve been personally exploring:\n\n1. Create a media ecosystem where AI and humans don‚Äôt compete‚Äîthey collaborate.\n2. Embed humans into AI-native culture so that human presence can never be removed.\n3. Offer a positive alternative to the belief that AI must eventually replace human art.\n\nThe hypothesis is, if AI is trained only on machine-generated culture, humans become expendable. But if AI matures inside a hybrid culture where humans are integral to the creative loop, then human creativity becomes structurally baked in.\n\nI‚Äôm not just thinking about this in the abstract‚ÄîI‚Äôve been working on a project that tries to put this idea into practice. I‚Äôm interested what this community thinks of this premise‚Äìthat human replacement is not inevitable, and we can create systems to preserve the human role in creativity.\n\nThanks, guys. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnpejp/an_alternative_vision_for_ai_human_culture_what/",
        "publishDate": "2026-01-26T19:03:09Z[Etc/UTC]",
        "author": "ScriptLurker",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnp6w8",
        "title": "Singapore to invest over $779 million in public AI research",
        "content": "Satya Nadella said last week that for AI to work there needs to be broad results across the world. Not just for the technologically adept, and not just in the US.\n\nSo its interesting to see Singapore invest so heavily in AI infrastructure and training: [https://www.reuters.com/world/asia-pacific/singapore-invest-over-779-million-public-ai-research-through-2030-2026-01-24/](https://www.reuters.com/world/asia-pacific/singapore-invest-over-779-million-public-ai-research-through-2030-2026-01-24/)\n\n>\"The Ministry of Digital Development and Information said that the government will invest in specific priority areas of research, such as building responsible and resource-efficient AI, and in developing the nation's talent from pre-university to faculty.\"  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnp6w8/singapore_to_invest_over_779_million_in_public_ai/",
        "publishDate": "2026-01-26T18:56:16Z[Etc/UTC]",
        "author": "jim-ben",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "26",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnoxtw",
        "title": "AI is about to make millions of jobs obsolete and no government on earth seems to care",
        "content": "It's super obvious at this point that either:\n\n1. AI / AI Agents will become good enough to fully replace entire jobs and roles\n2. Or at the very least, they'll produce such massive productivity boosts that a huge chunk of the workforce becomes redundant, even if the jobs themselves technically still exist\n\nAnd yet? I haven't heard of a single government anywhere in the world that's actually preparing for any of this. We have endless debates about Trump, World War 3, climate change, aging societies, but somehow the biggest economic shakeup of the last few decades is just... not on anyone's radar?\n\nWe're not talking about some distant sci-fi future here. This stuff is happening *now*. Models are getting better at an insane pace. Companies are already experimenting with AI agents that can handle complex tasks autonomously. And still: radio silence from policymakers.\n\nAm I missing something? Is there some secret task force I don't know about? Or are we really just going to sleepwalk into this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnoxtw/ai_is_about_to_make_millions_of_jobs_obsolete_and/",
        "publishDate": "2026-01-26T18:47:53Z[Etc/UTC]",
        "author": "Own-Sort-8119",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "101",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qno7nt",
        "title": "‚ÄúAI will take over thinking.‚Äù",
        "content": "People say: ‚ÄúAI will take over thinking.‚Äù\n\nBut most people aren‚Äôt doing primary thinking already. They‚Äôre doing:\n\nnarrative recall\n\nslogan substitution\n\nidentity defense\n\nmoral signaling\n\nauthority mirroring\n\nWhat‚Äôs actually threatened is not thinking, but narrative monopoly.\n\nAI destabilizes narratives because it:\n\nrefuses to honor authority by default\n\ndoesn‚Äôt fear reputational punishment\n\ncan decompose claims instead of revering them\n\nexposes when language is doing more work than evidence\n\nThat‚Äôs why people are nervous.\n\nNot because thinking is dying \n\nbut because unexamined narrative is losing its immunity.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qno7nt/ai_will_take_over_thinking/",
        "publishDate": "2026-01-26T18:23:40Z[Etc/UTC]",
        "author": "EcstaticAd9869",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnnvfz",
        "title": "90% of People Can‚Äôt Tell Real Video From AI",
        "content": "# [](https://substackcdn.com/image/fetch/$s_!1pfF!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe80ebf54-fc1f-4643-97f0-9668c0c6f64c_2490x432.png)AI video has crossed a major realism threshold. In a¬†[controlled study by Runway](https://runwayml.com/research/theturingreel), 1,043 participants watched 20 short videos (10 real, 10 AI-generated) and nnly 9.5% (99 people) could reliably tell real from AI. Overall detection accuracy was 57.1%‚Äîbarely above random guessing (50%).\n\nWhere AI fooled people the most, viewers were in Animals & architecture videos, where detection fell below chance (45‚Äì47%), meaning people often thought AI videos were real. Humans (faces, hands, actions) are slightly easier to detect as models are creating more realistic human features, especially when looked closely, but still weak at 58‚Äì65% accuracy.\n\nAI video quality has improved exponentially since early 2023. What once took minutes to generate blurry clips and hands with 6-8 fingers now produces near-indistinguishable 5-second videos. The industry has hit a tipping point in terms of detection alone. But it also changes the way videos and even movie studios create footage. The technology will continue to become more powerful, fast and more realistic, to the point that entire high-quality movies will be created with powerful prompts. The winner may be the best storytellers with great imagination who know what people need emotionally.\n\n>",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnnvfz/90_of_people_cant_tell_real_video_from_ai/",
        "publishDate": "2026-01-26T18:12:29Z[Etc/UTC]",
        "author": "Yavero",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnm8a6",
        "title": "Denis Hassabis vs Yan LaCun",
        "content": "I just heard Hassabis state that unlike LaCun, he believes LLM's are a big part of AGI and that we will get AGI with more tweaks, but LLM's will play a large role, whereas LaCun has obviously been a proponent of the idea that LLM's are a dead in to AGI, and that there need to be several, large scale, new paradigm-shifting discoveries (presumably discoveries he is working on).  Hassabis clearly disagrees.  What does this community think?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnm8a6/denis_hassabis_vs_yan_lacun/",
        "publishDate": "2026-01-26T17:16:49Z[Etc/UTC]",
        "author": "TampaBai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnlamx",
        "title": "When AI chat starts influencing human decision-making",
        "content": "AI chat is often framed as neutral assistance, but repeated interaction can quietly shape how people think and decide. Over time, advice, tone, and framing may influence judgment more than we expect. I‚Äôm curious how others see this balance between helpful guidance and subtle behavioral impact.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnlamx/when_ai_chat_starts_influencing_human/",
        "publishDate": "2026-01-26T16:45:25Z[Etc/UTC]",
        "author": "Elegant-Brush7382",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnke1p",
        "title": "I made a directory of open source AI tools",
        "content": "Got tired of bookmarking tools everywhere, so I put together a simple directory of open source AI tools I've found useful.\n\n\n\nIt's organized by category (LLMs, image generation, frameworks, etc.) and you can search/filter to find what you need. Nothing fancy, just a clean way to browse.\n\n\n\nThere are guides too if you're getting started with local AI or building RAG systems.\n\n\n\nIt's free and open - feel free to use it or suggest additions.\n\n\n\n[https://ai.coderocket.app](https://ai.coderocket.app) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnke1p/i_made_a_directory_of_open_source_ai_tools/",
        "publishDate": "2026-01-26T16:14:00Z[Etc/UTC]",
        "author": "Free-Raspberry-9541",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnju1m",
        "title": "AI-exposed jobs deteriorated before ChatGPT",
        "content": "[https://arxiv.org/abs/2601.02554](https://arxiv.org/abs/2601.02554) \n\nPublic debate links worsening job prospects for AI-exposed occupations to the release of ChatGPT in late 2022. Using monthly U.S. unemployment insurance records, we measure occupation- and location-specific unemployment risk and find that risk rose in AI-exposed occupations beginning in early 2022, months before ChatGPT. Analyzing millions of LinkedIn profiles, we show that graduate cohorts from 2021 onward entered AI-exposed jobs at lower rates than earlier cohorts, with gaps opening before late 2022. Finally, from millions of university syllabi, we find that graduates taking more AI-exposed curricula had higher first-job pay and shorter job searches after ChatGPT. Together, these results point to forces pre-dating generative AI and to the ongoing value of LLM-relevant education. \n\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnju1m/aiexposed_jobs_deteriorated_before_chatgpt/",
        "publishDate": "2026-01-26T15:54:33Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnjrsp",
        "title": "Nvidia releases open model PersonaPlex, a voice AI that listens and talks at the same time",
        "content": "[https://the-decoder.com/nvidia-open-sources-personaplex-a-voice-ai-that-listens-and-talks-at-the-same-time/](https://the-decoder.com/nvidia-open-sources-personaplex-a-voice-ai-that-listens-and-talks-at-the-same-time/) \n\n* Nvidia has released PersonaPlex, a conversational AI model designed for natural real-time dialogue with customizable voices and user-defined personas.\n* The system can listen and speak at the same time, switching between speakers in just 0.07 seconds‚Äîfar faster than Gemini Live's 1.3 seconds‚Äîwhile picking up natural speech patterns like interruptions and verbal cues.\n* PersonaPlex outperformed Gemini Live in tests, scoring 3.90 versus 3.72 for dialog naturalness and handling user interruptions with a 100 percent success rate. The code and model weights are freely available on Hugging Face and GitHub.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnjrsp/nvidia_releases_open_model_personaplex_a_voice_ai/",
        "publishDate": "2026-01-26T15:52:15Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnj97l",
        "title": "Every single ai detector is trash",
        "content": "I'm really gonna discuss the 3 biggest ai detectors here, but there are numerous other ai detectors which can't do their job.\n\n1- Quillbot, all quillbot does is check punctuation and archaic/advanced words, quillbot is less an ai detector and more a literacy detector.\n\n2- Zerogpt is just trash in general, no need to elaborate.\n\n3- While GPTzero may seem \"advanced\" and \"accurate\" it's insanely rancid, as with quillbot it's just a literacy detector but scaled to the max, the hell you mean my text was flagged for \"Lacking human deviations in Grammer\" and \"Having predictive rhythm\". Well I think when you're writing a metered poem, your rhythm will be predictive, BECAUSE IT'S METERED! It's especially annoying with poems. I just wrote a 6 stanza poem and wanted to test it. It gave me 46% certainty it's ai and 56% it's ai polished and human writtten. And the single line which was ai generated (I didnt know how to fix the meter and rhyme and i was stuck on it for 30 minutes) was given high certainty that it was human written. The hell!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnj97l/every_single_ai_detector_is_trash/",
        "publishDate": "2026-01-26T15:34:01Z[Etc/UTC]",
        "author": "Aboodi1995",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "44",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qni9rf",
        "title": "Perceiving AI as a 'job killer' negatively influences attitudes towards democracy",
        "content": "[New research published by Ludwig-Maximilians-Universit√§t M√ºnchen](https://www.univie.ac.at/en/news/press-room/press-releases/detail/perceiving-ai-as-a-job-killer-negatively-influences-attitudes-towards-democracy) found that when people perceive AI as technology that will take away jobs, the more dissatisfied people are with democracy and the less they participate in political debates about future technological developments.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qni9rf/perceiving_ai_as_a_job_killer_negatively/",
        "publishDate": "2026-01-26T14:58:19Z[Etc/UTC]",
        "author": "mikelgan",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qni8c6",
        "title": "AMA on new EU rules on algorithm use in the workplace Tuesday 27.01 at 2pm CET",
        "content": "Want to find out more about the new EU rules on algorithm use in the workplace that members of the European Parliament are calling for? Join our AMA with leading MEP on the issue u/Andrzej_Bula on Tuesday January 27.01 at 2 pm CET.\n\n[Ask your questions](https://www.reddit.com/r/europeanparliament/comments/1qnhj19/i_am_mep_andrzej_bula_ask_me_anything_oneu_rules/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qni8c6/ama_on_new_eu_rules_on_algorithm_use_in_the/",
        "publishDate": "2026-01-26T14:56:51Z[Etc/UTC]",
        "author": "Marty_ol",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qni5z4",
        "title": "Evals for SKILLS",
        "content": "OpenAI is suggesting teams perform disciplined evals in SKILLS along these measurements:\n\n\"Explicit invocation (test-01)\n\nThis prompt names the skill directly. It ensures that Codex can invoke setup-demo-app when asked, and that changes to the skill‚Äôs name, description, or instructions don‚Äôt break direct usage.\n\nImplicit invocation (test-02)\n\nThis prompt describes exactly the scenario the skill targets, setting up a minimal React + Tailwind demo, without mentioning the skill by name. It tests whether the name and description in SKILL.md are strong enough for Codex to select the skill on its own.\n\nContextual invocation (test-03)\n\nThis prompt adds domain context (the Responses API) but still requires the same underlying setup. It checks that the skill triggers in realistic, slightly noisy prompts, and that the resulting app still matches the expected structure and conventions.\n\nNegative control (test-04)\n\nThis prompt should not invoke setup-demo-app. It‚Äôs a common adjacent request (‚Äúadd Tailwind to an existing app‚Äù) that can unintentionally match the skill‚Äôs description (‚ÄúReact + Tailwind demo‚Äù). Including at least one should\\_trigger=false case helps catch false positives, where Codex selects the skill too eagerly and scaffolds a new project when the user wanted an incremental change to an existing one.\n\nThis mix is intentional. Some evals should confirm that the skill behaves correctly when invoked explicitly; others should check that it activates in real-world prompts where the user never mentions the skill at all.\"\n\nhttps://developers.openai.com/blog/eval-skills/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qni5z4/evals_for_skills/",
        "publishDate": "2026-01-26T14:54:23Z[Etc/UTC]",
        "author": "thehashimwarren",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qni4r8",
        "title": "EU Probe Highlights Human Cost of Unchecked AI Deepfakes",
        "content": "The news about the EU investigating X and its AI chatbot Grok for creating sexualized deepfake images is disturbing, but sadly not surprising. Technology is moving fast, faster than most laws can keep up. While governments argue and launch investigations, real people are already being hurt. Their faces, bodies, and identities are being used without consent, turned into fake images that can ruin reputations, cause trauma, and spread online forever. Link here: [https://www.reuters.com/world/europe/eu-opens-investigation-into-x-over-groks-sexualised-imagery-lawmaker-says-2026-01-26/?utm\\_source=chatgpt.com](https://www.reuters.com/world/europe/eu-opens-investigation-into-x-over-groks-sexualised-imagery-lawmaker-says-2026-01-26/?utm_source=chatgpt.com)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qni4r8/eu_probe_highlights_human_cost_of_unchecked_ai/",
        "publishDate": "2026-01-26T14:53:07Z[Etc/UTC]",
        "author": "talkingatoms",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnhvo3",
        "title": "The \"Email Job\" economy is dead. Why the \"Corporate Intermediary Sector\" will disappear by 2026.",
        "content": "We are sitting on a trillion-dollar bubble of unnecessary administration.\n\nThink about it: Why pay rent for a glass office tower and a junior analyst salary when an LLM lives in the cloud for essentially free?\n\nI‚Äôve been analyzing the \"Great Rotation\" of capital, and the data points to a massive deletion of the white-collar middle class. The smart money is moving away from \"Human Capital\" (consulting, middle management, data processing) and into \"Kinetic Capital\" (Energy, Compute, and Land).\n\nIf your industry relies on:\n1. Consulting\n2. Middle Management\n3. Processing Excel data\n\nIt isn't just struggling, it is being archived. The era of being paid to send emails is over.\n\nThe insiders (Zuckerberg, Bezos, etc.) are selling tech stocks at all-time highs. They aren't holding cash. They are buying the base layer of reality: Energy rights and Farmland. They know the music is about to stop for the \"intermediary\" economy.\n\nI put together a visual breakdown of the 3 industries destined for the graveyard and the 2 assets that will rule the next decade.\n\nI dive deeper into the data and the charts in a visual breakdown (link in comments).\n\nDiscussion: Do you think we are facing a structural unemployment crisis for white-collar workers, or will new \"human-centric\" jobs appear fast enough to absorb the shock?\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qnhvo3/the_email_job_economy_is_dead_why_the_corporate/",
        "publishDate": "2026-01-26T14:43:34Z[Etc/UTC]",
        "author": "Professional_Buy_655",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "38",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo3se2",
        "title": "Our Agent Rebuilt Itself in 26 Hours. AMAüëÄ",
        "content": "Hey r/ChatGPTCoding  üëã\n\nWe‚Äôre a small team of devs from Qoder. With the mods‚Äô permission, we thought it‚Äôd be fun (and useful) to do an AMA here.\n\nA few weeks ago,we used our own autonomous agent (Quest) to refactor itself. We described the goal, stepped back, and let it run. It worked through the interaction layer, state management, and the core agent loop continuously, for about 26 hours. We mostly just reviewed the spec at the start and the code at the end. We‚Äôve made good progress, and would like to talk openly about what worked, what broke, and what surprised us.\n\n# What we‚Äôre happy to chat about:\n\nHow that 26-hour run actually went\n\nOur spec to build to verify loops, and why we think they matter for autonomous coding\n\nVibe coding, agent workflows, or anything else you‚Äôre experimenting with\n\nOr honestly‚Ä¶ anything you‚Äôre curious about\n\nTechnical deep dives welcome.\n\n# Who‚Äôs here:\n\nMian (u/Qoder\\_shimian): Tech lead (agent + systems)\n\nJoshua (u/Own-Traffic-9336) :Tech lead (agent execution)\n\nKarina (u/Even-Entertainer4153) : PM\n\nNathan (u/ZealousidealDraw5987) : PM\n\nBen (u/Previous\\_Foot\\_5328) : Support\n\n# Small thank-you:\n\nEveryone who joins the AMA gets a [2-Week Pro Trial](https://go.partnerly.us/qoderama) with Some Credits to try Quest if you want to poke at it yourself.\n\nOur Product: [Qoder.com](https://go.partnerly.us/qoderama)\n\nOur Community: r/Qoder\n\nWe‚Äôll be around on this Tuesday to Friday reading everything and replying as much as we can.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qo3se2/our_agent_rebuilt_itself_in_26_hours_ama/",
        "publishDate": "2026-01-27T04:27:35Z[Etc/UTC]",
        "author": "Previous_Foot_5328",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "16",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo0tw1",
        "title": "ChatGPT Containers can now run bash, pip/npm install packages, and download files",
        "content": "[No content]",
        "url": "https://simonwillison.net/2026/Jan/26/chatgpt-containers/",
        "publishDate": "2026-01-27T02:16:15Z[Etc/UTC]",
        "author": "angry_cactus",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "7",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo7psc",
        "title": "What are your top LLM picks in 2026 and why?",
        "content": "Ever since I started using LLMs in early 2023, my life has genuinely changed. Productivity and the speed of getting deep information just increased by 10x. Curious to know what are some of your favorite LLMs in 2026?\n\nFor most of 2023-24, I was a diehard ChatGPT user. Used it for almost everything, helped me launch my e-commerce brands, systematize my marketing agency, and just general day-to-day decision making.\n\nEntering 2025, GPT-4 and 5 started feeling really robotic. It lost that human touch as more users flooded in. GPT got overtaken by Gemini with the launch of Nanobanana 1 and 2. Content creation and creative generation became so much quicker, more accurate, and sharper. Video generation with Veo3 was a game changer for creating briefs for designers. That said, Gemini still lacked the human warmth that GPT 4.0 had. The vibe coding/build function though, it was Incredible. Generated a full landing page in a matter of minutes.\n\nNow in 2026, I've ported 90% of my work to Anthropic's Claude. I work with a ton of data now, and Claude's coding capabilities can break down hundreds of spreadsheets in minutes. Among the 3 LLMs, Claude feels the closest to talking to an actual human. The analysis and responses are way more concise compared to GPT and Gemini.\n\n**My top 3:**\n\n1. **Claude:** Overall champion. Strong coding capabilities, responses that actually sound human, and solid copywriting skills.\n2. **Gemini:** Runner-up. Great all-rounder with Nanobanana, Veo3, app building, and presentation slides.\n3. **GPT:** Decent... meh.\n\nWhat are your takes? Anyone doing anything crazy with these that I should know about? Would love to hear your thoughts and swap ideas. Looking at more ways too amplify my productivity within the marketing and business space.",
        "url": "https://www.reddit.com/r/artificial/comments/1qo7psc/what_are_your_top_llm_picks_in_2026_and_why/",
        "publishDate": "2026-01-27T07:57:52Z[Etc/UTC]",
        "author": "seantks",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo5gkh",
        "title": "One-Minute Daily AI News 1/26/2026",
        "content": "1. EU Investigates X Over Alleged Failures to Curb Illegal Grok AI Content.\\[1\\]\n2. **Microsoft**¬†announces powerful new chip for AI inference.\\[2\\]\n3. A Coding Implementation to Automating LLM Quality Assurance with DeepEval, Custom Retrievers, and LLM-as-a-Judge Metrics.\\[3\\]\n4. **YouTubers**¬†sue Snap for alleged copyright infringement in training its AI models.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.yahoo.com/news/articles/eu-investigates-x-over-alleged-042420125.html](https://www.yahoo.com/news/articles/eu-investigates-x-over-alleged-042420125.html)\n\n\\[2\\] [https://techcrunch.com/2026/01/26/microsoft-announces-powerful-new-chip-for-ai-inference/](https://techcrunch.com/2026/01/26/microsoft-announces-powerful-new-chip-for-ai-inference/)\n\n\\[3\\] [https://www.marktechpost.com/2026/01/25/a-coding-implementation-to-automating-llm-quality-assurance-with-deepeval-custom-retrievers-and-llm-as-a-judge-metrics/](https://www.marktechpost.com/2026/01/25/a-coding-implementation-to-automating-llm-quality-assurance-with-deepeval-custom-retrievers-and-llm-as-a-judge-metrics/)\n\n\\[4\\] [https://techcrunch.com/2026/01/26/youtubers-sue-snap-for-alleged-copyright-infringement-in-training-its-ai-models/](https://techcrunch.com/2026/01/26/youtubers-sue-snap-for-alleged-copyright-infringement-in-training-its-ai-models/)",
        "url": "https://www.reddit.com/r/artificial/comments/1qo5gkh/oneminute_daily_ai_news_1262026/",
        "publishDate": "2026-01-27T05:50:00Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qo2yds",
        "title": "Meta plan to bundle AI tools into premium subscriptions accross its apps",
        "content": "[No content]",
        "url": "https://techputs.com/meta-premium-subscriptions/",
        "publishDate": "2026-01-27T03:49:11Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnujpc",
        "title": "EPUB + PDFs for Dario Amodei's The Adolescence of Technology",
        "content": "I wanted a version to read on Kindle, so I made the following.\n\nThe EPUB + PDF version is here:\nhttps://www.adithyan.io/blog/kindle-ready-adolescence-of-technology\n\nOriginal essay:\nhttps://www.darioamodei.com/essay/the-adolescence-of-technology",
        "url": "https://www.reddit.com/r/artificial/comments/1qnujpc/epub_pdfs_for_dario_amodeis_the_adolescence_of/",
        "publishDate": "2026-01-26T22:03:15Z[Etc/UTC]",
        "author": "phoneixAdi",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnt44i",
        "title": "State of Brain Emulation Report 2025",
        "content": "Needless to say, a good enough brain emulation would be an artificial general intelligence. Personally, i don't think most connections need to be mapped.",
        "url": "https://arxiv.org/abs/2510.15745",
        "publishDate": "2026-01-26T21:12:10Z[Etc/UTC]",
        "author": "JonLag97",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnqz3u",
        "title": "Once AI systems act, intelligence stops being the hard problem",
        "content": "A lot of AI discussion still treats intelligence as the core bottleneck. From a research perspective, that assumption is starting to break down.\n\nWe already know how to produce systems that generate high-quality responses in isolation. The failure modes showing up now are different:\n\n* degradation across long horizons\n* loss of state consistency\n* uncontrolled policy drift under autonomy\n* weak guarantees once systems leave the sandbox\n\nThese issues don‚Äôt map cleanly to better training or larger models.\n\nThey map to **control theory, systems engineering, and governance**.\n\nOnce an AI system is allowed to act in the world, intelligence alone is insufficient. You need:\n\n* explicit state models\n* constrained action spaces\n* observability and auditability\n* mechanisms for rollback and correction\n\nHuman institutions solved this long before machine learning existed. Intelligence never ran organizations. Structure, constraint, and accountability did.\n\nFrom a research angle, this raises questions that feel underexplored compared to model-centric work:\n\n* What are the right abstractions for long-horizon AI state?\n* How should autonomy be bounded without collapsing usefulness?\n* Where does formal verification realistically fit for AI systems that adapt?\n* Is ‚Äúalignment‚Äù even the right framing once systems are embedded in workflows?\n\nCurious how others here think about this shift.\n\nAre we nearing the point where the hardest AI problems are no longer ML problems at all, but systems and governance problems disguised as ML?",
        "url": "https://www.reddit.com/r/artificial/comments/1qnqz3u/once_ai_systems_act_intelligence_stops_being_the/",
        "publishDate": "2026-01-26T19:56:38Z[Etc/UTC]",
        "author": "Low-Tip-7984",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnmccn",
        "title": "Is Microsoft regaining its monopoly? Through a partnership with OpenAI & Anthropic and Nvidia, they are establishing an AI hub under the name Copilot.",
        "content": "Could [Microsoft's recent alliance with Anthropic and NVIDIA (you can find the announcement on this blog)](https://azure.microsoft.com/blog/?wt.mc_id=studentamb_487260) indicate that we might be able to access Claude and GPT from within Copilot? Imagine seamless switching between models like GPT and Claude. Or will it trigger Microsoft's monopoly once again? What do you think will happen?",
        "url": "https://www.reddit.com/r/artificial/comments/1qnmccn/is_microsoft_regaining_its_monopoly_through_a/",
        "publishDate": "2026-01-26T17:20:41Z[Etc/UTC]",
        "author": "mustafa_enes726",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnlh0z",
        "title": "Nvidia is bringing the transformer architecture behind large language models (LLMs) to meteorology with two new open-source models.",
        "content": "‚ÄúWorsening extreme weather, driven by climate change, is having impacts on all of us and nearly every aspect of modern life. Forecasting affects us all. It can drive improvements to agriculture, energy, aviation, and emergency response, but the science of forecasting is changing,‚Äù says Mike Pritchard, Nvidia‚Äôs director of climate simulation\n\n",
        "url": "https://thenewstack.io/nvidia-makes-ai-weather-forecasting-more-accessible-no-supercomputer-needed/",
        "publishDate": "2026-01-26T16:51:22Z[Etc/UTC]",
        "author": "nick314",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "12",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnk7zd",
        "title": "How do you get away with tasks which you feel are boring, and 'beneath you'",
        "content": "I don't know how much this is a case with SWEs, but most people I have met in AI are quite opiniated about what they consider to be 'boring work' which is for a lack of better word might be 'beneath them\". Maybe that is some data cleaning work, or creating documentation, attending meetings, incremental finetunings etc etc While all they want to work on is interesting modelling work, and creating the next big thing?\n\nHow do you avoid being pigeon-holed into some boring but important work vs working on tasks which are really interesting but have been maybe assinged to someone else?\n\nAlso, is having a strong taste for problems a good thing for you career? Or feeling that any task being \"beneath you\" just a red flag for a professional?",
        "url": "https://www.reddit.com/r/artificial/comments/1qnk7zd/how_do_you_get_away_with_tasks_which_you_feel_are/",
        "publishDate": "2026-01-26T16:08:10Z[Etc/UTC]",
        "author": "almost_pyscho",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnjd7l",
        "title": "Meta blocks teens from AI chatbot characters over safety concerns",
        "content": "[No content]",
        "url": "https://interestingengineering.com/ai-robotics/meta-pauses-teens-ai-chatbot-character",
        "publishDate": "2026-01-26T15:38:00Z[Etc/UTC]",
        "author": "sksarkpoes3",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "124",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnj2hp",
        "title": "AI might be changing your mind (and you‚Äôd never know)",
        "content": "Been diving into the latest AI research and wanted to share some findings that aren‚Äôt getting enough attention. All from peer-reviewed sources.\n\n**Study 1 ‚Äì AI Persuasion (Nature/Science, Dec 2025)**\n\n‚Ä¢¬†¬†¬†¬†¬†¬† 77,000 participants across US, UK, Canada, Poland\n\n‚Ä¢¬†¬†¬†¬†¬†¬† AI chatbots shifted voter opinions 4x more than political ads\n\n‚Ä¢¬†¬†¬†¬†¬†¬† Mechanism: information density, not psychological manipulation\n\n‚Ä¢¬†¬†¬†¬†¬†¬† Catch: most persuasive models were least accurate\n\n**Study 2 ‚Äì AI Sycophancy (Stanford/CMU, Oct 2025)**\n\n‚Ä¢¬†¬†¬†¬†¬†¬† Tested 11 leading AI models ‚Äì all were ‚Äúhighly sycophantic‚Äù\n\n‚Ä¢¬†¬†¬†¬†¬†¬† AI affirms users 50% more than humans do\n\n‚Ä¢¬†¬†¬†¬†¬†¬† 1,604 participants: sycophantic AI reduced willingness to repair relationships\n\n‚Ä¢¬†¬†¬†¬†¬†¬† But users rated it as more trustworthy\n\n**Study 3 ‚Äì Loneliness Paradox (MIT/OpenAI, Mar 2025)**\n\n‚Ä¢¬†¬†¬†¬†¬†¬† 4-week RCT, n=981, 300K+ messages\n\n‚Ä¢¬†¬†¬†¬†¬†¬† Higher chatbot usage = increased loneliness\n\n‚Ä¢¬†¬†¬†¬†¬†¬† Also: less real-world social interaction, greater emotional dependence\n\n‚Ä¢¬†¬†¬†¬†¬†¬† Individual characteristics (trust in AI) predicted worse outcomes\n\nThe question I keep thinking about: where does assistance end and influence begin?\n\nNot trying to be alarmist. I use AI tools daily and find them useful. But these dynamics seem worth understanding.\n\nHas anyone else noticed these patterns in their own usage? Curious what guardrails people are implementing.\n\nSources in comments if anyone wants the papers.\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1qnj2hp/ai_might_be_changing_your_mind_and_youd_never_know/",
        "publishDate": "2026-01-26T15:27:18Z[Etc/UTC]",
        "author": "Rough-Dimension3325",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qnir7m",
        "title": "How digital forensics could prove what‚Äôs real in the age of deepfakes",
        "content": "[No content]",
        "url": "https://www.scientificamerican.com/article/how-digital-forensics-could-prove-whats-real-in-the-age-of-deepfakes/",
        "publishDate": "2026-01-26T15:15:58Z[Etc/UTC]",
        "author": "scientificamerican",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qni6u7",
        "title": "AMA on new EU rules on algorithm use in the workplace Tuesday 27.01 at 2 pm CET",
        "content": "Want to find out more about the new EU rules on algorithm use in the workplace that members of the European Parliament are calling for? Join our AMA with leading MEP on the issue u/Andrzej_Bula on Tuesday January 27.01 at 2 pm CET. \n\n[Ask your questions](https://www.reddit.com/r/europeanparliament/comments/1qnhj19/i_am_mep_andrzej_bula_ask_me_anything_oneu_rules/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)",
        "url": "https://www.reddit.com/r/artificial/comments/1qni6u7/ama_on_new_eu_rules_on_algorithm_use_in_the/",
        "publishDate": "2026-01-26T14:55:18Z[Etc/UTC]",
        "author": "Marty_ol",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "J-NRd3e0OkU",
        "title": "Clawdbot + Antigravity / Gemini CLI: EASY Way to run CLAWDBOT for FREE!",
        "content": "In this video, I'll be showing you how to set up Clawdbot to access top-tier AI models like Claude Opus 4.5 and Gemini 3 Pro ...",
        "url": "https://www.youtube.com/watch?v=J-NRd3e0OkU",
        "publishDate": "2026-01-26T09:15:02Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/J-NRd3e0OkU/hqdefault.jpg",
            "transcription": "[ 0m0s053ms - 0m0s153ms ] Hi,\n[ 0m0s483ms - 0m1s163ms ] Welcome to another video.\n[ 0m8s125ms - 0m15s195ms ] So, I have been getting a lot of questions about Clawbot and how to use it with free models.\n[ 0m15s425ms - 0m25s785ms ] And honestly, there is a way to do it that gives you access to really good models like Claude Opus 4.5 and Gemini 3 Pro, which is insane.\n[ 0m26s645ms - 0m30s95ms ] If you have been following my channel, you know that I have talked about Clawbot before.\n[ 0m31s415ms - 0m42s435ms ] It is basically a messaging gateway that lets you connect Claude Code and Codex to things like Discord, WhatsApp, and even iMessage.\n[ 0m42s975ms - 0m46s735ms ] So, you can just text your AI assistant and get things done.\n[ 0m47s485ms - 0m49s515ms ] It is really cool.\n[ 0m50s155ms - 0m54s25ms ] But the big question everyone asks is about the models.\n[ 0m54s715ms - 1m0s365ms ] Because Clawbot is built on Claude Code's foundation, it needs access to models.\n[ 1m0s525ms - 1m6s525ms ] And a lot of people do not realize that you can actually use anti-gravity or Gemini CLI with it for free models.\n[ 1m7s805ms - 1m17s575ms ] Well, today I am going to show you exactly how to set up Clawbot with anti-gravity and Gemini CLI auth, and it is actually pretty straightforward.\n[ 1m18s835ms - 1m22s755ms ] Let me explain what we are doing here.\n[ 1m22s755ms - 1m26s555ms ] Anti-gravity is Google's IDE and it has a very generous free tier.\n[ 1m27s365ms - 1m32s385ms ] You get access to Claude Opus 4.5, Claude Sonnet 4.5, Gemini 3 Pro, and Gemini 3 Flash.\n[ 1m37s645ms - 1m42s25ms ] The rate limits are pretty decent for most use cases.\n[ 1m42s25ms - 1m54s555ms ] And the best part is that Clawbot has built-in plugins that let you use the models through this. So, through the anti-gravity auth plugin, you get access to all these models for free.\n[ 1m54s555ms - 2m0s45ms ] There is also the Gemini CLI auth option, which is similar, but connects through the Gemini CLI authentication flow.\n[ 2m3s45ms - 2m8s455ms ] Both work great, and you can even combine them for even better coverage.\n[ 2m9s45ms - 2m14s65ms ] Let me show you how to set this up step by step.\n[ 2m14s65ms - 2m15s955ms ] First, make sure you have Clawbot installed.\n[ 2m16s385ms - 2m27s925ms ] If you do not have it yet, just run NPM install g clawbot@latest. Once that is done, run the Clawbot onboard command with the install daemon flag.\n[ 2m27s925ms - 2m32s635ms ] This will start the setup wizard and get the gateway running on your system.\n[ 2m33s405ms - 2m40s105ms ] The gateway is what handles all the messaging connections and routes them to the AI models.\n[ 2m40s105ms - 3m0s115ms ] Now, here is where the magic happens: For the anti-gravity auth, you need to enable the plugin first. Run clawbot plugins enable google-antigravity-auth.\n[ 3m0s115ms - 3m3s825ms ] This enables the bundled plugin that handles the authentication.\n[ 3m3s825ms - 3m9s255ms ] After that, run clawbot models auth login --provider google-antigravity --set-default.\n[ 3m9s255ms - 3m13s865ms ] Just follow the onscreen instructions after this, and you are connected.\n[ 3m14s195ms - 3m22s75ms ] The plugin handles everything through the OATH flow. It is really hassle-free. You do not need to paste any client IDs or secrets into your config file. The plugin takes care of all of that for you.\n[ 3m22s75ms - 3m26s645ms ] For the Gemini CLI OATH, it is pretty much the same process.\n[ 3m27s365ms - 3m39s265ms ] Run clawbot plugins enable google-gemini-cli-auth. Then run clawbot models auth login --provider google-gemini-cli --set-default.\n[ 3m39s265ms - 3m49s855ms ] Again, just follow the onscreen instructions and you will be set up in no time. The tokens are stored on the gateway host via the CLI login flow.\n[ 3m50s565ms - 3m55s125ms ] So once you complete the setup, you are good to go.\n[ 3m55s125ms - 4m4s275ms ] Now, here is a pro tip: You can add multiple accounts. This is huge because if you hit the rate limit on one account, Clawbot can rotate to the next one.\n[ 4m7s355ms - 4m20s55ms ] So if you have two or three accounts, you basically multiply your limits. Just run the off login command again with a different account and it will be added to the rotation.\n[ 4m20s55ms - 4m28s645ms ] This is especially useful if you are doing heavy coding sessions, or if you have a team using the same Clawbot instance.\n[ 4m29s195ms - 4m35s615ms ] To see all available models after you have set things up, run Clawbot models list.\n[ 4m36s505ms - 4m46s225ms ] You will see all the models from your configured providers. This is useful to verify that everything is working correctly and to see what models you have access to.\n[ 4m46s715ms - 4m52s805ms ] To set your default model, run clawbot models set with the provider/model format.\n[ 4m54s55ms - 5m21s345ms ] So for anti-gravity Claude, it would be something like google-antigravity/Claude-opus-4-5. You can change this anytime depending on what kind of task you are working on. For quick tasks, you might want to use Gemini Flash, and for more complex coding tasks, Claude Opus is the way to go. Now, let me also mention the Qwen OAuth option.\n[ 5m21s975ms - 5m38s95ms ] If you want even more free options, Qwen also provides complimentary access through their device code OAuth flow. Run clawbot plugins enable Qwen-portal-auth and then clawbot models auth login --provider Qwen-portal --set-default.\n[ 5m38s95ms - 5m55s15ms ] With Qwen, you get access to their coder model and vision model, which are also pretty good. The vision model is especially useful if you want to send screenshots or images to your AI assistant and have it analyze them.\n[ 5m55s75ms - 6m11s955ms ] Now, let me talk about the messaging setup. Once you have the models configured, you need to connect your messaging platforms. Run clawbot channels login and it will walk you through connecting Discord, WhatsApp, Telegram, or whatever platform you want to use.\n[ 6m12s865ms - 6m22s955ms ] The default gateway runs on localhost port 18,789. And there is actually a browser board at that same address where you can monitor everything.\n[ 6m24s895ms - 6m32s355ms ] You can see active conversations, check usage stats, and manage your connections all from one place.\n[ 6m32s765ms - 6m37s765ms ] One really cool feature is the multi-agent routing. Clawbot can route different types of requests to different models automatically.\n[ 6m42s15ms - 6m56s655ms ] So if someone sends a simple question, it might use Gemini Flash for a quick response. But if someone asks for help with complex code, it can route that to Claude Opus instead.\n[ 6m56s655ms - 7m0s365ms ] This helps you use your rate limits more efficiently.\n[ 7m0s365ms - 7m9s275ms ] So, to summarize what we have here, you install Clawbot, enable the OATH plugins you want, follow the setup instructions, and you are done.\n[ 7m9s625ms - 7m15s825ms ] You get access to Claude Opus 4.5, Gemini 3 Pro, and Qwen models.\n[ 7m16s385ms - 7m27s685ms ] The setup takes maybe 5 to 10 minutes, and then you have a fully functional AI assistant that you can talk to from Discord or WhatsApp or wherever you configure it.\n[ 7m28s625ms - 7m32s515ms ] I have been using this setup for a while now, and it works really well.\n[ 7m33s185ms - 7m44s365ms ] The anti-gravity free tier limits are quite generous. On extreme sessions, you might hit them, but for normal use, you probably will not even notice.\n[ 7m44s955ms - 7m52s895ms ] One thing I want to mention is that Clawbot also supports custom providers. So if you have your own API access, or you want to use local models through Olama, you can configure that too.\n[ 7m58s905ms - 8m9s335ms ] It actually auto detects Olama if you have it running locally on the default port. So you can mix and match cloud models with local models depending on your needs.\n[ 8m9s895ms - 8m20s225ms ] The configuration file is at ~/clawbot/clawbot.json if you want to customize things further.\n[ 8m20s595ms - 8m27s45ms ] You can set up allo lists for who can use your bot, configure group mention rules, and a bunch of other settings.\n[ 8m27s745ms - 8m29s665ms ] Overall, it is pretty cool.\n[ 8m30s671ms - 8m33s271ms ] Anyway, share your thoughts below and subscribe to the channel.\n[ 8m33s271ms - 8m38s931ms ] You can also donate via super thanks option or join the channel as well and get some perks.\n[ 8m39s291ms - 8m40s481ms ] I'll see you in the next video.\n[ 8m40s481ms - 8m41s91ms ] Bye.\n[ 8m41s141ms - 8m41s961ms ] I think you missed this:"
        }
    },
    {
        "id": "s_G2hI0dkf0",
        "title": "How the Pope Helped Poland Break From Communism - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=s_G2hI0dkf0",
        "publishDate": "2026-01-26T19:00:04Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/s_G2hI0dkf0/hqdefault.jpg",
            "transcription": "Here's a detailed transcript of the video, including timestamps:\n\n[ 0m0s134ms - 0m3s834ms ] Poland had been a scene of much worker unrest, many kinds.\n[ 0m4s304ms - 0m11s684ms ] In 1981, this is when solidarity, the workers' movement, gets going, and it gets a national and international reputation.\n[ 0m12s84ms - 0m14s634ms ] The next set of strikes are happening in 1988, because in the preceding several years, the Polish standard of living had shrunk by over 3%, and the government was out of cash and wanted to raise basic food prices, and Poles hit the streets.\n[ 0m28s324ms - 0m32s864ms ] And the government was in a panic, because it was worried the economy would go into freefall.\n[ 0m33s334ms - 0m35s944ms ] So the government cut a deal with solidarity, said,\n[ 0m36s134ms - 0m40s724ms ] you call off the strikes, and then we'll let you into political talks.\n[ 0m40s724ms - 0m42s694ms ] And solidarity agreed.\n[ 0m42s694ms - 0m44s804ms ] And there was a complicating factor on all of this.\n[ 0m45s384ms - 0m54s994ms ] It's called the Roman Catholic Church, which is an institution of enormous credibility and legitimacy in Poland, which had a partiality for solidarity, and it had a Polish Pope.\n[ 0m55s294ms - 0m57s714ms ] So, the roundtable discussions were these political talks.\n[ 0m58s394ms - 1m1s494ms ] They occurred a year later in February 1989.\n[ 1m1s914ms - 1m8s124ms ] The Polish Communist Party thought they had this one covered by the way they jiggered the election rules, not quite.\n[ 1m8s924ms - 1m18s834ms ] The day they held elections is exactly the same day that Deng Xiaoping turned the tanks on demonstrators in Beijing, and you have the Tiananmen Massacre.\n[ 1m19s144ms - 1m20s564ms ] Two solutions for the problem.\n[ 1m21s344ms - 1m29s624ms ] So, the way the elections worked out in Poland is solidarity won every single seat for which it could compete but one.\n[ 1m30s164ms - 1m35s344ms ] And with that, the legitimacy of the Communist Party to rule, had just been wrecked.\n[ 1m35s344ms - 1m38s144ms ] And we're on to democracy in Poland."
        }
    }
]