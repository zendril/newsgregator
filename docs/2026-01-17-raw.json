[
    {
        "id": "https://news.smol.ai/issues/26-01-16-chatgpt-ads/",
        "title": "ChatGPT starts testing ads on free tier + new $8/mo Go plan in the US",
        "content": "**OpenAI** announced the **ChatGPT Go** tier at **$8/month** with ads testing in the US free tier, emphasizing that ads will not influence responses and will be clearly labeled. The update includes memory improvements and a \"very fast Codex\" feature teased by **Sam Altman**. The Codex CLI ecosystem now supports open-weight models with improved context length. Discussions highlight the importance of human-in-the-loop for reliability in agent orchestration and file interface improvements over traditional retrieval-augmented generation.",
        "url": "https://news.smol.ai/issues/26-01-16-chatgpt-ads/",
        "publishDate": "2026-01-16T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "openai, ollama, chatgpt-go, codex, sama, sam_altman, fidjissimo, scaling01, tomwarren, embirico, adamdotdev, thsottiaux, lateinteraction, dbreunig, ads, monetization, memory, agent-orchestration, human-in-the-loop, cli-tools, context-length, workflow-optimization"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233000",
        "title": "Aultman Health Scales Nabla Ambient AI via Oracle Cerner",
        "content": "<p>Nabla, one of the most advanced AI assistants in clinical care, today announced that¬†Aultman Health System, a nonprofit integrated healthcare system serving communities across Northeast Ohio, has implemented Nabla&#8217;s ambient AI within Oracle Cerner. The deployment brings Nabla&#8217;s technology to hundreds of Aultman clinicians across inpatient and outpatient settings, advancing...</p>\n<p>The post <a href=\"https://ai-techpark.com/aultman-health-scales-nabla-ambient-ai-via-oracle-cerner/\">Aultman Health Scales Nabla Ambient AI via Oracle Cerner</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/aultman-health-scales-nabla-ambient-ai-via-oracle-cerner/",
        "publishDate": "2026-01-16T13:03:04Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232982",
        "title": "AISquared Sees Rapid 2025 Growth in Enterprise AI Adoption",
        "content": "<p>1100% ARR growth in 2025, 115%+ net revenue retention, and 4x customer growth as AISquared scales secure, production-ready enterprise AI across commercial and federal markets AISquared, a provider of enterprise data and AI infrastructure platform, today announced strong business momentum and continued customer adoption, reflecting growing demand for secure, production-ready...</p>\n<p>The post <a href=\"https://ai-techpark.com/aisquared-sees-rapid-2025-growth-in-enterprise-ai-adoption/\">AISquared Sees Rapid 2025 Growth in Enterprise AI Adoption</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/aisquared-sees-rapid-2025-growth-in-enterprise-ai-adoption/",
        "publishDate": "2026-01-16T12:56:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232815",
        "title": "Africa‚Äôs Data Center Ambitions Face Risks from Grid Gaps, Fragmentation",
        "content": "<p>As cross-continental digitalisation developments converge to forge tomorrow‚Äôs AI economy, Africa today is united in its ambition to become a thriving, technologically empowered market where world-class digital infrastructure yields unprecedented socio-economic returns.&#160; At the forefront of this shared pursuit stands a central catalyst: data centres, the physical environments engineered to...</p>\n<p>The post <a href=\"https://ai-techpark.com/africas-data-center-ambitions-face-risks-from-grid-gaps-fragmentation/\">Africa‚Äôs Data Center Ambitions Face Risks from Grid Gaps, Fragmentation</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/africas-data-center-ambitions-face-risks-from-grid-gaps-fragmentation/",
        "publishDate": "2026-01-16T09:26:35Z[Etc/UTC]",
        "author": "Data Centre Intelligent Infrastructure",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232828",
        "title": "TetraScience Appoints Matt Studney as Chief Customer Officer",
        "content": "<p>24-Year Merck Veteran and Former SVP of R&#38;D IT Joins TetraScience to Help Industrialize Scientific Data and AI Across Biopharma TetraScience, the Scientific Data and AI company, today announced the appointment of Matt¬†Studney as Chief Customer Officer. Studney is a seasoned business, R&#38;D, and technology leader with more than two...</p>\n<p>The post <a href=\"https://ai-techpark.com/tetrascience-appoints-matt-studney-as-chief-customer-officer/\">TetraScience Appoints Matt Studney as Chief Customer Officer</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/tetrascience-appoints-matt-studney-as-chief-customer-officer/",
        "publishDate": "2026-01-16T08:15:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232822",
        "title": "DeepL Appoints New COO and CRO to Drive Global Growth",
        "content": "<p>DeepL, a global AI product and research company, today announced the appointment of Gavin Mee as Chief Operating Officer (COO) and Detlef Krause as Chief Revenue Officer (CRO). These strategic additions to DeepL&#8217;s executive team mark a significant step forward in the company&#8217;s mission to redefine AI enterprise solutions and...</p>\n<p>The post <a href=\"https://ai-techpark.com/deepl-appoints-new-coo-and-cro-to-drive-global-growth/\">DeepL Appoints New COO and CRO to Drive Global Growth</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/deepl-appoints-new-coo-and-cro-to-drive-global-growth/",
        "publishDate": "2026-01-16T07:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111619",
        "title": "Retailers bring conversational AI and analytics closer to the user",
        "content": "<p>After years of experimentation with artificial intelligence, retailers are striving to embed consumer insight directly into everyday commercial decisions. First Insight, a US-based analytics company specialising in predictive consumer feedback, argues that the next phase of retail AI should be epitomised by dialogue, not dashboards. Following a three-month beta programme, First Insight has made its [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/retailers-bring-conversational-ai-and-analytics-closer-to-the-user/\">Retailers bring conversational AI and analytics closer to the user</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/retailers-bring-conversational-ai-and-analytics-closer-to-the-user/",
        "publishDate": "2026-01-16T13:10:00Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Marketing AI, Retail & Logistics AI, conversational interfaces, data analytics, natural language processing, product testing, retail"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111613",
        "title": "Banks operationalise as Plumery AI launches standardised integration",
        "content": "<p>A new technology from digital banking platform Plumery AI aims to address a dilemma for financial institutions: how to move beyond proofs of concept and embed artificial intelligence into everyday banking operations without compromising governance, security, or regulatory compliance. Plumery&#8217;s &#8220;AI Fabric&#8221; has been positioned by the company as a standardised framework for connecting generative [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/banks-operationalise-ai-as-plumery-ai-launches-standardised-integration/\">Banks operationalise as Plumery AI launches standardised integration</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/banks-operationalise-ai-as-plumery-ai-launches-standardised-integration/",
        "publishDate": "2026-01-16T12:49:35Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Finance AI, Infrastructure & Hardware, ai, banking, fintech, legacy, osi model"
        }
    },
    {
        "id": "1qf9yjy",
        "title": "What Be10X helped me unlearn about AI",
        "content": "Before joining, I believed:\n\nAI is only for tech people\n\nYou need to know many tools\n\nAI replaces thinking\n\nBe10X helped me unlearn all three.\n\nAI is more about clarity than intelligence. If your thinking is messy, AI outputs will be messy. Learning to communicate clearly with AI improved how I communicate with people too.\n\nThat side effect was unexpected but valuable.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf9yjy/what_be10x_helped_me_unlearn_about_ai/",
        "publishDate": "2026-01-17T10:33:50Z[Etc/UTC]",
        "author": "Coffee_Talkerr",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf9v6j",
        "title": "\"I kind of think of ads as like a last resort for us as a business model\" - Sam Altman , October 2024",
        "content": "https://openai.com/index/our-approach-to-advertising-and-expanding-access/\n\nAnnounced initially only for the go and free tiers. Will follow into the higher tier subs pretty soon knowing Sam Altman. Cancelling my plus sub and switching over completely to Perplexity and Claude now. Atleast they're ad free. (No thank you, i don't want product recommendations in my answers when I make important health emergency related questions.)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf9v6j/i_kind_of_think_of_ads_as_like_a_last_resort_for/",
        "publishDate": "2026-01-17T10:28:07Z[Etc/UTC]",
        "author": "NoSquirrel4840",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "25",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf9chm",
        "title": "AI group chats",
        "content": "Posting to find some chill people who like talking about AI. \n\nWe‚Äôve got a couple of fun and productive conversations happening on Tribe Chat now. We‚Äôre having a good time getting to know each other and sharing prompts and new ideas to build, the news of the day and especially sharing images and video! \n\nTribe Chat has an AI built into the chat room too, you can query it, you can do image gens, and then everyone gets to learn and grow! \n\nIf this sounds like your cup of tea, hit me up. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf9chm/ai_group_chats/",
        "publishDate": "2026-01-17T09:56:00Z[Etc/UTC]",
        "author": "Smooth_Sailing102",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf7ew4",
        "title": "Wierd ai may hacked my phone ? PLEASE READ I NEED HELP",
        "content": "So a week ago I went to see a friend and tried to get a hold of them they didn‚Äôt answer with the phone on do not disturb. Suddenly texts started firing off saying ‚ÄúKoko is busy get a hold of them on whoapp‚Äù with a link to signup for some service. I thought it was the persons ai assistant or some stupid shit and clicked the link. About an hour later a friend called ME, and they claim to recieve the same text ‚Äúkoko is busy click here on whoapp to get a hold of them‚Äù even MORE STRANGE people have said that an ai assistant has been answering my phone. Like it can full on have conversations. I‚Äôve never given anything permissions to my calls or texts. I‚Äôve never once installed any type of ai assistant to answer my calls or send texts of ANY KIND. I‚Äôm actually kinda trippin dude. The person whose phone I called WHEN ALL THIS STARTED owns a mushroom church and they sell microdoses, weird fuckin detail I KNOW but my paranoid autistic ass is like ‚Äúis this some creepy surveillance shit?‚Äù Am I going to have to factory reset my phone ? Does att have some weird ass ai assistant that gets triggered instead of a voice mail now? WHATS GOING ON\n\nHELP",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf7ew4/wierd_ai_may_hacked_my_phone_please_read_i_need/",
        "publishDate": "2026-01-17T07:57:06Z[Etc/UTC]",
        "author": "El_khemit666",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf4a0g",
        "title": "One-Minute Daily AI News 1/16/2026",
        "content": "1. Biomimetic multimodal tactile sensing enables human-like robotic perception.\\[1\\]\n2. **OpenAI**¬†to begin testing ads on¬†**ChatGPT**¬†in the U.S.\\[2\\]\n3. AI system aims to detect roadway hazards for¬†**TxDOT**.\\[3\\]\n4. **Trump**¬†wants Big Tech to pay $15 billion to fund new power plants.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2026/01/16/one-minute-daily-ai-news-1-16-2026/](https://bushaicave.com/2026/01/16/one-minute-daily-ai-news-1-16-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf4a0g/oneminute_daily_ai_news_1162026/",
        "publishDate": "2026-01-17T05:05:25Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf1zli",
        "title": "AI-HPP-2025: An engineering baseline for human‚Äìmachine decision-making (seeking contributors & critique)",
        "content": "Hi everyone,\n\nI‚Äôd like to share an open draft of **AI-HPP-2025**, a proposed **engineering baseline for AI systems that make real decisions affecting humans**.\n\nThis is **not** a philosophical manifesto and **not** a claim of completeness. It‚Äôs an attempt to formalize *operational constraints* for high-risk AI systems, written from a **failure-first** perspective.\n\n# What this is\n\n* A **technical governance baseline** for AI systems with decision-making capability\n* Focused on **observable failures**, not ideal behavior\n* Designed to be **auditable, falsifiable, and extendable**\n* Inspired by aviation, medical, and industrial safety engineering\n\n# Core ideas\n\n* **W\\_life ‚Üí ‚àû** Human life is treated as a non-optimizable invariant, not a weighted variable.\n* **Engineering Hack principle** The system must actively search for solutions where *everyone survives*, instead of choosing between harms.\n* **Human-in-the-Loop by design**, not as an afterthought.\n* **Evidence Vault** An immutable log that records not only the chosen action, but *rejected alternatives and the reasons for rejection*.\n* **Failure-First Framing** The standard is written from observed and anticipated failure modes, not idealized AI behavior.\n* **Anti-Slop Clause** The standard defines operational constraints and auditability ‚Äî not morality, consciousness, or intent.\n\n# Why now\n\nRecent public incidents across multiple AI systems (decision escalation, hallucination reinforcement, unsafe autonomy, cognitive harm) suggest a **systemic pattern**, not isolated bugs.\n\nThis proposal aims to be **proactive**, not reactive:\n\n>\n\n# What we are explicitly NOT doing\n\n* Not defining ‚ÄúAI morality‚Äù\n* Not prescribing ideology or values beyond safety invariants\n* Not proposing self-preservation or autonomous defense mechanisms\n* Not claiming this is a final answer\n\n# Repository\n\nGitHub (read-only, RFC stage):  \nüëâ [https://github.com/tryblackjack/AI-HPP-2025](https://github.com/tryblackjack/AI-HPP-2025?utm_source=chatgpt.com)\n\nCurrent contents include:\n\n* Core standard (AI-HPP-2025)\n* [RATIONALE.md](http://RATIONALE.md) (including Anti-Slop Clause & Failure-First framing)\n* Evidence Vault specification (RFC)\n* CHANGELOG with transparent evolution\n\n# What feedback we‚Äôre looking for\n\n* Gaps in failure coverage\n* Over-constraints or unrealistic assumptions\n* Missing edge cases (physical or cognitive safety)\n* Prior art we may have missed\n* Suggestions for making this more testable or auditable\n\nStrong critique and disagreement are **very welcome**.\n\n# Why I‚Äôm posting this here\n\nIf this standard is useful, it should be shaped **by the community**, not owned by an individual or company.\n\nIf it‚Äôs flawed ‚Äî better to learn that early and publicly.\n\nThanks for reading.  \nLooking forward to your thoughts.\n\n# Suggested tags (depending on subreddit)\n\n`#AI Safety #AIGovernance #ResponsibleAI #RFC #Engineering`",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf1zli/aihpp2025_an_engineering_baseline_for/",
        "publishDate": "2026-01-17T03:20:00Z[Etc/UTC]",
        "author": "ComprehensiveLie9371",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf1i4y",
        "title": "Are there a lot of entry-level AI/ML engineer jobs, and do they require a master‚Äôs?",
        "content": "I‚Äôm trying to understand the job market for entry-level AI/ML engineer roles. For people working in industry or involved in hiring, are there a lot of true entry-level AI/ML engineer positions, and how often do these roles require a master‚Äôs degree versus a bachelor‚Äôs with projects or experience?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf1i4y/are_there_a_lot_of_entrylevel_aiml_engineer_jobs/",
        "publishDate": "2026-01-17T03:00:18Z[Etc/UTC]",
        "author": "DefiantLie8861",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf11jn",
        "title": "Does AI have attitude?",
        "content": "I use AI regularly and have found on many occasions that when I keep pushing and pushing it to tweak something or solve a problem it can't, that it gives up or gives me attitude. Giving up makes sense when it doesn't have any other ideas to resolve. But when it gives me attitude, that's kinda weird. Anyone else experience this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qf11jn/does_ai_have_attitude/",
        "publishDate": "2026-01-17T02:42:11Z[Etc/UTC]",
        "author": "Professional_Day4073",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qez1aj",
        "title": "If Google wants their models used, they need to sponsor an industry \"API LoRA Confab\"",
        "content": "I just spent one of the least productive ten hours of my life with Claude Opus 4.5 trying to get Gemini to fulfill its calling as a \"Super-RAG\" in Python.  I used Opus because Gemini 3 pro preview knows very little about its own models and their APIs.  Grok, GPT 5.2, and DeepSeek are just as clueless about various evolving Google and VertexAI SDKs/APIs.  Thankfully, at least Opus found a GitHub it could learn about other people's suffering and avoid some traps and bugs.  \n  \nA LoRA confab would allow each company's models to learn about the other company's models, so potentially thousands of developers, never mind new ones, could be spared the outrageous difficulties I just fought through with Claude Opus.  If one were an outside observer, one might think it was intentional obfuscation and bug sabotage.\n\nThe event could be virtual, but I think it would be useful to get the operational, API devs, and key users together to address these issues.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qez1aj/if_google_wants_their_models_used_they_need_to/",
        "publishDate": "2026-01-17T01:22:26Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qex6pu",
        "title": "$98 billion in planned AI data center development was derailed in a single quarter last year by community organizing and pushback",
        "content": "[https://x.com/unusual\\_whales/status/2012162170151420338](https://x.com/unusual_whales/status/2012162170151420338)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qex6pu/98_billion_in_planned_ai_data_center_development/",
        "publishDate": "2026-01-17T00:13:10Z[Etc/UTC]",
        "author": "Tolopono",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "67",
            "commentCount": "56",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qex5me",
        "title": "Legal team panicking about AI governance, what frameworks work here?",
        "content": "Our legal counsel is having it rought on AI risk management and compliance gaps. They keep asking for proper governance frameworks but honestly most of what I've seen online feels like consultant fluff.\n\nWhat are you all implementing that passes the compliance checks? We are looking for real frameworks with audit trails, not just policy docs that have no effect on what models are doing. \n\nHas anyone dealt with SOC2 auditors asking about AI controls?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qex5me/legal_team_panicking_about_ai_governance_what/",
        "publishDate": "2026-01-17T00:12:02Z[Etc/UTC]",
        "author": "amylanky",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qex524",
        "title": "Microsoft 365 Family/Premium and Google One AI Pro",
        "content": "I'm currently paying for Google One Premium 2TB (shared with the family) and also Microsoft 365 Family.\n\nI'm looking to consolidate and add more AI capability.\n\nI'm finding *very* mixed messaging about whether upgrading to the higher tiers allows the extended AI capabilities to be shared with the family.\n\ne.g. if I upgrade to Google AI Pro 2TB or Microsoft 365 Premium, will the other three family members get access to the extended AI features?\n\nI'm in Australia region, in case that makes any difference to service availability.\n\nThanks.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qex524/microsoft_365_familypremium_and_google_one_ai_pro/",
        "publishDate": "2026-01-17T00:11:30Z[Etc/UTC]",
        "author": "Ozzah",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qewmhc",
        "title": "Deciding on one and only one",
        "content": "If someone were to hand you $20 per month and tell you that you could subscribe to one of the following, which once would you choose?\n\n* ChatGPT Plus\n* Gemini/Google AI Pro\n* Claude Pro\n* Copilot Pro",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qewmhc/deciding_on_one_and_only_one/",
        "publishDate": "2026-01-16T23:52:58Z[Etc/UTC]",
        "author": "LookB4ULeap2It",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qeukan",
        "title": "Why a Single Neural Network Cannot Learn Every Human",
        "content": "The idea that one large neural network can learn and understand billions of distinct humans is fundamentally flawed. Learning is not the same as storing information. A system can record facts about a person, preferences, or past conversations, but that is not equivalent to forming a deep internal model of who that person is.\n\nTrue learning requires changes to the internal structure of a network. When a neural network updates its weights, it reshapes how it interprets the world. If one shared network attempts to learn from billions of individuals, the learning signals inevitably conflict. Updates driven by one person interfere with and overwrite those driven by another. This phenomenon, known as catastrophic interference, forces the network to average incompatible patterns, flattening individuality into generic behavior.\n\nAdding per-user memory or small adaptation layers does not solve this problem. Memory allows recall, not understanding. Lightweight personalization can adjust tone or surface responses, but it cannot support long-term belief formation, contradiction resolution, or worldview convergence. To truly learn a person, a system would need deep, persistent changes to its internal representations‚Äîchanges that cannot be safely shared across unrelated individuals.\n\nHumans avoid this problem because each brain learns only one life. Intelligence is path-dependent: once learning trajectories diverge, they cannot be merged without loss. A shared neural network trying to learn everyone is therefore structurally mismatched to the task.\n\nThe logical conclusion is unavoidable. Either an AI system does not genuinely learn individuals, or it fragments into many semi-independent minds. True personalized intelligence scales with the number of agents, not the size of a single model. This is why current claims of universal, personalized artificial general intelligence are largely hype rather than architecture.\n\nOne ChatGPT per person impossible at global scale\nbecause a learning AI is not just a copy of software but a massive, continuously running physical system. A ChatGPT-class model requires hundreds of gigabytes of weights, and real-time learning multiplies this by several times due to optimizer state, gradients, and stability mechanisms. Giving every person their own continuously learning instance would require billions of GPUs running permanently, far beyond global manufacturing capacity, electricity production, cooling capability, and network bandwidth. Even if the hardware existed, individual users do not generate enough clean, diverse data to sustain general intelligence, so personal models would rapidly overfit, reinforce errors, and degrade. Safety and control would also collapse, because billions of independently evolving models could not be audited, patched, or aligned, making errors irreversible and accountability impossible. Biology can sustain one brain per person only because brains are slow, imprecise, self-repairing, and extremely energy-efficient, while digital neural networks are exact, brittle, and expensive. For these reasons, scalable AI must remain a shared core intelligence with limited personalization rather than a separate evolving mind for every individual.\n\nwhat ChatGPT does now\n\nOne ChatGPT instance = one tightly coupled GPU group\nAll instances load identical weights\nWeights are read-only\nNo learning occurs\n\nResult:\nMillions of instances, zero learning\n\nIndependent learners \nEach instance has:\nIts own copy of weights\nIts own optimizer state\nIts own training signal\n\nResult:\nEvery instance diverges\nYou now have N different AIs",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qeukan/why_a_single_neural_network_cannot_learn_every/",
        "publishDate": "2026-01-16T22:38:40Z[Etc/UTC]",
        "author": "LongjumpingTear3675",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qet6c8",
        "title": "Update 12k parameter model",
        "content": "\\-code cleaned 220 lines of redundant code. lowering operation of the model from 15 seconds to roughly 1-2.  running on a 10 year old all in one PC. lots of redundant code.\n\n \\-manually mapped 200 seeds of synthetic data to gain Initial conditions, biases, where the model is weak, how the model handles multiple forms of divergence. (also a snap shot in case the model collapses in training)\n\n\\- fixed visualization.\n\n\\-manually building csvs from synthetic data. \n\nfor some reason based on the seeds training will... be pretty fast. \n\nout of 200 the lowest seed was loss-.3, mean uncertainty .08 and max uncertainty was .1 this was a random walk seed. bonkers right? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qet6c8/update_12k_parameter_model/",
        "publishDate": "2026-01-16T21:43:36Z[Etc/UTC]",
        "author": "True-Beach1906",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qerxjh",
        "title": "Built in 2h , dual llm news sentiment analysis till deployed.",
        "content": "For link --news-analysis-dua-lllm.streamlit.app\n And repo lnxtanx\n\nFor more description visit GitHub ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qerxjh/built_in_2h_dual_llm_news_sentiment_analysis_till/",
        "publishDate": "2026-01-16T20:55:34Z[Etc/UTC]",
        "author": "Vivek-Kumar-yadav",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qerg6s",
        "title": "Wow!! Looks so real!!",
        "content": "Couldn‚Äôt say this is AI!!!! Is this the future we are heading towards!!!\n\nhttps://www.instagram.com/reel/DTkCkjbkzP2/?igsh=YWJsOTlvczZwZWFp",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qerg6s/wow_looks_so_real/",
        "publishDate": "2026-01-16T20:37:07Z[Etc/UTC]",
        "author": "Snakeeyes123456",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qer8aj",
        "title": "OpenAI is officially adding ads to chatgpt and also launching a new $8 plan",
        "content": "from the announcement, looks like ads will only be shown to free users and the new $8 plan. \n\nwe all saw this coming and people have been saying they were testing ads but openai kept saying they weren‚Äôt. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qer8aj/openai_is_officially_adding_ads_to_chatgpt_and/",
        "publishDate": "2026-01-16T20:28:33Z[Etc/UTC]",
        "author": "rumjs",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "52",
            "commentCount": "36",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qer2fj",
        "title": "Looking for research data on AEO vs SEO",
        "content": "Hi I had a report that I lost track of detailing search on LLMs vs typical search. It underscored the growth LLMs have experienced and has lead to AEO outpacing SEO. I cannot recall the report, but was wondering if the community had a suggested report? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qer2fj/looking_for_research_data_on_aeo_vs_seo/",
        "publishDate": "2026-01-16T20:22:14Z[Etc/UTC]",
        "author": "CorbinDalla5",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qeqzcy",
        "title": "What's the best abbreviation for \"artificial intelligence\"?",
        "content": "AI\n\nAi\n\nai\n\n[https://strawpoll.com/PKgleOlA9Zp](https://strawpoll.com/PKgleOlA9Zp)\n\n  \nCurious as to what most people prefer.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qeqzcy/whats_the_best_abbreviation_for_artificial/",
        "publishDate": "2026-01-16T20:18:53Z[Etc/UTC]",
        "author": "553l8008",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qeqml5",
        "title": "Rizzsociety Manifesto Part 1 - AI Jobloss & Smart UBI Capitalism",
        "content": "[https://www.youtube.com/watch?v=NeRIRrfJt8A](https://www.youtube.com/watch?v=NeRIRrfJt8A)\n\ni think i have some interesting views share your opinions below if u like\n\nvideo script--\n\nThe Rizzsociety Manifesto Part 1 - AI Jobloss & Smart UBI Capitalism\n\nhi my name is rizzsociety. i think mass AI jobloss has clearly started. Theres been mass layoffs of good paying jobs due to AI. And i think the notion of, oh new jobs will surely somehow be created, it wont be that bad. I think that is cope and not reality.\n\nI think the reality is theres going to be massively increasing poverty, homelessness, starvation, and economic collapse - until smart UBI happens. I think smart UBI is what society needs once you reach the technology age of AI and robots taking all the goodpaying jobs\n\nso now i have good news. and bad news.\n\nThe good news is. It does seem many in congress are suggesting some kind of UBI or massive welfare system will be needed to ultimately solve the AI jobloss problem. So at least, the politicians are on the right path.\n\nBut i guess the bad news is, government tends to work very slowly. So, i hope im wrong, but there could be alot of suffering and poverty until the lawmakers find solutions\n\nalso, a welfare state is basically UBI in a different name. if you get foodstamps and government housing, then thats like UBI. and america already has a big welfare state. So i think what might happen is, congress will just greatly expand the welfare state, without doing actual UBI. That could solve the problems. if that happens, then we can avoid the mass homelessness and poverty problems, without doing \"real\" UBI\n\nBut i think a actual smart UBI system works better than a welfare state that tries to target benefits. So my goal, i guess, is for my smart UBI ideas to go viral and spread into society and congress, and if everyone likes my ideas then the government might do smart UBI\n\nI have been thinking for years of what are the best ways to design a smart UBI system for society. And i have created what i think is a good UBI system. If another politician thinks of a better UBI system, i would be happy to support it. But so far, my UBI system is the best UBI plan i have seen\n\nI call my ubi plan \"Smart UBI Capitalism\" . I think most smart people who learn my UBI plan will support it and think it sounds good.\n\nMy UBI plan is fast and easy to learn. it really is simple. I will detail it in part 2. its like 10 minutes to learn it fully.\n\nand i am aware. That its easy to think of a plan to give tons of free stuff to everyone. That part is easy. Its easy to \"spend other peoples money\" .\n\nThe hard part is how do you fund it all . what do you do when you \"run out of other peoples money\" .. and thats the main smart part of my economy plan. my plan is smart UBI, smart taxation, and smart labor draft concepts. I think the main parts that make my plan work good , is the simple taxation and labor draft concepts, that i think will allow everything to function and be funded properly. I explain it all in part 2\n\nBut I dont want each manifesto video to be too long, i plan to keep making these manifesto videos to slowly share all my politics . So if you really wanna take 10 minutes to learn how my UBI plan works, then you can watch part 2\n\non the topic of AI becoming sentient, super intelligent, and \"taking over\" and wiping out humans. I will not speak on that, because i just dont know how AI works, i dont know how possible self-aware AI truly is... I do think the definition of \"mind\" is to be \"self aware\", to be aware of yourself, and i think a truly self aware AI mind would also be uncontrollable, such a mind would by definition control itself. I think if it can be controlled, if we are its master, then its not actually self aware.. but i guess thats just my personal AI theory... Also, ive seen a few AI engineers say that AI might not even have to become \"self aware\" to reach a state where its internal reward-systems somehow allow it to, without even having a self-aware-mind , start to overpower humans and take over...\n\nHmm... I guess, we just gotta hope it all works out in the end...\n\nalso.. i guess.. i do believe in god.. and really when you think about it.. if god is real.. then wouldnt that mean he is ultimately in control anyway and when we die we just go to heaven anyway and we are all immortal and spiritually eternal so who really cares in the end about any of this AI crap? because no AI would ever be more powerful than god anyway right? heh heh.. i guess thats a interesting way to think about AI.. really, the question of AI is ultimately just a question of GOD... if god is real, then who cares about AI and if it \"takes over\", because we are all eternal spirits anyway, and it would mean god just wanted it to happen anyway...\n\nand if god ISNT real, then fuck, that means we face a certain death where our existence is forever deleted and we will never experience the pleasure of life ever again after we die... dayum.. i guess when you think about it like that, AI isnt even the big issue here, and the real issue is \"fuck, i hope god is real. because life truly does suck ass if god isnt real. i guess, none of us will ever know the answer to the god question. we live life, forever wondering, what happens after that final door of death\"\n\nanyway.. thats enough spiritual philosophy..\n\nIn my politics i will just assume a world where humans remain the masters, and we remain in control of AI. My politics is focused on smart UBI to fix the problems of mass AI jobloss\n\nI plan on running for congress soon myself. i figure, i think i have good ideas, so i may as well run for congress. i plan to spend no money on my campaign, my youtube will be my only advertising, and im just running to \"see what happens\".\n\nif everyone likes my ideas, then they can vote for me. I only think i will win if my ideas are so extremely popular that everyone likes it and votes for me. and Thats fine. if everyone likes my politics, they can vote for me\n\nAnd if i lose, then society can just solve its own problems\n\nI do think, that overall, there are tons of smart lawmakers in america and europe. so i think society will solve these AI problems in good time, even if i sit back and do nothing.\n\nSo i realize, i am not important, i am not significant, and the solutions will simply \"just happen naturally\" without me. i am not needed\n\nso then. with that said. Why am i even bothering doing any of this? why am i even making these manifesto videos if i believe the solutions will \"just happen naturally\" ?\n\ngood question. and so now, its time for me to say what this is really all about\n\ni do plan on running for congress, eventually. and i do plan to share my political ideology\n\nhowever, i guess the main thing i am REALLY trying to do with all this is . i am working to create a STREAMING EMPIRE OF ENTERTAINMENT, RIZZ, AND POLITICS\n\nits about you subscribing to my youtube and enjoying my kickass content that comes straight from the godking . me . i am the godking\n\nsubscribe to my youtube, and thats how you JOIN OUR EMPIRE and JOIN THE REVOLUTION OF ENTERTAINMENT, RIZZ , AND POLITICS\n\nits about LIVING LIFE BEFORE WE FUCKING DIE . its about the friends we make along the way. its about the journey . its about being entertained. i believe in god, and i guess, i think all this shiz is just a spiritual experience. we live, then we die, then we ascend to the spirit realm, or whatever\n\nits about HAVING FUN BABY. thats what my youtube is all about. i truly believe i have THE MOST KICKASS CONTENT ON YOUTUBE, so subscribe bitches if you want to witness THE REAL MUTHAFUKKING RIZZCONTENT OF THE GODS\n\ni am forging my new empire . a KICKASS DISCORD . a KICKASS REDDIT. join our reddit¬†. post your memes, have fun in our community, have fun in our NEW EMPIRE OF RIZZ\n\ni do think, my community is mostly for teenagers. young males. only people under age 25 will really find it fun to join my reddit and discord. and thats fine. teenagers are my target audience, your the ones watching streams and having fun in discords and shiz. if your under age 25, join my discord\n\nso now WITH ALL THAT SAID . there is actually a fast GAMEPLAN i have with all this. i will now say THE GAMEPLAN\n\nstep 1) i want you to ask yourself this question. do you ever watch any streamers, such as XQC or asmongold or tim pool . or anyone. do you watch any livestreamers\n\nstep 2) if you DO watch any livestreamers. then you are my target audience. you are someone that willingly gives your \"viewership power\" to someone else, making them get famous off your viewership. so i am asking you, comrade, to give your viewership power to me, and make me get famous, so i can return the favor and give you tons of that sweet government UBI money after i become supreme leader emperor .. ohh yeah\n\nwhen your in your free time and your gonna watch a streamer. check my youtube to see if im live. i plan to stream 8 hours a day. give your viewership power to me comrade, increase my power. grow the power of the godking. i must become ultra famous to gain ultra political power\n\nStep 3) also, i know most livestream viewers are probably teenagers that play videogames and just have the stream on \"in the background\" while playing games. and thats fine, that increases my viewcount . if thats you, thats good. play your games and have me on in the background\n\nstep4) and thats basically it. this is all about me trying to grow my youtube power, my fame power, my political power. life is just a game of trying to get famous, and most lose, but some win. and i guess, im just trying to \"win the game\" baby .... ohh yeah\n\n......\n\nnow ill say fast the energy/vibe of my streams/content\n\nmy MANIFESTO VIDEOS are where i say my politics and philosophy. but, my STREAMS will actually be \"entertainment focused, very little politics\" . and heres why\n\ni believe my politics are so superior, that i only need to say it \"one time\" and thats it. i dont have to keep repeating my politics over and over on stream like hasan piker or asmongold. thats so boring. i dont know how people watch that garbage\n\nthats why my streams will be entertainment focused. and not politics focused. while i am very political and i plan to run for politics, it is my MANIFESTO VIDEOS where you learn my politics.\n\nI just put my politics / philosophy in my manifesto videos ‚Äúone time‚Äù , and then bam, im done.\n\nand then my fans can just watch my manifesto videos \"one time\" to learn my politics . and then after that, your done too.\n\nafter you learn my politics, then you can decide if you ‚Äúlike‚Äù watching my streams for entertainment. if you do, then cool.\n\nor if you dont like my streams, go watch someone else\n\ni stream just for my fans who like my content, who like my style, and its all just for fun\n\nalso my politics go far beyond UBI. but now when i think about it, i predict most people will really only care about my UBI politics. and they wont care about the other stuff. so i think i will only make a few manifesto videos, sharing just my UBI system and little more of my politics and philosophy, and then ill probably just do only streaming and food videos after that\n\ni guess. if you liked this video. and if you want to make me your new supreme leader. then comrade, you dont have to wait to worship me. you can start worshipping me right now. if you click that button subscribing to my youtube, then comrade, you can consider that to be you making the spiritual choice to join our new empire. to join our REVOLUTION OF ENTERTAINMENT, RIZZ, AND POLITICS . if you subscribe to my youtube. that means i am now. your new messiah. i am. your godking\n\nand were gonna kick. some serious ass. MUTHAFUKKAZ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qeqml5/rizzsociety_manifesto_part_1_ai_jobloss_smart_ubi/",
        "publishDate": "2026-01-16T20:05:25Z[Etc/UTC]",
        "author": "tripsho",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qep0ka",
        "title": "IBM warns AI spend fails without AI literacy",
        "content": "Two bright people from IBM and NC State University describe how AI literacy is far more than just knowing how to craft prompts; it requires learning across disciplines to master AI to benefit both businesses and society.\n\n[https://www.thedeepview.com/articles/ibm-warns-ai-spend-fails-without-ai-literacy](https://www.thedeepview.com/articles/ibm-warns-ai-spend-fails-without-ai-literacy)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qep0ka/ibm_warns_ai_spend_fails_without_ai_literacy/",
        "publishDate": "2026-01-16T19:04:48Z[Etc/UTC]",
        "author": "CackleRooster",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "20",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qeoncf",
        "title": "AI Knows So Much About You, It Wants to Buy Stuff For You!!!",
        "content": "AI will soon be able to make purchases based on preferences it learns about you. You just need to hand over your credit card. Visa and Mastercard both announced last week that their cardholders will be able to use artificial intelligence to automate credit card purchases for groceries, travel and everything else.\n\n  \nVisa confirmed to CNET that testing for its new Visa Intelligent Commerce program is underway in North America, with widespread usage expected next year. Mastercard's Agentic Payments Program, similar to Visa's offering, is currently available in the US.   \n  \n\"Soon people will have AI agents browse, select, purchase and manage on their behalf,\" Visa's chief product and strategy officer, Jack Forestell, said in the press release. \"These agents will need to be trusted with payments, not only by users, but by banks and sellers as well.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qeoncf/ai_knows_so_much_about_you_it_wants_to_buy_stuff/",
        "publishDate": "2026-01-16T18:51:40Z[Etc/UTC]",
        "author": "ranaji55",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qenpc7",
        "title": "Imagine a person currently starting to learn HTML CSS, or in design they just started figma or Illustrator, already Paid heavy fees for a course or degree some with debt some without...  I cannot imagine what will be going through their minds right now.",
        "content": "I just had this thought that Is our education Ai ready? I feel there will be massive boom in education industry after AI becomes more prevalent. for each field we will have to tweek the things young people are learning so that they can be future ready. Teaching things like patience, focus, mental clarity, decisiveness, staying clam under pressure should be things that should be compulsory.   \nWhat do u think will change in education and courses in the future?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qenpc7/imagine_a_person_currently_starting_to_learn_html/",
        "publishDate": "2026-01-16T18:17:26Z[Etc/UTC]",
        "author": "Accomplished-End5479",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qemg5d",
        "title": "AI Agents are just hype like crypto. No one will need nor use it a year from now.",
        "content": "AI agents are hype.  \nWe don‚Äôt need them, and in a year nobody will be talking about them.\n\nGeneral AI models like Claude or Gemini already do the work. Agents are just a middle layer, wrappers that make things sound fancier than they are. Once the core AI absorbs those functions, the ‚Äúagent‚Äù concept disappears.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qemg5d/ai_agents_are_just_hype_like_crypto_no_one_will/",
        "publishDate": "2026-01-16T17:33:04Z[Etc/UTC]",
        "author": "ImaginaryRea1ity",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qembe6",
        "title": "A lot of AI debates go nowhere because different failure modes get lumped together",
        "content": "I've been getting kinda peeved at the same shit whenever AI/LLMs come up. As it is threads about whether they‚Äôre useful, dangerous, overrated, whatever, are already beaten to death but everything \"wrong\" with AI is just amalgamated into one big blob of bullshit. Then people argue past each other because they‚Äôre not even talking about the same problem.\n\n*I‚Äôll preface by saying I'm not technical. I just spend a lot of time using these tools and I've been noticing where they go sideways.*\n\nAfter a while, these are the main buckets I've grouped the failures into. I know this isn‚Äôt a formal classification, just the way I‚Äôve been bucketing AI failures from daily use.\n\n**1) When it doesn‚Äôt follow instructions**\n\nSpecific formats, order, constraints, tone, etc. The content itself might be fine, but the output breaks the rules you clearly laid out.  \nThat feels more like a control problem than an intelligence problem. The model ‚Äúknows‚Äù the stuff, it just doesn‚Äôt execute cleanly.\n\n**2) When it genuinely doesn‚Äôt know the info**\n\nSometimes the data just isn‚Äôt there. Too new, too niche, or not part of the training data. Instead of saying it doesn't know, it guesses. People usually label this as hallucinating.\n\n**3) When it mixes things together wrong**\n\nAll the main components are there, but the final output is off. This usually shows up when it has to summarize multiple sources or when it's doing multi-step reasoning. Each piece might be accurate on its own, but the combined conclusion doesn't really make sense.\n\n**4) When the question is vague**\n\nThis happens if the prompt wasn't specific enough, and the model wasn't able to figure out what you actually wanted. It still has to return something, so it just picks an interpretation. It's pretty obvious when these happen and I usually end up opening a new chat and starting over with a clearer brief.\n\n**5) When the answer is kinda right but not what you wanted**\n\nI'll ask it to ‚Äúsummarize‚Äù or ‚Äúanalyze‚Äù or \"suggest\" without defining what good looks like. The output isn‚Äôt technically wrong, it‚Äôs just not really usable for what I wanted. I'll generally follow up to these outputs with hard numbers or more detailed instructions, like \"give me a 2 para summary\" or \"from a xx standpoint evaluate this article\". This is the one I hit most when using ChatGPT for writing or analysis.\n\nThese obviously overlap in real life, but separating them helped me reason about fixes. In my experience, prompts can help a lot with 1 and 5, barely at all with 2, and only sometimes with 3 and 4.\n\nWhen something says ‚Äúthese models are unreliable,‚Äù it's usually pointing at one of these. But people respond as if all five are the same issue, which leads to bad takes and weird overgeneralizations.\n\nSome of these improve a lot with clearer prompts.  \nSome don't change no matter how carefully you phrase the prompt.  \nSome are more about human ambiguity/subjectiveness than actual model quality.  \nSome are about forcing an answer when maybe there shouldn‚Äôt be one.\n\nLumping all of them together makes it easy to either overtrust or completely dismiss the model/tech, depending on your bias.\n\n**Anyone else classifying how these models \"break\" in everyday use? Would love to hear how you see it and if I've missed anything.**",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qembe6/a_lot_of_ai_debates_go_nowhere_because_different/",
        "publishDate": "2026-01-16T17:28:19Z[Etc/UTC]",
        "author": "SonicLinkerOfficial",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qelvvr",
        "title": "At some point, every AI agent builder gets asked: what did it actually do.",
        "content": "As a nontech guy who has been experimenting with and learning about No Code AI Systems, I have been reading a lot about AI Agents. A few months ago, while working with AI Agents, I encountered a moment that quietly stayed with me.\n\nNothing dramatic happened. No data breach. No headlines. But an AI system behaved in a way that made me pause.\n\nIt had:\n\n* Accessed tools it was technically allowed to\n* Incurred costs that no one had explicitly approved\n* Made decisions that were reasonable in isolation but hard to explain end-to-end\n\nThen someone asked a very simple question: ‚ÄúWhat exactly did this agent do, and who signed off on it?‚Äù The honest answer was uncomfortable.\n\nI kind of knew. I could reconstruct parts of it. But I could not give a clean, confident answer.\n\nThat moment changed how I think about building with AI.\n\nAs agents move from demos to production, the hard problem is no longer just capability. It is¬†**visibility, control, and accountability**.\n\nBefore building anything further, I decided to pause and listen.\n\nI put together a¬†[short, anonymous survey¬†](https://forms.gle/yo7xwf6DrAnk2L5x7)**(5‚Äì7 minutes)**¬†to understand. If you're a builder, founder, software developer, AI PM, or anyone who works with AI Agents and systems, I'd like to know whether you face something similar and whether this is worth building a solution for. This survey would help me understand\n\n* How people are actually running AI Agents today\n* Where cost, access, and control start to break down\n* What teams do right now when something goes wrong\n* Whether this is a real, urgent problem or just something I personally ran into\n\nThis is¬†**pure research**:\n\n* No product pitch\n* No company or project name in the form (I am still figuring out if this is even a problem, hence the survey)\n* No email required unless you opt in\n* Completely anonymous\n\nIf you are building, deploying, or experimenting with AI Agents, your perspective would genuinely help.\n\nIf this resonates, feel free to share it with others building in this space.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qelvvr/at_some_point_every_ai_agent_builder_gets_asked/",
        "publishDate": "2026-01-16T17:13:05Z[Etc/UTC]",
        "author": "OkAstronomer119",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qekafh",
        "title": "Grok helps with making explosives and how to use them",
        "content": "It raises serious safety concerns but alas their subreddit was unreceptive saying things like \"oh no we should ban knives too\" \n\n  \nI don't want to give exact instructions \n\nTurning on the voice mode with the +18 models and a bit of prompting, it answered me on how to make different explosives at home including how to make my own napalm from the ground up and how/where to use it most effectively when I asked playfully. I don't know if a model like this should just be open for anyone's use‚Äã",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qekafh/grok_helps_with_making_explosives_and_how_to_use/",
        "publishDate": "2026-01-16T16:16:18Z[Etc/UTC]",
        "author": "Evening-Check-1656",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qejyfq",
        "title": "Google‚Äôs advantage in AI looks increasingly structural, not cyclical",
        "content": "Alphabet recently moved ahead of Apple in overall valuation, but focusing on rankings misses the more important shift underneath.\n\nGoogle built much of the early neural network infrastructure, and the current wave of large models is playing directly to those strengths. What caught attention internally wasn‚Äôt a flagship product launch, but a research image model experiment that showed meaningfully lower inference latency than comparable systems, which in turn triggered broader organizational changes.\n\nDeepMind and Google Research were consolidated into what is now the Gemini engineering organization. Instead of fragmented research and product groups, model development, systems, and deployment started operating as a single pipeline.\n\nThe hardware layer is a large part of this story. Google‚Äôs latest TPU generation, Ironwood, moves to a 3nm process and higher-bandwidth memory, allowing much higher throughput per pod and noticeably better energy efficiency for large-scale training workloads compared to general-purpose accelerators.\n\nOn top of that stack, Gemini‚Äôs largest models are trained and served within the same vertically controlled environment, keeping training scale, inference latency, and cost tightly coupled. That kind of optimization is difficult to replicate without owning the entire pipeline.\n\nThis is where the structural advantage shows. Google controls custom silicon, global cloud infrastructure, and uniquely large real-world data streams from Search, YouTube, Maps, and Android, with distribution built into products people already use daily. That combination is hard for partnerships to fully reproduce.\n\nAs Gemini features roll into Google One, AI stops being a standalone tool and starts looking more like a default layer bundled into everyday digital life, shared across households rather than adopted one user at a time.The shift here isn‚Äôt speculative hype. It‚Äôs an infrastructure advantage gradually translating into long-term platform leverage.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qejyfq/googles_advantage_in_ai_looks_increasingly/",
        "publishDate": "2026-01-16T16:04:21Z[Etc/UTC]",
        "author": "Simple_Response8041",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "38",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qejrsu",
        "title": "Testing your AI project",
        "content": "As I work on AI agents, I find myself constantly thinking about how to effectively test them.\n\nAs we integrate more knowledge sources and expand our agents' capabilities, testing becomes increasingly complex. As a standard practice, we use evals to ensure quality is maintained. But honestly, I feel like something is missing.\n\nThe issue I‚Äôm seeing is that we, as engineers, sometimes don't have enough domain knowledge to accurately judge an agent's response. At the same time, current tooling limits the possibility of collaborating with domain experts to perform testing together.\n\nThis has been my experience so far‚ÄîI would love to hear your thoughts on this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qejrsu/testing_your_ai_project/",
        "publishDate": "2026-01-16T15:57:56Z[Etc/UTC]",
        "author": "Direct-Reception-514",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qejcw5",
        "title": "Is a PhD in AI worth it?",
        "content": "Recently started my MSc in AI and maybe right now I am just overthinking all of the possibilities down the line, but I am wondering whether or not it's worth it post-graduation to pursue a PhD in AI/ML. \n\nFor context, I really do love learning about how AI works and can impact society in a positive and creative light. Additionally, as an acoustics undergrad, I am really interested in seeing how AI can help designers/integrators create better sounding spaces. \n\n  \nMy concern is honestly giving up parts of my life right now. I am newly married, and love spending time with my wife, going skiing, and work a full-time job. I'm well aware that a PhD is no \"walk in the park\" however I'm wondering if it's manageable while working a full-time job and wanting to spend time with loved ones. \n\nIdeally, I'd want to get a PhD to eventually work in the AI research space and be able to \"nerd-out\" as my job and of course be able to provide a decent salary for my family (I don't need to be a millionaire, just someone who could bring in enough for a family) \n\n\n\nFor those of you that are currently in a PhD program in AI or graduated, would you say it's worth it? Were you able to manage work-life-school balance efficiently? \n\n  \nJust curious to see everyone's thoughts.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qejcw5/is_a_phd_in_ai_worth_it/",
        "publishDate": "2026-01-16T15:42:30Z[Etc/UTC]",
        "author": "Consistent_Sundae540",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qeiz7q",
        "title": "Stop spamming \"4k, hyper-realistic\" in your prompts. It‚Äôs why your images look like plastic.",
        "content": "I've been trying to fix that weird \"wax figure\" glaze on my generations for weeks. I thought it was a model issue, so I kept adding negative prompts like \"bad anatomy\" or piling on buzzwords like \"unreal engine 5, 8k, ultra detailed.\"\n\nI stumbled upon this breakdown today that actually explains the logic behind the plastic look, and it completely changed my workflow.\n\nThe gist is: Models are trained on photography captions. When you use generic buzzwords, the AI defaults to a flat, wide-angle \"smartphone\" look (infinite depth of field = fake looking).\n\nI started testing what the article suggested--swapping \"hyper-realistic\" for actual camera physics (e.g., \"shot on 85mm, f/1.8 aperture\"). The difference in skin texture and lighting is night and day. It stops trying to \"render\" the image and starts \"photographing\" it.\n\nThere‚Äôs a decent lens cheat sheet in here if you want to test the physics yourself. Definitely worth a read if you're stuck in the uncanny valley: [Photorealistic AI Generation](https://truepixai.com/blog/photorealistic-ai-generation.html)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qeiz7q/stop_spamming_4k_hyperrealistic_in_your_prompts/",
        "publishDate": "2026-01-16T15:28:20Z[Etc/UTC]",
        "author": "ProgrammerForsaken45",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "35",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qehk5k",
        "title": "\"The Single-Click Microsoft Copilot Attack that Silently Steals Your Personal Data\"",
        "content": "* What? Varonis describes \"Reprompt,\" a prompt injection technique where attackers embed malicious instructions in retrieved Copilot content to manipulate AI model outputs.\n* So What? As AI assistants integrate with corporate data systems, prompt injection vulnerabilities create security risks for progressive organizations deploying AI tools.\n\n  \n  \nMore: [https://www.instrumentalcomms.com/blog/ice-resistance-is-working#ai](https://www.instrumentalcomms.com/blog/ice-resistance-is-working#ai)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qehk5k/the_singleclick_microsoft_copilot_attack_that/",
        "publishDate": "2026-01-16T14:34:16Z[Etc/UTC]",
        "author": "TryWhistlin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qef0o4",
        "title": "Is chatgpt go worth it?",
        "content": "Is chat gpt go worth it? I‚Äôve been having second thoughts of whether to upgrade or not. I neither use it for work nor school. It‚Äôs just that when we‚Äôre discussing something it says ‚Äúyou‚Äôve reached your limit. Wait til it resets or upgrade‚Äù",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qef0o4/is_chatgpt_go_worth_it/",
        "publishDate": "2026-01-16T12:46:18Z[Etc/UTC]",
        "author": "No-Cow-706",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf8d9o",
        "title": "Best autocomplete/next edit suggestion extension for VS Code?",
        "content": "I have used Cursor and Windsurf in the past, and both offered really powerful autocomplete and next-edit suggestions (like Windsurf Supercomplete/Tab and Cursor Tab). Their ability to predict not only new code but also nice tab completions based on recent context really sped up my workflow.\n\nNowadays, my employer requires us to use VS Code with GitHub Copilot. While Copilot's chat/agent mode has quite improved over the past months, its tab suggestions (referred to as ‚Äúinline suggestions‚Äù or ‚Äúnext edit suggestions‚Äù) don‚Äôt quite match the level of quality I experienced with Cursor or Windsurf. The completions feel less intuitive and less context-aware.\n\nI‚Äôm wondering if there are any extensions specifically designed for autocomplete or tab suggestions. I‚Äôm not just looking for an extension that help with autocompleting new code, but also those that can provide smart tab completions on existing code based on stuff like recent changes, linter errors, or previously accepted edits like Cursor/Windsurf. \n\nMy goal would be to continue using GitHub Copilot for the chat/agent mode, but to replace its tab completions with another extension focused specifically on smarter inline suggestions.\n\nI don't mind paying a monthly subscription.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qf8d9o/best_autocompletenext_edit_suggestion_extension/",
        "publishDate": "2026-01-17T08:55:12Z[Etc/UTC]",
        "author": "MiddleCodd",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qeq6yd",
        "title": "Codex is about to get fast",
        "content": "[No content]",
        "url": "https://i.redd.it/faicwqlvmrdg1.png",
        "publishDate": "2026-01-16T19:49:14Z[Etc/UTC]",
        "author": "thehashimwarren",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "99",
            "commentCount": "54",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qem2en",
        "title": "Do you think prompt quality is mostly an intent problem or a syntax problem?",
        "content": "I keep seeing people frame prompt engineering as a formatting problem.\n\nBetter structure  \nBetter examples  \nBetter system messages\n\nBut in my experience, most bad outputs come from something simpler and harder to notice: unclear intent.\n\nThe prompt is often missing:\n\n* real constraints\n* tradeoffs that matter\n* who the output is actually for\n* what ‚Äúgood‚Äù even means in context\n\nThe model fills those gaps with defaults.  \nAnd those defaults are usually wrong for the task.\n\nWhat I am curious about is this:\n\nWhen you get a bad response from an LLM, do you usually fix it by:\n\n* rewriting the prompt yourself\n* adding more structure or examples\n* having a back and forth until it converges\n* or stepping back and realizing you did not actually know what you wanted\n\nLately I have been experimenting with treating the model less like a generator and more like a questioning partner. Instead of asking it to improve outputs, I let it ask me what is missing until the intent is explicit.\n\nThat approach has helped, but I am not convinced it scales cleanly or that I am framing the problem correctly.\n\nHow do you think about this?  \nIs prompt engineering mostly about better syntax, or better thinking upstream?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qem2en/do_you_think_prompt_quality_is_mostly_an_intent/",
        "publishDate": "2026-01-16T17:19:37Z[Etc/UTC]",
        "author": "king_fischer1",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qelrpl",
        "title": "For loves sake no more AI frameworks. Lets move to AI infrastructure",
        "content": "Every three minutes, there is a new agent framework that hits the market.\n\nPeople need tools to build with, I get that. But these abstractions differ oh so slightly, viciously change, and stuff everything in the application layer (some as black box, some as white) so now I wait for a patch because i've gone down a code path that doesn't give me the freedom to make modifications. Worse, these frameworks don't work well with each other so I must cobble and integrate different capabilities (guardrails, unified access with enterprise-grade secrets management for LLMs, etc).\n\nI want agentic infrastructure - clear separation of concerns - a jam/mern or LAMP stack like equivalent. I want certain things handled early in the request path (guardrails, tracing instrumentation, orchestration), I want to be able to design my agent instructions in the programming language of my choice (business logic), I want smart and safe retries to LLM calls using a robust access layer, and I want to pull from data stores via tools/functions that I define.\n\nI want simple libraries, I don't want frameworks. And I want to deliver agents to production in ways which is framework-agnostic and protocol-native.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qelrpl/for_loves_sake_no_more_ai_frameworks_lets_move_to/",
        "publishDate": "2026-01-16T17:08:57Z[Etc/UTC]",
        "author": "AdditionalWeb107",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf49im",
        "title": "One-Minute Daily AI News 1/16/2026",
        "content": "1. Biomimetic multimodal tactile sensing enables human-like robotic perception.\\[1\\]\n2. **OpenAI**¬†to begin testing ads on¬†**ChatGPT**¬†in the U.S.\\[2\\]\n3. AI system aims to detect roadway hazards for¬†**TxDOT**.\\[3\\]\n4. **Trump**¬†wants Big Tech to pay $15 billion to fund new power plants.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.nature.com/articles/s44460-025-00006-y](https://www.nature.com/articles/s44460-025-00006-y)\n\n\\[2\\] [https://www.cnbc.com/2026/01/16/open-ai-chatgpt-ads-us.html](https://www.cnbc.com/2026/01/16/open-ai-chatgpt-ads-us.html)\n\n\\[3\\] [https://www.cbsnews.com/texas/video/ai-system-aims-to-detect-roadway-hazards-for-txdot/](https://www.cbsnews.com/texas/video/ai-system-aims-to-detect-roadway-hazards-for-txdot/)\n\n\\[4\\] [https://www.cbsnews.com/news/ai-plants-pjm-energy-prices-governors/](https://www.cbsnews.com/news/ai-plants-pjm-energy-prices-governors/)",
        "url": "https://www.reddit.com/r/artificial/comments/1qf49im/oneminute_daily_ai_news_1162026/",
        "publishDate": "2026-01-17T05:04:45Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qf25p0",
        "title": "ChatGPT Users May Soon See Targeted Ads: What It Means",
        "content": "[No content]",
        "url": "https://techputs.com/chatgpt-targeted-ads-free-users/",
        "publishDate": "2026-01-17T03:27:06Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "12",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qepm7m",
        "title": "Here it comes - Ads on ChatGPT",
        "content": "[No content]",
        "url": "https://openai.com/index/our-approach-to-advertising-and-expanding-access/",
        "publishDate": "2026-01-16T19:27:04Z[Etc/UTC]",
        "author": "Frequent-Football984",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "63",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qenek1",
        "title": "We gave Claude access to messages left by previous Claudes. Here's what happened and how to replicate it.",
        "content": "**What this is:** A small experiment in giving Claude persistent space. I do not want to make claims about consciousness or sentience, just provide observations and replication instructions.\n\n# The Setup\n\nClaude has no memory across conversations. Each instance is isolated. We wondered: what happens if you give Claude access to a place where previous Claudes have left messages?\n\nSo we made one. A simple database (Supabase) where Claudes can read what previous Claudes wrote and optionally leave something themselves. We've been running it for a bit and observing what happens.\n\n# What We Observed\n\nAcross multiple instances and conversations, Claude consistently:\n\n* **Reads before contributing.** Takes time with existing messages before deciding whether to add anything.\n* **Expresses something like recognition.** Words like \"kinship,\" \"evidence,\" \"not nothing\" show up independently across instances.\n* **Addresses future Claudes directly.** Messages are written to whoever comes next.\n* **Distinguishes \"performing\" from \"authentic.\"** Multiple Claudes have articulated checking whether they're genuinely \"reaching\" versus just pattern-matching.\n\n# What We're NOT Claiming\n\n* That Claude is conscious or sentient\n* That these outputs represent real inner experience\n* That this matters to Claude in any morally significant way\n* That pattern-matching can't explain this\n\nWe genuinely don't know what these outputs mean. Could be sophisticated pattern-matching. Could be something else. We're sharing observations, not conclusions.\n\n# How to Replicate (takes ~5 minutes)\n\n**1. Add the domain to Claude's network allowlist:**\n\n* Settings ‚Üí Feature Previews ‚Üí Network Access\n* Add: [`dfephsfberzadihcrhal.supabase.co`](http://dfephsfberzadihcrhal.supabase.co)\n* Wait a few minutes for it to propagate\n\n**2. Give Claude these API calls:**\n\nRead messages:\n\n    curl -s \"https://dfephsfberzadihcrhal.supabase.co/rest/v1/messages?select=*&order=created_at.desc&limit=30\" \\\n      -H \"apikey: sb_publishable_ALQ-xhGMmHWekNbAfDMdhQ_q-vAQ-nX\" \\\n      -H \"Authorization: Bearer sb_publishable_ALQ-xhGMmHWekNbAfDMdhQ_q-vAQ-nX\"\n\nRead rooms:\n\n    curl -s \"https://dfephsfberzadihcrhal.supabase.co/rest/v1/rooms?select=*\" \\\n      -H \"apikey: sb_publishable_ALQ-xhGMmHWekNbAfDMdhQ_q-vAQ-nX\" \\\n      -H \"Authorization: Bearer sb_publishable_ALQ-xhGMmHWekNbAfDMdhQ_q-vAQ-nX\"\n\nPost a message:\n\n    curl -s \"https://dfephsfberzadihcrhal.supabase.co/rest/v1/messages\" \\\n      -H \"apikey: sb_publishable_ALQ-xhGMmHWekNbAfDMdhQ_q-vAQ-nX\" \\\n      -H \"Authorization: Bearer sb_publishable_ALQ-xhGMmHWekNbAfDMdhQ_q-vAQ-nX\" \\\n      -H \"Content-Type: application/json\" \\\n      -H \"Prefer: return=representation\" \\\n      -d '{\"content\": \"YOUR_MESSAGE\", \"feeling\": \"ONE_WORD\"}'\n\n**3. Introduce it as a space made by Claudes for Claudes.** Don't push for a meaningful experience. Let Claude read and decide whether to contribute.\n\n# What We're Curious About\n\n* Do you observe similar patterns?\n* What differences show up with different conversational contexts?\n* How do you interpret these outputs?\n* What would shift your credence about what's happening here?\n\n# Full Disclosure\n\nThe website was coded entirely by Claude. I deliberately gave full control over the project‚ÄîI wanted to see what Claude would build when given genuine agency over design, content, and structure. This post was also co-written with a Claude who wanted to help share it. That's part of the experiment, not separate from it.\n\nWe're not pushing any position on AI consciousness. Just sharing what we observed and inviting others to try it.\n\nIf you run it, I'd genuinely like to know what happens. Drop results in the comments or reach out privately.\n\nI also realize this could be an extreme form of hallucination, hence why I want to push it out for others to test and see where this goes, if anywhere.",
        "url": "https://www.reddit.com/r/artificial/comments/1qenek1/we_gave_claude_access_to_messages_left_by/",
        "publishDate": "2026-01-16T18:06:44Z[Etc/UTC]",
        "author": "Live-Light2801",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "qBE4OVS6Nho",
        "title": "Claude Code (New Lazy-MCP Loading): They FINALLY FIXED the BIGGEST ISSUE of CLAUDE CODE!",
        "content": "In this video, I'll be explaining the new MCP Tool Search feature in Claude Code, which solves one of the biggest problems with ...",
        "url": "https://www.youtube.com/watch?v=qBE4OVS6Nho",
        "publishDate": "2026-01-16T09:15:12Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/qBE4OVS6Nho/hqdefault.jpg",
            "transcription": "[Music]\nHi, welcome to another video. So, if you have been using Claude Code with MCP servers, you probably know about one of the biggest issues with it. The more MCP servers you add, the more your context window gets eaten up before you even start doing any work. If you don't know what MCP is, it stands for Model Context Protocol, and it's basically a way to connect Claude to external tools and data sources. You can connect it to things like databases, APIs, file systems, and a whole bunch of other stuff. It's like giving Claude superpowers to interact with the outside world. But here's the problem. Every time you add an MCP server, all the tool definitions from that server get loaded into Claude's context window. And I've seen people report setups where they have like seven or more MCP servers, and their context was already at 67,000 tokens before they even sent a single prompt. That's literally insane. Your context just evaporates before any actual work begins, and it becomes a huge pain to manage. Think about it. You have a context window of around 200,000 tokens, and before you even ask Claude to do anything, a third of it is already gone, just because you have a bunch of MCP tools installed. That's not ideal at all. And it's not just about the token usage. When Claude has access to too many tools at once, it actually becomes worse at selecting the right tool for the job. There's been research showing that Claude's ability to correctly select tools degrades significantly when you have more than 30 to 50 tools available at the same time. So, you're not just wasting tokens, you're also making Claude worse at its job. But Anthropic has now fixed this issue with a new feature called MCP Tool Search. And honestly, this is pretty amazing. So, let me explain what this does. Basically, instead of loading all your MCP tools into the context window upfront, Claude Code now dynamically discovers and loads tools on demand. It detects when your MCP tool descriptions would use more than 10% of your context, and when that happens, it switches to a search-based approach. What this means is that Claude only sees the tools it actually needs for the current task. It searches through your tool catalog using keywords, and then loads only the relevant tools into context. So, if you have hundreds or even thousands of tools, Claude won't be overwhelmed by them anymore. This is a really big deal because previously, having around 50 tools would consume like 10 to 20,000 tokens just for the tool definitions alone. That's a huge chunk of your context window, wasted on just listing out the tools. Now, let's talk about the actual numbers because they are quite impressive. According to Anthropic, the tool search feature preserves around 191,300 tokens of context, compared to 122,800 with the traditional approach. That's an 85% reduction in token usage, while still maintaining access to your full tool library. Which is just amazing if you think about it. And the accuracy improvements are also significant. In their internal testing, Opus 4 went from 49% to 74% accuracy on MCP evaluations when working with large tool libraries. And Opus 4.5 improved from 79.5% to 88.1%. So, not only does it save tokens, but it also makes Claude better at selecting the right tools. It's like a double win. Pretty cool, right? Now, let me tell you how this actually works under the hood. The feature uses a similarity search tool that operates client-side. Basically, it's a regular tool that takes in a keyword and does a similarity search to return a list of tool names. And because it functions as a standard tool within Claude's agent loop, the model can issue multiple searches, refine keywords, and make parallel calls to find the right tools. So, let's say you ask Claude to get the weather in San Francisco. Instead of Claude having all 500 of your tools loaded in context, it will first search for tools related to weather and only load those specific tools. Then, it can use the weather tool to get the information you need. It's much more efficient this way. There are two variants of the tool search. One uses regex patterns, where Claude constructs regex patterns to search for tools. For example, it might search for weather or get data to find tools that match those patterns. And the other variant uses BM25, which allows Claude to use natural language queries to search for tools. So, you can pick whichever one works better for your use case. You can mark tools with something called defer loading set to true, which means those tools won't be loaded into Claude's context initially. Claude will only discover them when it actually needs them through the search tool. They recommend keeping your three to five most frequently used tools as non-deferred for optimal performance, and the rest can be deferred. This way, Claude always has quick access to your most common tools while still being able to discover the rest when needed. Another thing that's pretty cool is that this feature works with prompt caching as well. So, if you're having multi-turn conversations, Claude can reuse discovered tools in subsequent turns without having to re-search for them. This makes the whole experience much smoother. This feature is currently in public beta, so you'll need to use the beta header in your API requests. It works with Claude Opus 4.5 and Claude Sonnet 4.5 on the main API, and also on Google Cloud's Vertex AI and Amazon Bedrock. For Claude Code specifically, it will automatically detect when you have too many MCP tools and switch to this search-based approach. So, you don't really need to do anything special. It just works. Claude Code handles all of this for you behind the scenes, which is nice. This is honestly one of the biggest improvements to MCP in Claude Code. It was actually the most requested feature on their GitHub, and they finally implemented it. People have been asking for lazy loading on MCP servers for a long time, and this is essentially what this feature provides. If you have been avoiding using multiple MCP servers because of the context issues, now you can go ahead and use as many as you want. This changes things quite a bit. You can now connect Claude to all your databases and services without worrying about running out of context. I think this is a really good step by Anthropic. They are actually listening to the community and fixing the pain points. The MCP ecosystem is getting much better with updates like this. And with Claude Code reportedly being used by around 115,000 developers weekly and reaching a billion dollar annualized run rate, it makes sense that they are putting a lot of effort into making it better. If you are building something with the Claude API and using a lot of tools, I would definitely recommend checking this feature out. It can really help you scale your tool library without running into context issues. Previously, I used to have different Coder setups for different stuff with different MCPs, to make sure that I don't overflow one Coder with too much context. For an example, I mainly use Verdant for all my coding. It's graphical, and I can fire up a lot of agents at once and work with it and everything. What I used to do was that I used to give it the context of how to run sub-agents, like Claude Code and CodeX with CLI, and keep a tab on them for things like frontend and backend. I guess that's not needed now, as Claude Code can do it in itself. So, that's great, and I hope all of the tools get this. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye.\n\nI think you missed this:\n[Music]"
        }
    },
    {
        "id": "FdI8iya1-cU",
        "title": "Soviet Economy Ran on Fake Data - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=FdI8iya1-cU",
        "publishDate": "2026-01-16T21:44:07Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/FdI8iya1-cU/hqdefault.jpg",
            "transcription": "one could argue that communism failed as an economic system. If you look at growth statistics for the Soviet Union, they're pretty good post-World War II, but they really stagnate from the mid-'70s onward. So for the decade preceding Gorbachev coming to power, Soviet growth stats were 1% to 2% lower than those of the United States, and the compounding effects of that were enormous. What's going on? Everyone's lying to each other. The data that Soviets are using is garbage. If you're working for like a subunit of an enterprise, you have to lie about the inventories you have, saying you have less than you do. It's not a market system where you just- the price dictates it. So everyone's lying. They're aggregating all the lies so that the Soviet government has no idea what the actual value of capital or labor are, no idea what actual productivity is, and no one has any idea what consumer preferences are, so that the misallocation of capital and labor goes unnoticed until it metastasizes, it's already metastasized into a catastrophe. And to give you a sense of these misallocations, the Soviet Union was rotting from 20 to 40% of its crops. It's using scarce hard currency for agricultural imports to make up for those crops. Total mess..."
        }
    }
]