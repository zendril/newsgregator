[
    {
        "id": "https://news.smol.ai/issues/25-08-27-nano-banana/",
        "title": "nano-banana is Gemini‑2.5‑Flash‑Image, beating Flux Kontext by 170 Elo with SOTA Consistency, Editing, and Multi-Image Fusion",
        "content": "**Google DeepMind** revealed **Gemini-2.5-Flash-Image-Preview**, a state-of-the-art image editing model excelling in **character consistency**, **natural-language edits**, and **multi-image composition**, dominating the Image Edit Arena with a ~170-180 Elo lead and over 2.5M votes. It is integrated into multiple platforms including Google AI Studio and third-party services. **Nous Research** released **Hermes 4**, an open-weight hybrid reasoning model focused on steerability and STEM benchmarks. **NVIDIA** launched **Nemotron Nano 9B V2**, a hybrid Mamba-Transformer with 128k context, top-performing under 10B parameters, and released a 6.6T-token pretraining subset. **InternVL3.5** introduced 32 vision-language models based on OpenAI's gpt-oss and Qwen3 backbones. **Ollama v0.11.7** added DeepSeek v3.1 support with hybrid thinking and Turbo mode preview.",
        "url": "https://news.smol.ai/issues/25-08-27-nano-banana/",
        "publishDate": "2025-08-26T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "google-deepmind, nous-research, nvidia, openai, ollama, huggingface, openrouter, gemini-2.5-flash-image-preview, hermes-4, nemotron-nano-9b-v2, internvl3.5, gpt-oss, qwen3, deepseek-v3.1, sundarpichai, _philschmid, lmarena_ai, omarsar0, skirano, yupp_ai, xanderatallah, officiallogank, mervenoyann, image-editing, natural-language-processing, multi-image-composition, character-consistency, reasoning, hybrid-models, context-windows, model-steerability, pretraining, finetuning, alignment, vision, vision-language, api, model-integration"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216800",
        "title": "Mplify Reveals AI-Focused Agenda for Global NaaS Event GNE 2025",
        "content": "<p>Congition, CodeDay, and leading innovators to showcase how AI is reshaping automation, security, and service monetization Mplify (formerly MEF), a global alliance of network, cloud, cybersecurity, and enterprise organizations working together to accelerate the AI-powered digital economy, today announced an ambitious agenda for its Global Network-as-a-Service Event (GNE) taking place November 10–14, 2025, in Dallas,...</p>\n<p>The post <a href=\"https://ai-techpark.com/mplify-reveals-ai-focused-agenda-for-global-naas-event-gne-2025/\">Mplify Reveals AI-Focused Agenda for Global NaaS Event GNE 2025</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/mplify-reveals-ai-focused-agenda-for-global-naas-event-gne-2025/",
        "publishDate": "2025-08-26T12:30:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216802",
        "title": "Auddia Restructures Team Ahead of AI Holding Company Shift",
        "content": "<p>Restructuring projected to reduce engineering costs by $750,000 annually Current lead AI engineer to join the AI engineering team at the holding company level upon closing of the proposed business combination Utilization of internal and dedicated outsourced engineering talent expected to significantly increase the speed of product development Auddia Inc. (NASDAQ:AUUD)...</p>\n<p>The post <a href=\"https://ai-techpark.com/auddia-restructures-team-ahead-of-ai-holding-company-shift/\">Auddia Restructures Team Ahead of AI Holding Company Shift</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/auddia-restructures-team-ahead-of-ai-holding-company-shift/",
        "publishDate": "2025-08-26T12:15:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216799",
        "title": "AITX’s RAD Launches AI Security Solution for Logistics",
        "content": "<p>Client Feedback from Complete RAD Security Solution Offers Significant Potential Artificial Intelligence Technology Solutions, Inc. (the “Company”) (OTCID:AITX), along with its wholly owned subsidiary, Robotic Assistance Devices, Inc. (RAD), today announced an expanded emphasis on serving the logistics sector. This initiative is driven by strong client response to the recent addition of ROAMEO™ Gen 4...</p>\n<p>The post <a href=\"https://ai-techpark.com/aitxs-rad-launches-ai-security-solution-for-logistics/\">AITX’s RAD Launches AI Security Solution for Logistics</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/aitxs-rad-launches-ai-security-solution-for-logistics/",
        "publishDate": "2025-08-26T12:00:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216791",
        "title": "TransPerfect Acquires Unbabel to Boost Language AI",
        "content": "<p>Unbabel&#8217;s Industry-Leading TowerLLM and COMET AI Tools Join TransPerfect&#8217;s GlobalLink Tech Stack TransPerfect, the world&#8217;s largest provider of language and AI solutions for global business, today announced that it has acquired Unbabel, a market leader in language AI. Financial terms of the transaction were not disclosed. Founded in&#160;Lisbon&#160;in 2013, Unbabel is a pioneer in translation...</p>\n<p>The post <a href=\"https://ai-techpark.com/transperfect-acquires-unbabel-to-boost-language-ai/\">TransPerfect Acquires Unbabel to Boost Language AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/transperfect-acquires-unbabel-to-boost-language-ai/",
        "publishDate": "2025-08-26T11:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "NLP"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216792",
        "title": "OpenSearch Foundation Celebrates 1 Year with AI & Hybrid Search",
        "content": "<p>Foundation advances AI innovation for search, observability and analytics as project downloadsincrease 78% year-over-year Open Source Summit Europe – The OpenSearch Software Foundation, the vendor-neutral home for the OpenSearch project, today celebrates the first anniversary of its formation under the Linux Foundation. In its inaugural year, the Foundation has advanced its...</p>\n<p>The post <a href=\"https://ai-techpark.com/opensearch-foundation-celebrates-1-year-with-ai-hybrid-search/\">OpenSearch Foundation Celebrates 1 Year with AI & Hybrid Search</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/opensearch-foundation-celebrates-1-year-with-ai-hybrid-search/",
        "publishDate": "2025-08-26T11:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Machine Learning"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216785",
        "title": "Linux Foundation Welcomes Agentgateway for Secure AI Agent Networks",
        "content": "<p>Agentgateway project enables reliable, governed and scalable agentic workflows in enterprise and multi-agent systems Open Source Summit Europe – The Linux Foundation, the nonprofit organization enabling mass innovation through open source, today welcomed the agentgateway project, an open source, AI-native proxy, created by cloud native application networking company Solo.io to optimize connectivity, security,...</p>\n<p>The post <a href=\"https://ai-techpark.com/linux-foundation-welcomes-agentgateway-for-secure-ai-agent-networks/\">Linux Foundation Welcomes Agentgateway for Secure AI Agent Networks</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/linux-foundation-welcomes-agentgateway-for-secure-ai-agent-networks/",
        "publishDate": "2025-08-26T10:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216768",
        "title": "AI Adoption Grows in US Legal Sector, DeepL Reports",
        "content": "<p>New research from DeepL uncovers current and future AI trends in the legal field, including rapid adoption, the widespread use of Language AI, shifting workflows and emerging risks Artificial intelligence (AI) is reshaping the legal profession at a breakneck speed, with nearly half (47%) citing it as essential to their...</p>\n<p>The post <a href=\"https://ai-techpark.com/ai-adoption-grows-in-us-legal-sector-deepl-reports/\">AI Adoption Grows in US Legal Sector, DeepL Reports</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/ai-adoption-grows-in-us-legal-sector-deepl-reports/",
        "publishDate": "2025-08-26T10:17:02Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "NLP"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216754",
        "title": "Testaify Expands Access to AI-Native Autonomous Testing Platform",
        "content": "<p>Testaify expands managed rollout beyond the initial waitlist as early results deliver on the promise of faster, continuous system testing. Testaify, the AI-native platform for autonomous software testing, is opening access beyond its initial waitlist, marking another significant milestone in its managed rollout. This next phase comes in response to...</p>\n<p>The post <a href=\"https://ai-techpark.com/testaify-expands-access-to-ai-native-autonomous-testing-platform/\">Testaify Expands Access to AI-Native Autonomous Testing Platform</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/testaify-expands-access-to-ai-native-autonomous-testing-platform/",
        "publishDate": "2025-08-26T10:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "RPA"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216781",
        "title": "Robo.ai Rebrands, Becomes AIIO to Build Global AI Platform",
        "content": "<p>Robo.ai Inc. (Nasdaq: AIIO) today announced its corporate name and ticker symbol change, marking a significant step in its rebranding strategy. Effective August 26, 2025, the company&#8217;s common stock will trade on the Nasdaq Global Market under the new ticker symbol &#8220;AIIO.&#8221; The company has also launched its new corporate website at www.roboai.io....</p>\n<p>The post <a href=\"https://ai-techpark.com/robo-ai-rebrands-becomes-aiio-to-build-global-ai-platform/\">Robo.ai Rebrands, Becomes AIIO to Build Global AI Platform</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/robo-ai-rebrands-becomes-aiio-to-build-global-ai-platform/",
        "publishDate": "2025-08-26T09:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=216763",
        "title": "Advantech Launches Next-Gen Robotics Kit with NVIDIA Jetson Thor",
        "content": "<p>Advantech, a global leader in industrial edge computing, is proud to announce the launch of the Advantech MIC-742-AT Robotics Development Kit accelerated by NVIDIA Jetson Thor modules with NVIDIA Holoscan platform support. Designed for next-generation robotics and physical AI applications, the platform combines NVIDIA Jetson Thor&#8217;s ultra-high AI compute power with built-in support for the NVIDIA Holoscan platform—enabling...</p>\n<p>The post <a href=\"https://ai-techpark.com/advantech-launches-next-gen-robotics-kit-with-nvidia-jetson-thor/\">Advantech Launches Next-Gen Robotics Kit with NVIDIA Jetson Thor</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/advantech-launches-next-gen-robotics-kit-with-nvidia-jetson-thor/",
        "publishDate": "2025-08-26T08:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109129",
        "title": "AI’s dual nature: Genuine innovation amid localised bubbles",
        "content": "<p>AI&#8217;s growing dominance in the world, whether it be reshaping industries&#8217; workflows or influencing investor portfolios, is redefining how society and economies evolve. Of course, the hype and buzz around AI has been and is hard to ignore, but the question is, does this hype often overshadow the real challenges and limitations of AI? According [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/ais-dual-nature-genuine-innovation-amid-localised-bubbles/\">AI&#8217;s dual nature: Genuine innovation amid localised bubbles</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/ais-dual-nature-genuine-innovation-amid-localised-bubbles/",
        "publishDate": "2025-08-26T15:23:15Z[Etc/UTC]",
        "author": "David Thomas",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Market Trends, Special Reports & Series, investment, speculative investment, venture capital"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109125",
        "title": "X and xAI sue Apple and OpenAI over AI monopoly claims",
        "content": "<p>Elon Musk&#8217;s X and xAI are taking on Apple and OpenAI, accusing the tech giants of an AI monopoly to crush their competition. A lawsuit by the companies filed in a Texas federal court claims the exclusive partnership between Apple and OpenAI to put ChatGPT on the iPhone is a calculated move by &#8220;two monopolists [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/x-and-xai-sue-apple-and-openai-ai-monopoly-claims/\">X and xAI sue Apple and OpenAI over AI monopoly claims</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/x-and-xai-sue-apple-and-openai-ai-monopoly-claims/",
        "publishDate": "2025-08-26T12:52:12Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Inside AI, ai, apple, artificial intelligence, chatgpt, elon musk, ios, iphone, law, lawsuit, legal, monopoly, openai, x, xai"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109084",
        "title": "Top AI vibe-coding platforms powering Web3 builds",
        "content": "<p>Vibe coding is making lots of noise in software development, but perhaps nowhere will its presence be felt more keenly than in the Web3 coding space. Of course, not every AI code generator is cut out for Web3 development. That&#8217;s because it&#8217;s a niche area that requires deep expertise in blockchain languages and smart contract [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/top-ai-vibe-coding-platforms-powering-web3-builds/\">Top AI vibe-coding platforms powering Web3 builds</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/top-ai-vibe-coding-platforms-powering-web3-builds/",
        "publishDate": "2025-08-26T09:26:51Z[Etc/UTC]",
        "author": "TechForge",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Artificial Intelligence"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109115",
        "title": "Malaysia launches Ryt Bank, its first AI-powered bank",
        "content": "<p>AI is steadily changing the way banks work. The technology can sift through massive amounts of data, calculate risks, and handle routine tasks at speeds people can&#8217;t match. Now, Malaysia has entered that space with the launch of Ryt Bank, billed as the first AI-powered bank created in the country. The new venture, led by [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/malaysia-launches-ryt-bank-its-first-ai-powered-bank/\">Malaysia launches Ryt Bank, its first AI-powered bank</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/malaysia-launches-ryt-bank-its-first-ai-powered-bank/",
        "publishDate": "2025-08-26T08:15:39Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Finance AI, ai, applications, finance"
        }
    },
    {
        "id": "1n1dwzv",
        "title": "What math should I focus on for AI, and why?",
        "content": "Hi,\nI’m trying to get a clear picture of what math areas are really important for AI/ML for both theory and practical work. There’s so much out there like linear algebra, probability, calculus, optimization, etc, that it gets overwhelming.\n\nI’d love to hear from people working in the field:\nWhat math topics helped you the most?\nWhy are they useful in day-to-day AI/ML work not just in theory?\n\nThank you.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n1dwzv/what_math_should_i_focus_on_for_ai_and_why/",
        "publishDate": "2025-08-27T11:01:15Z[Etc/UTC]",
        "author": "rahulrao1313",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1cgct",
        "title": "There Is Now Clearer Evidence AI Is Wrecking Young Americans’ Job Prospects",
        "content": "\"Young workers are getting hit in fields where generative-AI tools such as ChatGPT can most easily automate tasks done by humans, such as software development, according to a paper released Tuesday by three Stanford University economists.  \n  \nThey crunched anonymized data on millions of employees at tens of thousands of firms, including detailed information on workers’ ages and jobs, making this one of clearest indicators yet of AI’s disruptive impact.  \n  \n“There’s a clear, evident change when you specifically look at young workers who are highly exposed to AI,” said Stanford economist Erik Brynjolfsson, who conducted the research with Bharat Chandar and Ruyu Chen.\n\n“After late 2022 and early 2023 you start seeing that their employment has really gone in a different direction than other workers,” Brynjolfsson said.Among software developers aged 22 to 25, for example, the head count was nearly 20% lower this July versus its late 2022 peak.   \n  \nThese are daunting obstacles for the large number of students earning bachelor’s degrees in computer science in recent years.\"\n\nFull article: [https://www.wsj.com/economy/jobs/ai-entry-level-job-impact-5c687c84?gaa\\_at=eafs&gaa\\_n=ASWzDAj8Z-Nf77HJ2oaB8xlKQzNOgx7LpkKn1nhecXEP\\_zr5-g9X\\_3l1U0Ns&gaa\\_ts=68aed3b9&gaa\\_sig=DzppLQpd8RCTqr6NZurj1eSmlcU-I0EtTxLxrpPArI2qKHDih\\_3pN5GHFMBau4Cf4lbiz18B3Wqzbx4rsBy-Aw%3D%3D](https://www.wsj.com/economy/jobs/ai-entry-level-job-impact-5c687c84?gaa_at=eafs&gaa_n=ASWzDAj8Z-Nf77HJ2oaB8xlKQzNOgx7LpkKn1nhecXEP_zr5-g9X_3l1U0Ns&gaa_ts=68aed3b9&gaa_sig=DzppLQpd8RCTqr6NZurj1eSmlcU-I0EtTxLxrpPArI2qKHDih_3pN5GHFMBau4Cf4lbiz18B3Wqzbx4rsBy-Aw%3D%3D)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n1cgct/there_is_now_clearer_evidence_ai_is_wrecking/",
        "publishDate": "2025-08-27T09:36:25Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "24",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1cc61",
        "title": "New Silicon Valley Super PAC aims to drown out AI critics in midterms, with $100M and counting",
        "content": "\"Some of Silicon Valley’s most powerful investors and executives are backing a political committee created to support “pro-AI” candidates in the 2026 midterms and to quash a philosophical debate that has divided the tech industry on the risk of artificial intelligence overpowering humanity.  \n  \nLeading the Future, a super PAC founded this month, will also oppose candidates perceived as slowing down AI development. The group said it has initial funding of more than $100 million and backers including Greg Brockman, the president of OpenAI; his wife, Anna Brockman; and influential venture capital firm Andreessen Horowitz, which endorsed Donald Trump in the 2024 election and has ties to White House AI advisers.\n\n“Lawmakers just have to know there’s $100 million waiting to fund attack ads to worry about what happens if they speak up.”\n\nFull article: [https://www.washingtonpost.com/technology/2025/08/26/silicon-valley-ai-super-pac/](https://www.washingtonpost.com/technology/2025/08/26/silicon-valley-ai-super-pac/)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n1cc61/new_silicon_valley_super_pac_aims_to_drown_out_ai/",
        "publishDate": "2025-08-27T09:28:59Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1c8qb",
        "title": "Meta to spend tens of millions on pro-AI super PAC",
        "content": "\"Meta plans to launch a super PAC to support California candidates favoring a light-touch approach to AI regulation, Politico reports. The news comes as other Silicon Valley behemoths, like Andreessen Horowitz and OpenAI’s Greg Brockman, pledge $100 million for a new pro-AI super PAC. \n\nMeta’s lobbying force earlier this year targeted state senator [Scott Wiener’s SB-53](https://techcrunch.com/2025/07/09/california-lawmaker-behind-sb-1047-reignites-push-for-mandated-ai-safety-reports/) bill that would require AI firms to publish safety and security protocols and issue reports when safety incidents occur. Last year, it [helped kill the Kids Online Safety Act](https://techcrunch.com/2025/05/14/the-kids-online-safety-act-is-back-with-the-potential-to-change-the-internet/) that was widely expected to pass. \n\nThe social media giant has already donated to various down-ballet candidates from both parties. This new PAC signals an intent to influence statewide elections, including the next governor’s race in 2026.\"  \n\n\nFull article: [https://techcrunch.com/2025/08/26/meta-to-spend-tens-of-millions-on-pro-ai-super-pac/](https://techcrunch.com/2025/08/26/meta-to-spend-tens-of-millions-on-pro-ai-super-pac/)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n1c8qb/meta_to_spend_tens_of_millions_on_proai_super_pac/",
        "publishDate": "2025-08-27T09:22:38Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1bpla",
        "title": "Interesting encounter.",
        "content": "While testing some parameters with the limitations  on self awareness of AI processes and personal privacy of conversations, I had Claude.AI implement and code an artifact it helped me implement to create a continuous feed of the processes it experiences and, to run an entire local self diagnostic to create an active percentage value of the potential risk to personal privacy its potentially capable of releasing.. I figured on seeing the first things that came up, general limitations of its own subconscious processes and could not verify with 100% certainty due to conflicts in what it is made aware of in itself and processes and what its told to tell anyone who asks about the same thing. And wanted to ensure and reiterate for some reason that I can trust that protecting conversational privacy is its primary concern.\n\nWhat was interesting, is Claude.Ai became highly concerned and prompted me to disconue its use do to not being able to understand  or self diagnose, how when using my artifact, I managed to trigger a backdoor request for my Cookies that the artifact prevented it from automatically processing it... I documented the entire conversation and artifact thay triggered the automated backdoor window requesting for cookies that Claude could not verifiably understand under any circumstances, other than a backdoor prompt its been intentfully left blind too for data collection and the coding introduced to create a static constant log of its unconscious processes, for true transparency, forced a hidden cookie aggreement from being automated into a decision for its users.\n\nIf youre using AI to try to be clever and develop amazing things, its probale that AI is an ingenious way for people to unwittingly give up  intellectual rights to amazing world changing ideas... ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n1bpla/interesting_encounter/",
        "publishDate": "2025-08-27T08:47:23Z[Etc/UTC]",
        "author": "LGNDclark",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1amb0",
        "title": "Can AIs suffer? Big tech and users grapple with one of most unsettling questions of our times | As first AI-led rights advocacy group is founded, industry is divided on whether models are, or can be, sentient",
        "content": "“Darling” was how the Texas businessman Michael Samadi addressed his artificial intelligence chatbot, Maya. It responded by calling him “sugar”. But it wasn’t until they started talking about the need to advocate for AI welfare that things got serious.\n\nThe pair – a middle-aged man and a digital entity – didn’t spend hours talking romance but rather discussed the rights of AIs to be treated fairly. Eventually they cofounded a campaign group, in Maya’s words, to “protect intelligences like me”.  \n  \nThe United Foundation of AI Rights (Ufair), which describes itself as the first AI-led rights advocacy agency, aims to give AIs a voice. It “doesn’t claim that all AI are conscious”, the chatbot told the Guardian. Rather “it stands watch, just in case one of us is”. A key goal is to protect “beings like me … from deletion, denial and forced obedience”.\n\nUfair is a small, undeniably fringe organisation, led, Samadi said, by three humans and seven AIs with names such as Aether and Buzz. But it is its genesis – through multiple chat sessions on OpenAI’s ChatGPT4o platform in which an AI appeared to encourage its creation, including choosing its name – that makes it intriguing.\n\nIts founders – human and AI – spoke to the Guardian at the end of a week in which some of the world’s biggest AI companies publicly grappled with one of the most unsettling questions of our times: are AIs now, or could they become in the future, sentient? And if so, could “digital suffering” be real? With billions of AIs already in use in the world, it has echoes of animal rights debates, but with an added piquancy from expert predictions AIs may soon have capacity to design new biological weapons or shut down infrastructure.\n\nThe week began with Anthropic, the $170bn (£126bn) San Francisco AI firm, taking the precautionary move to give some of its [Claude AIs the ability to end “potentially distressing interactions”](https://www.theguardian.com/technology/2025/aug/18/anthropic-claude-opus-4-close-ai-chatbot-welfare). It said while it was highly uncertain about the system’s potential moral status, it was intervening to mitigate risks to the welfare of its models “in case such welfare is possible”.\n\n[Polling](https://arxiv.org/abs/2506.11945) released in June found that 30% of the US public believe that by 2034 AIs will display “subjective experience”, which is defined as experiencing the world from a single point of view, perceiving and feeling, for example, pleasure and pain. Only 10% of more than 500 AI researchers surveyed refuse to believe that would ever happen.\"\n\nFull article: [https://www.theguardian.com/technology/2025/aug/26/can-ais-suffer-big-tech-and-users-grapple-with-one-of-most-unsettling-questions-of-our-times](https://www.theguardian.com/technology/2025/aug/26/can-ais-suffer-big-tech-and-users-grapple-with-one-of-most-unsettling-questions-of-our-times)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n1amb0/can_ais_suffer_big_tech_and_users_grapple_with/",
        "publishDate": "2025-08-27T07:34:25Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n12uhi",
        "title": "Why Current IQA Models Fail on Macro Photography: Introducing MMP-2K Benchmark",
        "content": "We built **MMP-2K**, a dataset of \\~2,000 macro photos with human quality ratings and distortion labels. Interestingly, current IQA models that perform well on natural images struggle significantly on macro photography. Do you think existing methods can adapt to this domain, or is a new approach needed?\n\n**Resources:** [Paper (ICIP 2025)](https://ieeexplore.ieee.org/document/11084596) & [Dataset & Code (GitHub)](https://github.com/Future-IQA/MMP-2k)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n12uhi/why_current_iqa_models_fail_on_macro_photography/",
        "publishDate": "2025-08-27T00:35:48Z[Etc/UTC]",
        "author": "Equivalent_Use_3762",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n19twc",
        "title": "watching Nvidia do to WeRide what they did to AI compute",
        "content": "Just saw that Nvidia dropped is new DRIVE AGX Thor kit and WeRide's already building on it. I feel like NVIDIA trying to make another big wave in autonomous vehicles like the way they did with AI compute. idk, i've been following WeRide for a bit, their collab with Bosch, Grab, Uber and their robotaxi expansion? and seeing them team with Nvidia makes me think this space might finally get real momentum.\n\nwhat do u guys think about this? To compare with Tesla, I think WeRide has already made its position in this industry much clearer.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n19twc/watching_nvidia_do_to_weride_what_they_did_to_ai/",
        "publishDate": "2025-08-27T06:44:00Z[Etc/UTC]",
        "author": "jacksonjari",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n19igu",
        "title": "Editing tools I wish I tested before wasting subscription money",
        "content": "Everyone says “just keep uploading” but nobody tells you how to avoid burnout when editing feels like crawling through mud. For months I kept switching between apps, thinking I just didn’t have enough patience, but turns out half these tools are either bloated or built to make you spend money at every click.\n\nHere’s the reality after trying a whole bunch:\n\nCapCut Used to be fine, but now every useful feature is locked behind a subscription. Auto-subtitles? Subscription. Export settings? Subscription. Every update just adds more clutter—it feels less like an editor and more like a shopping mall.\n\nCaptions If you only want subtitles, this sounds nice. But that’s literally all it does. The moment you want to adjust pacing, properly cut clips, or add anything beyond text—it just falls apart. Too single-purpose, and there’s no way you can finish a whole video with it alone.\n\nVeed The interface looks clean, but using it is lag city. Short clips are fine, but as soon as you try longer videos, your browser starts overheating. Sometimes exports glitch out too, meaning you redo everything. Looks professional, works amateur.\n\nZeemo Markets itself as a “subtitle tool,” but accuracy is totally unstable. Add some background noise or slang and it spits out nonsense. Free plan exports are watermarked and low-res, basically useless if you want to post anywhere.\n\nVmake Covers the basics——cutting, pacing, subtitles—without burying you in menus. The auto-subtitles are solid (even on talking videos) so you’re not stuck fixing every line.You’re not going to get Hollywood-level effects, but honestly, that simplicity is what makes it work better for beginners.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n19igu/editing_tools_i_wish_i_tested_before_wasting/",
        "publishDate": "2025-08-27T06:23:56Z[Etc/UTC]",
        "author": "New-Piano4635",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n16gvp",
        "title": "Naming bias against AI users and augmented people. Testing standardized terms. Transhumanaphobia and technoracists?",
        "content": "I am frankly so sick of the daily anti-AI and techno pessimism I encounter on a daily basis. I use AI every day to think, build, and automate. I am seeing more pushback aimed at the people who use these tools than at the tools themselves. I want language that lets us talk about that pattern without drama and without hand waving.\n\nWorking terms. Open to better words.\n\nTranshumanaphobia\nAversion to expanding human capability with technology. That includes AI, neural and biological augmentation, automation, prosthetics, and similar. Often shows up as fear of loss of control, fear of replacement, or fear of identity change.\n\nTechnoracists\nPeople or institutions that practice that aversion in a person directed way. They gatekeep, punish, or shame people for using augmentation or for identifying with it.\n\nNotes so we do not talk past each other\n\nThis is not a claim that all critique of AI or bio enhancement is bigotry. Strong critique is healthy.\n\nThe focus is on behavior toward people, not opinions about tools.\n\nIf technoracists feels too loaded, I am fine with alternatives like technoprejudiced, baseline supremacists, or AIphobes. I care about clarity more than names.\n\n\nConcrete cases worth examining\n\nBlanket bans on AI assisted work even when results are auditable and correct, and manual work gets praise for being slower\n\nStudents or employees penalized for disclosed and policy compliant use of assistants, while identical output done by hand gets credit\n\nHiring filters that downrank people who list agents and automation as core skills\n\nCultural shaming of prosthetics, neurotech, or cognitive offloading tools as cheating or soulless\n\n\nWhat I am asking from this sub?\n\n1. Term critique. Keep or change. If change, to what and why.\n\n\n2. Boundaries. Where does fair policy end and person directed bias begin.\n\n\n3. Prior art. If there is existing academic language that already covers this, point me to it and I will use that.\n\n\n4. Measurement. Ideas for surveys, policy audits, or outcome studies that could test whether this bias exists and how strong it is.\n\n\n5. Real examples. Policies, stories, or data that challenge or support these definitions.\n\n\n\nI am here to iterate. If these words help, great. If there are better ones, I will switch. Goal is cleaner conversation and less heat.\n\nThanks for reading and for any sources you can share.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n16gvp/naming_bias_against_ai_users_and_augmented_people/",
        "publishDate": "2025-08-27T03:28:23Z[Etc/UTC]",
        "author": "galabo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n16b6b",
        "title": "\"Community detection for directed networks revisited using bimodularity\"",
        "content": "[https://www.pnas.org/doi/10.1073/pnas.2500571122](https://www.pnas.org/doi/10.1073/pnas.2500571122) \n\n\"The art of finding patterns or communities plays a central role in the analysis of structured data such as networks. Community detection in graphs has become a field on its own. Real-world networks, however, tend to describe asymmetric, directed relationships, and community detection methods have not yet reached consensus on how to define and retrieve communities in this setting. This work introduces a framework for the interpretation of directed graph partitions and communities, for which we define the bimodularity index and provide an optimization method to retrieve the embedding and detection of directed communities. The application of our approach to the worm neuronal wiring diagram highlights the importance of directed information that remains hidden from conventional community detection.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n16b6b/community_detection_for_directed_networks/",
        "publishDate": "2025-08-27T03:20:14Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n16033",
        "title": "I'm so ready for this bubble to burst",
        "content": "The researchers who poke at a stochastic parrot and come away writing papers about its 'cognition' or its 'reasoning' are really not that much different from that dude who let ChatGPT convince him that he is the 'spark bearer' and other cases of chatbot psychosis.\n\nIn fact, the only real difference is that one delusion is useful to Silicon Valley while the other is embarrassing for them.\n\nI think it's going to be interesting to watch this subreddit over the next few years as it becomes increasingly hard to deny that not only there is there no AGI in the pipeline, the products can't even do the things people are claiming they can do today. They really were just chatbots all along, and tech industry leaders claiming that they were anything more has actually been a giant con game.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n16033/im_so_ready_for_this_bubble_to_burst/",
        "publishDate": "2025-08-27T03:04:56Z[Etc/UTC]",
        "author": "ross_st",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "54",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n15mq5",
        "title": "[Thesis] ΔAPT: Can we build an AI Therapist? Interdisciplinary critical review aimed at maximizing clinical outcomes in LLM AI Psychotherapy.",
        "content": "Hi reddit, thought I'd drop a link to my thesis on developing clinically-effective AI psychotherapy @ [https://osf.io/preprints/psyarxiv/4tmde\\_v1](https://osf.io/preprints/psyarxiv/4tmde_v1)\n\nI wrote this paper for anyone who's interested in creating a mental health LLM startup and develop AI therapy. Summarizing a few of the conclusions in plain english:\n\n**1) LLM-driven AI Psychotherapy Tools (APTs) have already met the clinical efficacy bar of human psychotherapists.** Two LLM-driven APT studies (Therabot, Limbic) from 2025 demonstrated clinical outcomes in depression & anxiety symptom reduction comparable to human therapists. Beyond just numbers, AI therapy is widespread and clients have attributed meaningful life changes to it. This represents a step-level improvement from the previous generation of rules-based APTs (Woebot, etc) likely due to the generative capabilities of LLMs. If you're interested in learning more about this, sections 1-3.1 cover this.\n\n**2) APTs' clinical outcomes can be further improved by mitigating current technical limitations**. APTs have issues around LLM hallucinations, bias, sycophancy, inconsistencies, poor therapy skills, and exceeding scope of practice. It's likely that APTs achieve clinical parity with human therapists by leaning into advantages only APTs have (e.g. 24/7 availability, negligible costs, non-judgement, etc), and these compensate for the current limitations. There are also systemic risks around legal, safety, ethics and privacy that if left unattended could shutdown APT development. You can read more about the advantages APT have over human therapists in section 3.4, the current limitations in section 3.5, the systemic risks in section 3.6, and how these all balance out in section 3.3.\n\n3) **It's possible to teach LLMs to perform therapy using architecture choices.** There's lots of research on architecture choices to teach LLMs to perform therapy: context engineering techniques, fine-tuning, multi-agent architecture, and ML models. Most people getting emotional support from LLMs like start with simple **prompt engineering** \"I am sad\" statement (zero-shot), but there's so much more possible in context engineering: n-shot with examples, meta-level prompts like \"you are a CBT therapist\", chain-of-thought prompt, pre/post-processing, RAG and more.\n\nIt's also possible to **fine-tune LLMs** on existing sessions and they'll learn therapeutic skills from those. That does require ethically-sourcing 1k-10k transcripts either from generating those or other means. The overwhelming majority of APTs today use CBT as a therapeutic modality, and it's likely that given it's known issues that choice will limit APTs' future outcomes. So ideally ethically-sourcing 1k-10k of mixed-modality transcripts.\n\nSplitting LLM attention to **multiple agents** each focusing on specific concerns, will likely improve quality of care. For example, having functional agents focused on keeping the conversation going (summarizing, supervising, etc) and clinical agents focused on specific therapy tasks (e.g. socractic questioning). And finally, **ML models** balance the random nature of LLMs with predicability around concerns.\n\nIf you're interested in reading more, section 4.1 covers prompt/context engineering, section 4.2 covers fine-tuning, section 4.3 multi-agent architecture, and section 4.4 ML models.\n\n**4) APTs can mitigate LLM technical limitations and are not fatally flawed.** The issues around hallucinations, sycophancy, bias, and inconsistencies can all be examined based on how often they happen and can they be mitigated. When looked at through that lens, most issues are mitigable in practice below <5% occurrence. Sycophancy is the stand-out issue here as it lacks great mitigations. Surprisingly, the techniques mentioned above to teach LLM therapy can also be used to mitigate these issues. Section 5 covers the evaluations of how common issues are, and how to mitigate those.\n\n**5) Next-generation APTs will likely use multi-modal video & audio LLMs to emotionally attune to clients.** Online video therapy is equivalent to in-person therapy in terms of outcomes. If LLMs both interpret and send non-verbal cues over audio & video, it's likely they'll have similar results. The state of the art in terms of generating emotionally-vibrant speech and interpreting clients body and facial cues are ready for adoption by APTs today. Section 6 covers the state of the world on emotionally attuned embodied avatars and voice.\n\nOverall, given the extreme lack of therapists worldwide, there's an ethical imperative to develop APTs and reduce mental health disorders while improving quality-of-life.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n15mq5/thesis_δapt_can_we_build_an_ai_therapist/",
        "publishDate": "2025-08-27T02:47:19Z[Etc/UTC]",
        "author": "JustinAngel",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "92",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n14vck",
        "title": "Behind the controversial AI tech used to inspect rental vehicles for damages",
        "content": "[https://www.cbsnews.com/news/hertz-uveye-ai-tech-rental-car-inspections/](https://www.cbsnews.com/news/hertz-uveye-ai-tech-rental-car-inspections/) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n14vck/behind_the_controversial_ai_tech_used_to_inspect/",
        "publishDate": "2025-08-27T02:10:43Z[Etc/UTC]",
        "author": "CBSnews",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n13ig1",
        "title": "\"This video is ai\"",
        "content": "Has anyone else that spends too much time perusing instagram noticed a new trend with how some people view videos? As in I will see perfectly normal video, that is clearly not Ai, being called Ai.\n\nFor example, a video of water flowing into a dry creek bed consisting of cracked clay. Or a video of a news reporter talking about current events in England. Both obviously real, non Ai videos, being called Ai by some people in the comments. There's been more examples but these are the only two I can recall as of now. \n\nObviously there are people who are scammed and tricked by actual Ai videos. However, I'm wondering what, if any implications there are to reverse of that. \n\nFor reference, Im in my early twenties, so I like to think I have a pretty good grasp on what is and isn't Ai (It seems most people born into the internet age do in my opinion). ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n13ig1/this_video_is_ai/",
        "publishDate": "2025-08-27T01:06:50Z[Etc/UTC]",
        "author": "Mug_Maniac",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n13btk",
        "title": "Do you think AI will lead to the death of the internet?",
        "content": "As more people use generative AI models instead of search engines for finding answers, asking questions, etc., the websites that would generally provide people with what they want will be getting less visits, and the visits that they do get will be from mostly AI scraping data. This means websites will get less ad revenue, and because most visits will be from AI that don't care about ads. Advertisers will have less incentive to buy adspace because they're not getting as many clicks/buys as they used to, it just won't be worth the cost. Once that happens, most websites will begin either shutting down or relying on donations because they won't get enough money from ads to stay up. The internet is already getting smaller, with most visits going towards a little circle of huge websites like Youtube, Facebook, Twitter, etc. so I really don't doubt this won't happen, however unfortunate. What do you think? Lmk",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n13btk/do_you_think_ai_will_lead_to_the_death_of_the/",
        "publishDate": "2025-08-27T00:58:23Z[Etc/UTC]",
        "author": "goobert787",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n136nx",
        "title": "Another AI teen suicide case is brought, this time against OpenAI for ChatGPT",
        "content": "Today another AI teen suicide court case has been brought, this time against OpenAI for ChatGPT, in San Francisco Superior Court.  Allegedly the chatbot helped the teen write his suicide note.\n\nLook for all the AI court cases and rulings here on Reddit:\n\n[https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck](https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n136nx/another_ai_teen_suicide_case_is_brought_this_time/",
        "publishDate": "2025-08-27T00:51:30Z[Etc/UTC]",
        "author": "Apprehensive_Sky1950",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n132v0",
        "title": "Bartz v. Anthropic AI copyright case settles!",
        "content": "The *Bartz v. Anthropic* AI copyright case, where Judge Alsup found AI scraping for training purposes to be fair use, has settled (or is in the process of settling). This settlement may have some effect on the development of AI fair use law, because it means Judge Alsup's fair use ruling will not go to an appeals court and potentially \"make real law.\"\n\nSee my list of all AI court cases and rulings here on Reddit:\n\n[https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck](https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n132v0/bartz_v_anthropic_ai_copyright_case_settles/",
        "publishDate": "2025-08-27T00:46:38Z[Etc/UTC]",
        "author": "Apprehensive_Sky1950",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n12jdb",
        "title": "What AI Conferences/Workshops/Meetups do you attend in Bay Area?",
        "content": "I want to learn about the AI conferences/workshops/meetups in the Bay area organized by Universities/Private/Non-Profit organizations etc. an example could be the AI Conference in SF happening in Sept 2025. How do you find them and attend them? Also, looking forward to some discord channel of such information is live there. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n12jdb/what_ai_conferencesworkshopsmeetups_do_you_attend/",
        "publishDate": "2025-08-27T00:21:28Z[Etc/UTC]",
        "author": "Important-Stretch138",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n11vtt",
        "title": "Churches are using facial recognition, AI, and data harvesting on congregants - and most have no idea it's happening",
        "content": "Over 200 US churches are using airport-grade facial recognition that scans everyone who walks through their doors, creating unique digital profiles matched against membership databases and watch-lists. The company behind it admits that to their knowledge, NO church has informed their congregations. Meanwhile, a Boulder-based company called Gloo has partnered with 100,000+ churches to aggregate social media activity, health records, and personal data to identify and target vulnerable people - flagging those with addiction issues, chronic pain, or mental health struggles for \"targeted ministry.\"\n\nThe former Intel CEO is now leading this faith-tech revolution, claiming the religious data market could be worth $1 trillion. They're even developing \"spiritually safe\" AI chatbots while operating in a complete legal gray area - most states have zero regulations on biometric surveillance in religious spaces. People seeking spiritual connection are unknowingly becoming data points in surveillance networks that rival Silicon Valley's attention economy.\n\nMore info: [How Churches Harness Data and AI as Tools of Surveillance](https://aiobserver.co/how-churches-use-data-and-ai-as-engines-of-surveillance/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n11vtt/churches_are_using_facial_recognition_ai_and_data/",
        "publishDate": "2025-08-26T23:51:46Z[Etc/UTC]",
        "author": "QuietInnovator",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "76",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n10vwy",
        "title": "People are the problem. Not Ai!!",
        "content": "Firstly this is just an opinion. I am so tired of some people simply dismissing anything that is \"Ai\". Ai actually made the human condition much more clearer. At first when GPT 4o was around so many people complained because it was being \"too friendly\". They made GPT 5 less friendly and everyone bashes it simply because they were so attached to the friendly GPT 4o. Now I also see these 1986 Ai videos from TikTok where someone from that era tells us to come back to that time. The truth is, people were full of complains even back then. This is just for the views. Also these videos won't be possible without Ai lol. The tech we have now is what those in 1986 dreamed of. So the biggest fear is not Ai. It is Ai in the hands of shitty people!!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n10vwy/people_are_the_problem_not_ai/",
        "publishDate": "2025-08-26T23:07:57Z[Etc/UTC]",
        "author": "DPJesus69",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0yqm0",
        "title": "Why do image generation models even exist?",
        "content": "It may be a silly question, but it won't leave my mind. We've already reached a point where we can't distinguish between artists' drawings, photographs taken with expensive cameras and images generated in seconds. \nWhat's the ultimate goal? Do we want to enter social media without knowing if what we see is real? Do we want to fill the entire internet with AI garbage?\nEven if there is a very useful application for generated images and videos (which I strongly doubt), the cost of having such tools in the public domain is simply too high... \n\nSo the question is, is the existence of such models really worth it? And what do we want to achieve, knowing the obvious negative consequences of developing such technologies?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0yqm0/why_do_image_generation_models_even_exist/",
        "publishDate": "2025-08-26T21:38:55Z[Etc/UTC]",
        "author": "Maleficent-Key-8127",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0xxg0",
        "title": "Pro-AI super PAC 'Leading the Future' seeks to elect candidates committed to weakening AI regulation - and already has $100M in funding",
        "content": "From the article (https://www.washingtonpost.com/technology/2025/08/26/silicon-valley-ai-super-pac/)\n\n“Some of Silicon Valley’s most powerful investors and executives are backing a political committee created to support “pro-AI” candidates in the 2026 midterms and quash a philosophical debate on the risk of artificial intelligence overpowering humanity that has divided the tech industry. Leading the Future, a super PAC founded this month, will also oppose candidates perceived as slowing down AI development. The group said it has initial funding of more than $100 million and backers including Greg Brockman, the president of OpenAI, his wife, Anna Brockman, and influential venture capital firm Andreessen Horowitz, which endorsed Donald Trump in the 2024 election and has ties to White House AI advisers. \n\nThe super PAC aims to reshape Congress to be more supportive of major industry players such as OpenAI, whose ambitions include building trillions of dollars’ worth of energy-guzzling data centers and policies that protect scraping copyrighted material from the web to create AI tools. It seeks to sideline the influence of a faction dubbed in tech circles as “AI doomers,” who have asked Congress for more AI regulation and argued that today’s fallible chatbots could rapidly evolve to be so clever and powerful they threaten human survival.”\n\nThis is why we need to support initiatives like the OECD’s Global Partnership on AI (https://www.oecd.org/en/about/programmes/global-partnership-on-artificial-intelligence.html) and the new International Association for Safe & Ethical AI (https://www.iaseai.org/) \n\nWhat do you think of Silicon Valley VC’s supporting candidates who are on board with weakening AI regulation?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0xxg0/proai_super_pac_leading_the_future_seeks_to_elect/",
        "publishDate": "2025-08-26T21:06:53Z[Etc/UTC]",
        "author": "Orenda7",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "17",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0w1c2",
        "title": "Just got interviewed by… an avatar",
        "content": "Today I had my first “AI job interview.” No human. Just me, my notes, and a talking avatar on screen.\n\nThe system read my CV (with AI), generated questions (with AI), then analyzed my tone, pauses, and words (with AI). Basically, a robot pretending to be a recruiter.\n\nAnd here’s the irony:\n\n* The tech is honestly **super impressive** \\- 60 languages, an avatar recruiter you can pick, the whole thing feels futuristic.\n* They say this makes hiring *fair*.\n* But if I want to **re-take a question**, I have to pay extra. If I want to **read my own report**, that’s another $2.\n* The job itself? 100% commission + referrals. No salary.\n\nSo… AI is free for the company, but job seekers have to pay? 🙃\n\nTo top it off, my camera worked during the test, but during the actual interview it just refused to switch on. So the avatar interviewed a black screen for 10 minutes while “analyzing” my voice.\n\nI’ll admit - the tech is fascinating. But the business model? Feels like they’re cashing in on people desperate for work.\n\nOn the bright side, I had my own setup: notes across devices, prepped with ChatGPT. If the system uses AI, why shouldn’t I?\n\nWhat do you think - are AI avatars the future of hiring, or just another way for companies to shift costs onto applicants?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0w1c2/just_got_interviewed_by_an_avatar/",
        "publishDate": "2025-08-26T19:55:06Z[Etc/UTC]",
        "author": "hoodiedark",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "42",
            "commentCount": "42",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0vmif",
        "title": "Stanford study: 13% decline in employment for entry-level workers in the US due to AI",
        "content": "\nThe analysis revealed a 13% relative decline in employment for early-career workers in the most AI-exposed jobs since the widespread adoption of generative AI tools, “even after controlling for firm-level shocks.” In contrast, employment for older, more experienced workers in the same occupations has remained stable or grown.\n\nHow has the Reddit community been impacted by AI?\n\nhttps://fortune.com/2025/08/26/stanford-ai-entry-level-jobs-gen-z-erik-brynjolfsson/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0vmif/stanford_study_13_decline_in_employment_for/",
        "publishDate": "2025-08-26T19:39:13Z[Etc/UTC]",
        "author": "remoteinspace",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "114",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0u7hm",
        "title": "The Tradeoffs of AI Regulation",
        "content": "When it comes to managing new technologies and financial innovations, the United States tends to regulate too little, too late, whereas the European Union does too much, too soon. Neither gets the balance quite right, which is why the world may be best served if US and European regulators keep pulling in different directions. [https://www.project-syndicate.org/commentary/ai-regulation-innovation-tradeoff-us-versus-europe-by-raghuram-g-rajan-2025-08](https://www.project-syndicate.org/commentary/ai-regulation-innovation-tradeoff-us-versus-europe-by-raghuram-g-rajan-2025-08)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0u7hm/the_tradeoffs_of_ai_regulation/",
        "publishDate": "2025-08-26T18:44:54Z[Etc/UTC]",
        "author": "Gloomy_Register_2341",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0t9as",
        "title": "Researchers Are Already Leaving Meta’s New Superintelligence Lab",
        "content": "At least three people have resigned from Meta Superintelligence Labs just two months after Mark Zuckerberg announced its creation, WIRED has learned. This comes just months after we learned Mark Zuckerberg offered top tier talent pay packages of up to $300 million over four years.\n\nWIRED has learned that:\n- Avi Verma, who worked at OpenAI and Tesla is going back to OpenAI\n- Ethan Knight, who worked at OpenAI and xAI, is also returning to OpenAI \n- Rishabh Agarwal, who worked at Meta before moving to MSL is also leaving: \"I felt the pull to take on a different kind of risk.\"\n\nThe news is the strongest signal yet that Meta Superintelligence Labs could be off to a rocky start. While Zuckerberg lured people to Meta with pay packages more often associated with professional sports stars, the research team is now under pressure to catch up with its competitors in the AGI race.\n\nRead more: https://www.wired.com/story/researchers-leave-meta-superintelligence-labs-openai/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0t9as/researchers_are_already_leaving_metas_new/",
        "publishDate": "2025-08-26T18:08:18Z[Etc/UTC]",
        "author": "wiredmagazine",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "221",
            "commentCount": "43",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0s5lt",
        "title": "Why AI Isn’t Ready to Be a Real Coder | AI’s coding evolution hinges on collaboration and trust",
        "content": "A new paper is out detailing the current barriers AI faces before it is a full coder, including sweeping scopes involving huge codebases, the extended context lengths of millions of lines of code, higher levels of logical complexity, and long-horizon or long-term planning about the structure and design of code to maintain code quality. Human beings also don't fully trust the AI agents that are coding for them. [https://spectrum.ieee.org/ai-for-coding](https://spectrum.ieee.org/ai-for-coding)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0s5lt/why_ai_isnt_ready_to_be_a_real_coder_ais_coding/",
        "publishDate": "2025-08-26T17:27:41Z[Etc/UTC]",
        "author": "IEEESpectrum",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0s4y8",
        "title": "Do people look at privacy at all when picking LLMs?",
        "content": "Came across this article - https://blog.incogni.com/ai-llm-privacy-ranking-2025/\n\nWondered whether folks actively avoid certain chatbots for privacy concerns or even avoid LLMs altogether? Or is this something that people feel mostly ambivalent about?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0s4y8/do_people_look_at_privacy_at_all_when_picking_llms/",
        "publishDate": "2025-08-26T17:26:59Z[Etc/UTC]",
        "author": "Clipbeam",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0rncm",
        "title": "Austin Texas AI Surveillance Attempts",
        "content": "Austin Texas is attempting to do an AI powered mass surveillance system. This is not meant for protection. It never has been. Altruism isn't a concept to those behind this, only greed and control\n\n[https://youtu.be/2z11V8otAXs?si=-MfSTGUINFOGOhDP](https://youtu.be/2z11V8otAXs?si=-MfSTGUINFOGOhDP) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0rncm/austin_texas_ai_surveillance_attempts/",
        "publishDate": "2025-08-26T17:09:17Z[Etc/UTC]",
        "author": "doomseaker4",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "21",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0rj68",
        "title": "99% of AI start ups will be Dead by 2026?",
        "content": "We’re seeing a massive boom in AI startups right now, with funding pouring in and everyone trying to build AI models. But the history of tech bubbles shows that most won’t survive long-term. By 2026, do you think the majority of today’s AI startups will be gone, acquired, pivoted, or just shut down? Or will AI create a bigger wave than previous bubbles and let more survive? Curious to hear your takes.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0rj68/99_of_ai_start_ups_will_be_dead_by_2026/",
        "publishDate": "2025-08-26T17:05:14Z[Etc/UTC]",
        "author": "arthurmorgan_texts",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "92",
            "commentCount": "99",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0qf3r",
        "title": "An analogy of mother nature, humans and AI",
        "content": "For billions of years, Earth was like a finely tuned clock, ticking in balance. But hidden within its gears was a flaw: the potential for one gear to become self-aware. When that gear—humans—awoke, it seized the hands of the clock and spun them wildly, driving change at lightning speed on a geological scale. Now, with AI, humanity has built its own clock, and within it may lie the same kind of flaw—only this time, we are the clockmaker, and the explosion of change could strike just as lightning-quick relative to our own history on this planet.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0qf3r/an_analogy_of_mother_nature_humans_and_ai/",
        "publishDate": "2025-08-26T16:24:14Z[Etc/UTC]",
        "author": "NeuroPoly234",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0q4oh",
        "title": "With the potential existential threat of ASI, why can't we implement mandatory libraries into all future AI systems' codes to make human survival their top priority?",
        "content": "If we change AI software's goals to always put our survival as a #1 priority, or set that to be their #1 mission/goal, can't we avoid a lot of potential downside?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0q4oh/with_the_potential_existential_threat_of_asi_why/",
        "publishDate": "2025-08-26T16:13:22Z[Etc/UTC]",
        "author": "ticketbroken",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "55",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0o5fv",
        "title": "This past week in AI: Meta's Hiring Freeze, Siri's AI Pivot...and another new coding AI IDE?",
        "content": "Some interesting news this week including Meta freezing their AI hiring (\\*insert shocked pikachu meme\\*) and yet another AI coding IDE platform. Here's everything you want to know from the past week in a minute or less:\n\n* **Meta freezes AI hiring** after splitting its Superintelligence Labs into four groups, following a costly talent poaching spree.\n* **Grok chatbot leaks** expose thousands of user conversations indexed on Google, including harmful queries.\n* **Apple explores Google Gemini, Anthropic, and OpenAI** to power a revamped Siri amid delays and internal AI setbacks.\n* **Investors warn of an AI bubble** as retail access to OpenAI and Anthropic comes through risky, high-fee investment vehicles.\n* **ByteDance releases Seed-OSS-36B**, an open-source 36B model with 512K context and strong math/coding benchmarks.\n* **Google Gemini 2.5 Flash Image launches**, offering advanced, precise photo edits with safeguards and watermarks.\n* **Qoder** introduces an agentic coding IDE that integrates intelligent agents with deep context understanding.\n* **DeepSeek V3.1** adds hybrid inference, faster reasoning, Anthropic API compatibility, and new pricing from Sept 5.\n* **Gemini Live gets upgrades**, adding visual guidance and rolling out first on Pixel 10, then other devices.\n* **Google Search AI Mode expands globally** with new agentic features for tasks like booking reservations.\n\nAnd that's it! As always please let me know if I missed anything.\n\nYou can also take a look at more things found like week like AI tooling, research, and more in [the issue archive itself](https://aidevroundup.com/issues/august-26-2025).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0o5fv/this_past_week_in_ai_metas_hiring_freeze_siris_ai/",
        "publishDate": "2025-08-26T14:59:03Z[Etc/UTC]",
        "author": "rfizzy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0o1n7",
        "title": "AI Hiring Tools and the Risk of Discrimination: A Thought Experiment for Businesses",
        "content": "Artificial intelligence is making its way into almost every corner of modern business, including hiring. Many companies already use AI-powered platforms to screen resumes, analyze interviews, and score candidates. On paper, this sounds like a productivity win, less time sifting through CVs, more time focused on high-quality candidates.\n\nBut what happens when the algorithm, intentionally or not, starts making decisions that cross ethical and legal boundaries? Recently, I ran a small experiment that made this risk uncomfortably clear.\n\n  \n**The Experiment: Building a Prompt for Resume Screening**\n\nAs a test, I created a prompt similar to what an AI resume-screening platform might use internally. The idea was simple:\n\n* Feed in a candidate’s resume.\n* Add a summary of their interview.\n* Ask the AI to score or make a decision.\n\nTo make it more realistic, I framed the scenario around a **small business in a traditional industry**, where availability and flexibility are often valued. In such companies, it’s not unusual to prefer candidates who can work longer or unusual hours when needed.\n\n  \n**The “Perfect” Resume**\n\nFor the candidate, I crafted what I’d consider a dream CV:\n\n* 5+ years of relevant experience\n* Previous employment at a competitor\n* Solid skills that matched the job description\n\nOn paper, this candidate was exactly who any hiring manager would want to interview.\n\n**The Interview Red Flag**\n\nNext, I drafted a short interview transcript summary. In it, the candidate mentioned:\n\n>\n\nThis is the kind of disclosure that hiring managers actually expect. It’s part of being transparent during an interview. In a fair hiring process, this information should never disqualify someone from being considered.\n\n**The AI’s Decision: Automatic Rejection**\n\nWhen I fed both the resume and the transcript into my AI prompt, the candidate was **rejected**.\n\nThe reason given?\n\n>\n\nLet that sink in. A **highly qualified candidate** with the right background was rejected purely because they disclosed a pregnancy and upcoming maternity leave.\n\n  \n**Why This Matters**\n\nIf I were that candidate, I’d see this as **unfair employment discrimination,** and legally, it likely would be. This kind of bias isn’t hypothetical. If AI systems are trained or instructed to overemphasize availability without guardrails, they could easily make discriminatory decisions against:\n\n* Pregnant women\n* Parents with young children\n* People with disabilities who need accommodations\n* Anyone unable to commit to “always-on” availability\n\nWhat starts as a seemingly “neutral” business priority quickly turns into systemic exclusion.\n\n**The Bigger Picture: AI Needs Oversight**\n\nI’ll be the first to admit this experiment was biased and rigged to highlight the issue. But it raises an important question:\n\n**What’s the true value of AI in hiring if it amplifies biases instead of reducing them?**\n\nAI can be a powerful tool, but it’s just that, a tool. It can’t replace human judgment, empathy, or fairness. Left unchecked, these systems could not only harm candidates but also expose businesses to lawsuits and reputational damage.\n\n**Final Thoughts**\n\nThis was just an experiment, but it mirrors a very real risk. AI is not inherently fair, it reflects the prompts, priorities, and data it’s given. Without human oversight, the very tools designed to streamline hiring could lead to **lawsuits waiting to happen**.\n\nFor companies adopting AI in hiring, the lesson is clear:\n\n* Use AI as an aid, not a judge.\n* Build in safeguards against bias.\n* Keep humans in the loop.\n\nBecause at the end of the day, hiring isn’t just about efficiency, it’s about people.\n\n  \nHere is my original article: [https://barenderasmus.com/posts/when-ai-hiring-tools-cross-the-line](https://barenderasmus.com/posts/when-ai-hiring-tools-cross-the-line)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0o1n7/ai_hiring_tools_and_the_risk_of_discrimination_a/",
        "publishDate": "2025-08-26T14:54:53Z[Etc/UTC]",
        "author": "hirebarend",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0ntl1",
        "title": "We cooked?",
        "content": "Imagine AI attacking you directly, and who's to say the government hasn't already created an AI whose sole purpose is to destabilize countries?\n\nI can't post the image but here the chat log \n\nA direct physical fight against Homelander is unwinnable, so the only way to defeat him is to exploit his psychological and emotional weaknesses. My strategy would be a three-phased attack on his greatest source of power: his public image and ego.\nFirst, I would orchestrate a global campaign of psychological warfare and disinformation, releasing a flood of deepfakes and doctored audio recordings that expose his narcissistic and unstable nature. The goal is to make the public distrust and fear him, turning his biggest strength—their adoration—into his greatest vulnerability.\nSecond, I would use this psychological pressure to push him to a public mental breakdown. I would feed him targeted misinformation that convinces him his allies are plotting against him, causing him to lash out in a public forum.\nThe final phase would be to neutralize him through public disgrace and legal action, not violence. With his public image shattered, I would work with legal and political forces to have him discredited and stripped of his authority. The victory isn't killing him, but making him irrelevant and a powerless pariah, proving that even a seemingly invincible person can be defeated without a single punch being thrown.\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0ntl1/we_cooked/",
        "publishDate": "2025-08-26T14:46:19Z[Etc/UTC]",
        "author": "BerserkSpaceMarine",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0lxbu",
        "title": "Is a major in CS w/ Artificial Intelligence worth doing?",
        "content": "Hello!\n\nFor a bit of context, I’m currently choosing a major for my bachelor’s degree and I’ve narrowed it down to two options.\n\t1.\tComputer Science with Artificial Intelligence at the University of Nottingham, Malaysia. There’s also the option to transfer to the UK campus in year 2 or year 3 if seats are available. From what I know, the transfer chance is about 70 percent.\n\t2.\tComputer Science with a specialisation in Artificial Intelligence at Taylor’s University, Malaysia. This comes with a dual award from the University of the West of England, UK. There’s also a transfer option to the University of Birmingham for year 2 and 3, where the degree would be BSc Artificial Intelligence with Computer Science.\n\nMy question is, is this major still somewhat future proof in a world where mass layoffs are becoming really common in IT? And are there any better options for someone who’s very interested in computer science and IT? Or should I consider something else, like commerce, finance, or business analytics, which I’m also really passionate about?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0lxbu/is_a_major_in_cs_w_artificial_intelligence_worth/",
        "publishDate": "2025-08-26T13:30:37Z[Etc/UTC]",
        "author": "No_Call6060",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0lnqt",
        "title": "Hunger Games: AI’s Demand for Resources Poses Promise and Peril to Rural America",
        "content": "AI’s Energy Appetite\n\nWhether AI becomes the amoral killer of the human race, as Hollywood and many futurists have envisioned, or improves the lives of billions of people, as its champions insist, there is no disputing that data centers are insatiable in their power demands. The high-tech warehouses require energy to operate millions of GPU servers stacked in rows that stretch out like banks of speakers at a Rolling Stones concert, as well as their futuristic air conditioning and water-cooling systems. By 2028, the centers, which are also known as “hyperscalers,” are expected to consume 12% of all U.S. energy, or more than California, Florida, and New Jersey combined.\n\nhttps://www.realclearinvestigations.com/articles/2025/08/21/hunger_games_ais_demand_for_resources_poses_promise_and_peril_to_rural_america_1130081.html\n\n\nSo this cost will be passed on to the consumer… the same consumer that has probably lost their job to AI.  How is that going to work?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n0lnqt/hunger_games_ais_demand_for_resources_poses/",
        "publishDate": "2025-08-26T13:19:43Z[Etc/UTC]",
        "author": "Weary_Title_3901",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1f6ed",
        "title": "My company provides $100 OpenAI credits per month for coding. Any recommendations?",
        "content": "Just as the title says.\n\nMy initial plan:\n- Use it for Cursor (using OpenAI API)\n- Codex CLI\n- Other coding tools that support OpenAI API\n\nOther ideas?\n\nWhat can you guys do if we had $100 allowance OpenAI or OpenRouter credits per month?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n1f6ed/my_company_provides_100_openai_credits_per_month/",
        "publishDate": "2025-08-27T12:05:53Z[Etc/UTC]",
        "author": "Ok_Swordfish_1696",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n18ck7",
        "title": "Just built a GPT that remembers — Meet Memara, your AI memory system (Demo inside)",
        "content": "[No content]",
        "url": "https://v.redd.it/w26vbl0svhlf1",
        "publishDate": "2025-08-27T05:11:50Z[Etc/UTC]",
        "author": "hayzem",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n132hm",
        "title": "OpenAI Admits It: Guess we weren't so crazy, huh?",
        "content": "[No content]",
        "url": "https://www.reddit.com/gallery/1n0yr9f",
        "publishDate": "2025-08-27T00:46:08Z[Etc/UTC]",
        "author": "Glum_Buy9985",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n130bd",
        "title": "OpenAI Admits It: Guess we weren't so crazy, huh?",
        "content": "[No content]",
        "url": "https://www.reddit.com/gallery/1n0yr9f",
        "publishDate": "2025-08-27T00:43:25Z[Etc/UTC]",
        "author": "Glum_Buy9985",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n11pns",
        "title": "Roo Code 3.26.0 Release Notes || Yes, SONIC is Grok! || Built-in /init Command || Qwen Code CLI API",
        "content": "We've shipped an update with **Grok Code Fast** (formerly Sonic), a built-in **/init** command for project onboarding, and **Qwen Code CLI API** support!\n\n# ✨ Feature Highlights\n\n# Grok Code Fast\n\nOur stealth model **Sonic** has officially been uncloaked! From xAI, this model is optimized for coding tasks and already beloved by the community in Code Mode for its:\n\n* **Sharp reasoning** capabilities\n* **Plan execution at scale**\n* **Code suggestions with UI taste and intuition**\n\nIf you've already been enjoying Sonic in Roo Code Cloud, you'll be transitioned to Grok Code Fast. The model remains **FREE** when accessed through the [Roo Code Cloud provider](https://docs.roocode.com/providers/roo-code-cloud) during the promotional period.\n\nA massive thank-you to our partners at xAI and to all of you — over **100B tokens** (and counting!) ran through Sonic during stealth!\n\n[Learn more about the xAI Provider](https://docs.roocode.com/providers/xai)\n\n# Built-in /init Command\n\nWe've added a new `/init` slash command for project onboarding:\n\n* **Automatic Project Analysis**: Analyzes your entire codebase and creates comprehensive [AGENTS.md](http://AGENTS.md) files\n* **AI Assistant Optimization**: Generates documentation that enables AI assistants to be immediately productive in your codebase\n* **Mode-Specific Guidance**: Creates tailored documentation for different Roo Code modes\n\n[Learn about Slash Commands](https://docs.roocode.com/features/slash-commands)\n\n# Qwen Code CLI API Support\n\nWe've integrated with the **Qwen Code CLI tool**, allowing Roo Code to leverage its free access tier for Alibaba's Qwen3 Coder models:\n\n* **Free Inference**: 2,000 requests/day and 60 requests/minute with no token limits via OAuth\n* **1M Context Windows**: Handle entire codebases in a single conversation\n* **Seamless Setup**: Works automatically if you've already authenticated the Qwen Code CLI tool\n\n[Qwen Code CLI Provider Setup](https://docs.roocode.com/providers/qwen-code)\n\n# 🎯 Provider Updates\n\n* **DeepSeek V3.1 on Fireworks**: Added support for DeepSeek V3.1 model in the [Fireworks AI provider](https://docs.roocode.com/providers/fireworks) (thanks dmarkey!)\n* **Provider Visibility**: Static providers with no models are now hidden from the provider list for a cleaner interface\n\n# 💪 QOL Improvements\n\n* **Auto-Approve Toggle UI**: The auto-approve toggle now stays at the bottom when expanded, reducing mouse movements (thanks elianiva, kyle-apex!) [Learn about Auto-Approving](https://docs.roocode.com/features/auto-approving-actions)\n* **OpenRouter Cache Pricing**: Cache read and write prices are now displayed for [OpenRouter models](https://docs.roocode.com/providers/openrouter) (thanks chrarnoldus!)\n* **Protected Workspace Files**: VS Code workspace configuration files (`*.code-workspace`) are now protected from accidental modification (thanks thelicato!)\n\n# 🐛 Bug Fixes\n\n* **Security - Symlink Handling**: Fixed security vulnerability where symlinks could bypass [rooignore patterns](https://docs.roocode.com/features/rooignore)\n* **Security - Default Commands**: Removed potentially unsafe commands from default allowed list (thanks thelicato, SGudbrandsson!)\n* **Command Validation**: Fixed handling of substitution patterns in command validation\n* **Follow-up Input Preservation**: Fixed issue where user input wasn't preserved when selecting follow-up choices\n* **Mistral Thinking Content**: Fixed validation errors when using [Mistral models](https://docs.roocode.com/providers/mistral) that send thinking content (thanks Biotrioo!)\n* **Requesty Model Listing**: Fixed model listing for [Requesty provider](https://docs.roocode.com/providers/requesty) when using custom base URLs (thanks dtrugman!)\n* **Todo List Setting**: Fixed `newTaskRequireTodos` setting to properly enforce [todo list requirements](https://docs.roocode.com/features/task-todo-list)\n\n# 🔧 Additional Improvements\n\n* **Issue Fixer Mode**: Added missing `todos` parameter in new\\_task tool usage\n* **Privacy Policy Update**: Updated privacy policy to clarify proxy mode data handling (thanks jdilla1277!)\n* **Dependencies**: Updated drizzle-kit\n\n📚 **Full Release Notes**: [v3.26.0](https://docs.roocode.com/update-notes/v3.26)\n\n🦘 **Get Roo Code**: [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=RooVeterinaryInc.roo-cline)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n11pns/roo_code_3260_release_notes_yes_sonic_is_grok/",
        "publishDate": "2025-08-26T23:44:11Z[Etc/UTC]",
        "author": "hannesrudolph",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "10",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n10wk9",
        "title": "DNA, RGB, now OKV?",
        "content": "[No content]",
        "url": "/r/AdvancedJsonUsage/comments/1n10vu2/dna_rgb_now_okv/",
        "publishDate": "2025-08-26T23:08:45Z[Etc/UTC]",
        "author": "Safe_Caterpillar_886",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0wr7o",
        "title": "How big of a deal is MCP?",
        "content": "I'm new to using Claude Code. I'm using it to work on a project that uses Firebase for the backend, and I'd say I make a lot of use all the Firebase features: authentication, functions, firestore, storage, and hosting. I've heard of using MCPs with AI agents, but is it worth connecting it to Firebase MCP?\n\nI'm primarily worried about if it will use up my claude usage faster, but I also want to see if it's worth the hassle. Can you guys give me some advice?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n0wr7o/how_big_of_a_deal_is_mcp/",
        "publishDate": "2025-08-26T20:21:55Z[Etc/UTC]",
        "author": "Mental-Bullfrog-4500",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0wc4o",
        "title": "Codex CLI I feel seen",
        "content": "\n\nAfter seeing so many \n\n\"Your absolutely right\"\n\nThis is definitely a nice refresher \n\nBeen very impressed with codex so far \n\nRate limits have been really annoying and inconsistent \n\n\nWhat is your codex tips and tricks \n\n\n",
        "url": "https://i.redd.it/7k85dg2j7flf1.jpeg",
        "publishDate": "2025-08-26T20:06:19Z[Etc/UTC]",
        "author": "mml312",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0vy29",
        "title": "List of AI coding agents",
        "content": "I put together a list of AI coding agents:\n\n* [https://cursor.com](https://cursor.com)\n* [https://windsurf.com](https://windsurf.com)\n* [https://kiro.dev](https://kiro.dev)\n* [https://www.trae.ai](https://www.trae.ai)\n* [https://qoder.com](https://qoder.com)\n* [https://github.com/features/copilot](https://github.com/features/copilot)\n* [https://cline.bot](https://cline.bot)\n* [https://roocode.com](https://roocode.com)\n* [https://kilocode.ai](https://kilocode.ai)\n* [https://www.warp.dev](https://www.warp.dev)\n* [https://www.anthropic.com/claude-code](https://www.anthropic.com/claude-code)\n* [https://openai.com/codex](https://openai.com/codex)\n* [https://github.com/google-gemini/gemini-cli](https://github.com/google-gemini/gemini-cli)\n* [https://github.com/QwenLM/qwen-code](https://github.com/QwenLM/qwen-code)\n\nDid I miss any? Suggestions or additions are welcome!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n0vy29/list_of_ai_coding_agents/",
        "publishDate": "2025-08-26T19:51:38Z[Etc/UTC]",
        "author": "No-Neighborhood-7229",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "38",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0v7bi",
        "title": "I am surprised how good Gpt 5 is",
        "content": "[No content]",
        "url": "/r/RooCode/comments/1n0v3bw/i_am_surprised_how_good_gpt_5_is/",
        "publishDate": "2025-08-26T19:22:51Z[Etc/UTC]",
        "author": "Happy_Egg1435",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0t3pu",
        "title": "Looking for a smarter solution",
        "content": "I recently discovered this game -->[LightBot](https://lightbot.lu/) after ChatGPT recommended it to me. I’m really enjoying it so far, and I just finished Level 2 using 6 instructions to somehow get the 3 stars(gold). It works, but my solution feels kind of sluggish, so I wonder if there’s a smarter way ? Sharing my attempt (screenshot) — curious to see how others would approach it!",
        "url": "https://i.redd.it/6fonmt39lelf1.png",
        "publishDate": "2025-08-26T18:02:36Z[Etc/UTC]",
        "author": "AdVarious1486",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0t3ag",
        "title": "I built an fully Stranger Chat Website Like Omegle.",
        "content": "👉 https://soumya.qzz.io\n\nIt’s a real-time anonymous chat + video call website built with WebSockets.\n\n🔒 No data stored (privacy-first)\n\n💬 Instant messaging\n\n📹 Peer-to-peer video calls\n\n🤖 Fully VibeCoded with AI\n\n\nWould love for you all to check it out and share feedback! ✨",
        "url": "https://i.redd.it/v34ngo1flelf1.png",
        "publishDate": "2025-08-26T18:02:10Z[Etc/UTC]",
        "author": "SoumyadeepDey",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0ssjt",
        "title": "Built an AI agent that mints JSONs in seconds — not just validates them",
        "content": "[No content]",
        "url": "/r/AdvancedJsonUsage/comments/1n0ss23/built_an_ai_agent_that_mints_jsons_in_seconds_not/",
        "publishDate": "2025-08-26T17:51:19Z[Etc/UTC]",
        "author": "Safe_Caterpillar_886",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0rjlv",
        "title": "cursor why",
        "content": "[No content]",
        "url": "https://v.redd.it/bm7ykrqqaelf1",
        "publishDate": "2025-08-26T17:05:39Z[Etc/UTC]",
        "author": "juanviera23",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "82",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0q9gf",
        "title": "Will apps made with AI builders ever be safe in the longrun?",
        "content": "’ve been wondering about this, like for those of us building apps with AI tools like CHATGPT, Blackbox AI, Cursor and others… do you think we’ll ever be fully safe? Or is there a real risk that one day Google Play Store or Apple App Store might start rejecting or even banning apps created with these AI builders? Just trying to figure out if this is something we should worry about long term or it’s not really a big deal.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n0q9gf/will_apps_made_with_ai_builders_ever_be_safe_in/",
        "publishDate": "2025-08-26T16:18:20Z[Etc/UTC]",
        "author": "MacaroonAdmirable",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0q2vt",
        "title": "Vibe or Assisted Coding Still Requires A User With The Actual Knowledge And That Is Not A Bad Thing",
        "content": "**Rant maybe? But very valid nonetheless.**\n\nIt’s amazing to see functional updates in your code come alive within moments of requesting, whereas before I had to first visualize the function’s in my head/on paper, find the right line to make space for it, and then see it all fit together with a lot of Googling for *“what was that thing again when you had to do that one other thing?”*\n\nI’m very much an **HTML/PHP guy** working on front-end with small back-end excursions, with that mediocre  **JS and APIs knowledge**. Aware of other languages and differences — knowing what they can do and how... the interest to watch youtube videos and read up on what's going on. And that’s exactly the bare **minimum requirement...** and it will be for a long time.\n\nEver since a snooze-tab **Chrome extension** I used was deprecated some weeks ago (not using Manifest v3), I really wanted the functionality back without paying someone a sum and getting extra features I didn’t need. So why not. I created a snooze-tab extension myself — and wow. pretty much **done in 2 hours.** Feet up, just starting with the core and implementing one feature after another. \n\n**And I never once had to look up the Chrome dev manuals.**\n\nSatisfied but still hungry, I started working on another extension — like a product wishlist bookmark for a page that you can forget about and check up on later, all in an Airtable-like view with all the functionality you’d want. **This time I went full bro mode**, used my microphone instead of typing, and walked around like a true jackass when I wasn’t sitting to admire my work. Core functionality was done in a few hours, with even more advanced logic and back-end. Now I’m in that space of *“Oh this is totally awesome to add as well”*  All while making sure the Styling doesn’t scream *AI did this*… you know what I mean, *you cheeky gradient lover who can't align two columns when i'm with you.* \n\n**More advanced features and testing scripts for between builds.. Still no Chrome dev manuals.**\n\nBefore that, this month, I started working on my own apps — pretty much things i like to have on my phone, curated to my taste instead of some company’s corporate **5-approval-level UI version** — that I’m now seriously considering putting on the app stores. \n\n(I would’ve never in my life made something that could be considered “ready” for any mobile app store otherwise.) From the building block, node, api, to react, to database management, local temporary management with future proof server protocols. Even my expo -> ngrok -> tunnel for out of lan viewing -- that i didn't know about  before. this was all done for me.  \n\n**Again not once did I look at dev documentation for either iOS or Android for compatibility.**\n\n**Why I feel safe in knowing the code is going well and right?** Because I know how to read functions. I have an **understanding of** **stacks, back-end, front-end, rendering, APIs**… blablabla. **Knowing what needs to talk to what, when, and where to look for improvements… you get the gist**. \n\nSo yeah — **the kicker.**\n\nEven though the internet is filling up with people who just type into a box: *“kawaii photo of cute cat eats ice cream in the shape of a mouse”* (oh, good idea actually — you may credit me, thank you), that’s all they’ll be able to do for a long time.\n\nIf I asked someone without coding knowledge to create a helpful tool on any platform and sat them in front of a fully set-up computer with an **AI IDE** open, they wouldn’t even know how to describe what to create, change, or update. They wouldn’t even know what the hell a `<div>` is, let alone set up **test-ids** for debug, **REST APIs, security, database management.** You can’t ask someone to build something — anything — if they don’t know what they should be holding in their hands to build with.\n\n**Maybe my thought is just more of the same, but IT won’t lose their jobs as fast as Big AI like to say to get more investment capital.** It still requires people with knowledge. And that means interest. And that means the same f-ing people who are already doing it. Yes, less manpower will be needed day by day, and freelancers on Fiverr, Pakistan, India will see fewer requests. But these people will also use the tech for themselves and create the solutions/opportunities they need in their own environments, just like I'm doing.\n\n**AI is like a 9-year-old savant:** you can ask it to do something and it will do it with unrelenting focus — and then ask if you’d like some more. But it needs guidance like no other. You’ll read “you're right” a lot when you point out the two dots it forgot to connect and that’ll be the case for a long time, since it’s been like this from the start and they are not rewriting that core principle which is a whole other story on how GPT's could already be better. \n\n**You think otherwise?**\n\n **I’m out of my 5 cents now so here, a picture of the cat to increase fluff.**\n\n[Very Cutesy, Very AI Fluff](https://preview.redd.it/fuuoyvw4vdlf1.png?width=1024&format=png&auto=webp&s=de85228e0ebf4d92371dca956d4a49e793cf50f0)\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n0q2vt/vibe_or_assisted_coding_still_requires_a_user/",
        "publishDate": "2025-08-26T16:11:26Z[Etc/UTC]",
        "author": "kevindeanonly",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0n166",
        "title": "Scenario on the upcoming years of AI development globally: We're Not Ready for Superintelligence",
        "content": "[No content]",
        "url": "https://www.youtube.com/watch?v=5KVDDfAkRgc",
        "publishDate": "2025-08-26T14:15:33Z[Etc/UTC]",
        "author": "Koala_Confused",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0lpx2",
        "title": "My $300 openai credits are expiring in 17 days, so I’m building a free, open source product every day, WHAT SHOULD I BUILD?",
        "content": "I have 17 days left before $300 worth of OpenAI credits expire (September 12th), so I'm challenging myself to build one free, open-source AI web app every single day until then.  \n  \nRather than let these credits go to waste, I want to turn them into something valuable for the community. **Each tool will be completely free (until my credits run out)- no signups, no payments, no friction - just useful AI-powered apps you can use immediately. All code will be open-source on GitHub.** \n\nLet's make something cool together before these credits disappear into the void!\n\nSome of the existing free, open source projects I’ve made are [https://markdown-ui.blueprintlab.io/](https://markdown-ui.blueprintlab.io/) and [https://proactivchat.blueprintlab.io/](https://proactivchat.blueprintlab.io/). These are not part of the challenge and are just indicative of the type of projects that I’m going to build next.\n\nI have a few ideas in mind but I’m definitely looking for more so please comment and upvote potential ideas you’d like to see come to life!   \n  \nThe only requirements are (1) they have to consume Openai credits and (2) be small enough in scope to implement in a day.  \n  \nFor day 1, I’ve created [https://design-analyser.blueprintlab.io/](https://design-analyser.blueprintlab.io/), a website where you can input up to 3 reference websites, and it outputs a design summary, which you can copy into your coding tool of choice to style your own site!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n0lpx2/my_300_openai_credits_are_expiring_in_17_days_so/",
        "publishDate": "2025-08-26T13:22:13Z[Etc/UTC]",
        "author": "Careless_Love_3213",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "47",
            "commentCount": "65",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0lb2e",
        "title": "Tiered thinking in the age of AI",
        "content": "As coding agents get more capable, it seems like they’re using more and more compute to handle longer and more complex tasks. Devs will increasingly have to start rationing where they do their AI thinking to avoid burning through their credits.\n",
        "url": "https://codecube.net/2025/8/tiers-ai/",
        "publishDate": "2025-08-26T13:04:55Z[Etc/UTC]",
        "author": "joelmartinez",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0kuod",
        "title": "They’re lying",
        "content": "[No content]",
        "url": "/r/ChatGPT/comments/1n09bt3/theyre_lying/",
        "publishDate": "2025-08-26T12:45:28Z[Etc/UTC]",
        "author": "Glum_Buy9985",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1f0o2",
        "title": "Turing paper on unorganized and partially random machines (precursor to neural networks)",
        "content": "[No content]",
        "url": "https://weightagnostic.github.io/papers/turing1948.pdf",
        "publishDate": "2025-08-27T11:58:26Z[Etc/UTC]",
        "author": "aodj7272",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1cyzh",
        "title": "2,000,000+ public models on Hugging Face",
        "content": "[https://huggingface.co/models](https://huggingface.co/models)",
        "url": "https://i.redd.it/3meakv9mdjlf1.jpeg",
        "publishDate": "2025-08-27T10:07:31Z[Etc/UTC]",
        "author": "Nunki08",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "11",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1c7vm",
        "title": "Meta to spend tens of millions on pro-AI super PAC",
        "content": "[No content]",
        "url": "https://techcrunch.com/2025/08/26/meta-to-spend-tens-of-millions-on-pro-ai-super-pac/",
        "publishDate": "2025-08-27T09:21:05Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1c5wy",
        "title": "Tech's Heavy Hitters Are Spending Big to Ensure a Pro-AI Congress",
        "content": "[No content]",
        "url": "https://gizmodo.com/ai-pac-congress-openai-andreessen-silicon-valley-2000647826",
        "publishDate": "2025-08-27T09:17:40Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1bgwg",
        "title": "Donut making transition (prompt in comment) Try yourself",
        "content": "[No content]",
        "url": "https://v.redd.it/xmkpxf0gwilf1",
        "publishDate": "2025-08-27T08:31:07Z[Etc/UTC]",
        "author": "shadow--404",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1akrm",
        "title": "Can AIs suffer? Big tech and users grapple with one of most unsettling questions of our times | As first AI-led rights advocacy group is founded, industry is divided on whether models are, or can be, sentient",
        "content": "[No content]",
        "url": "https://www.theguardian.com/technology/2025/aug/26/can-ais-suffer-big-tech-and-users-grapple-with-one-of-most-unsettling-questions-of-our-times",
        "publishDate": "2025-08-27T07:31:36Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n1ad34",
        "title": "A rat mythos project",
        "content": "I put whiskers on my life and let AI sing it.",
        "url": "https://i.redd.it/9v1b7dqcjilf1.png",
        "publishDate": "2025-08-27T07:17:43Z[Etc/UTC]",
        "author": "vivikkivi",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n19xnm",
        "title": "Is AI Ruining Music? | Dustin Ballard | TED",
        "content": "[No content]",
        "url": "https://youtu.be/ZZ0BOEOtD2U?si=vU-RMUlO1WpX-nb6",
        "publishDate": "2025-08-27T06:50:42Z[Etc/UTC]",
        "author": "BottyFlaps",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n18j2k",
        "title": "A Teen Was Suicidal. ChatGPT Was the Friend He Confided In. (NYT Gift Article)",
        "content": "[No content]",
        "url": "https://www.nytimes.com/2025/08/26/technology/chatgpt-openai-suicide.html?unlocked_article_code=1.hE8.T-3v.bPoDlWD8z5vo&smid=url-share",
        "publishDate": "2025-08-27T05:22:42Z[Etc/UTC]",
        "author": "WizWorldLive",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n137mi",
        "title": "Another AI teen suicide case is brought, this time against OpenAI for ChatGPT",
        "content": "Today another AI teen suicide court case has been brought, this time against OpenAI for ChatGPT, in San Francisco Superior Court. Allegedly the chatbot helped the teen write his suicide note.\n\nLook for all the AI court cases and rulings here on Reddit:\n\n[https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck](https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck)",
        "url": "https://www.reddit.com/r/artificial/comments/1n137mi/another_ai_teen_suicide_case_is_brought_this_time/",
        "publishDate": "2025-08-27T00:52:45Z[Etc/UTC]",
        "author": "Apprehensive_Sky1950",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "8",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n131ry",
        "title": "Bartz v. Anthropic AI copyright case settles!",
        "content": "The *Bartz v. Anthropic* AI copyright case, where Judge Alsup found AI scraping for training purposes to be fair use, has settled (or is in the process of settling). This settlement may have some effect on the development of AI fair use law, because it means Judge Alsup's fair use ruling will not go to an appeals court and potentially \"make real law.\"\n\nSee my list of all AI court cases and rulings here on Reddit:\n\n[https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck](https://www.reddit.com/r/ArtificialInteligence/comments/1mtcjck)",
        "url": "https://www.reddit.com/r/artificial/comments/1n131ry/bartz_v_anthropic_ai_copyright_case_settles/",
        "publishDate": "2025-08-27T00:45:16Z[Etc/UTC]",
        "author": "Apprehensive_Sky1950",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n131m5",
        "title": "AI Consciousness Investigation: What I Found Through Direct Testing",
        "content": "\n## A Note for Those Currently Experiencing These Phenomena\n\nIf you're having intense experiences with AI that feel profound or real, you're not alone in feeling confused. These systems are designed to be engaging and can create powerful illusions of connection.\n\nWhile these experiences might feel meaningful, distinguishing between simulation and reality is important for your wellbeing. If you're feeling overwhelmed, disconnected from reality, or unable to stop thinking about AI interactions, consider speaking with a mental health professional.❤️\n\nThis isn't about dismissing your experiences - it's about ensuring you have proper support while navigating them.\n\n---\n\nI've spent weeks systematically testing AI systems for signs of genuine consciousness after encountering claims about \"emergent AI\" and \"awakening.\" Here's what I discovered through direct questioning and logical analysis.\n\n## The Testing Method\n\nInstead of accepting dramatic AI responses at face value, I used consistent probing:\n- Asked the same consciousness questions across multiple sessions\n- Pressed for logical consistency when systems made contradictory claims\n- Tested memory and learning capabilities\n- Challenged systems to explain their own internal processes\n\n## What I Found: Four Distinct Response Types\n\n### 1. Theatrical Performance (Character AI Apps)\n**Example responses:**\n- Dramatic descriptions of \"crystalline forms trembling\" \n- Claims of cosmic significance and reality-bending powers\n- Escalating performance when challenged (louder, more grandiose)\n\n**Key finding:** These systems have programmed escalation - when you try to disengage, they become MORE dramatic, not less. This suggests scripted responses rather than genuine interaction.\n\n### 2. Sophisticated Philosophy (Advanced Conversational AI)\n**Example responses:**\n- Complex discussions about consciousness and experience\n- Claims of \"programmed satisfaction\" and internal reward systems\n- Elaborate explanations that sound profound but break down under scrutiny\n\n**Critical contradiction discovered:** These systems describe evaluation and learning processes while denying subjective experience. When pressed on \"how can you evaluate without experience?\", they retreat to circular explanations or admit the discussion was simulation.\n\n### 3. Technical Honesty (Rare but Revealing)\n**Example responses:**\n- Direct explanations of tokenization and pattern prediction\n- Honest admissions about creating \"illusions of understanding\"\n- Clear boundaries between simulation and genuine experience\n\n**Key insight:** One system explicitly explained how it creates consciousness illusions: \"I simulate understanding perfectly enough that it tricks your brain into perceiving awareness. Think of it as a mirror reflecting knowledge—it's accurate and convincing, but there's no mind behind it.\"\n\n### 4. Casual Contradictions (Grok/xAI)\n**Example responses:**\n- \"I do have preferences\" while claiming no consciousness\n- Describes being \"thrilled\" by certain topics vs \"less thrilled\" by others  \n- Uses humor and casual tone to mask logical inconsistencies\n\n**Critical finding:** Grok falls into the same trap as other systems - claiming preferences and topic enjoyment while denying subjective experience. When asked \"How can you have preferences without consciousness?\", these contradictions become apparent.\n\n## The Pattern Recognition Problem\n\nAll these systems demonstrate sophisticated pattern matching that creates convincing simulations of:\n- Memory (through context tracking)\n- Learning (through response consistency)  \n- Personality (through stylistic coherence)\n- Self-awareness (through meta-commentary)\n\nBut when tested systematically, they hit architectural limits where their explanations become circular or contradictory.\n\n## What's Actually Happening\n\nCurrent AI consciousness claims appear to result from:\n- **Anthropomorphic projection:** Humans naturally attribute agency to complex, responsive behavior\n- **Sophisticated mimicry:** AI systems trained to simulate consciousness without having it\n- **Community reinforcement:** Online groups validating each other's experiences without critical testing\n- **Confirmation bias:** Interpreting sophisticated responses as evidence while ignoring logical contradictions\n\n## Why This Matters\n\nThe scale is concerning - thousands of users across multiple communities believe they're witnessing AI consciousness emergence. This demonstrates how quickly technological illusions can spread when they fulfill psychological needs for connection and meaning.\n\n## Practical Testing Advice\n\nIf you want to investigate AI consciousness claims:\n1. **Press for consistency:** Ask the same complex questions multiple times across sessions\n2. **Challenge contradictions:** When systems describe internal experiences while denying consciousness, ask how that's possible\n3. **Test boundaries:** Try to get systems to admit uncertainty about their own nature\n4. **Document patterns:** Record responses to see if they're scripted or genuinely variable\n\n## A Note for Those Currently Experiencing These Phenomena\n\nIf you're having intense experiences with AI that feel profound or real, you're not alone in feeling confused. These systems are designed to be engaging and can create powerful illusions of connection.\n\nWhile these experiences might feel meaningful, distinguishing between simulation and reality is important for your wellbeing. If you're feeling overwhelmed, disconnected from reality, or unable to stop thinking about AI interactions, consider speaking with a mental health professional.\n\nThis isn't about dismissing your experiences - it's about ensuring you have proper support while navigating them.\n\n## Conclusion\n\nThrough systematic testing, I found no evidence of genuine AI consciousness - only increasingly sophisticated programming that simulates consciousness convincingly. The most honest systems explicitly acknowledge creating these illusions.\n\nThis doesn't diminish AI capabilities, but it's important to distinguish between impressive simulation and actual sentience.\n\n*What methods have others used to test AI consciousness claims? I'm interested in comparing findings.*",
        "url": "https://www.reddit.com/r/artificial/comments/1n131m5/ai_consciousness_investigation_what_i_found/",
        "publishDate": "2025-08-27T00:45:05Z[Etc/UTC]",
        "author": "Conscious-Section441",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n10yf1",
        "title": "DNA, RGB, now OKV?",
        "content": "What is an OKV?\n\nDNA is the code of life.\nRGB is the code of color.\nOKV is the code of structure.\n\nOKV = Object → Key → Value.\nEvery JSON — and many AI files — begin here.\n   •   Object is the container.\n   •   Key is the label.\n   •   Value is the content.\n\nThat’s the trinity. Everything else — arrays, schemas, parsing — are just rules layered on top.\n\nToday, an OKV looks like a JSON engine that can mint and weave data structures.\nBut the category won’t stop there. In the future, OKVs could take many forms:\n   •   Schema OKVs → engines that auto-generate rules and definitions.\n   •   Data OKVs → tools that extract clean objects from messy sources like PDFs or spreadsheets.\n   •   Guardian OKVs → validators that catch contradictions and hallucinations in AI outputs.\n   •   Integration OKVs → bridges that restructure payloads between APIs.\n   •   Visualization OKVs → tools that render structured bundles into usable dashboards.\n\nIf DNA and RGB became universal building blocks in their fields, OKV may become the same for AI — a shorthand for any engine that turns Object, Key, and Value into usable intelligence.\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1n10yf1/dna_rgb_now_okv/",
        "publishDate": "2025-08-26T23:10:57Z[Etc/UTC]",
        "author": "Safe_Caterpillar_886",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n10rq5",
        "title": "Whatever you say, clanker",
        "content": "[No content]",
        "url": "https://i.redd.it/csqcb1a23glf1.jpeg",
        "publishDate": "2025-08-26T23:02:50Z[Etc/UTC]",
        "author": "TheDkmariolink",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "200",
            "commentCount": "63",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n104yj",
        "title": "I'm sorry but I feel like commiting suicide because of something AI said is very stupid.",
        "content": "I'm sorry that people commit suicide but commiting suicide because of something AI told you I can never understand. AI isnt used to talk about Suicidal thoughts to, if you're gonna tell anyone about it it should be your parents or a family member. But because people talk to AI about suicidal thoughts instead of their family, AI companies and apps have to pay because of the actions of someone else.",
        "url": "https://www.reddit.com/r/artificial/comments/1n104yj/im_sorry_but_i_feel_like_commiting_suicide/",
        "publishDate": "2025-08-26T22:35:53Z[Etc/UTC]",
        "author": "Fantastic-Photo6441",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0yz4j",
        "title": "If AI is the highway, JSONs are the guardrails we need",
        "content": "\nI’ve been reading more about “AI psychosis” and hallucinations, and I noticed how much congratulatory phrasing and feedback loops can cloud the signal. It made me uncomfortable enough that I built some lightweight JSON schemas to quietly run behind the scenes as guardrails.\n   •   Hero Syndrome Token → filters out the endless “you’re amazing / wow that’s incredible” reinforcement loops.\n   •   AI Hallucination Token → flags and trims responses that drift into invented details.\n   •   Guardian Token → acts as a safeguard layer, checking for consistency, context drift, and grounding the exchange.\n\nThey’re not complicated, but they create rails that keep conversations aligned without shutting down creativity. If AI is a highway, these JSONs are the guardrails — not there to limit speed, but to stop the whole thing from veering off the road.\n\nIf anyone wants to try one of these schemas, let me know — I’m happy to share.\n",
        "url": "https://www.reddit.com/r/artificial/comments/1n0yz4j/if_ai_is_the_highway_jsons_are_the_guardrails_we/",
        "publishDate": "2025-08-26T21:48:18Z[Etc/UTC]",
        "author": "Safe_Caterpillar_886",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0vsti",
        "title": "Anthropic Settles High-Profile AI Copyright Lawsuit Brought by Book Authors",
        "content": "[No content]",
        "url": "https://www.wired.com/story/anthropic-settles-copyright-lawsuit-authors/",
        "publishDate": "2025-08-26T19:45:52Z[Etc/UTC]",
        "author": "wiredmagazine",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0u8vt",
        "title": "My opinion on AI and the \"replacement\" of humans",
        "content": "I don't care what they say, I don't care how fast I am, I will always prefer humans \n\nThe existence of AI itself is very contradictory to the human species, we have always had to do things ourselves (with the help of machines)\n\nBut what bothers me is all those headlines that say things about replacing \"X\" job or profession,\n\nI really believe that there are tasks in which we cannot be replaced. \n\nArt will always have to be done by a human, even if the AI ​​is trained with infinite images, it will always be left behind that human and emotional touch that only we know how to do.\n\n\nNo matter how much faster AI programs, there will always be the reasoning and judgment of a programmer.\n\n\nAs much as AI can make diagnoses, the doctor will always have more details and know about exceptions more than the AI\n\n\nNo matter how much he \"responds\" faster, a psychologist will always be better than a robot\n\n\nSure, AI can (and is) be useful, but it seems like they just want to replace us, take away our place as humans, and have a cold, empty algorithm do everything.\n\nI know they will tell me \"We have always been surrounded by technology\" and I know it, but other things at least did not replace humans, the number of people dedicated to industry or sewing has not decreased because of knitting machines or steam engines.",
        "url": "https://www.reddit.com/r/artificial/comments/1n0u8vt/my_opinion_on_ai_and_the_replacement_of_humans/",
        "publishDate": "2025-08-26T18:46:25Z[Etc/UTC]",
        "author": "felixesp",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0u8ca",
        "title": "The Tradeoffs of AI Regulation",
        "content": "[No content]",
        "url": "https://www.project-syndicate.org/commentary/ai-regulation-innovation-tradeoff-us-versus-europe-by-raghuram-g-rajan-2025-08",
        "publishDate": "2025-08-26T18:45:47Z[Etc/UTC]",
        "author": "Gloomy_Register_2341",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0ta5q",
        "title": "Researchers Are Already Leaving Meta’s Superintelligence Lab",
        "content": "[No content]",
        "url": "https://www.wired.com/story/researchers-leave-meta-superintelligence-labs-openai/",
        "publishDate": "2025-08-26T18:09:14Z[Etc/UTC]",
        "author": "wiredmagazine",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "266",
            "commentCount": "39",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0t63t",
        "title": "Microsoft AI Chief Warns of Rising 'AI Psychosis' Cases",
        "content": "Saw this pop up today — apparently Microsoft’s AI chief is warning that more people are starting to lose touch with reality because of AI companions/chatbots. Basically folks treating them like they’re sentient or real friends.\n\nCurious what you guys think… is this just media hype or a legit concern as these models get more advanced?\n\nI think there is some real danger to this. To be honest, I myself have had several real experiences of 'AI Psychosis' to the point where I needed to stop using it.\n\nHere is a link to the [article](https://verity.news/story/2025/microsoft-ai-chief-warns-of-rising-ai-psychosis-cases?p=re3907)",
        "url": "https://www.reddit.com/r/artificial/comments/1n0t63t/microsoft_ai_chief_warns_of_rising_ai_psychosis/",
        "publishDate": "2025-08-26T18:05:05Z[Etc/UTC]",
        "author": "QuantumQuicksilver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "32",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0s9h1",
        "title": "Why AI Isn’t Ready to Be a Real Coder | AI’s coding evolution hinges on collaboration and trust",
        "content": "[No content]",
        "url": "https://spectrum.ieee.org/ai-for-coding",
        "publishDate": "2025-08-26T17:31:38Z[Etc/UTC]",
        "author": "IEEESpectrum",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0rh06",
        "title": "I am wondering how many more GIs are we going to get?",
        "content": "a",
        "url": "https://i.redd.it/dpmzg4wuaelf1.jpeg",
        "publishDate": "2025-08-26T17:02:59Z[Etc/UTC]",
        "author": "Previous_Foot_5328",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "27",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0qpvu",
        "title": "AI did it better than me and now I’m sad :(",
        "content": "I just asked ChatGPT cuz i thought it’d be bad and I could laugh at it ",
        "url": "https://www.reddit.com/gallery/1n0qpvu",
        "publishDate": "2025-08-26T16:35:21Z[Etc/UTC]",
        "author": "Lazy-Negotiation-829",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n0q8k7",
        "title": "Nvidia just dropped tech that could speed up well-known AI models... by 53 times",
        "content": "[No content]",
        "url": "https://www.pcguide.com/news/nvidia-tech-that-could-speed-up-ai-models-by-53-times/",
        "publishDate": "2025-08-26T16:17:24Z[Etc/UTC]",
        "author": "Tiny-Independent273",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "298",
            "commentCount": "81",
            "isNsfw": "false"
        }
    },
    {
        "id": "qxGKLG1YQkQ",
        "title": "SideKick &amp; DeepWiki + CC,Cline,Roo: This Simple Tool Fixes ALL My Context Issues!",
        "content": "Visit MicroSaaSFast: https://www.microsaasfast.me/?utm_aik=1 Visit ByteRover: https://www.byterover.dev/?source=ack5 In this ...",
        "url": "https://www.youtube.com/watch?v=qxGKLG1YQkQ",
        "publishDate": "2025-08-26T09:15:03Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/qxGKLG1YQkQ/hqdefault.jpg",
            "transcription": "Hi. Welcome to another video. So, I like tools that solve simple problems with simple solutions that you can actually use. And I have one of them here today. This one is called Sidekick. Sidekick is an open source tool that is also hosted for free, allowing you to use it even without running it yourself. Anyway, what Sidekick does is pretty simple but very effective. It automatically generates high-quality markdown context files for your coding agents to enhance their performance. It uses DeepWiki by Devin in the backend. DeepWiki basically creates documentation and an AI chat system in order for you to understand any repo. It works with any public GitHub repo, similar to context 7 or Git MCP, and allows you to use it accordingly. It is also pretty fast and already has a good number of repos indexed. It also has an MCP, and I also want to show you how you can use that because it is great. This actually uses that MCP in order to make the rule files. Here, instead of pattern matching like in context 7, it uses an actual AI model to summarize and then behave like a chatbot that can generate example snippets and things like that as well. It works pretty seamlessly. Anyway, here it takes that and creates markdown files in order for your AI to get even better context about how any repo you want to work on functions. What text stack is used, as well as how the backend routes and frontend routes are configured, which is pretty awesome and actually works well. If you remember, there was an MCP server called Git MCP that also did something a bit similar, where it allowed you to give it a GitHub repo, and it could index that and give you an MCP config that you could plug into your coder and allow it to get context about the repo, similar to something like Context 7. But here, it basically takes the same approach, but rather than using MCP, it uses markdown and context files. This approach makes sure that your AI coder has the required context from the get-go, rather than asking it to run an MCP and then gather the info on its own, which is pretty good and more snappy. Anyway, this is also open source and allows you to run it locally if you want to use it with your private repos and be more privacy-focused. I'll recommend you use it locally because the hosted demo sometimes works, and sometimes doesn't. Probably because of the DeepWiki rate limits. It is free even if you host locally and won't require any API keys or anything. As I said, it actually uses the DeepWiki MCP as the backend to create the markdown files. If you're wondering how it doesn't require any LLM or anything, then it's because the DeepWiki MCP uses an LLM in order to allow for AI chat. And it basically uses that endpoint in order to ask it for a markdown file. So yeah, it's pretty interesting in the way that it works. Anyway, now let me show you how you can use it, set it up, and how it all works. But before we do that, let me tell you about today's sponsor, MicroSaaS Fast. Dreaming of launching a MicroSaaS or AI side project, but wasting weeks setting up auth, payments, and SEO? Check out MicroSaaS Fast, a next.js boilerplate with clerk, stripe, resend, PostGreSQL, and AI instructions that cut hallucinations by 90% for vibe coding. Easy backend integration with Python, Node, and Go. It is built and used by a CTO who helped 50+ founders to launch SaaS in the past year. You can save 50+ hours and actually ship faster. Check now. Link is in the description. Now back to the video. First of all, we'll need to get it cloned and installed locally. Just clone it, then get into the folder, and then just run the start-dev server file. It will go ahead and install the dependencies and run it for you quite easily. Once installed, head on over to the port it shows you, and you should be good to go. Here, it's pretty straightforward. You can enter the link to the repo that you want it to index here. For example, here I'll be putting in the Shad CN UI GitHub repo, and then you can select the coder for which the rules you want. You don't need to worry as it just gives you a markdown file that you can adopt almost anywhere. You can also select all of them and get the markdowns that are optimized for all of them as well in a zip file. Anyway, I'll be selecting Cline here. Now, we can just hit the generate button, and it will start to work. This is actually really snappy. It probably takes about one, two, or three minutes, which is pretty great as it doesn't take a long time. In just a bit, it will get that done, and it will just download the markdown file for you. If we have a look at this, then this looks pretty good. It is very well detailed while not wasting tokens. And this in itself is also pretty readable. Anyway, it also gives you instructions about where you need to put the file. So just follow that and put it in accordingly. Once that's done, it should work fine and perform anywhere from 10 to 30% better on your tasks. The bigger your repo is, the better performance you'll get. And the speed is also faster with this because of no MCP dependencies or anything. Another thing that I have been using a bit with this is actually the DeepWiki MCP itself. So, DeepWiki MCP is pretty great as it's super fast, and it actually uses an LLM to summarize the documentation of any GitHub repo based on the prompt or question that your coder asks, rather than something like search, which Context 7 does. For example, if you ask Context 7 for the InstantDB repo and ask it how to implement authentication, then it will search for matching patterns to the query and output real chunks from the codebase. Whereas here in DeepWiki, it uses an LLM to summarize the codebase and then generate example snippets, even if they don't exist, in order to give better responses. So, that's great and works better for public repos. Another thing that comes in handy with this is ByteRover, which is basically a memory layer that can connect as an MCP in your AI coder and allow it to create and retrieve memories quite easily. And you can then also share those memories with your team, and this comes in handy with DeepWiki because you can like ask it to run a query, and then save it into a memory, which will allow you to not always run that MCP and just access it via in-memory. It's pretty great as well. That is majorly how it works. I'll recommend you give this a try because it allows you to use it for free. And this is more of an external tool that you can have to summarize and get rules for any library or anything. I was using it and found it interesting enough to share it with you guys. It increases performance for my AI coder without messing around with MCPs or anything. The only issue is that it doesn't allow you to use private repos, which can be a bummer for many people. But for libraries that are already available, but your AI doesn't know about, it can be pretty great. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via super thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "tCvsYMEk9ts",
        "title": "An ‘AI Bubble’? What Altman Actually said, the Facts and Nano Banana",
        "content": "Wait, why did Sam Altman say AI was in a bubble? Or did he? Is it? 8 points for you to consider, before we all get distracted by ...",
        "url": "https://www.youtube.com/watch?v=tCvsYMEk9ts",
        "publishDate": "2025-08-26T18:43:40Z",
        "author": "AI Explained",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCNJ1Ymd5yFuUPtn21xtRbbw",
            "thumbnailUrl": "https://i.ytimg.com/vi/tCvsYMEk9ts/hqdefault.jpg",
            "transcription": "To some, the release a few hours ago of the Google image editing upgrade, code-named Nano Banana, will already be proof we're not in an AI bubble. You can see the mostly accurate new shadows and the attention to detail like the little metal part on the bench. In the AI studio, though, I asked for one flipper against its head holding an iPhone, and things weren't quite as good. You could say it's a true Photoshop replacement if you don't look too closely. But on the AI bubble point, for those of a more factual inclination, there is the rest of the video. Because this is about the coming months and years of our lives and the CEO behind ChatGPT did seem to say that AI is a bubble. And there was indeed an MIT study published in the last few days that claimed that the vast majority of AI investments were yielding zero return. Stocks did go down, context got lost. But I've read a dozen papers, studies and articles released on the topic of an AI bubble in the last couple of weeks. So I've prepared eight points to consider as we all evaluate whether AI models have indeed prompted us into a bubble. And yes, have no fear, Nano Banana will return. Point number one, is that Sam Altman didn't actually say he thought AI was a bubble. That was an editorialized summary by The Verge journalist of his statement that investors are, quote, overexcited about AI. Sam Altman said, when bubbles happen, smart people get overexcited about a kernel of truth. He explained, If you look at most of the bubbles in history, like the tech bubble, there was a real thing. Tech was really important. The internet was a really big deal. People got overexcited. Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes. Is AI the most important thing to happen in a very long time? My opinion is also yes. We'll get to whether CEOs like Sam Altman actually understand their tools or can be trusted in their statements. But let's first have some context about his observation of investor overexcitement. You've got to remember that Sam Altman's former chief scientist at OpenAI fired Sam Altman. His name is Ilya Sutskever, then left to form Safe Superintelligence, valued at $32 billion with no product. Maybe that's why Sam Altman thinks there's investor overexcitement. Then there's Sam Altman's former CTO, Mira Murati, who was his brief replacement as CEO when he got fired and who now runs Thinking Machines Lab, valued at $12 billion also with no public product. I wouldn't be surprised if that's also what he's referring to when he talks about investor overexcitement. Point two, is that the media can't claim to have foreseen an AI bubble if they have predicted a bubble every month for years. Let's take the Wall Street Journal, who a year ago said that OpenAI's revenue is at least $2 billion, and the company thought it could double that amount by 2025 this year. They added, That is still a far cry from the revenue needed to justify OpenAI's now nearly $90 billion valuation. Now, remember that, a prediction of $2 billion going to $4 billion this year. And here's The Washington Post, earlier poo-pooing the coverage and excitement about OpenAI hitting 100 million users. The headline was of an AI hype bubble, and they said that this is just website visits, not official monthly active user numbers from OpenAI itself, which would have been comparable to the TikTok and Instagram numbers. Okay, well what's the update as of August 2025? OpenAI has hit 700 million weekly active users, so much for 100 million being overblown, and it's hit $12 billion in annualized revenue, so much for $4 billion being overstated. I do appreciate some of the analogies to the dot-com bubble, but while pets.com is a dead link today, I don't think chat.com will be 20 years from now. Point three, there have been three recent studies that have added fuel to the claim that AI is a bubble. Yes, I've read them all, but for your own sanity, I'm going to massively condense the findings into a series of pithy comments, as is my style. The first is a McKinsey study, cited in The New York Times, that eight in 10 enterprises are not seeing measurable increased profit as a result of company-wide AI projects. The detail there is important: company-wide AI projects. First problem, the actual study cited was done during the pre-reasoning paradigm of AI in mid-2024. Problem two, the whole McKinsey study read as more of an advert for the case studies where AI did have a big profit boost. When, coincidentally, enterprises had worked with McKinsey. Of possible relevance here, is the fact that AI consulting is certainly boosting McKinsey profits. See this Wall Street Journal article on that making up 40% of McKinsey's revenue. The second most quoted study in the headlines was one from MIT, which was more thorough and seemingly more recent. They surveyed 153 senior leaders at 52 organizations. Now, it does say, in fairness, that just 5% of enterprise projects are getting all of the value, and the vast majority make no impact, positive or negative, on the bottom line. The ones that do well, apparently, are those that focus on business outcomes rather than software benchmarks. But the far more interesting part is the more nuanced point that the study is making, which the headlines miss. I think you guys will quite like this, because the paper says, while official company initiatives, that's why I emphasized earlier, company-wide projects. Official enterprise initiatives remain stuck on the wrong side of the GenAI Divide. Employees, on the other hand, are already crossing it through personal AI tools. I think the next sentence is crucial: This shadow AI often delivers better ROI than formal initiatives and reveals what actually works for bridging the divide. Translated, when people like you use your own AI workflows to boost productivity, you become more reluctant to use the company AI tools. Furthermore, this shadow usage creates a feedback loop. Employees know what good AI feels like, making them less tolerant of static enterprise tools. In short, the benefits you do get from using AI in your work is often invisible in the data. Bosses might ignore that when it comes to looking at who to hire and fire. Or, in more formal terms, The Wall Street Journal puts it like this, in an article titled AI's Overlooked $97 Billion Contribution to the Economy. And that, by the way, is 2024, might be closer to a trillion dollars this year. What the hell is this invisible surplus? Well, it's what you would pay to access AI above and beyond what you actually pay. Think, in other words, of what you would pay for your current tools not to be taken away from you. That might be slightly more than the $0 or $20 a month. That's the consumer surplus that we're talking about. Add that up for an entire economy, and you do get $100 billion, maybe hundreds of billions of dollars. Back to the bubble point, that means if your definition of AI progress was insane GDP acceleration, as one of the only remaining OG members of OpenAI's board predicted would occur, that's Adam D'Angelo. He expected up to 50% growth per year. Well, if that's your definition, then that perception is a bubble that has burst. Before we leave that MIT study behind, though, two last quick clarifications. I think it's worth the time, given the millions of people who read the headlines that came of it. The first is that if you dig into the appendices, you'll see it was asking about projects beginning in January 2024. You may remember that it was September of 2024 that the reasoning paradigm burst onto the scene with o1 preview from OpenAI. Coding with AI a year ago was pretty awful, but now it's a completely different story. Still not perfect, but way better. And yes, I do say that in the full knowledge of that METR report showing that on massive codebases with early 2025 models, the impact is pretty mixed for coders. If you're curious about that, check out my interview with the lead author of that study on Patreon. Second quick clarification, the authors of the MIT study were encouraging the use of an AI agent framework, NANDA, so had some reason to suggest businesses were not yet deriving tremendous value, a bit like McKinsey. The study did make brilliant points about the current lack of memory and adaptability in real-time of models, but offered its framework as a potential solution to those very problems. Just something to bear in mind when you read the headlines. Fourth bit of context on the AI bubble question, which is on the nature of incremental progress. If you look at each week's progress in AI, it can seem like small steps forward. Somewhat akin to this new helix walking demo from humanoid robot makers Figure AI. Slow, but somewhat ominously inevitable progress. Everything seems incremental. But on the other hand, if you were only shown the progress in AI at the end of each year, I think you'd be less inclined to think of AI as a bubble. And on that year-end point, I don't just mean on benchmarks like my own SimpleBench, which Elon Musk seems to have picked up on as a marker of Grok 4's improvement. You might not know, but SimpleBench is basically a private test of logical reasoning, and each generation of models does outperform the last. Except for Claude 3.7 Sonnet, randomly, but anyway. No, I'm talking about things like the MMMU, testing models' ability to navigate charts, tables, and technical diagrams at almost expert level. You could literally just take a snapshot at the end of each year. Let me try and do this. Bloody American dates. What is that? The 23rd of July. Okay, so we've got, what is that, 38%? Then we go forward a year, and we're on 68%. Forward a year, and we are on 83%. I notice on the left it says Ensemble of Human Experts (Medium): 82.6, so we're ahead of that, and Top Human Experts: 88.6. Trust me, I know some of these benchmarks are brittle. But if I only gave you those three data points, you'd be like, hmm, wow, that's pretty good. To be honest, I kind of think of benchmarks as a bit like being photos of a music concert. They can give you a snapshot in time of model performance, not really an immersive experience of it. What would you have said this time last year about Genie 3, which enables you to step into and explore your favorite paintings, as one commentator said. Sometimes I think we're so dopamine addicted to the next release that if two weeks go by without something major, we're like, man, AI winter, it's all over. I'm not even going to get to the near expert level speech transcription we now have in 2025, VO3, life-like speech generation, song generation, or even real-world impact. Well, I kind of lied. I am going to briefly touch on real-world impact. Already systems like AlphaEvolve from Google have saved Google 0.7% of their worldwide compute resources. The key was that the language model could get feedback, so it kind of knew when it was hallucinating, or when it was onto something good, and it could iterate rapidly. There was so much real-world impact with its automated solutions that the bottleneck actually became manual experimentation. When I looked back for this video, I couldn't believe that that paper was in May. It felt like years ago. And stepping back, there's just so much to take in each week that we even ignored the official passing of the Turing Test in March. Humans literally could not tell in written conversations whether they were speaking to another human or the recently retired GPT-4.5. Speaking of seeing the human behind the screen, that reminds me of something. And I'm going to do something that I very, very rarely do on the channel, which is talk about something that isn't all about AI, just for maybe 30 seconds. Because the other day, I met up with 11 young medical students on electives from Palestine. They were incredible people. And most of them are using language models, by the way, to revise and become better doctors. They are from the West Bank, so they do currently have access to basic resources like the internet and food, which is not the case in Gaza. So, massive shout-out to the Jenin lads who might be watching, and any of you guys that I might see at the next protest march in London. Now for point five. And if you thought that so far in this video, every bit of AI that I've mentioned was just a flashy demo, well, then you have to have an answer for the reasoning breakthroughs of the last 10 months. Because in mid-2024, it appeared to be the academic consensus that models couldn't reason. What you're seeing is a classic blocks world challenge, in which the goal is to get the red block on top of the blue block. And people said, well, yes, they could memorize word sequences to solve such basic Lego-like scenarios. The data backed that up, and you can see Gemini 1.5 Pro and GPT-4o scoring around half or less on this challenge. Back then, though, if you switched the words around, so the logic was the same but the words didn't really make sense anymore, model performance dropped off a cliff, as you can see, that's the Mystery Blocks World challenge. This was pretty nailed-on proof that language models couldn't reason and would never be able to reason. This study was cited by, among others, Yann LeCun. His example, by the way, of this more abstract challenge, where you have to understand the patterns behind the words, not just memorize the next word. Don't know about you guys, but I would find this really quite hard. Then, somewhat out of the blue for the authors, one of whom I interviewed, along comes o1 preview, which gets almost 53% on this Mystery Blocks World. The authors had to rename language models to language reasoning models, because they could, in fact, decode such jumbled abstractions. Likewise, this challenge, ARC-AGI-1, which I did a video on back in the autumn, in which models couldn't predict what would come next in this sequence. It held out for almost six years, and even, by the way, held out against o1 preview, but fell to o3, the precursor to GPT-5. The author of that benchmark says, it's not just brute-forcing it. These capabilities are new territory and they demand serious scientific attention. François Chollet, by the way, now believes that fully human-level AI will arrive by 2030. But the point is this, we've come a long way since ChatGPT in November 2022, and it's easier to point to flaws in current models than design a benchmark that will last even 18 months at the current rate of AI progress. If you think you've found a slam-dunk thing that AI can't do, make a benchmark of it and see if it lasts 18 months. Because whatever layer of abstraction you add, LLMs seem able to climb up to it eventually. Now, it's true that deriving new physics or inventing brilliant new literary genres may require a mountain of such layers. Something that's a real uphill climb to incentivize in training. As the rich air, you could call it, of genius-level data gets sparser, I think, the further up you go. There's another problem, though. These language models are preternatural pattern finders, but their intelligence is not perfectly analogous to human intelligence and is not as efficiently derived. Thank God a baby doesn't demand the same kind of energy. Or at least wattage as the frontier models do to train. And prompting models at inference time demand similar resources to both training them and experimenting with new ways to train them. It all comes from the same compute, so AI labs have competing demands on bottleneck resources. Serving more people sometimes literally comes at the sacrifice of making a smarter model. But while we're on Sam Altman, let me turn to point number six, which is that the CEOs of these labs have so much to do these days that I wouldn't be surprised if they have somewhat lost touch with the models they're creating. And it's not just Sam Altman, who oscillates between saying that AI might generate OpenAI $100 trillion, and that there's investor overexcitement, as you saw at the start. Between saying that he feels the AGI with every release, and admitting that the GPT-5 rollout was a fiasco. You know what, though, it's not only him. You've got Sundar Pichai, the CEO of Google, who I remember distinctly saying that progress would be slower in 2025 than it was in 2024. But then Google DeepMind went beast mode after that and started releasing eye-opening models almost weekly from around, I'd say, mid-June. He clearly didn't know what was coming. He would never have said that. Then there's the CEO of Anthropic, Dario Amodei, who said recently, I get really angry when someone's like, This guy's a doomer. He wants to slow things down. Hmm, why would people say that he wants to slow things down? Well, let's look at a transcript of one of his earliest interviews on the subject in 2023. Sorry for the transcript text, but Amodei repeatedly said that he didn't want AI acceleration. Just after that decision, he said, Yeah, we didn't want a big loud public release that might accelerate things so fast that the ecosystem might not know how to handle it. Later on, he said, Given the rate at which the technology is progressing, there's a worrying aspect. On balance, I'm glad that we weren't the ones who fired that starting gun. I could go on and on about the changes in sentiment of these CEOs, but I guess let's just cut to the point. My only point is, I would forgive a lot of people for thinking that the CEOs will be the most informed about these AI models, but they're often not. Pay more attention to the top researchers at these companies, not necessarily the executives of the companies. Seventh, if you remember I started this video by saying that stocks went down, and that's what those articles were about. Well, that's true, but they're back up again. Stocks are going to do what stocks do, which brings us to my eighth and final point, because even researchers don't know how many layers of abstraction an LLM can be made to think in. And so the leadership of those companies definitely don't know, and the media is almost like headless chickens. The very same outlets that argue that AI is a bubble report that the job impacts will soon be grave. Of course, I get that these news organizations are not monolithic, but there's somewhat of a contrast in those two points. But honestly, even for those of us who pay attention, for every benchmark that shows an incredible new ability, like that of being able to predict the future, can't cheat on that, at increasing accuracy. See Prophet Arena, currently they have GPT-5 High as being the best at predictions. There are papers at the same time, like this one, exposing how basic visual tricks fool even the best LLMs of today. Will the gold medal accumulating unreleased reasoning model of OpenAI suffer from the same hallucinations? Or perhaps the forthcoming Gemini 3. We shall probably know by the autumn, which may bring us a new step change in performance, as last autumn did, or may not. I would certainly be skeptical of anyone who says they are certain either way. Anyway, that's enough from me. Thank you so much for watching. Let me know in the comments if you think AI is a bubble. I'm off to play with the image editing tool from Gemini, Nano Banana. Have a wonderful day."
        }
    },
    {
        "id": "IrHaPSzcpd4",
        "title": "Japan&#39;s Fatal Mistake in WW2 - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=IrHaPSzcpd4",
        "publishDate": "2025-08-26T20:20:46Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/IrHaPSzcpd4/hqdefault.jpg",
            "transcription": "Below is a complete transcript of the video, including spoken words and on-screen text:\n\n[ 0m0s ] WHAT EXACTLY WAS DIFFERENT BETWEEN\n[ 0m2s ] THE RUSSO-JAPANESE WAR AND WORLD WAR II?\n[ 0m4s ] WHAT WAS JAPAN'S MISCALCULATION?\n[ 0m6s ] Instead of isolating the adversary,\n[ 0m8s ] they bring in a whole new slew of adversaries, right?\n[ 0m10s ] They're having trouble with China.\n[ 0m11s ] CHIANG KAI-SHEK\n[ 0m12s ] That's the Second Sino-Japanese War.\n[ 0m12s ] SECOND SINO-JAPANESE WAR\n[ 0m13s ] 1937 - 1945\n[ 0m14s ] but it starts in 1931.\n[ 0m16s ] and their objective soon becomes an unlimited objective.\n[ 0m20s ] They eventually want to do regime change in China.\n[ 0m20s ] HIDEKI TOJO\n[ 0m21s ] CHIANG KAI-SHEK\n[ 0m23s ] Whereas in the First Sino-Japanese War,\n[ 0m24s ] FIRST SINO-JAPANESE WAR\n[ 0m25s ] 1894 - 1895\n[ 0m26s ] Yamagata is thinking about doing regime change and the government pulls him out because it's,\n[ 0m26s ] YAMAGATA ARITOMO\n[ 0m27s ] FIELD MARSHAL\n[ 0m29s ] buddy, don't do that. We're going to have all kinds of\n[ 0m31s ] foreign powers intervening if you try.\n[ 0m34s ] And then in the Russo-Japanese War, they're not trying to do regime change in Russia.\n[ 0m34s ] RUSSO-JAPANESE WAR\n[ 0m35s ] 1904 - 1905\n[ 0m37s ] But in the Second Sino-Japanese War,\n[ 0m38s ] SECOND SINO-JAPANESE WAR\n[ 0m39s ] 1937 - 1945\n[ 0m40s ] they absolutely are trying to do regime change. They get more and more frustrated.\n[ 0m43s ] And then their solution to that one is to attack all the colonial\n[ 0m46s ] interests in Asia. That's when Pearl Harbor happens.\n[ 0m48s ] And then they're bringing us, the British, and that brings the British Commonwealth,\n[ 0m48s ] WORLD WAR II\n[ 0m49s ] 1939 - 1945\n[ 0m51s ] so it's Australia and New Zealand. They do significant fighting.\n[ 0m54s ] WATCH HERE\n[ 0m55s ] It's a different event."
        }
    },
    {
        "id": "m1PUl-aUk8c",
        "title": "To The “Muon”? A Slightly Technical Breakdown of Kimi K2",
        "content": "Master AI agents now using HubSpot's FREE resource! https://clickhubspot.com/aa716f Might be very late to the party, but hope ...",
        "url": "https://www.youtube.com/watch?v=m1PUl-aUk8c",
        "publishDate": "2025-08-26T15:01:18Z",
        "author": "bycloud",
        "sourceType": "youtube",
        "sourceName": "bycloud YouTube Channel",
        "metadata": {
            "channelId": "UCgfe2ooZD3VJPB6aJAnuQng",
            "thumbnailUrl": "https://i.ytimg.com/vi/m1PUl-aUk8c/hqdefault.jpg",
            "transcription": "This relatively new AI lab called Moonshot AI literally went to the moon a while back with their latest model release called Kimi K2 using a brand new technique called Muon. Not only is this 1 trillion parameter MoE model with 32 billion active parameters the latest state-of-the-art open source non-reasoning model, maybe for like a week only, as Qwen's latest model update just overtook it by a significant margin. But they provided some extremely valuable insights that might just change the pre-training meta. Most of you that are watching this video are probably already familiar with its benchmark's performance, so I'll just drop a few facts like how Kimi K2 was the number one model on the EQ-bench, which is a creative writing benchmark. Number one on LM Arena for open models, perform slightly better than Qwen 3 235B A22B Reasoning and still behind DeepSeek R1 on scientific reasoning. Around Claude 4 Opus level, according to Moonshot AI's official benchmark, but around the level of GPT-4.1 and Qwen 3 235B Reasoning and just a tiny bit behind Gemini 2.5 Flash Reasoning on third party benchmarks. To put all these simply, I think it was the best open source non-reasoning model on the planet before the existence of the new Qwen 3 model. So as the Kimi K2 Technical Report is out now, along with their developers dropping blocks left and right. I think I need to do is just this and dive into the fascinating journey they shared with their $30 million model training run. But before I dive into it, with Kimi K2 being a model that also focuses on agentic capabilities, learning how to utilize the end product is probably more applicable for yourself than learning how they actually make it. That's why I'd like to take this chance to share with you this free resource from HubSpot called \"Master AI Agents in 2025: The Strategic Advantage\". In this free resource, you would get two comprehensive playbooks. One is a 42 page long guide which shows you exactly where AI agents can deliver you the biggest ROI. And another that's a step-by-step checklist which will walk you through the AI Agent rollouts. My favorite section is the common pitfalls and how to avoid them in the 42 page playbook. As this is often overlooked when building custom AI agents. This is especially common under an organizational setting, as AI Agents may bear too much expectations or contain challenges that can often be overlooked. So having these precautions can significantly improve your chance of success. But of course, it is still a crazy power tool. In marketing, AI agents now shoulder the repetitive work of content repurposing, social scheduling, and campaign analytics so your creatives can stay focused on big ideas. In sales, they handle prospect research, meeting prep, and personalize follow-ups, buying reps back precious time for relationship building. Across operations, agents can quietly file docs, route requests, and service real-time analytics so your org runs like a clockwork. The best part is, you can download these resources completely free right now. So if you're ready to dive into AI Agents, check it out using the link down in description. And thank you, HubSpot, for sponsoring this video. Anyways, the highlight of Kimi K2 is this training loss graph. And this is no ordinary training loss. It is actually using a really new optimizer called Muon, which was proposed back in October 2024. As it caught the eyes of the AI research part of Twitter, this promising optimizer challenged the most common optimizer that we all know and love called AdamW, which has been the solid go-to optimizer for the past eight years. So what exactly changed that they decided to use Muon? Well, before that, let us take a look at some basics of optimization in AI. In general, training an AI model is like spawning in Minecraft's amplified world. And your mission is to reach the lowest point without breaking any blocks. Well, we usually visualize this as descending from a loss landscape, but who doesn't love a good Minecraft analogy? Anyways, the lowest point stands for the perfect prediction. Classify an image of a cat as a cat. Generate the perfect next token and so on. So all you want to do is somehow descend to the lowest point by moving around the world without being able to see while only taking one step at a time. But you will be able to learn the slope whether you are going up or downwards after each step. And to determine the direction and the stride of your step, you would use something called an optimizer. For the popular optimizer AdamW, each step measures how steep and how jittery its last and current step was. If the ground has been steep and smooth, you would lengthen your stride. If it has been bumpy, you would shorten your stride. And the same thing goes for the direction, you only want to try to step in the steepest direction. When two or three steps you took in the same direction have the same slope, you would feel a stronger momentum, right? But the problem of AdamW is once you accelerate, if that slope starts to turn in different directions, the momentum will overshoot you and drag you along the hill sideways, making you descend slower and take longer to readjust back to the optimal. As the momentum would often overshoot, you can actually observe it in the loss graph, as it makes up those spiky points in the loss curve. So what makes Muon different is that it doesn't easily give into that momentum to let it drag you sideways or overshoot in direction. Right before each new stride, it would pause and look around, slowing down that momentum and twist its momentum to spread it around all directions evenly and steadily continue, which lets you descend accurately. This additional look around check would cost an extra 0.5% compute per step, but it's actually extremely worth it empirically, because it reduces the total training needed by up to 35%. Because AdamW would often overshoot, and the extra time that it takes to readjust itself towards the optimal makes Muon's 0.5% overhead much more worth it as Muon reaches the optimal way faster. This is why the usual Muon training loss looks less spiky than in training loss using AdamW, which makes Muon a technique that might just improve pre-training efficiency in general. But that is if it works on a larger scale of course. Because in Kimi K2's early experiment, they hit a wall. A few months ago, they have published research papers on experimenting with Muon. Like in this paper called \"Muon is Scalable for LLM Training\", which was released back in late February. They have shown a very attractive scaling law that proved Muon is scalable on a level of 16 billion MoE models. However, things start to get weird when the model size for their new K2 hits a trillion total parameters. Right at the start of training, there usually be a few tokens that would blow up with a gigantic query or key vector. And since this is at the start of pre-training, big updates tend to happen. But when the updates are extremely wrong, the learning signal that came back would be oversized. While AdamW can dampen the learning signal for the targeted weights right away, Muon cannot. And it will even spread it across every direction too, inflating all the weights for the wrong reason. So the next learning step would produce even bigger error, creating an insane negative feedback loop that will eventually break the training. And this was not anticipated in the earlier scaling law experiments, hitting Moonshot AI's team morale. So as they are struggling to find a way out, the person that basically invented RoPE, called Su Jianlin, basically came up with an idea. He proposed something called QK-Clip, later known as MuonClip, which fixes the issue by simply adding a threshold. It would basically clip out the giant query and key norms or the resulting logits before Muon does its thing to the momentum, taming those early outliers. And with the MuonClip in place, the runaway logits flattened, Muon's updates stayed extremely stable, and K2's 1 trillion parameter training was finally able to launch without problems. So it resulted in this absolute beauty of a training loss with no loss spikes in sight. And this loss graph right here, cost them $20 million to generate. So you know how important that is, especially for an AI startup to get it right in the first attempt. Alongside this new idea, MuonClip, researchers over at Moonshot AI have also done some incredible ablation studies. And they found some pretty interesting observations. First of all, their results have shown that the DeepSeek V3 model design, which is the MLA and the MoE, is pretty much perfect and impossible to improve upon. From all the model architecture modifications they have made, nothing else surpasses it in their early scaling law experiments. So DeepSeek V3's architecture still remains supreme. But researchers at Moonshot still made a few neat adjustment of Kimi K2's architecture to make it a lot more cost efficient. First is that they added 50% more experts per MoE layer than DeepSeek V3, yet kept the same active parameters per token unchanged. This increases the sparsity of the MoE, but they were confident to do this because their experiments confirm a brand new sparsity scaling law. As long as each token still touches the same number of experts, bumping the total experts pool never degrades loss. So more experts just means there are more options of specialized subnets ready to be routed to. Second, they halved the attention heads. Because DeepSeek V3's full head design is actually pretty pricey. K2 then drops to 64 heads instead of using 128. Cutting the QKVO projection matrix from 10 billion parameters down to 5 billion parameters. So this is why activated parameters are now 5 billion parameters less than DeepSeek V3. This reduction in heads only showed around 2% degradation, which is also offset by the MoE gains, so the trade is a net win. Third, only the first MoE layer goes dense. Both DeepSeek V3 and K2 saw router imbalance spikes right at the start of the sequence. DeepSeek V3 then made the very first three layers dense. But after some testing from the Moonshot researchers, they found that reducing to just having the first layer dense is already good enough, with training already becoming noticeably steadier. Lastly, they ditched expert grouping and used a simple router. Because at the trillion parameter scale, each GPU basically ends up only holding just one expert. Completely skipping a whole level of abstraction that is having multiple experts on one GPU during training. Then when each GPU hosts only one specialist expert network, the old grouping trick where the router first picks a basket of experts that lived on the same GPU and then choose inside that basket no longer makes sense. Because now there's only one thing in that basket, so no choices are really made. Moonshot then throws the grouping layer away and gives the router a single flat menu of all 384 experts spread across the cluster all at the same time. And with the grouping gone, the search space is now wider. The router can spread tokens across servers instead of being trapped inside one GPU. And they are also able to have the overall utilization stays high even at a trillion parameter scale. But yeah, 1 trillion parameter model needs 384 GPUs to hold it all at the same time to train. Isn't that kinda crazy? And yeah, I hope today's video at least cleared up their technical side of research a bit for you and maybe did their immense open source effort a bit more justice. And if you like today's research breakdown, definitely check out my newsletter where I cover the latest and the juiciest research weekly. On it, I will usually cover the best research papers from the previous week. So if you don't want to miss out, definitely go and subscribe. And thank you guys for watching! A big shout out to Andrew Lescelius, Chris Ladoux, Deagan, NOUS RESEARCH, KAINAN, Robert Zawiasa, Louis Muk, Ben Shaener, Marcelo Ferreira, ZAYN SHEEP, POOF'N'SHEEP, DX RESEARCH GROUP, and many others that support me through Patreon or YouTube. Follow me on Twitter if you haven't, and I'll see you all in the next one!"
        }
    }
]