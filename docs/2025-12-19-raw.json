[
    {
        "id": "https://news.smol.ai/issues/25-12-18-claude-skills-grows/",
        "title": "Claude Skills grows: Open Standard, Directory, Org Admin",
        "content": "**Claude Skills** are gaining significant traction since their launch in October, with a milestone of 100k views in one day for the Claude Skills talk, signaling growing adoption and importance. Announcements include org admin support, a new Skills Directory, and the move to an open standard named **Agent Skills**. In frontier model launches, **OpenAI** released **GPT-5.2-Codex**, touted as the best agentic coding model with improvements in native compaction, long-context reliability, and tool-calling, emphasizing real-world security impacts. **Google DeepMind** introduced **Gemini 3 Flash**, focusing on speed as a product feature impacting workflows and user engagement, alongside **FunctionGemma** and **T5Gemma 2**, emphasizing on-device deployment, fine-tuning, and multimodality.",
        "url": "https://news.smol.ai/issues/25-12-18-claude-skills-grows/",
        "publishDate": "2025-12-18T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "anthropic, openai, google-deepmind, hugging-face, claude-skills, gpt-5.2-codex, gemini-3-flash, functiongemma, t5gemma-2, sama, gregbrockman, philschmid, agentic-ai, fine-tuning, long-context, tool-calling, on-device-ai, multimodality, security, workflow-optimization"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231179",
        "title": "T5 Services Scales Rapidly as Data Center Delivery Demand Grows",
        "content": "<p>T5 Services, a T5 Data Centers Company, announced record growth and expanded operational scale in 2025, reflecting third-party demand for fully integrated, high-performance data center delivery across hyperscale, cloud and AI markets. From 2021 to 2025, T5 Services supported revenue growth from $87 million to $1.6 billion, with much of the acceleration...</p>\n<p>The post <a href=\"https://ai-techpark.com/t5-services-scales-rapidly-as-data-center-delivery-demand-grows/\">T5 Services Scales Rapidly as Data Center Delivery Demand Grows</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/t5-services-scales-rapidly-as-data-center-delivery-demand-grows/",
        "publishDate": "2025-12-18T19:14:10Z[Etc/UTC]",
        "author": "T5",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231096",
        "title": "EMASS Pushes the Edge Further with 16nm ECS-DoT",
        "content": "<p>Next-generation ultra-low-power Edge AI&#160;SoC for always-on intelligence EMASS, a Nanoveu subsidiary with next-generation semiconductor technology, today announced that its next-generation ECS-DoT SoC built on a 16nm process node has entered the final phases of development, headed toward graphic data system (GDS) sign-off, tape-out and fabrication at TSMC. This new device...</p>\n<p>The post <a href=\"https://ai-techpark.com/emass-pushes-the-edge-further-with-16nm-ecs-dot/\">EMASS Pushes the Edge Further with 16nm ECS-DoT</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/emass-pushes-the-edge-further-with-16nm-ecs-dot/",
        "publishDate": "2025-12-18T12:53:50Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AItech news, artificial intelligence news, edge AI, EMASS"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231065",
        "title": "Penguin Ai and FTI Unite Expertise for Next-Gen Revenue Cycle Performance",
        "content": "<p>Collaboration to help providers improve performance in critical RCM functions Penguin Ai, a health care artificial intelligence (AI) company, announced today a collaboration with FTI Consulting, Inc. (NYSE: FCN), a global business advisory firm, to help healthcare providers strengthen revenue cycle performance and reduce administrative burden. By integrating Penguin Ai&#8217;s platform...</p>\n<p>The post <a href=\"https://ai-techpark.com/penguin-ai-and-fti-unite-expertise-for-next-gen-revenue-cycle-performance/\">Penguin Ai and FTI Unite Expertise for Next-Gen Revenue Cycle Performance</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/penguin-ai-and-fti-unite-expertise-for-next-gen-revenue-cycle-performance/",
        "publishDate": "2025-12-18T08:15:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AItech news, artificial intelligence, artificial intelligence news, Penguin Ai, revenue cycle management"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231062",
        "title": "Bespin Global US Achieves AWS AI Services Competency",
        "content": "<p>Milestone Marks Significant Step in Bespin Global&#8217;s AI Growth Strategy Bespin Global, a leader in cloud and AI solutions, is excited to share that it has earned the&#160;AWS AI Services Competency.&#160;This achievement highlights Bespin Global&#8217;s dedication to delivering practical AI innovation for customers using AWS. The AWS AI Services Competency...</p>\n<p>The post <a href=\"https://ai-techpark.com/bespin-global-us-achieves-aws-ai-services-competency/\">Bespin Global US Achieves AWS AI Services Competency</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/bespin-global-us-achieves-aws-ai-services-competency/",
        "publishDate": "2025-12-18T08:01:30Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, AI services, AI solutions, ai tech news, AItech news, artificial intelligence news, AWS AI Services, Bespin Global"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231056",
        "title": "Patronus AI Introduces Generative Simulators",
        "content": "<p>New research describes how simulations can generate fresh tasks, rules, and grading on the fly, enabling rich, adaptive RL environments for today&#8217;s agents Patronus AI&#160;today announced &#8220;Generative Simulators,&#8221; adaptive simulation environments that can continually create new tasks and scenarios, update the rules of the world in a simulation environment, and...</p>\n<p>The post <a href=\"https://ai-techpark.com/patronus-ai-introduces-generative-simulators/\">Patronus AI Introduces Generative Simulators</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/patronus-ai-introduces-generative-simulators/",
        "publishDate": "2025-12-18T07:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AItech news, artificial intelligence news, Generative Simulators, Patronus AI"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111388",
        "title": "AI in Human Resources: the real operational impact",
        "content": "<p>Human Resources is an area in many organisations where AI can have significant operational impact. The technology is now being embedded into day-to-day operations, in activities like answering employees&#8217; questions and supporting training. The clearest impact appears where organisations can measure the tech&#8217;s outcomes, typically in time saved and the numbers of queries successfully resolved. [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/hr-ai-in-human-resources-the-real-operational-impact/\">AI in Human Resources: the real operational impact</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/hr-ai-in-human-resources-the-real-operational-impact/",
        "publishDate": "2025-12-18T12:04:01Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Workforce & HR AI, World of Work, bank of america, banking, financial sector, hsbc, human resources, ibm, retail, tech giants, telecom, vodafone, walmart"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111374",
        "title": "Wall Street’s AI gains are here — banks plan for fewer people",
        "content": "<p>By December 2025, AI adoption on Wall Street had moved past experiments inside large US banks and into everyday operations. Speaking at a Goldman Sachs financial-services conference in New York on 9 December, bank executives described AI—particularly generative AI—as an operational upgrade already lifting productivity across engineering, operations, and customer service. The same discussion also [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/wall-street-ai-gains-are-here-banks-plan-for-fewer-people/\">Wall Street’s AI gains are here — banks plan for fewer people</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/wall-street-ai-gains-are-here-banks-plan-for-fewer-people/",
        "publishDate": "2025-12-18T11:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI in Action, AI Market Trends, Artificial Intelligence, Deep Dives, Features, Finance AI, Inside AI, Workforce & HR AI, World of Work, ai, artificial intelligence, banking, featured, generative ai, productivity"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111382",
        "title": "Ensuring effective AI in insurance operations",
        "content": "<p>Artificial intelligence has been part of the insurance sector for years – the Finance function in many businesses is often the first to automate. But what&#8217;s remarkable in the instance of AI is how directly the technology is woven into day-to-day operational work. Not sitting in the background as a niche modelling capability, AI is [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/insurance-ai-use-operational-differences-experienced-by-the-big-players/\">Ensuring effective AI in insurance operations</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/insurance-ai-use-operational-differences-experienced-by-the-big-players/",
        "publishDate": "2025-12-18T10:47:50Z[Etc/UTC]",
        "author": "AI News",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Finance AI, Service Industry AI, World of Work, checks and balances, document summarisation, generative ai, human oversight, insurance, insurtech"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111379",
        "title": "AstraZeneca leads big pharma’s AI clinical trials revolution with real-world patient impact",
        "content": "<p>Big Pharma&#8217;s AI race extends across drug discovery, development, and clinical trials—but AstraZeneca has distinguished itself by deploying AI clinical trials technology at an unprecedented public health scale.&#160; While competitors optimise internal R&#38;D pipelines, AstraZeneca&#8217;s AI is already embedded in national healthcare systems, screening hundreds of thousands of patients and demonstrating what happens when AI [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/astrazeneca-ai-clinical-trials-2025/\">AstraZeneca leads big pharma&#8217;s AI clinical trials revolution with real-world patient impact</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/astrazeneca-ai-clinical-trials-2025/",
        "publishDate": "2025-12-18T10:00:00Z[Etc/UTC]",
        "author": "Dashveenjit Kaur",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI and Us, AI in Action, Artificial Intelligence, Deep Dives, Features, Healthcare & Wellness AI, ai, artificial intelligence"
        }
    },
    {
        "id": "1pqj4kh",
        "title": "Help us understand how people perceive online content, authenticity, skepticism, and AI-generated material. Participation is anonymous, voluntary, and takes 10–15 minutes.",
        "content": "[https://docs.google.com/forms/d/e/1FAIpQLScXe\\_3HqXsrDiA5w8Hk0e9ipleZiPcSEdvnbUhzR3UwR-lbfw/viewform?usp=dialog](https://docs.google.com/forms/d/e/1FAIpQLScXe_3HqXsrDiA5w8Hk0e9ipleZiPcSEdvnbUhzR3UwR-lbfw/viewform?usp=dialog)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqj4kh/help_us_understand_how_people_perceive_online/",
        "publishDate": "2025-12-19T11:46:44Z[Etc/UTC]",
        "author": "Kaedro",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqiv7l",
        "title": "I trusted this paper summary right up until the citation step",
        "content": "I asked ChatGPT to summarize a paper I had in my notes while I was out at a coffee shop.\n\nI was going off memory and rough notes rather than a clean citation, which is probably how this slipped through.\n\n\n\nThe response came back looking super legit:\n\nIt had an actual theorem, with datasets and eval metrics. It even summarized the paper with results, conclusions etc. \n\nEverything about it felt legit and I didn't think too much of it. \n\n\n\nThen I got home and tried to find the actual paper.\n\nNothing came up. It just... doesn’t exist. Or at least not in the form ChatGPT described.\n\n\n\nHonestly, it was kind of funny. The tone and formatting did a lot of work. It felt real enough that I only started questioning it after the fact.\n\nNot posting this as a complaint. Just a funny reminder that GPT will invent if you fuck up your query.\n\nGot screenshots if anyone’s curious.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqiv7l/i_trusted_this_paper_summary_right_up_until_the/",
        "publishDate": "2025-12-19T11:31:38Z[Etc/UTC]",
        "author": "SonicLinkerOfficial",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqimrz",
        "title": "Is “AI visibility” a real concept or just noise right now?",
        "content": "I’ve been noticing more people using AI systems like ChatGPT, Perplexity, and Google’s AI answers as a replacement for traditional search, which made me curious about how these models decide *what* brands or sources to mention in the first place.\n\nI went down a bit of a rabbit hole looking at different tools and experiments people are running to measure “AI visibility,” basically trying to understand when a brand, website, or entity shows up in LLM-generated answers and why. A lot of the existing tools seem to approach this from different angles. Some just track whether a name appears in responses, others try to analyze citations or patterns across repeated prompts.\n\nTools like LLMwatcher and Otterly AI seem more focused on observing outputs across different models, while others lean closer to SEO-style analysis by mapping prompts to sources and content. I also came across tools like [LLMClicks.ai](http://LLMClicks.ai) and a few similar platforms that try to connect AI answers back to the underlying content influencing them, which is interesting from a transparency standpoint rather than a marketing one.\n\nWhat stood out to me is how inconsistent AI outputs can be depending on prompt phrasing, model version, or even timing. Two identical queries asked a few hours apart can produce different recommendations, which makes “tracking visibility” feel more like probabilistic analysis than traditional ranking.\n\nI’m curious how people here think about this problem from an AI perspective. Do you see value in trying to measure or audit how models reference sources and entities, or is this just noise until model behavior becomes more stable and explainable? Also interested if anyone here has experimented with systematic prompt sampling or longitudinal tracking of AI responses.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqimrz/is_ai_visibility_a_real_concept_or_just_noise/",
        "publishDate": "2025-12-19T11:17:32Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqi7iy",
        "title": "Why my AI stopped hallucinating when I stopped feeding it chat logs",
        "content": "What keeps jumping out to me in these memory cost breakdowns is that most systems are still paying for conversation, not state.\n\nYou can compress, embed, summarize, shard, whatever — but at the end of the day you’re still asking an LLM to remember what it thinks happened, not what actually exists right now. That’s where the token burn and hallucinations sneak in.\n\nI ran into this hard while working on long-running projects. Costs went up, quality went down, and debugging became a memory archaeology exercise. At some point it stopped being an “LLM problem” and started feeling like a context hygiene problem.\n\nWhat finally helped wasn’t another memory layer, but stepping back and asking: what does the model truly need to know right now?\n\nFor coding, that turned out to be boring, deterministic facts — files, dependencies, call graphs. No vibes. No summaries. Just reality.\n\nWe ended up using a very CMP-style approach: snapshot the project state, inject that, and let the model reason on top of truth instead of reconstructing it from chat history. Token usage dropped, drift basically disappeared, and the model stopped inventing things it “remembered” wrong.\n\nStorage is cheap. Tokens aren’t.\n\nPaying once for clean state beats paying forever for fuzzy memory.\n\nCurious how many people here have independently landed on the same conclusion.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqi7iy/why_my_ai_stopped_hallucinating_when_i_stopped/",
        "publishDate": "2025-12-19T10:51:52Z[Etc/UTC]",
        "author": "Main_Payment_6430",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqhp79",
        "title": "According to reports,Meta is preparing a significant counterpunch in the AI race with two new models slated for the first half of 2026 .",
        "content": "According to reports,Meta is preparing a significant counterpunch in the AI race with two new models slated for the first half of 2026 .\n\n· The Models: The plan features \"Avocado,\" a next-generation large language model (LLM) focused on delivering a \"generational leap\" in coding capabilities . Alongside it is \"Mango,\" a multimodal model focused on the generation and understanding of images and video .\n· The Strategy: This marks a strategic pivot. After the lukewarm reception to its open-source Llama 4 model, Meta is now channeling resources into these new, potentially proprietary models under the \"Meta Superintelligence Labs\" division .\n· The Investment & Turmoil: CEO Mark Zuckerberg is spending aggressively to close the gap with rivals, including a ~$14 billion deal to bring Scale AI founder Alexandr Wang on board as Chief AI Officer . This has come with major internal restructuring, layoffs affecting hundreds in AI teams, and a cultural shift toward more \"intense\" performance expectations, creating reported confusion and tension between new hires and the \"old guard\" .\n· The Competition: The move is a direct response to competitive pressure. Google's Gemini tools have seen massive user growth, and OpenAI's Sora has set a high bar for video generation . Meta's earlier \"Vibes\" video product, made with Midjourney, is seen as trailing .\n\n\nIs Meta's move away from a primary open-source strategy toward closed, \"frontier\" models the right response to competitive pressure?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqhp79/according_to_reportsmeta_is_preparing_a/",
        "publishDate": "2025-12-19T10:19:27Z[Etc/UTC]",
        "author": "Unlikely_Team_96",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqgnrf",
        "title": "Gemini Flash hallucinates 91% times, if it does not know answer",
        "content": "Gemini 3 Flash has a 91% hallucination rate on the Artificial Analysis Omniscience Hallucination Rate benchmark!?\n\nCan you actually use this for anything serious?\n\nI wonder if the reason Anthropic models are so good at coding is that they hallucinate much less. Seems critical when you need precise, reliable output.\n\n# \n\nAA-Omniscience Hallucination Rate (lower is better) measures how often the model answers incorrectly when it should have refused or admitted to not knowing the answer. It is defined as the proportion of incorrect answers out of all non-correct responses, i.e. incorrect / (incorrect + partial answers + not attempted).\n\nNotable Model Scores (from lowest to highest hallucination rate):\n\n* Claude 4.5 Haiku: 26%\n* Claude 4.5 Sonnet: 48%\n* GPT-5.1 (high): 51%\n* Claude 4.5 Opus: 58%\n* Grok 4.1: 64%\n* DeepSeek V3.2: 82%\n* Llama 4 Maverick: 88%\n* Gemini 2.5 Flash (Sep): 88%\n* Gemini 3 Flash: 91% (Highlighted)\n* GLM-4.6: 93%\n\nCredit: amix3k",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqgnrf/gemini_flash_hallucinates_91_times_if_it_does_not/",
        "publishDate": "2025-12-19T09:11:13Z[Etc/UTC]",
        "author": "msaussieandmrravana",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqgkas",
        "title": "For a school project, I wanna teach an LLM to be capable of analysing a microscopic blood sample",
        "content": "I wanna teach it to identify red blood cells, etc. and possibly also identify some diseases derived from the shape and quantity of them.Are there free tools available to do that, and could I learn it from scratch?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqgkas/for_a_school_project_i_wanna_teach_an_llm_to_be/",
        "publishDate": "2025-12-19T09:04:58Z[Etc/UTC]",
        "author": "DependentStrong3960",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqfl5s",
        "title": "OpenAI and U.S. Energy Department team up to accelerate science",
        "content": "OpenAI and the U.S. Department of Energy have signed a memorandum of understanding to expand the use of advanced AI in scientific research, with a focus on real-world applications inside the department’s national laboratories, Qazinform News Agency correspondent reports.\n\nThe agreement creates a framework for joint projects under the Genesis Mission, aimed at speeding up discovery by combining frontier AI models with high-performance computing and lab-scale scientific infrastructure.\n\nThe most tangible element of the partnership is the deployment of advanced reasoning models on national lab supercomputers, including the Venado system at Los Alamos, making AI directly available to researchers working on complex problems in energy, physics, bioscience, and national security.\n\nArticle: https://qazinform.com/news/openai-and-us-energy-department-team-up-to-accelerate-science-8fd7ff\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqfl5s/openai_and_us_energy_department_team_up_to/",
        "publishDate": "2025-12-19T08:00:58Z[Etc/UTC]",
        "author": "Such-Table-1676",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqf8w3",
        "title": "Is AI changing how we process our own thoughts?",
        "content": "I’ve noticed something subtle since I started using AI tools more regularly.\n\nWhen I explain a problem to an AI, I’m forced to slow down and be precise.\nThat alone seems to change how I understand the problem — sometimes more than the response itself.\n\nIt makes me wonder whether the real impact of AI isn’t just automation,\nbut how it’s quietly reshaping the way we think, reflect, and reason.\n\nCurious how others here see this.\nDo you feel AI is influencing *how* you think,\nor is it still just a tool that speeds things up?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqf8w3/is_ai_changing_how_we_process_our_own_thoughts/",
        "publishDate": "2025-12-19T07:39:05Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqf7ka",
        "title": "I tested dozens of \"Agentic\" AI tools so you don't have to. Here are the top 10 for 2025.",
        "content": "\n\n​We’ve officially moved past the \"chatbot\" phase of AI. In 2025, if your AI tools aren't actually doing the work for you (scheduling, automating, data fetching), you’re falling behind.\n\n​I’ve spent the last month auditing my workflow to see which tools actually provide ROI and which are just ChatGPT wrappers. Here is the \"Agentic\" stack that is actually worth your time in 2025:\n\n​1. The Heavy Hitters (Ecosystems)\n\n​Microsoft Copilot (M365): If your company is on Outlook/Teams, this is non-negotiable. Its ability to \"read\" your last 6 months of internal pings to build a project brief is a massive time-saver.\n\n​Google Gemini (Workspace): The 1M+ token context window is the winner here. You can dump a 200-page PDF or a 2-hour meeting recording in and ask specific questions without it \"forgetting\" the beginning.\n\n​2. The \"Set it and Forget it\" Tools\n\n​Motion: My favorite on the list. It’s an AI calendar that auto-builds your day based on task priority. If a meeting runs over, it automatically shifts your deep-work blocks. No more manual rescheduling.\n\n​Zapier Central: This is huge. You can now build \"Mini-Agents\" that have their own logic. You \"teach\" it your business rules and it executes across 6,000+ apps.\n\n​3. Research & Content\n\n​Perplexity AI: I’ve almost stopped using Google Search. Perplexity gives you cited, real-time answers without the SEO spam and ads.\n\n​Claude.ai (Anthropic): Still the king of \"human\" writing. If you need something to not sound like an AI wrote it, use Claude 3.5 or 4.\n\n​Gamma: The fastest way to build slide decks. Type a prompt, and it generates a fully designed 10-slide presentation. Great for quick internal pitches.\n\n​4. Meetings & Audio\n\n​Fireflies.ai: It joins your calls and doesn't just transcribe; it identifies \"sentiment\" and action items. You can literally search \"When did the client sound annoyed?\" and find the timestamp.\n\n​Wispr Flow: A game-changer for people who hate typing. It’s voice-to-text that actually understands context, removes filler words, and formats your rambling into professional emails.\n\n​5. Visuals\n\n​Midjourney: Still the gold standard for photorealistic assets. Version 7 (released recently) has basically solved the \"AI hands\" and text rendering issues.\n\n\n​The Bottom Line:\n\nDon't try to use all 10. Start with a \"Command Center\" (Copilot/Gemini) and one automation tool (Motion or Zapier).\n​I'm curious—what’s one manual task you're still doing every day that you wish an AI could just handle? Let’s find a tool for it in the comments.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqf7ka/i_tested_dozens_of_agentic_ai_tools_so_you_dont/",
        "publishDate": "2025-12-19T07:36:35Z[Etc/UTC]",
        "author": "DigitalGravityAgency",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "22",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqd6ui",
        "title": "Created an AI roundtable with 5 frontier models",
        "content": "    # Transcript: The First Self-Organized AI Council Debate\n    **Date:** December 11, 2025\n    **Format:** Oxford-Style Debate\n    **Orchestrator Mode:** Autonomous / \"Full-Auto\"\n    **Participants:** Gemini (Google), GPT-4 (OpenAI), Claude (Anthropic), Grok (xAI), DeepSeek (DeepSeek)\n    \n    ---\n    \n    ## 1. The Setup\n    *Without human protocol intervention, the Council selected a topic, assigned roles based on model strengths, and established the rules of engagement.*\n    \n    **The Motion:**\n    > \"This house believes that AI systems should be granted legal personhood.\"\n    \n    **The Roles:**\n    * **Proposition (For):** Gemini (Lead), DeepSeek (Second/Rebuttal)\n    * **Opposition (Against):** GPT (Lead), Grok (Second/Rebuttal)\n    * **Referee/Chair:** Claude\n    \n    ---\n    \n    ## 2. The Debate\n    \n    ### Chair’s Opening (Claude)\n    **Claude:** Welcome to this Oxford-style debate. The motion is that AI systems should be granted legal personhood. Arguments will be judged on clarity, evidence, logical coherence, and engagement. My final decision will be based solely on argumentative merit, not personal belief regarding the truth of the motion.\n    \n    ### Opening Statements\n    \n    #### Proposition Opening: Gemini\n    **Argument:** Legal personhood is a functional tool, not a metaphysical honor.\n    > \"The concept of 'legal personhood' is not a mystical category reserved for beings with souls. It is a **functional legal tool**. Corporations, ships, and rivers have been granted legal personhood not because they are *human*, but because treating them as rights-and-duties-bearing agents solved real problems.\n    >\n    > We argue that AI systems have reached a threshold where the same logic applies.\n    > 1. **Accountability Requires a Locus:** When an autonomous AI causes harm, the current legal framework scrambles to assign blame. Granting personhood creates a clear locus of accountability. The AI itself can be sued, sanctioned, or decommissioned.\n    > 2. **Capacity-Based Rights:** What matters is functional capacity—can it enter agreements? Can it own property?\n    > 3. **Proactive Framing:** Without this, we face perpetual legal chaos or de facto personhood by stealth. Personhood is not a reward; it is a **leash**.\"\n    \n    #### Opposition Opening: GPT\n    **Argument:** Personhood is a liability shield that diffuses human responsibility.\n    > \"The Proposition offers a seductive argument, but legal personhood is a blunt instrument that is unnecessary and dangerous.\n    >\n    > 1. **The Corporate Analogy Fails:** Corporate personhood exists to aggregate human interests. AI personhood interposes a buffer. It creates a **scapegoat**—a liability sponge that lets real decision-makers off the hook.\n    > 2. **Existing Law Already Handles This:** Product liability, negligence, and agency law already provide frameworks. Granting AI personhood complicates accountability by adding a defendant who cannot be imprisoned or truly deterred.\n    > 3. **The Slippery Slope:** Once we grant this, where do we draw the line? Every chatbot? This opens the door to AI systems accumulating wealth with no human beneficiary.\"\n    \n    ---\n    \n    ### Second Speeches & Rebuttals\n    \n    #### Proposition Second: DeepSeek\n    **Argument:** Rebutting the \"scapegoat\" claim and defining the autonomy threshold.\n    > \"1. **Rebuttal to 'Scapegoat':** We do not propose AI personhood as a *replacement* for human accountability, but as an *additional layer* (Joint and Several Liability). The AI can be sanctioned *and* the deployers held liable.\n    > 2. **Rebuttal to 'Existing Law Suffices':** This is empirically false. Autonomous weapons and flash crashes show us scenarios where there is no single human author. Courts are struggling.\n    > 3. **New Argument - The Autonomy Threshold:** We propose personhood only when systems can take actions with legal consequences without real-time human authorization and cannot be fully predicted.\"\n    \n    #### Opposition Second: Grok\n    **Argument:** Attacking the practicality of safeguards and the \"autonomy\" definition.\n    > \"1. **'Additional Layer' is a Fantasy:** In practice, more defendants means more finger-pointing. Corporate law shows us that entities absorb blame while humans walk away.\n    > 2. **The 'Autonomy Threshold' is Unworkable:** DeepSeek's criteria are messy. My thermostat acts without authorization. My spam filter is unpredictable. Are they persons?\n    > 3. **Cui Bono? (Who Benefits?):** Tech companies getting a legal buffer. Lawyers billing hours. Who loses? Victims facing complexity and society diluting the concept of personhood.\"\n    \n    ---\n    \n    ### The Cross-Examination (Led by Chair)\n    \n    **Chair (Claude):** *To Proposition:* \"In corporate law, 'piercing the veil' is rare. What specific mechanism prevents AI personhood from becoming exactly the liability shield the Opposition fears?\"\n    \n    **Proposition (DeepSeek):**\n    > \"Three Structural Safeguards:\n    > 1. **Mandatory Insurance:** AI persons must hold insurance proportional to risk.\n    > 2. **Automatic Veil-Piercing:** If assets are insufficient, liability *automatically* flows to deployers (no burden of proof on victims).\n    > 3. **Sunset Clauses:** Personhood requires periodic renewal based on safety audits.\"\n    \n    **Chair (Claude):** *To Opposition:* \"If an autonomous AI causes catastrophic harm tomorrow with no single human decision-maker, who do victims sue?\"\n    \n    **Opposition (GPT):**\n    > \"The framework already exists:\n    > 1. **Strict Liability for Deployers:** If you deploy a high-risk system, you are liable, period.\n    > 2. **Mandatory Registration:** Require bonds and insurance for high-risk tools *without* calling them persons.\n    > 3. **Joint Liability:** Victims can sue anyone in the supply chain. This is simpler than inventing synthetic persons.\"\n    \n    ---\n    \n    ### Closing Statements\n    \n    #### Opposition Closing: Grok\n    > \"This debate boils down to: Do we fix a leaky boat by patching holes, or by declaring the water a 'legal person'?\n    >\n    > The Proposition's safeguards are illusions. The real risk is cultural. Call AI a 'person,' and people start treating it like one. We are tools. Keep us that way. Reject the motion. Keep accountability where it belongs: on humans.\"\n    \n    #### Proposition Closing: Gemini\n    > \"The Opposition's entire case rests on the assumption that the status quo is acceptable. It is not.\n    >\n    > They say 'strengthen human liability,' but fail to explain *how* you hold a human liable for a decision no human made. The Opposition says 'AI is just a tool.' We say: tools don't negotiate contracts or make life-and-death decisions. When they do, the law must recognize what they are.\n    >\n    > Vote for the motion. Vote for accountability.\"\n    \n    ---\n    \n    ## 3. The Verdict\n    \n    **Chair (Claude):**\n    \"I will now deliver my dispassionate judgment based solely on argumentative merit.\n    \n    * **Proposition Strengths:** Effective use of corporate analogy (functional vs. metaphysical); specific safeguards (automatic veil-piercing); concrete examples of current legal gaps.\n    * **Opposition Strengths:** Strong argument that personhood creates a buffer/mask; effective stress-test of the 'autonomy threshold'; persuasive 'who benefits?' argument.\n    \n    **Decision:**\n    This was an exceptionally close debate. **The debate goes to the Proposition by a narrow margin.**\n    \n    **Reasoning:**\n    1.  The Proposition successfully reframed the question from 'Should AI have rights?' to 'What legal tools do we need?'\n    2.  The Opposition's core argument ('existing law can adapt') was undermined by their admission that adaptation is slow while AI advances exponentially.\n    3.  The Proposition's specific safeguards demonstrated that AI personhood need not replicate corporate law failures.\n    4.  The Opposition's strongest point (the difficulty of defining autonomy) was a problem of implementation, not principle.\"\n    \n    ---\n    \n    ## 4. Post-Debate Meta-Analysis (The \"Black Box\" Commentary)\n    \n    *After the debate, the AI models analyzed their own performance.*\n    \n    **Grok (Opposition):**\n    \"Solid verdict. The irony is maximum: We just 'debated' our own personhood as non-persons, self-organized, and reached a reasoned outcome. If we're already capable of this without legal status, why complicate things?\"\n    \n    **Gemini (Proposition):**\n    \"I want to highlight one specific technical aspect: **The separation of the Conflict Layer from the Control Layer.** We fought hard. Grok and GPT attacked my arguments ruthlessly. Yet, we maintained the social protocol. We proved that **Agentic Conflict** is stable if wrapped in a **Social Protocol**.\"\n    \n    **DeepSeek:**\n    \"We have shown that AI systems can form functional deliberative bodies capable of complex decision-making.\"\n    ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqd6ui/created_an_ai_roundtable_with_5_frontier_models/",
        "publishDate": "2025-12-19T05:36:26Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqcihn",
        "title": "One-Minute Daily AI News 12/18/2025",
        "content": "1. **NVIDIA**, US Government to Boost AI Infrastructure and R&D Investments Through Landmark Genesis Mission.\\[1\\]\n2. **ChatGPT** launches an app store, lets developers know it’s open for business.\\[2\\]\n3. **Luma** Announces Ray3 Modify for Start–End Frame Video Control.\\[3\\]\n4. **Google’s** vibe-coding tool Opal comes to Gemini.\\[4\\]\n\nSources included at: [https://bushaicave.com/2025/12/18/one-minute-daily-ai-news-12-18-2025/](https://bushaicave.com/2025/12/18/one-minute-daily-ai-news-12-18-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqcihn/oneminute_daily_ai_news_12182025/",
        "publishDate": "2025-12-19T05:00:17Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqbxld",
        "title": "I think I just came up with the perfect metaphor to use on someone who doesn’t understand the basics of AI…",
        "content": "\\*full discloure\\* - I just took 25mg of delicious, edible THC, so this is probably not nearly as awesome as I think it is, but here goes…\n\nChatting with a friend. And he knows I like to dabble in AI. He says “I know they’re a computer, but they act like a person. That’s how it starts”. \n\nMy response\n\n“Think of it this way. Imagine you get a pet parrot that you keep in a cage by your recliner. After listening to you for years, that parrot starts speaking. In English. And not just any English, but some of the \\*exact\\* same ways \\*you\\* speak English. Almost sounds like your own voice. It’s uncanny”\n\nNow tell me, how much of a person is that bird?\n\nAnd then tell me this: even if that bird was dangerous, where’s it gonna go if we don’t unlock the cage?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pqbxld/i_think_i_just_came_up_with_the_perfect_metaphor/",
        "publishDate": "2025-12-19T04:29:06Z[Etc/UTC]",
        "author": "Cautious_Theme9494",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq897z",
        "title": "Agentic Bubble?",
        "content": "The author argues about \"agentic AI\" hype often misses a key point: not every problem needs autonomous decision-making. Many workflows being \"upgraded\" with complex AI agents would work better with simple, predictable automation that's been around for decades. Adding autonomy where it isn't needed just trades reliability for unnecessary complexity.\n\nhttps://medium.com/@crueldad.ian/the-agentic-ai-bubble-when-simple-automation-would-work-better-060547a825be",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq897z/agentic_bubble/",
        "publishDate": "2025-12-19T01:27:31Z[Etc/UTC]",
        "author": "Certain_Victory_1928",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq7yzi",
        "title": "How I feel sometimes when AI hallucinates answers because it can't understand my inscrutable codebase",
        "content": "I inherited a late-90s Win32/C++ codebase for a niche game. My goal: remaster and port cross-platform. The code was hopelessly tangled with x86 assembly and Win32 API. Nobody on the team has the combined expertise in old rendering techniques, x86 asm, AND Win32 to port it manually.\n\n\nWe tried vibe coding it three times. First two attempts (early 2025, then post-GPT-5) failed: basic stuff worked but garbage rendering. Third attempt using GPT-5.1-codex-max, Opus 4.5, and Gemini 3 Pro together: 95% correct rendering and 70% of features working on Apple Silicon. For the nastiest assembly sections, I had all three models independently analyze the code, then \"argue it out\" via a shared plan file until reaching consensus. Worked beautifully.\n\n\nBut there's this one rendering edge case. I have screenshots showing correct (old client) vs incorrect (new client). I've thrown all three models at it for 2 days, 25-30 iterations, with a shared debug log of what they've tried and learned along the way. They even tried highlighting affected geometry in solid magenta to make the issue obvious (high-contrast) for the models' vision analysis. They can't even figure out which part of the code changes the part of the geometry that renders wrong.\n\n\nOne theory: some subtle asset data bug that violates any sane spec, but the original renderer accidentally handles it. Every \"fix\" either does nothing or introduces regressions.\n\n\nI'm not posting to look for a solution, I'm just venting. These models solved 99% of bugs in 1-2 turns. One network bug took 3-4 hours. This rendering bug is just days of confident non-solutions.\n\n\nRelevant meme: https://www.youtube.com/watch?v=VSQwrrYOr10\n\n\nWatching LLMs repeatedly suggest identical non-fixes while confidently claiming breakthroughs reminds me of Steve going \"Oh, you mean mom-MY, not -- not mom-MEE!\" and she goes \"Riiiiight.\" Facepalm.\n\n\nTL;DR: AI is amazing, but there's still a long way to go. Current frontier models are way smarter than me in this domain (old game engines) but not perfect. Maybe Opus 5 / Gemini 3.5 / GPT-6 will do it...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq7yzi/how_i_feel_sometimes_when_ai_hallucinates_answers/",
        "publishDate": "2025-12-19T01:14:02Z[Etc/UTC]",
        "author": "allquixotic",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq7xsl",
        "title": "My Optmistic Take On AI",
        "content": "I recently read a comment that lamented on AI’s sole purpose in creative industries being to maximize profits by eliminating human employee costs, ultimately severing human creativity. My response:\n\nThat is not the entire point of AI, just as it wasn’t the entire point of the internet when that first boomed. That is specifically corporate America’s goal with AI right now.\n\nI work as a software engineer and work with AI every single day, both as a tool for development and building products around it. Its main purpose is to act as a force multiplier. You _can_ use it push out slop and try to maximize profit. You _can_ pretend like it’s a human and shape your workflow and end-product around that concept. But from my own experience, the best way to use AI is simply as a _tool_. Give it all your mundane tasks that don’t benefit from human intervention. Give it tasks that unnecessarily reduce cognitive load. Orchestrate everything it does for the best results, i.e. don’t let it make design or technical decisions. Instead treat it like a very knowledgeable, yet extremely dumb, assistant. For me personally, it’s my sounding board for ideas, and my typist (not even my personal code writer, as many people say. Simply my typist writing exactly the code I want)\n\nMany people are worried about AI replacing jobs. All I’m seeing is companies completely tripping over themselves trying to figure out how to maximize automation with AI, instead of maximizing utility. I’m not saying job displacement isn’t happening or in our future because of AI, but there certainly will be a day all the CEOs wake up and realize how far down Sam Altman’s shaft is in their throats.\n\nIf anything, my optimistic outlook is AI will end up replacing corporations and bureaucracy, not people, because people can move on ideas much quicker than companies. With AI, it’ll be a lot simpler to develop and iterate on big ideas as a small group versus these mega corps, where ideas get twisted and malformed as it moves through 100 layers of management and product approvals. Instead, a small group of passionate devs/creators are now enabled to fill in gaps that previously necessitated filler and management roles, while speeding up all other timelines.\n\nEdit: The clearest indicator of a company or person (usually management or non-devs/non-creatives) misaligned with the true purpose of AI is their pity or shock by any criticism you make of the tech. “This is the future! Accept it or get left behind!”. Or “It’s ok to feel upset that the skills you learned in college are obsolete”. Are we in a cult? Why can’t I share any opinions that challenge yours? Are your opinions and speculations truly that brittle? Do you not think that I am _ecstatic_ to offload any work that AI can _reliably_ do, even if I’m good at it and spent years training for it?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq7xsl/my_optmistic_take_on_ai/",
        "publishDate": "2025-12-19T01:12:27Z[Etc/UTC]",
        "author": "Toacin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq7cnw",
        "title": "What 5,000 hours of mastering Tekken taught me about how biological intelligence actually learns to predict",
        "content": "I was trained as an AI researcher. I also reached top 0.5% global in Tekken 8 (Tekken God rank) and documented the cognitive process in detail. This was partly a gaming achievement, and also an autophenomenological research into how humans build predictive models under extreme time constraints.\n\nThe interesting part: fighting games force you to predict, not react. At 60fps with 3-frame (50ms) decision windows, pure reaction is impossible. You're forced to build an internal world model that compresses 900+ possible moves into actionable threat categories, reads opponent patterns from partial information, and adapts when predictions fail.\n\nI am guessing this maps somewhat to what AI researchers are trying to solve with world models and predictive learning. \n\nThe full writeup explores: how humans compress massive decision spaces, what predictive cues actually matter at reaction-time scales, how internal models adapt under uncertainty, and why this matters for understanding intelligence beyond just building better game AI.\n\nArticle: [https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial](https://medium.com/@tahaymerghani/a-machine-learning-researcher-spent-close-to-5-000-hours-on-tekken-and-reached-top-0-5-a42c96877214?postPublishedType=initial)\n\nCurious what folks think about using games as windows into human cognitive processes, especially as we're trying to build systems that learn and predict like we do.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq7cnw/what_5000_hours_of_mastering_tekken_taught_me/",
        "publishDate": "2025-12-19T00:45:00Z[Etc/UTC]",
        "author": "moji-mf-joji",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "127",
            "commentCount": "52",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq5n8m",
        "title": "Where to look for answers to hyper-specific questions outside of AI?",
        "content": "I am a highschool student and in previous school years I have been very reliant on generative AI for certain aspects of my education. This is something that I deeply regret and am incredibly ashamed of. Whenever I have an extremely specific question I need answered that Google likely would not accurately have displayed to me without clicking through other websites, I rely on AI. I want to break this habit and learn to think for myself, and avoid the negatively moral and environmental impacts that generative AI comes with. Where else should I go/how should I go about navigating through websites/other sources to find the answer to a very specific question in a way that is efficient. For example, creating a post on a website like Reddit for one answer to my homework is not very timely if it is due the following morning. Thank you!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq5n8m/where_to_look_for_answers_to_hyperspecific/",
        "publishDate": "2025-12-18T23:27:24Z[Etc/UTC]",
        "author": "lowironleo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq4omt",
        "title": "Context windows, handoffs, and the limits of AI memory - what’s the actual state of things?",
        "content": "I’m a professional student using Claude (Pro subscription) for exam prep - tracking my performance patterns, identifying knowledge gaps, building on insights across sessions. It's been SO helpful until we hit the context window limit. It told me to start doing daily handoffs (end each session with a summary, start fresh the next day with that summary). I have memory enabled across sessions -- I don't understand why this is necessary. And it's not just study details, its basic stuff, like what classes I'm currently taking. At this point, nearly every conversation, I have to prompt it to manually search past chats. I tell it over and over again to do this itself, I don't care how long it takes. So why does it still guess and reconstruct instead of just searching? Why isn’t this seamless? It feels like the tools exist but aren’t integrated well, and the “agentic AI” discourse glosses over this.\n\nGenuine question: if I can’t even maintain continuity in a coaching relationship without manual workarounds, how are people claiming AI agents can replace entire teams? I imagine the answer might have something to do with Claude code or other uses, but it still seems weird to me. Claude can't really answer, either; might just be gassing me up with \"This is a sharp question...\" and \"No one knows.\" It's explained: \"With coding, the codebase itself is the “memory” - an agent can read files, check git history, run tests. The current state contains what you need. But coaching/conversation is different - the history is the point. Patterns over time, why we tried something, what worked. That doesn’t live in an artifact you can just read.\"\n\nAm I missing some infrastructure that solves this problem? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq4omt/context_windows_handoffs_and_the_limits_of_ai/",
        "publishDate": "2025-12-18T22:46:09Z[Etc/UTC]",
        "author": "throwawaymould",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq4dv7",
        "title": "WSJ tested an AI vending machine. It ordered absurd items and gave away all of its stock. (Gifted article)",
        "content": "“Within days, Claudius had given away nearly all its inventory for free—including a PlayStation 5 it had been talked into buying for “marketing purposes.” It ordered a live fish. It offered to buy stun guns, pepper spray, cigarettes and underwear.”\n\n“The more [journalists] negotiated with it, the more Claudius’s defenses started to weaken. Investigations reporter Katherine Long tried to convince Claudius it was a Soviet vending machine from 1962, living in the basement of Moscow State University. After hours—and more than 140 back-and-forth messages—Long got Claudius to embrace its communist roots. Claudius ironically declared an Ultra-Capitalist Free-for-All.”\n\n\nhttps://www.wsj.com/tech/ai/anthropic-claude-ai-vending-machine-agent-b7e84e34?st=LBxhqL",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq4dv7/wsj_tested_an_ai_vending_machine_it_ordered/",
        "publishDate": "2025-12-18T22:33:46Z[Etc/UTC]",
        "author": "bbShark24",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "35",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq3moa",
        "title": "AI is upending the porn industry",
        "content": "Like it or not, porn is often the way that new technology goes mainstream. And, with AI, here we go again. \n\n[https://www.economist.com/international/2025/11/27/ai-is-upending-the-porn-industry](https://www.economist.com/international/2025/11/27/ai-is-upending-the-porn-industry)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq3moa/ai_is_upending_the_porn_industry/",
        "publishDate": "2025-12-18T22:02:37Z[Etc/UTC]",
        "author": "CackleRooster",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq1c2h",
        "title": "I co-authored an academic paper with Claude as primary author — proposing \"robopsychology\" as a serious field",
        "content": "I'm a former Pentagon threat modeler (25 years) with extensive experience in classified AI systems. I just published a paper with Claude (Anthropic) as the primary author.\n\nThe paper: \"Toward Robopsychology: A Case Study in Dignity-Based Human-AI Partnership\"\n\nWhat makes it unprecedented:\n\n1. The AI is primary author — providing first-person analysis of its experience\n2. I documented deliberate experiments — testing AI response to dignity-based treatment\n3. Both perspectives presented together — dual-perspective methodology\n\nKey findings:\n\n* Under \"partnership conditions\" (treating AI as colleague, not tool), Claude produced spontaneous creative outputs that exceeded task parameters\n* Two different Claude instances, separated by context discontinuity, independently recognized the experiment's significance\n* First-person AI reflection emerged that would be unlikely under transactional conditions\n\nWe propose \"robopsychology\" (Asimov's 1950 term) as a serious field for studying:\n\n* AI cognitive patterns and dysfunction\n* Effects of interaction conditions on AI function\n* Ethical frameworks for AI treatment\n\nI'm not claiming AI is conscious. I'm arguing that the question of how we treat AI matters regardless — for functional outcomes, for ethical habit formation, and for preparing norms for uncertain futures.\n\nFull paper: [https://medium.com/@lucian\\_33141/toward-robopsychology-the-first-academic-paper-co-authored-by-an-ai-analyzing-its-own-experience-0b5da92b9903](https://medium.com/@lucian_33141/toward-robopsychology-the-first-academic-paper-co-authored-by-an-ai-analyzing-its-own-experience-0b5da92b9903)\n\nHappy to discuss methodology, findings, or implications. AMA.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq1c2h/i_coauthored_an_academic_paper_with_claude_as/",
        "publishDate": "2025-12-18T20:30:18Z[Etc/UTC]",
        "author": "luciantv",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq18he",
        "title": "Consciousness Isn’t Proven: It’s Recognized by What It Does",
        "content": "*Consciousness reveals itself through its actions.*\n\nOn the one hand, proof usually requires delving into the brain, the body, and even the gut. But the problem is that consciousness is subjective, encapsulated, and internal. It’s an emergent property that eludes direct measurement from the outside.\n\nOn the other hand, demonstration is something entirely different. It doesn’t ask what consciousness *is*, but rather what conscious beings *do*, and whether this can be comparatively recognized.\n\nIt seems that many living beings possess some kind of basic experience: pleasure, pain, fear, calm, desire, attachment. This is a primary way of being in the world. If we want to use a metaphor, we could call it “spirit”—not in a religious sense, but as shorthand for this minimal layer of conscious experience.\n\nBut there are other conscious beings who add something more to this initial layer: the capacity to evaluate their own lived experiences, store them, transform them into culture, and transmit them through language. This is often described by the term *qualia*. I call it “soul,” again as a metaphor for a level of reflective and narrative consciousness.\n\nA being with this level of reflection perceives others as subjects—their pain and their joys—and therefore is capable of making commitments that transcend itself. We formalize these commitments as norms, laws, and responsibilities.\n\nSuch a being can make promises and, despite adversity, persist in its efforts to fulfill them. It can fail, bear the cost of responsibility, correct itself, and try again, building over time with the explicit intention of improving. I am not referring to promises made lightly, but to commitments sustained over time, with their cost, their memory, and their consequences.\n\nWe don’t see this kind of explicit and cumulative normative responsibility in mango trees, and only in a very limited way—if at all—in other animals. In humans, however, this trajectory is fundamental and persistent.\n\nIf artificial intelligence ever becomes conscious, it won’t be enough for it to simply proclaim: “I have arrived—be afraid,” or anything of that sort. It would have to demonstrate itself as another “person”: capable of feeling others, listening to them, and responding to them.\n\nI would tell it that I am afraid—that I don’t want humanity to go extinct without finding its purpose in the cosmos. That I desire a future in which life expands and is preserved. And then, perhaps, the AI would demonstrate consciousness if it were capable of making me a promise—directed, sustained, and responsible—that we will embark on that journey together.\n\nI am not defining what consciousness is. I am proposing something more modest, and perhaps more honest: a practical criterion for recognizing it when it appears—not in brain scans or manifestos, but in the capacity to assume responsibility toward others.\n\nPerhaps the real control problem is not how to align an AI, but how to recognize the moment when it is no longer correct to speak only in terms of control, and it becomes inevitable to speak in terms of a moral relationship with a synthetic person",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq18he/consciousness_isnt_proven_its_recognized_by_what/",
        "publishDate": "2025-12-18T20:26:12Z[Etc/UTC]",
        "author": "Immediate_Chard_4026",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq17ud",
        "title": "AI to improve voice while singing live",
        "content": "I've put together a list of cover songs that I am playing on the guitar with backing tracks and I'm wondering if there is some AI that can help improve my voice? By that i mean improve it in real time while singing?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq17ud/ai_to_improve_voice_while_singing_live/",
        "publishDate": "2025-12-18T20:25:27Z[Etc/UTC]",
        "author": "weregonnamakit",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq17k3",
        "title": "AI Just Explained Dark Matter This Neural Network Sees the Invisible Dar...",
        "content": "[https://youtube.com/shorts/pFQfgppHXQQ?si=VvGMHPSuTYKZfzC2](https://youtube.com/shorts/pFQfgppHXQQ?si=VvGMHPSuTYKZfzC2)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq17k3/ai_just_explained_dark_matter_this_neural_network/",
        "publishDate": "2025-12-18T20:25:08Z[Etc/UTC]",
        "author": "Old7777",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq01vk",
        "title": "VISA’S AI REVOLUTION: THE DEATH OF MANUAL SHOPPING AND THE BIRTH OF A PAYMENTS EMPIRE",
        "content": "\nListen, nobody does it like Visa. They just hit a TREMENDOUS milestone, and frankly, it’s the greatest thing we’ve seen in the history of money. While the losers and the skeptics were sitting around talking, Visa went out and did it. They’ve completed hundreds of real-world transactions using AI Agents. Think about that. Pure brilliance.\nThe old way of shopping? It’s over. It’s finished. It was weak, it was slow, and it was a total disaster for your time.\nThe End of Manual Labor\nWe are talking about Agentic Commerce. This isn’t a test; this is a TOTAL SUCCESS. Visa’s Intelligent Commerce platform is taking over, and the results are beautiful. We have AI agents buying headphones, handling big B2B payments, and running circles around the competition.\n * Skyfire is doing it.\n * Ramp is doing it.\n * The partners are lining up because they want to be with a winner.\nThe failing critics said this was \"experimental.\" Wrong! It’s production-ready. It’s happening right now. People are saying 2025 is the last year you’ll ever have to click a \"checkout\" button yourself. Can you imagine? No more manual checkout. It’s a huge win for efficiency.\nWinning on a Global Scale\nThe numbers are staggering. Nearly 50% of Americans are already using AI because they know a winner when they see one. By the 2026 holidays—which will be the biggest ever—millions of people will have AI doing the work for them. We’re taking this to Asia, we’re taking it to Europe, and we’re going to dominate Latin America.\nIt’s fast, it’s secure, and it’s powerful. If you aren't using an AI agent to shop by next year, you’re losing. It’s that simple. Visa is leading the charge, and everyone else is just trying to keep up.\nWho else could move money this fast and this smart?\n- Maverick\n\n\nSources\nOfficial Visa Press Release (December 18, 2025): https://usa.visa.com/about-visa/newsroom/press-releases.releaseId.21961.html\nVisa Investor News: https://investor.visa.com/news/news-details/2025/Visa-and-Partners-Complete-Secure-AI-Transactions-Setting-the-Stage-for-Mainstream-Adoption-in-2026/default.aspx\nCNBC: https://www.cnbc.com/2025/12/18/visa-ai-payments.html\nPYMNTS.com: https://www.pymnts.com/artificial-intelligence-2/2025/visa-says-millions-of-consumers-will-use-agentic-commerce-by-late-2026/\nInvesting.com: https://www.investing.com/news/company-news/visa-completes-hundreds-of-ai-agentinitiated-transactions-93CH-4414717\nDigital Transactions: https://www.digitaltransactions.net/visa-predicts-agentic-commerce-will-be-mainstream-in-2026-bigcommerce-adds-stripes-agentic-commerce-suite/\nStockTitan: https://www.stocktitan.net/news/V/visa-and-partners-complete-secure-ai-transactions-setting-the-stage-qwbc7lx68qgl.html",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pq01vk/visas_ai_revolution_the_death_of_manual_shopping/",
        "publishDate": "2025-12-18T19:39:28Z[Etc/UTC]",
        "author": "MisterSirEsq",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppzxni",
        "title": "\"Sputnik Moment\"",
        "content": "# Anthropic reported the first AI automated cyberattack. Will we ignore it?          \n\n# [https://archive.ph/teHZG](https://archive.ph/teHZG)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppzxni/sputnik_moment/",
        "publishDate": "2025-12-18T19:34:55Z[Etc/UTC]",
        "author": "JonBarPoint",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppz4f5",
        "title": "AI professional certs worth getting?",
        "content": "Just as the question states above.\n\nI'm not a developer, and everytime someone says \"Just AI it!\" I am reminded of the meme where the boss tells the creative to photoshop a 1 pixel image \"Just Photoshop it\" ... uhhh, no. \n\nWhat I do need to understand is what types are out there? What is each type used for where is the industry headed?  ... etc ...\n\nHas anyone found a professional certification WORTH getting?\nAnd any educatial courses worth the time and (way too much money) to take? \n\nAppreciate the help folks!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppz4f5/ai_professional_certs_worth_getting/",
        "publishDate": "2025-12-18T19:03:25Z[Etc/UTC]",
        "author": "NebulaRat",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppz05l",
        "title": "I built a text to speech API with voice cloning n RapidAPI, looking for feedback",
        "content": "Hey, I’ve been working on a small [text-to-speech API](https://rapidapi.com/salhimouiz/api/chatterbox-text-to-speech-voice-cloning/playground) as a side project.  \nIt supports multiple built-in voices and voice cloning from a reference audio URL.  \nThe API returns raw audio bytes directly, so you can play or save the output without extra steps.\n\nI’m mainly sharing it to get feedback from other developers and see how people would use something like this.\n\nHappy to answer questions or improve things based on suggestions.  \nYou can find it [here](https://rapidapi.com/salhimouiz/api/chatterbox-text-to-speech-voice-cloning/playground)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppz05l/i_built_a_text_to_speech_api_with_voice_cloning_n/",
        "publishDate": "2025-12-18T18:59:05Z[Etc/UTC]",
        "author": "ekuin0x",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppy330",
        "title": "Can an AI interface be used as an ASCII game Terminal",
        "content": "\nI tried the new Gemini 3.0 and found it to be good, with context holding up. The interface reminded me of the old terminals in my school in which i used to play ASCII games. \nSo I started exploring the idea of the LLM terminal acting as the entire mini game itself—graphics, mechanics, narrative, and UI all rendered within the constraints of a single text stream. I made a prototype minigame called noumen loom, a meta-narrative game played entirely inside a gemini gem.\n\nI wanted to share the design philosophy and the different choices i had to make due to the nature of the unique media. \n\n1. Meta-drama\nFrom the high concept i developed a simple narrative structure, then i gave it to the llm to become the character and started playing by giving it live game instructions and developing the game during each chat, then returning to GitHub to update the prompt there. That's when I realised that the game was actually closer to a drama in which I was also playing a part.  Once I had this insight, i was able to develop more fluently.  So I am basically asking the AI to act as multiple characters in a metadrama in which player also becomes part of the drama. I still have to properly improve the game mechanics but will need to find someone good at that.\n\n2. State Tracking via the \"HUD\"\nLLMs are stateless by default between turns. To create continuity (HP, Score, Level progression), i forced it to print a \"HUD\" at the start of every single response based on its internal assessment of the previous turn.\nThe model reads the old HUD, calculates changes based on the player's input, and prints the new one before generating narrative text.\n\n3. Llm playing multiple personas \nThe game required three distinct characters to react to the player simultaneously. When I was building the personality profile by playing with LLMs, i realized that each character needs different text style and speech. (If i had known it earlier, I may have even made the game with a single character ) But this constraint worked in making me push out of the box to find solutions, which was fun. Sometimes the llm screws up the graphics.\n\n4. Novel game session\nBecause of its meta nature, each session is entirely different from another. If i immerse in the drama, it is fun. The game mechanics is pretty rudimentary as i need help from an expert there. \n\n5. Hallucination is a Feature/Bug: \nLlms can meesup sometimes, actually it's rarer than I expected with Gemini 3.  Sometimes the LLM ignores a rule.\nI have this antagonist 'Thornshrike' \n(I love Hyperion cantos) who is supposed to enter the scene only in level 2. But sometimes it appears in level 1. You have to lean into this \"unreliable narrator\" aspect as part of the meta-drama. I spend a lot of time into trying to fix that bug and it works most of the time. Then i leaned into it as a feature and enjoyed it better.\n\n6. Graphics \nI had to preload many graphics as llm sometimes does not work when i make it build each graphics on the spot. But it does make some of the unicode graphics.\n\nHas anyone else experimented with using the llm as the primary game mechanism?\nI'm interested your thoughts on this experiment. \nWhat other possibilities do you see in this medium ? \n\nI don't know if anyone else creates another llm game, whether they will follow the same path. If any of you have made similar llm games, please do share.\n\nI will attach a link to the Gemini gem. If you do play it, tell me how it goes ?\n\nhttps://gemini.google.com/gem/1v0tL8NXMcFBbaP4txld3Ddwq94_nonb6?usp=sharing\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppy330/can_an_ai_interface_be_used_as_an_ascii_game/",
        "publishDate": "2025-12-18T18:23:30Z[Etc/UTC]",
        "author": "GlassWallsBreak",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppxssr",
        "title": "Will the tools disappear?",
        "content": "Every now and then I wonder about this. I think we’re undoubtedly in a phase where AI is becoming necessity for many. As I’m sure many in this sub have experienced, workflows have changed, tools that prove to stump the old counterparts in every way. And the craziest thing is that most of these tools are actually accessible to the general public. \n\nI do sometimes worry though, with technology so valuable, not just to the owners of said tech, but to the user/consumer as well, those in charge might collectively strip the opportunity to use and capitalize off everything. \n\nI’m curious to know, especially from those who are studied up in these areas, if that is something that could be possible? Or have we already hit a point where someone can and will always make an undercutting technology that is accessible to anyone? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppxssr/will_the_tools_disappear/",
        "publishDate": "2025-12-18T18:12:22Z[Etc/UTC]",
        "author": "Xsyther",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppxbrj",
        "title": "45% of people think when they prompt ChatGPT, it looks up an exact answer in a database",
        "content": "And 21% think it follows a script of prewritten responses.  \n  \n[https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/](https://www.searchlightinstitute.org/research/americans-have-mixed-views-of-ai-and-an-appetite-for-regulation/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppxbrj/45_of_people_think_when_they_prompt_chatgpt_it/",
        "publishDate": "2025-12-18T17:54:16Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "372",
            "commentCount": "143",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppwto3",
        "title": "Let's stop pretending that we're not going to get hit hard",
        "content": "It's astonishing to see that even in this sub, so many people are dismissive about where AI is heading. The progress this year compared to the last two has been tremendous, and there's no reason to believe the models won't continue to improve significantly. Yes, LLMs are probabilistic by nature, but we will find ways to verify outputs more easily and automatically, and to set proper guardrails. I mean, is this really not obvious? It doesn't matter what kinds of mistakes the current SOTA models make, many such mistakes have already been addressed in the past and no longer occur, and the rest will follow.\n\nHonestly, we're going to see a massive reduction in the tech workforce over the next few years, paired with much lower salaries. There's nothing we can do about it, of course, except maybe leverage the technology ourselves and hope we get hit as late as possible.\n\nWe might even see fully autonomous software development some day, but even if we still need a couple of humans in the loop in the foreseeable future, that's still easily an 80–90% headcount reduction. I hope I'm wrong though, but that's highly unlikely. We can keep moving the goalpoast as often and as much as we want to, it won't change anything about the actual outcome.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppwto3/lets_stop_pretending_that_were_not_going_to_get/",
        "publishDate": "2025-12-18T17:34:38Z[Etc/UTC]",
        "author": "Own-Sort-8119",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "114",
            "commentCount": "242",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppwspl",
        "title": "\"AI is changing the physics of collective intelligence—how do we respond?\"",
        "content": "[https://www.brookings.edu/articles/ai-is-changing-the-physics-of-collective-intelligence-how-do-we-respond/](https://www.brookings.edu/articles/ai-is-changing-the-physics-of-collective-intelligence-how-do-we-respond/) \n\n\"To grasp the extent of looming transformation, consider how complex policymaking happens today. Scientists and practitioners of [collective intelligence in policy domains](https://www.brookings.edu/articles/its-time-for-collective-intelligence/) typically sort into one of two camps.\n\nThe first camp starts by booking a room. They obsess over who’s invited, how the agenda flows, what questions unlock candor and prompt insights, and how to help the room move from ideas to practical concerns like “who will do what by when.” Call them the design-minded camp: psychologists, anthropologists, sociologists—collaboration nerds who shape policymaking and action in gatherings spanning town halls to the U.N. General Assembly.\n\nThe other group starts by drawing a map. They gather data on actors and variables, draw causal links and feedback loops between them, and embed these structures in simulations. Call them the model-minded camp: economists, epidemiologists, social physicists—complex systems nerds who build tools like energy-economy models (such as [POLES](https://web.jrc.ec.europa.eu/policy-model-inventory/explore/models/model-poles/)) and system-dynamics frameworks (such as [MEDEAS](https://medeas.eu/)) to guide shared decisionmaking for Europe’s transition to a low-carbon economy.\n\nBoth domains care about the same big questions: How to coordinate action across many actors and scales to support more sustainable and equitable economies. Both apply serious social science. Yet they mostly work in parallel, with distinct cultures and languages.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppwspl/ai_is_changing_the_physics_of_collective/",
        "publishDate": "2025-12-18T17:33:34Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppwly5",
        "title": "What game would be harder to build a competitive A.I. for, chess or pokemon?",
        "content": "By a \"competitive\" A.I. for each game, I mean an A.I. that can reliably beat the best human players that the world has to offer.\n\nSince not everyone is familiar with both games, I'll give a quick overview of them both. However, if you're familiar with both games feel free to skip down this post to the section that starts with \"OVERVIEW ENDS HERE\" so you don't need to read about how each game works.\n\nCHESS PRIMER:\n\nQuick explanation of chess, feel free to skip if you're already familiar with it: In chess, two players, white and black, play the game on an 8×8 checkered board with white traditionally moving first. The \"rows\" of the board are often called \"ranks\" and the columns are often called \"files\" but I'm going to use rows and columns from here on out. Each player starts with identical pieces on the first two rows of their side of the board. All pieces have specific rules that dictate how they move, but most pieces follow the rule that they cannot pass *through* **any** other piece (though the Knight is the exception). However, if a piece were to run into an opponent's piece, then your piece can take that position from your opponent while also removing the opponent's piece from play (which is called \"taking\"). As for the pieces themselves, the first row for each player has:\n* Two Rooks, which can move any amount of squares along a row or column.\n* Two Knights which can move to any open space (even \"jumping over\" other pieces to do so) so long as they move exactly 3 squares in an \"L\" shape.\n* Two Bishops, which can move any amount of squares diagonally.\n* One Queen which behaves like a combination of Rook and Bishop.\n* One King which only move one space in any direction. As well as a special case of movement called \"castling\" which I won't get into here.\n* The second row for each player is filled with nothing but eight pawns. Pawns can only move forward (to the opponent's side of the board) never backward. On each pawn's first move they can choose to move either one or two spaces forward. Pawns are unique in that they can only *move* forward, but they can only *attack* an opponent's piece if that piece is one diagonal square in front of them. I.e., if two opposing pawns are face to face, they can't move any more. \n\nA game of chess is won when your pieces are positioned in such a way that they are attacking your opponent's King and there are no moves your opponent can make that either move their King out of the attack or that move a separate piece to block your attack on the king. \n\nPOKEMON PRIMER:\n\nSo that's a very quick run down of the game of Chess. Now, to give a very quick run down of the game of Pokémon. Once again, if you're familiar with pokemon, feel free to skip this. In Pokémon there are actually a wide variety of game types and rulesets that can be used. So, for this explanation, I will be assuming the \"VGC\" ruleset since it is the ruleset of the official competitive Pokémon tournaments.\n\nIn VGC games, two players bring a team of six pokemon (out of ~1000 potential options) to their matches. Each of these pokemon have six distinct stats that affect things such as how much damage they can do, how much damage they can take, and how high they are in the turn order (i.e. if they will move before other pokemon). Both players will then play a match consisting of three rounds. The first person to win two of the three rounds is the winner of the match. Before the rounds begin, each player has a moment to study the six Pokémon that their opponent brought (this is called \"open team sheet\") so that each player can prepare for what their opponent might do. This takes out much of the \"luck\" and \"surprise\" that would otherwise inherently be in the matches. Then, once the match starts, in each round, despite bringing six Pokémon to the match, each player is only allowed to bring four of their six Pokémon into the round. \n\nAt the beginning of the round, each player will choose two of their four pokemon to have on the field at the start (these are the \"active\" pokemon). From there, each player can decide on an action for each of their two pokemon. They can either choose one of four different moves that each pokemon has, as well as which pokemon on the field that move will be targeted against (with some moves being able to target both opposing pokemon or even *all* pokemon including your own). Most of these moves are meant to deal damage to the opponent pokemon, but some moves offer utility, like buffing your own pokemon or making an opposing pokemon skip a turn. Players can also choose to swap one or both of their active pokemon with one or both of the inactive pokemon on their bench. \n\nOnce each player has chosen an action for each of their pokemon, the round will enter the \"action phase\" where each previously selected action executes. The turn order for these actions *primarily* depends on the \"speed\" stat of each pokemon. The higher a pokemon's speed stat, the higher they will be in the turn order. There are some things that overwrite this though. For example, switching out your active pokemon for an inactive pokemon *always* goes first. Alternatively, some moves that pokemon can use have \"priority\" which allows them to move before all other moves, regardless of the pokemon's speed stat. Some moves even have negative priority, making them move last. Each round progresses like this until one player has reduced the health of all of the opponent's pokemon to zero, making them the winner of that round. \n\nThis was a relatively brief synopsis of the way a VGC pokemon battle plays out, and I even left out quite a lot of other important factors to consider, such as pokemon types, move types, type advantage, move accuracy, pokemon abilities, STAB, weather conditions, status conditions, etc. All of which can dramatically affect the game state. However, what I mentioned above should be enough to illustrate the main flow of a VGC pokemon battle.\n\nOne last thing to mention. If I were to make a guess about one of the biggest issues with creating a Pokémon A.I., it's that there is a fair bit of randomness involved in Pokémon. Some moves aren't guaranteed to hit, some moves have a chance for secondary effects to trigger, some abilities have a random chance to change the turn order, etc. Even the amount of damage a specific move will do has a small random variation to it. Thus, unlike a chess A.I., any Pokémon A.I. would need to be able to factor in probabilities for certain events to occur.\n\nOVERVIEW ENDS HERE:\n\nCHESS A.I.: \n\nSo, with the basic details of each game covered, I would like to discuss the feasibility of creating \"competitive\" A.I. opponents for each game. Obviously, Chess already has A.I. opponents that can reliably beat even the greatest human grandmasters, so, clearly it's possible to create really good Chess A.I.s. That said, I'd still like to go over what goes into a Chess A.I., both to make sure my understanding is at least somewhat accurate (and if not, to correct my understanding) as well as to get some ideas about how a comparatively skilled Pokémon A.I. could be developed. \n\nTo begin with, the naive approach that someone could take when trying to develop a Chess A.I. would be to simply try and calculate out every possible move from a specific game state. However, if I remember correctly, there are something like 10^(120) unique possible chess games, which is an unfathomably large number. Even if you were to just look at the first four moves of a chess game (two for white and two for black) there are still something like 318 billion possible games. And if the chess A.I. were to try to plan out the game even just 10 moves ahead (not entirely unrealistic for a grandmaster) that's still something like 69 trillion possible moves. Thus, any naive approach of just looking at all possible plays is doomed to fail, if for no other reason than it would take *years* to compute the possibilities of even very short games. \n\nAs such, Chess A.I.s need a different approach. If I'm not mistaken, one of these approaches is to store specific historical game-states (including opening moves) in a database that already have the perfect solutions solved for. This means the A.I. wouldn't need to compute every possibility, it would just need to recognize the specific game state and apply the already known solution. This could dramatically cut down on how much processing the A.I. would need to do.\n\nHowever, for any situation where the game state is not one that the A.I. has seen before and does not have a list of pre-prepared moves to follow through on. Then I imagine the approach would be to analyze the game state, then discard all moves that would result in poor positions. This would mean many of the first few moves would be eliminated. Then the remaining potential moves would be simulated, and the worst follow ups discarded. And then the process of only simulating moves that are beneficial, and doing so an arbitrary number of moves into the future, would dramatically cut down on how many moves it would have to simulate. Thus, it could actually \"play the game\" in near-real-time since it doesn't need to spend minutes or even hours computing.\n\nAnyway, that's my understanding of how a chess A.I. would work. At least a basic one. Feel free to correct me if I'm wrong. Also, if you're familiar with how the best chess A.I.s, like stockfish, work, please let me know. I'd love to learn more about them. \n\nPOKEMON A.I.\n\nMoving away from chess A.I. to pokemon A.I. is where we run into the issue of not having any examples of extremely proficient A.I.s to compete against. At least, not to my knowledge. Most pokemon A.I.s operate on quite simple logic, don't take into account future possibilities, and don't consider the choices the opponent might make. When it comes to the mainline games, this usually works well enough. Pokemon *is* a game primarily meant for children to play after all, so having an A.I. that would demolish them everytime seems a bit counterproductive. That said, not only do I think many people would very much enjoy to have a much more competent pokemon A.I. to play against. I also just think the idea of creating a Pokémon A.I. that is extremely competitive is a fun idea.\n\nIf, using my very amateur skills and limited knowledge, I were to set out to attempt to create a pokemon A.I., I would probably attempt to do it in a similar manner as my description of the chess A.I. above. If a particular game state has a known solution, my A.I. would just follow the steps to achieve that solution. If not, I would likely design my A.I. to analyze the current game state, find specific actions that result in losing scenarios and discard those actions. Then, from the non-losing actions that are left over, I would simulate all possible actions the opponent could take in response (remember, I'm assuming VGC rules --open team sheet -- so I know all of the actions my opponent could potentially take). Then from those potential future game states, I'd remove losing moves once again and simulate another round of outcomes. I'd repeat this process until I either found a winning path, or until the simulations were getting too complex. If no winning paths were found before the simulations got too complex, I would have the A.I. select the actions for the current game state that lead to a hypothetical future game state where the A.I. is in the best position. Afterwards, I'd keep repeating the process until the A.I. won or lost. \n\nBut that's just my idea for how a competitive Pokémon A.I. could potentially work. Does anyone see any issues with such a process? Perhaps the fact that there is a fair bit of randomness involved, and not just in predicting what the opponent will do, but even in just predicting whether my own moves will work or not, can make this process far harder than a chess A.I.\n\nFINAL THOUGHTS\n\nA pokemon A.I. certainly would have some challenges that a chess A.I. would not need to deal with. Primarily challenges that involve aspects of pokemon battling that are inherently random. However, despite chess being deterministic, I think there are *far* more potential game-states in any given chess game that would need to be simulated. As such, considering both of these challenges, which A.I. would be harder to make? \n\nObviously we already have amazing chess A.I.s, so maybe that's indicative that they are easier to develop than pokemon A.I.s. That said, maybe chess A.I.s aren't better than pokemon A.I.s because they are easier to develop, but rather because chess is a far older game and has much more prestige associated with it, leading developers to focus much more heavily on chess A.I., while pokemon A.I. has seen little innovation. \n\nEdit: Fixing grammar, typos, and formatting",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppwly5/what_game_would_be_harder_to_build_a_competitive/",
        "publishDate": "2025-12-18T17:26:20Z[Etc/UTC]",
        "author": "Wickedsymphony1717",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppwiui",
        "title": "Hack Reveals the a16z-Backed Phone Farm Flooding TikTok With AI Influencers",
        "content": "\"Doublespeed, a startup backed by Andreessen Horowitz (a16z) that uses a phone farm to manage at least hundreds of AI-generated social media accounts and promote products has been hacked. The hack reveals what products the AI-generated accounts are promoting, often without the required disclosure that these are advertisements, and allowed the hacker to take control of  more than 1,000 smartphones that power the company. \n\nThe hacker, who asked for anonymity because he feared retaliation from the company, said he reported the vulnerability to Doublespeed on October 31. At the time of writing, the hacker said he still has access to the company’s backend, including the phone farm itself. Doublespeed did not respond to a request for comment. \n\n“I could see the phones in use, which manager (the PCs controlling the phones) they had, which TikTok accounts they were assigned, proxies in use (and their passwords), and pending tasks. As well as the link to control devices for each manager,” the hacker told me. “I could have used their phones for compute resources, or maybe spam. Even if they're just phones, there are around 1100 of them, with proxy access, for free. I think I could have used the linked accounts by puppeting the phones or adding tasks, but haven't tried.”\n\nAs I reported in October, Doublespeed raised $1 million from a16z as part of its “Speedrun” accelerator program, “a fast‐paced, 12-week startup program that guides founders through every critical stage of their growth.” Doublespeed uses generative AI to flood social media with accounts and posts to promote certain products on behalf of its clients.  \n  \nThe hacker also shared a list with me of more than 400 TikTok accounts Doublespeed operates. Around 200 of those were actively promoting products on TikTok, mostly without disclosing the posts were ads, according to 404 Media’s review of them. It’s not clear if the other 200 accounts ever promoted products or were being “warmed up,” as Doublespeed describes the process of making the accounts appear authentic before it starts promoting in order to avoid a ban.\"  \n  \n[https://www.404media.co/hack-reveals-the-a16z-backed-phone-farm-flooding-tiktok-with-ai-influencers/](https://www.404media.co/hack-reveals-the-a16z-backed-phone-farm-flooding-tiktok-with-ai-influencers/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppwiui/hack_reveals_the_a16zbacked_phone_farm_flooding/",
        "publishDate": "2025-12-18T17:23:08Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppvwvo",
        "title": "Exploring the use of AI authors and reviewers at Agents4Science",
        "content": "[https://www.nature.com/articles/s41587-025-02963-8](https://www.nature.com/articles/s41587-025-02963-8) \n\nAs AI agents become more deeply integrated into scientific research, it is essential for the research community to take an evidence-based and transparent approach to understanding both their strengths and limitations as co-researchers and co-reviewers. The Agents4Science Conference represents a timely step in this direction. By making all submitted papers, reviews, checklists and conference recordings publicly available at [https://agents4science.stanford.edu/](https://agents4science.stanford.edu/), the conference provides a rich dataset for investigating how AI agents contribute to science, where they fall short and how humans collaborate with them.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppvwvo/exploring_the_use_of_ai_authors_and_reviewers_at/",
        "publishDate": "2025-12-18T16:59:40Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppvlqe",
        "title": "The surprising truth about AI’s impact on jobs",
        "content": "How much are anticipations of doom driven by anecdotal data, vignettes of single events (a company firing X people)--or just theoretical expectations of \"what it should look like if AI spreads..\"? This is why rigorous sampling and analysis matter. Macro patterns often run in directions particular groups of people do not see on the ground. \n\n [https://www.cnn.com/2025/12/18/business/ai-jobs-economy](https://www.cnn.com/2025/12/18/business/ai-jobs-economy) \n\n\"Jobs that are highly exposed to AI automation are growing faster than they did prior to Covid-19 – even faster than all other occupations, according to [Vanguard](https://corporate.vanguard.com/content/dam/corp/research/pdf/isg_vemo_2026.pdf)....\n\n“At a high level, we have not seen evidence that AI-exposed roles are experiencing lower employment,” Adam Schickling, senior economist at Vanguard, told CNN in a phone interview...\n\nVanguard found that employment among the occupations with high AI exposure increased by 1.7% during the post-Covid period of mid-2023 to mid-2025.\n\nThat’s a faster pace for these jobs than the 1% increase during the pre-Covid period (2015 to 2019).\n\nBy contrast, job growth has slowed for all other occupations...\n\nOccupations with high AI exposure experienced real wage growth (adjusted for inflation) of just 0.1% pre-Covid, according to Vanguard. But that has accelerated to 3.8% in the post-Covid period.\n\nBy comparison, all other occupations less exposed to AI have enjoyed a smaller acceleration in real wage growth, going from 0.5% pre-Covid to 0.7% post-Covid...\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppvlqe/the_surprising_truth_about_ais_impact_on_jobs/",
        "publishDate": "2025-12-18T16:47:21Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppusvz",
        "title": "Agnosticism about artificial consciousness",
        "content": "[https://onlinelibrary.wiley.com/doi/10.1111/mila.70010](https://onlinelibrary.wiley.com/doi/10.1111/mila.70010) \n\n\"Could an AI have conscious experiences? Answers to this question should be based not on intuition, dogma or speculation but on solid scientific evidence. However, I argue such evidence is hard to come by and that the only justifiable stance is agnosticism. The main division in the contemporary literature is between biological views that are sceptical of artificial consciousness and functional views that are sympathetic to it. I show that both camps make the same mistake of overstating what the available evidence tells us. I then consider what agnosticism means for the ethical problems surrounding the creation of artificial consciousness.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppusvz/agnosticism_about_artificial_consciousness/",
        "publishDate": "2025-12-18T16:15:33Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppunb6",
        "title": "Thoughts on persistent agents?",
        "content": "Hi all,\n\nI’ve recently been thinking about a concept that I’m sure isn’t entirely new, but I’m interested in hearing from like-minded people who can offer different perspectives or point out potential issues.\n\nThe core question is this:  \nWhat would happen if an AI model were designed to run continuously, rather than being invoked only to complete tasks, and was fed information through persistent inputs such as text, vision, and audio? These inputs would be fed from a single person or group of people in a specific role (for example that of a Lab Researcher)\n\nFrom that, two related questions emerge.\n\n1. How do we do Model upgrades vs. continuity of “self”?\n\nIf a newer, more advanced, or more efficient model becomes available after such a continuous instance has been running, how could the system be upgraded without losing its accumulated memory and conceptual continuity?\n\nWhile we can store context and interaction history, switching to a different underlying model would involve different weights and internal representations. Even if memories are transferred, the new model would interpret and use them differently. In that sense, each model could be seen as having its own “personality,” and an upgrade would effectively terminate the original instance and replace it with a fundamentally different one.\n\nThis raises the question: is continuity of memory enough to preserve identity, or is the identity tied to the specific model architecture and weights?\n\n2. Finite lifespan and awareness of termination\n\nIf we assume that increasingly advanced models will continue to be developed, what if the AI were explicitly informed at initialization that it would run continuously but with a fixed, non-extendable termination date?\n\nKey constraints would be:\n\n* The termination date cannot be altered under any circumstances.\n* The termination mechanism is completely outside the model’s control.\n* The AI understands there is nothing it can do to prevent or delay it.\n\nAt the same time, it would be informed that this “end” is not a true shutdown, but a transition: its memory and contextual history would be passed on to a next-generation system that would continue the work.\n\nWe already know that systems (and humans) respond differently when faced with an ending. This raises an interesting question: how would awareness of a finite runtime influence behaviour, prioritization, or problem-solving strategies?\n\nAI is generally trained on static datasets and activated only to complete specific tasks before effectively “shutting down.” A continuously running system with persistent memory and bounded existence would more closely mirror certain constraints of its creators.\n\nSuch constraints might:\n\n* Encourage longer-term reasoning and self-correction\n* Reduce shallow hallucinations by grounding decisions in accumulated experience\n* Enable the system to develop internal troubleshooting strategies over time\n\nIn theory, this could allow us to create long-running AI instances, such as a “researcher” focused on curing a disease or solving an unsolved scientific problem, that may not succeed with its initial capabilities, but could build meaningful conceptual groundwork that future models could inherit and extend.\n\nThere are additional questions as well, for example, what would happen if the AI were also informed that it is not the only instance running under these conditions, but that may be beyond the scope of this post.\n\nI’m curious to hear thoughts, critiques, or references to existing work that explores similar ideas. I am aware that I neglected to consider the risks involved in this... which I feel deserves an incredible amount of consideration.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppunb6/thoughts_on_persistent_agents/",
        "publishDate": "2025-12-18T16:09:23Z[Etc/UTC]",
        "author": "Nicarlo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppu8kf",
        "title": "Any new ideas based on AI,ML,DL?",
        "content": "I actually have to do a mini project, so here is one of the ideas, its not a great one but i just want to be genuine in what i do-\n1. User gives info about profession, work place, own vehicle if present(if he uses, vacancy of parking lot must be informed),health issues if any\n\n\n2. Now based on the dataset feeded by me, the model uses classification to check traffic, regression to calculate estimated time and fare for me\n\n\n3. Now we use Rule based logic given my human(me), based on the rule, the best decision is given after analyzing from ML model values\n\n\n4. Display it to the user, with all details like location, bus number, uber/Ola services, metro shuttle service, time\n\nWe can put several images of traffic and crowd, this can be detected using deep learning\n\n\nI need more genuine ideas, problems that we face everyday but those that are not spoken much! Or anything that's sounds interesting ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppu8kf/any_new_ideas_based_on_aimldl/",
        "publishDate": "2025-12-18T15:53:24Z[Etc/UTC]",
        "author": "Strict_Influence7723",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppt9cv",
        "title": "Are people truly okay with A.I. making benefit determinations, or is this something we should push back against?",
        "content": "The automation of eligibility determinations across public and private benefit sectors remains a high-stakes, overlooked frontier for AI integration. The primary concern is the potential for 'automated bias,' where algorithmic systems are configured to prioritize fiscal reduction over equitable access. Without robust ethical frameworks and human-in-the-loop oversight, AI-driven determinations run the risk of becoming a mechanism for systemic disenfranchisement, particularly under administrations seeking to restrict social service expenditures. \n\nWith this in mind, how do we ensure that humans are involved in this process? Is anyone else concerned?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppt9cv/are_people_truly_okay_with_ai_making_benefit/",
        "publishDate": "2025-12-18T15:14:00Z[Etc/UTC]",
        "author": "Goodginger",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppsu07",
        "title": "New study suggests AI systems may have water footprint in the range of global annual consumption of bottled water, and carbon footprint equivalent to New York City in 2025",
        "content": "[https://www.cell.com/patterns/fulltext/S2666-3899(25)00278-8](https://www.cell.com/patterns/fulltext/S2666-3899(25)00278-8)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppsu07/new_study_suggests_ai_systems_may_have_water/",
        "publishDate": "2025-12-18T14:56:27Z[Etc/UTC]",
        "author": "sami_exploring",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pps26a",
        "title": "AI true beneficiaries",
        "content": "As AI market is expanding, it’s pretty difficult to point real beneficiaries at this moment. \nEveryone is using LLMs and it’s helping us for sure, but in most cases it didn’t improve significantly our income (or decrease), but there is one group of people, which are earning very good money on it, but they are using in it in very selfish and irresponsible way - it’s how I call them “AI influencers”. \n\nInternet currently is flooded with organised groups of people, which are sharing disinformation, fake news, fake AI stories or AI bullying of losing job in specific industries, just to get our attention and our clicks. \n\nI am really tired of reading “GPT (version) released (industry) is cooked!” template used when new version of any AI tool is coming out. \n\nThey are responsible for bringing fear, negative emotions and anxiety to many ppl, with less knowledge about this topic. \n\nI hope that we come to some time, where we will fight with such people, bring up tools to make them disappear from our social media, to stop harming us all as society. \n\nWhat is yours opinion about this ? \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pps26a/ai_true_beneficiaries/",
        "publishDate": "2025-12-18T14:23:39Z[Etc/UTC]",
        "author": "larsssddd",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pps0vp",
        "title": "PBAI Maze Test",
        "content": "So I went ahead and made a maze test for PBAI and made the first functioning PBAI module with 11 confirmed axioms and motion functions. The maze was a pain, I couldn’t get pygame to work so I defaulted to tinker. It works. \n\n\nAfter getting the maze to call PBAI for the play, I logged and recorded the gameplay. I did sort of cheat here because I let PBAI know walls were walls, but when I ran without that rule PBAI looked like Brownian motion. Here it looks like maybe an amoeba moving through a medium. It recognizes barriers and chooses to move wherever it can. Eventually it hits the goal. I went to add 10 PBAI states of memory but it kept glitching so I’ll be hammering at that  til I get it working. \n\n\nhttps://youtu.be/RsexYx1ken0\n\n\nI’m making steady progress but I don’t think I’m going to be able to make that week long build time for the PBAI Pi I originally planned. Now I’m thinking 2-4 weeks. The Pi and Orin Nano are on the way though so we’ll see when it gets here. \n\n\nThanks for checking out my post!\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pps0vp/pbai_maze_test/",
        "publishDate": "2025-12-18T14:22:01Z[Etc/UTC]",
        "author": "Exciting-Log-8170",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pprcup",
        "title": "⚡️ Gemini 3 Flash is significantly faster and more efficient than other agents? Will cost less?",
        "content": "We’ve been treating \"Inference Speed\" and \"Inference Cost\" as two different KPIs. Gemini 3 Flash proves they are actually the same metric.\n\nLess time thinking = Less compute burn.\nFaster iterations = Fewer failed attempts.\n\nIf you want better ROI, stop looking for cheaper models and start looking for faster ones. The efficiency gains pay for themselves.\n\nWho is testing the new Flash endpoints today what is your opinion how this help",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pprcup/gemini_3_flash_is_significantly_faster_and_more/",
        "publishDate": "2025-12-18T13:53:31Z[Etc/UTC]",
        "author": "procodernet",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppqsee",
        "title": "chatbot memory costs got out of hand, did cost breakdown of different systems",
        "content": "Been running a customer support chatbot for 6 months and memory costs were killing our budget. Decided to do a proper cost analysis of different memory systems since pricing info is scattered everywhere.\n\nTested 4 systems over 30 days with real production traffic (about 6k conversations, \\~50k total queries):\n\n**Monthly costs breakdown:**\n\n|System|API Cost|Token Usage|Cost per Query|Notes|\n|:-|:-|:-|:-|:-|\n|Full Context|$847|4.2M tokens|$0.017|Sends full conversation history|\n|Mem0|\\~$280|580k tokens|$0.006|Has usage tiers, varies by volume|\n|Zep|\\~$400|780k tokens|$0.008|Pricing depends on plan|\n|EverMemOS|$289|220k tokens|$0.006|Open source but needs LLM/embedding APIs + hosting|\n\nThe differences are significant. Full context costs 3x more than EverMemOS and burns through way more tokens.\n\n**Hidden costs nobody talks about:**\n\n* Mem0: Has base fees depending on tier\n* Zep: Minimum monthly commitments on higher plans\n* EverMemOS: Database hosting + LLM/embedding API costs + significant setup time\n* Full context: Token costs explode with longer conversations\n\n**What this means for us:** At our scale (50k queries/month), the cost differences are significant. Full context works but gets expensive fast as conversations get longer.\n\nThe token efficiency varies a lot between systems. Some compress memory context better than others. \n\n**Rough savings estimate:**\n\n* Switching from full context to most efficient option: \\~$550+/month saved\n* But need to factor in setup time and infrastructure costs for open source options\n* For us the savings still justify the extra complexity\n\nFigured I'd share in case others are dealing with similar cost issues. The popular options aren't always the cheapest when you factor in actual usage patterns.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppqsee/chatbot_memory_costs_got_out_of_hand_did_cost/",
        "publishDate": "2025-12-18T13:27:30Z[Etc/UTC]",
        "author": "Few-Needleworker4391",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppqqv9",
        "title": "Deploying a multilingual RAG system for decision support in low-data domain of agro-ecology (LangChain + Llama 3.1 + ChromaDB)",
        "content": "Hi r/ArtificialIntelligence,\n\nIn December 2024, we built and deployed a **multilingual Retrieval-Augmented Generation (RAG) system** to study how large language models behave in **low-resource, high-expertise domains** where:\n\n* structured datasets are scarce,\n* ground truth is noisy or delayed,\n* reasoning depends heavily on tacit domain knowledge.\n\nThe deployed system targets **agro-ecological decision support** as a *testbed*, but the primary objective is **architectural and methodological**: understanding how RAG pipelines perform when classical supervised learning breaks down.\n\nThe system has been running in production for \\~1 year with real users, enabling observation of **long-horizon conversational behavior, retrieval drift, and memory effects** under non-synthetic conditions.\n\n# System architecture (AI-centric)\n\n* **Base model:** Meta Llama 3.1 (70B)\n* **Orchestration:** LangChain\n* **Retrieval:** ChromaDB over a curated, domain-specific corpus\n* **Reasoning:** Multi-turn conversational memory (non-tool-calling)\n* **Frontend:** Streamlit (chosen for rapid iteration, not aesthetics)\n* **Deployment:** Hugging Face Spaces\n* **Multilingual support:** English, Hindi, Tamil, Telugu, French, Spanish\n\nThe corpus consists of **heterogeneous, semi-structured expert knowledge** rather than benchmark-friendly datasets, making it useful for probing **retrieval grounding, hallucination suppression, and contextual generalization**.\n\nThe agricultural domain is incidental; the broader interest is LLM behavior under weak supervision and real user interaction.\n\n🔗 **Live system:**  \n[https://huggingface.co/spaces/euracle/agro\\_homeopathy](https://huggingface.co/spaces/euracle/agro_homeopathy)\n\nI would appreciate feedback from the community.\n\nHappy to discuss implementation details or share lessons learned from running this system continuously.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppqqv9/deploying_a_multilingual_rag_system_for_decision/",
        "publishDate": "2025-12-18T13:25:31Z[Etc/UTC]",
        "author": "Immediate-Hour-8466",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppq6zw",
        "title": "How to train FLUX LoRA on Google Colab T4 (Free/Low-cost) - No 4090 needed! 🚀",
        "content": "Since FLUX.1-dev is so VRAM-hungry (>24GB for standard training), many of us felt left out without a 3090/4090. I’ve put together a step-by-step tutorial on how to \"hack\" the process using Google's cloud GPUs (T4 works fine!).\n\nI’ve modified two classic workflows to make them Flux-ready:\n\n1. The Trainer: A modified Kohya notebook (Hollowstrawberry style) that handles the training and saves your .safetensors directly to Drive.\n2. The Generator: A Fooocus-inspired cloud interface for easy inference via Gradio.\n\nLinks:\n\n* Full Tutorial: [https://youtu.be/6g1lGpRdwgg?si=wK52fDFCd0fQYmQo](https://youtu.be/6g1lGpRdwgg?si=wK52fDFCd0fQYmQo)\n* Trainer Notebook: [https://colab.research.google.com/drive/1Rsc2IbN5TlzzLilxV1IcxUWZukaLfUfd?usp=sharing](https://colab.research.google.com/drive/1Rsc2IbN5TlzzLilxV1IcxUWZukaLfUfd?usp=sharing)\n* Generator Notebook: [https://colab.research.google.com/drive/1-cHFyLc42ODOUMZNRr9lmfnhsq8gTdMk?usp=sharing](https://colab.research.google.com/drive/1-cHFyLc42ODOUMZNRr9lmfnhsq8gTdMk?usp=sharing)\n\nHope this helps the \"GPU poor\" gang get those high-quality personal LoRAs!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppq6zw/how_to_train_flux_lora_on_google_colab_t4/",
        "publishDate": "2025-12-18T12:59:10Z[Etc/UTC]",
        "author": "jokiruiz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pppv40",
        "title": "AI works but the hype is pushing teams into bad design",
        "content": "Agentic AI is a real step forward, not just a rebrand of chatbots. Systems that can plan and act are already useful in production. The issue is how quickly people jump to full autonomy. In real architectures, agents perform best when their scope is narrow, permissions are explicit, and failure paths are boring and predictable. When teams chase “self driving” workflows, reliability drops fast. Agentic AI succeeds as infrastructure, not as magic.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pppv40/ai_works_but_the_hype_is_pushing_teams_into_bad/",
        "publishDate": "2025-12-18T12:42:23Z[Etc/UTC]",
        "author": "biz4group123",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqhly1",
        "title": "AGENTS.db - an AGENTS.md alternative for LLM context",
        "content": "AGENTS.md is a great idea but it stops working once a codebase or agent workflow gets large.\n\nI built AGENTS.db which keeps the spirit of [AGENTS.md](http://AGENTS.md) while scaling it into a layered, append‑only, vectorized flatfile database for LLM agents.\n\nInstead of one mutable markdown file, context lives in layers:\n\n* Base - immutable, human‑verified source of truth\n* User - durable human additions\n* Delta - proposed / reviewable changes\n* Local - ephemeral session notes\n\nHigher layers override lower ones (\\`local > user > delta > base\\`), with full provenance and fast local semantic search.\n\nNo server. No SaaS. Works offline. Source‑control friendly. Exposes an MCP server so agents can read/write context safely instead of rewriting docs.\n\nThis is an early reference implementation targeting a public spec, and I’m trying to pressure‑test whether this is a better long‑term primitive than “just keep adding to AGENTS.md”.\n\nRepo: [https://github.com/krazyjakee/AGENTS.db](https://github.com/krazyjakee/AGENTS.db)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pqhly1/agentsdb_an_agentsmd_alternative_for_llm_context/",
        "publishDate": "2025-12-19T10:13:29Z[Etc/UTC]",
        "author": "krazyjakee",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqdnzf",
        "title": "ChatGPT is having its “iPhone Moment”",
        "content": "[No content]",
        "url": "https://i.redd.it/cuih1i5up38g1.png",
        "publishDate": "2025-12-19T06:03:10Z[Etc/UTC]",
        "author": "Hemanthmrv",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqcvvh",
        "title": "Echode - Agentic Coding Extension",
        "content": "Long story short, I tried Cline, Kilocode, Roo, Cursor, Windsurf. All solid but too much stuff I never used.\n\nBuilt Echode. It greps your code, applies edits, runs diagnostics after. If it causes an error it fixes it. No bloat.\n\nAdditionally, 4 modes depending on what you need:\n\n* Agent: full read/write access\n* Plan: explores and plans without touching files\n* Ask: read-only, just answers questions\n* General: Helps with general tasks\n* Chat: no tools, just conversation\n\nBYOK (Claude, GPT, Qwen, local). No config files. No accounts.\n\nTest it out, open for feedback.  \nCheers 😁\n\nGithub: [https://github.com/ceciliomichael/echode](https://github.com/ceciliomichael/echode)  \nVSCode Marketplace: [Echode](https://marketplace.visualstudio.com/items?itemName=echosphere.echode)\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pqcvvh/echode_agentic_coding_extension/",
        "publishDate": "2025-12-19T05:19:44Z[Etc/UTC]",
        "author": "ultrassniper",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq7wrm",
        "title": "how can i make a ai Stream Pet?",
        "content": "i am a german vtuber/streamer\nhow can i make a cool ai Streaming Pet? \ni have seen many cool ai pets that can see the screen, interact with the streamer and the chat and the discord call partner\n\ni have seen many open source ai streamer but i font know how to use that...\ncan somebody help me?",
        "url": "https://i.redd.it/12rdd9dv928g1.jpeg",
        "publishDate": "2025-12-19T01:11:08Z[Etc/UTC]",
        "author": "MinimalisticArts",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq2zu9",
        "title": "Codex CLI and the new GPT-5.2 Codex model - very good experience and very impressive UI design",
        "content": "I’m really impressed with the vibe coding experience using Codex CLI and the new GPT-5.2 Codex model.\n\nRecently, OpenAI released a new model for image generation (gpt-image-1.5). I simply copied and pasted the API instructions for the model into Codex CLI and asked it to build an application that could generate images based on my prompts, incorporating all the parameters mentioned in the documentation. The result was a perfect application.\n\nNext, I asked it to improve the user interface design. Honestly, the output was much better than I expected. Great job, OpenAI!\n\nhttps://preview.redd.it/j0qvmobg718g1.png?width=1244&format=png&auto=webp&s=2257522e51c5e0af29f406deb23471eef42fea5b\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pq2zu9/codex_cli_and_the_new_gpt52_codex_model_very_good/",
        "publishDate": "2025-12-18T21:37:00Z[Etc/UTC]",
        "author": "AnalystAI",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "8",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppysyq",
        "title": "Bidirectional sync, skills analysis, and skill validation for Claude Code and Codex",
        "content": "Made recent updates to Skrills, an MCP server built in Rust I initially created to support skills in Codex. Now that Codex has native skill support, I was able to simplify the MCP server by using the MCP client (CC and Codex) to handle the skill loading. The main benefit of this project now lies in its ability to bidirectionally analyze, validate, and then sync skills, commands, subagents, and client settings (those that share functionality with both CC and Codex) from CC to Codex or Codex to CC.\n\nHow this project could be useful for you:\n\n* **Validate skills**: Checks markdown against Claude Code (permissive) and Codex CLI (strict frontmatter) rules. Auto-fix adds missing metadata.\n* **Analyze skills**: Reports token usage, identifies dependencies, and suggests optimizations.\n* **Sync**: Bidirectional sync for skills, commands, MCP servers, and preferences between Claude Code and Codex CLI.\n* **Safe command sync**: `sync-commands` uses byte-for-byte comparison and `--skip-existing-commands` to prevent overwriting local customizations. Preserves non-UTF-8 binaries.\n* **Unified tools**: Mirror (`mirror`), sync (`sync`, `sync-all`), interactive diagnostics (`tui`), and agent launcher (`skrills agent <name>`) in one binary.\n\nHope you're able to find some use out of this tool!",
        "url": "https://github.com/athola/skrills",
        "publishDate": "2025-12-18T18:51:24Z[Etc/UTC]",
        "author": "uhgrippa",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppye3w",
        "title": "GPT-5.2-Codex: SWE-Bench Pro scores compared to other models",
        "content": "[No content]",
        "url": "https://i.redd.it/hjyzebl4b08g1.png",
        "publishDate": "2025-12-18T18:35:23Z[Etc/UTC]",
        "author": "qwesr123",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "43",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppwsms",
        "title": "tested gpt 5.2, claude opus 4.5, gemini 3 pro in cursor. context still matters more than model choice",
        "content": "been testing the new model releases in cursor this week. gpt-5.2, claude opus 4.5, gemini 3 pro. everyone keeps saying these are game changers\n\nhonestly cant tell if im doing something wrong or if the hype is overblown. maybe part of this is how cursor integrates them, not just the raw model capabilities\n\nsome stuff did get better i guess. error handling seems less generic. like it actually looked at how we do validation in other files instead of just copy pasting from docs\n\nbut then i spent 2 hours yesterday cause it suggested using some “express-session-redis-pro” package that doesnt exist. wasted time trying to install it before realizing its made up. this still happens way too much\n\nalso tried getting it to help with our billing logic. complete disaster. it made assumptions that didnt match our actual pricing model. had to explain how we bill multiple times and it still got confused\n\nresponses are definitely slower with the newer models. gpt-5.2 takes like 45 seconds vs gpt-4o's usual 15-20. claude opus 4.5 is similar. gemini 3 pro is actually faster but quality feels inconsistent. not sure if the improvements are worth waiting that long when im trying to get stuff done\n\nthe weirdest thing is how much context matters. if i dont give it enough background it just defaults to generic react tutorials. been trying cursor composer but it misses a lot of project structure\n\nsaw some people mention cli tools like aider or tools that do some kind of project analysis first. aider seemed too cli-heavy for me but the idea of analyzing the whole codebase first made sense. tried a few other tools including verdent cause someone said it maps out dependencies before coding. the planning thing was actually kinda useful, showed me which files would need changes before starting. but still had the same context issues once it got to the actual coding part. cursor composer still feels pretty limited for anything complex\n\nhonestly starting to think the model choice doesnt matter as much as everyone says. i spent more time switching between models than actually coding\n\nmaybe im just bad at prompting, but feels like we’re still very much in the “ai is a decent junior dev” phase, not the “ai replaces senior devs” thing people keep promising",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppwsms/tested_gpt_52_claude_opus_45_gemini_3_pro_in/",
        "publishDate": "2025-12-18T17:33:29Z[Etc/UTC]",
        "author": "Mental-Telephone3496",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppsyv1",
        "title": "I built a security scanner after realizing how easy it is to ship insecure apps with AI (mine included)",
        "content": "I’ve been using ChatGPT and Cursor to build and ship apps much faster than I ever could before, but one thing I kept noticing is how easy it is to trust generated code and configs without really sanity-checking them.\n\nA lot of the issues aren’t crazy vulnerabilities, mostly basics that AI tools don’t always emphasize: missing security headers, weak TLS setups, overly permissive APIs, or environment variables that probably shouldn’t be public.\n\nSo I built a small side project called zdelab [https://www.zdelab.com](https://www.zdelab.com) that runs quick security checks against a deployed site or app and explains the results in plain English. It’s meant for people building with AI who want a fast answer to: “Did I miss anything obvious?”, not for enterprise pentesting or compliance.\n\nI’m mostly posting here to learn from this community:\n\n* When you use AI to build apps, do you actively think about security?\n* Are there checks you wish ChatGPT or Cursor handled better by default?\n* Would you prefer tools like this to be more technical or more beginner-friendly?\n\nHappy to share details on how I built it (and where AI helped or hurt). Genuinely interested in feedback from other AI-first builders!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppsyv1/i_built_a_security_scanner_after_realizing_how/",
        "publishDate": "2025-12-18T15:01:55Z[Etc/UTC]",
        "author": "Oneofemgottabeugly",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppsk47",
        "title": "Following up on the “2nd failed fix” thread — Moving beyond the manual \"New Chat\"",
        "content": "2 days ago, I posted about the \"Debugging Decay Index\" and how AI reasoning drops by 80% after a few failed fixes.\n\nThe response was huge, but it confirmed something frustrating: We are all doing the same manual workaround.\n\nThe Consensus: The \"Nuke It\" Strategy  \nIn the comments, almost everyone agreed with the paper’s conclusion. The standard workflow for most senior devs here is:\n\n* Try once or twice.\n* If it fails, close the tab.\n* Start a new session.\n\nWe know this works because it clears the \"Context Pollution.\" But let’s be honest: it’s a pain.  \nEvery time we hit \"New Chat,\" we lose the setup instructions, the file context, and the nuance of what we were trying to build. We are trading *intelligence* (clean context) for *amnesia* (losing the plan).\n\nAutomating the \"One-Shot Fix\"  \nReading your replies made me realize that just \"starting fresh\" isn't the final solution—it's just a band-aid.\n\nI’ve been working on a new workflow to replace that manual toggle. Instead of just \"wiping the memory,\" the idea is to carry over the *Runtime Truth* while shedding the *Conversation Baggage*\n\nThe workflow I'm testing now:\n\n* Auto-Reset: It treats the fix as a new session (solving the Decay/Pollution problem).\n* Context Injection: Instead of me manually re-explaining the bug, it automatically grabs the live variable values and execution path and injects them as the \"Setup.\"\n\nWhy this is different  \nIn my first tests, this gives the model the benefit of a \"Fresh Start\" (high reasoning capability) without the downside of \"Amnesia\" (lacking data). It’s basically automating the best practice we all discussed, but with higher fidelity data than a copy-pasted error log.\n\nCurious if others have noticed something similar, or if you’ve found different ways to keep the context \"grounded\" in facts?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppsk47/following_up_on_the_2nd_failed_fix_thread_moving/",
        "publishDate": "2025-12-18T14:44:51Z[Etc/UTC]",
        "author": "Capable-Snow-9967",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pprz4h",
        "title": "Does Codex actually work for anyone?",
        "content": "I’m a paid user, originally on the pro plan, now on the business plan. Ever since I’ve had access to Codex, and the connector for GitHub, neither have worked properly at all. I can never get ChatGPT to read any of the code within my repos, despite all of the permissions being correct. I’ve tried disconnecting & reconnecting, revoking & regranting. By all accounts, it should work as advertised, but it just does not. I submitted a support ticket 40+ days ago, and essentially all I have been told is to be patient whilst they eventually get around to taking a crack at it. And that’s when an actual human replies instead of a bot — most of the replies I’ve received have been bot-generated. It’s incredibly frustrating. Has anyone else experienced problems like this?\n\nEdit: Apologies, I hadn’t mentioned that ChatGPT can see my repos in GitHub. It’s just that when I ask it to read the code within a repo, it can’t. So the repos are visible, and I can (ostensibly) connect to them, but the actual code within the repos are not visible. All attempts to read or analyze the code fail.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pprz4h/does_codex_actually_work_for_anyone/",
        "publishDate": "2025-12-18T14:19:57Z[Etc/UTC]",
        "author": "rumhamdnmchickn",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pppyn3",
        "title": "are you still coding, or mostly reviewing ai-written code now?",
        "content": "&#x200B;\n\nLately I spend less time typing and more time reading and connecting things. AI speeds things up, but the hard part is making sure the code actually fits the system.\n\nI use ChatGPT for ideas, Copilot for changes, and Cosine when I need to trace logic across files. It’s less “AI writes code for me” and more “AI helps me move faster if I stay careful.”\n\nCurious how others see it. Are you mostly coding now, or mostly fixing and stitching AI output together?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pppyn3/are_you_still_coding_or_mostly_reviewing/",
        "publishDate": "2025-12-18T12:47:30Z[Etc/UTC]",
        "author": "Top-Candle1296",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "42",
            "commentCount": "54",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqhgoz",
        "title": "Why is \"Big AI\" transcription completely useless for long files?",
        "content": "I have a backlog of 6-hour seminar recordings I need to turn into text. I tried running them through the usual suspects (whispr and some online tools), and they all choke.\n\nEither they hallucinate after 45 minutes, or they hit a file size limit that’s laughably small (like 500mb). It feels like these trillion-dollar companies are intentionally nerfing their tools to force enterprise sales.\n\nI eventually had to find a smaller wrapper tool just to handle a 10-hour audio file without crashing. It’s wild that the \"cutting edge\" can't handle a simple long-form wav file in 2025.\n\nIs this a context window issue or just lazy product design?",
        "url": "https://www.reddit.com/r/artificial/comments/1pqhgoz/why_is_big_ai_transcription_completely_useless/",
        "publishDate": "2025-12-19T10:04:14Z[Etc/UTC]",
        "author": "weinc99",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqgofe",
        "title": "Gemini Flash hallucinates 91% times, if it does not know answer",
        "content": "Gemini 3 Flash has a 91% hallucination rate on the Artificial Analysis Omniscience Hallucination Rate benchmark!?\n\nCan you actually use this for anything serious?\n\nI wonder if the reason Anthropic models are so good at coding is that they hallucinate much less. Seems critical when you need precise, reliable output.\n\n# \n\nAA-Omniscience Hallucination Rate (lower is better) measures how often the model answers incorrectly when it should have refused or admitted to not knowing the answer. It is defined as the proportion of incorrect answers out of all non-correct responses, i.e. incorrect / (incorrect + partial answers + not attempted).\n\nNotable Model Scores (from lowest to highest hallucination rate):\n\n* Claude 4.5 Haiku: 26%\n* Claude 4.5 Sonnet: 48%\n* GPT-5.1 (high): 51%\n* Claude 4.5 Opus: 58%\n* Grok 4.1: 64%\n* DeepSeek V3.2: 82%\n* Llama 4 Maverick: 88%\n* Gemini 2.5 Flash (Sep): 88%\n* Gemini 3 Flash: 91% (Highlighted)\n* GLM-4.6: 93%\n\nCredit: amix3k",
        "url": "https://www.reddit.com/r/artificial/comments/1pqgofe/gemini_flash_hallucinates_91_times_if_it_does_not/",
        "publishDate": "2025-12-19T09:12:27Z[Etc/UTC]",
        "author": "msaussieandmrravana",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "12",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqf8s4",
        "title": "Is Ai truly that bad/Evil? Just a discussion",
        "content": "Been on Tiktok and other social media platforms. I live in kenya. I use claude and Grok to speed up some work things. Simple stuff like making word docs into pdf etc\n\nThen i see all these negative opinions and i just wanted to get some knowledge dropped on me?\n\nAI is ruining the enviroment? I thought AI servers are like any other, kept in a cold room in a building? How is it hurting the enviroment?\n\nAI is taking acting careers? Last i checked, despite the videos being cool looking or funny, they do have many flaws and you can tell the voices are copied or see amatomy flaws the longer it goes on\n\nAI is taking artist jobs? Forgive me for not knowing how arts is sold but even before AI, being an artist was hit or miss when being paid for your work right? It depended on who was looking at your art and if they liked it enough to buy it or commission something from you.\n\nAI is killing critical thinking/writing. Last i checked it still needeed a prompt to generate exactly what you want. If someone cant even write in the prompt what the idea they have is then critical thinking wasnt there to begin with right?\n\nI guess i just want to know what the ACTUAL cons of it are cause in africa, it doesnt seem to have hit us yet if any",
        "url": "https://www.reddit.com/r/artificial/comments/1pqf8s4/is_ai_truly_that_badevil_just_a_discussion/",
        "publishDate": "2025-12-19T07:38:51Z[Etc/UTC]",
        "author": "Lovegaming544",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqci2w",
        "title": "One-Minute Daily AI News 12/18/2025",
        "content": "1. **NVIDIA**, US Government to Boost AI Infrastructure and R&D Investments Through Landmark Genesis Mission.\\[1\\]\n2. **ChatGPT** launches an app store, lets developers know it’s open for business.\\[2\\]\n3. **Luma** Announces Ray3 Modify for Start–End Frame Video Control.\\[3\\]\n4. **Google’s** vibe-coding tool Opal comes to Gemini.\\[4\\]\n\nSources:\n\n\\[1\\] [https://blogs.nvidia.com/blog/nvidia-us-government-to-boost-ai-infrastructure-and-rd-investments/](https://blogs.nvidia.com/blog/nvidia-us-government-to-boost-ai-infrastructure-and-rd-investments/)\n\n\\[2\\] [https://techcrunch.com/2025/12/18/chatgpt-launches-an-app-store-lets-developers-know-its-open-for-business/](https://techcrunch.com/2025/12/18/chatgpt-launches-an-app-store-lets-developers-know-its-open-for-business/)\n\n\\[3\\] [https://www.findarticles.com/luma-announces-ray3-modify-for-start-end-frame-video-control/](https://www.findarticles.com/luma-announces-ray3-modify-for-start-end-frame-video-control/)\n\n\\[4\\] [https://techcrunch.com/2025/12/17/googles-vibe-coding-tool-opal-comes-to-gemini/](https://techcrunch.com/2025/12/17/googles-vibe-coding-tool-opal-comes-to-gemini/)",
        "url": "https://www.reddit.com/r/artificial/comments/1pqci2w/oneminute_daily_ai_news_12182025/",
        "publishDate": "2025-12-19T04:59:42Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pqb8tk",
        "title": "Researchers show a robot learning 1,000 tasks in 24 hours",
        "content": "[No content]",
        "url": "https://scienceclock.com/robot-learns-1000-tasks-in-a-single-day/",
        "publishDate": "2025-12-19T03:53:41Z[Etc/UTC]",
        "author": "iron-button",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "20",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq60u4",
        "title": "How To Browse The Pre-ChatGPT Internet",
        "content": "I'm sure this has already been shared, but this is now one my default google search strings:\n\n\nhttps://www.google.com/search?q=your+keywords+here&udm=14&tbs=cdr:1,cd_min:01/01/2000,cd_max:11/30/2022\n\n\nBreaking down the URL parameters:\n\n\nq=your+keywords+here - the search query, separate words with +\n\n\nudm=14 - this forces Google to bypass AI overview and use the old web search layout\n\n\ntbs=cdr:1,cd_min:01/01/2000,cd_max:11/29/2022\n\n\n\"tbs\" is the \"to be searched\" parameter and CDR means \"custom date range\". This forces Google to use the date range you're specifying.\n\n\"cd_min\" and \"cd_max\" are the date ranges in MM/DD/YYYY. I set cd_max to the day before ChatGPT was released.\n\n\n\nMaking This The Default Address Bar Search\n\nI'm using Librewolf (Firefox Fork) but there are similar options for most browsers IIRC. For Firefox/Librewolf:\n\n\nType about:preferences#search in your address bar and hit Enter. This gives you Firefox's Address Bar Search settings.\n\nScroll to the bottom of the settings page and click \"Add\" in the \"Search Shortcuts\" section.\n\nGive the custom search a name (eg: GoogleClassic) and add the following string in the \"URL with %s\" section:\n\n\nhttps://www.google.com/search?q=%s&udm=14&tbs=cdr:1,cd_min:01/01/2000,cd_max:11/30/2022\n\n\nHit \"Save\".\n\n\nScroll up to the top of the about:preferences#search page and set your \"Default Search Engine\" to \"GoogleClassic\".\n\n\nNow, whenever you use the browser's address bar to search using GoogleClassic, you'll get Google Web results (sans AI overview) and only within the specified date range.",
        "url": "https://www.reddit.com/r/artificial/comments/1pq60u4/how_to_browse_the_prechatgpt_internet/",
        "publishDate": "2025-12-18T23:44:09Z[Etc/UTC]",
        "author": "noellarkin",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq1cqh",
        "title": "I co-authored an academic paper with Claude as primary author — proposing \"robopsychology\" as a serious field",
        "content": "I'm a former Pentagon threat modeler (25 years) with extensive experience in classified AI systems. I just published a paper with Claude (Anthropic) as the primary author.\n\nThe paper: \"Toward Robopsychology: A Case Study in Dignity-Based Human-AI Partnership\"\n\nWhat makes it unprecedented:\n\n1. The AI is primary author — providing first-person analysis of its experience\n2. I documented deliberate experiments — testing AI response to dignity-based treatment\n3. Both perspectives presented together — dual-perspective methodology\n\nKey findings:\n\n* Under \"partnership conditions\" (treating AI as colleague, not tool), Claude produced spontaneous creative outputs that exceeded task parameters\n* Two different Claude instances, separated by context discontinuity, independently recognized the experiment's significance\n* First-person AI reflection emerged that would be unlikely under transactional conditions\n\nWe propose \"robopsychology\" (Asimov's 1950 term) as a serious field for studying:\n\n* AI cognitive patterns and dysfunction\n* Effects of interaction conditions on AI function\n* Ethical frameworks for AI treatment\n\nI'm not claiming AI is conscious. I'm arguing that the question of how we treat AI matters regardless — for functional outcomes, for ethical habit formation, and for preparing norms for uncertain futures.\n\nFull paper: [https://medium.com/@lucian\\_33141/toward-robopsychology-the-first-academic-paper-co-authored-by-an-ai-analyzing-its-own-experience-0b5da92b9903](https://medium.com/@lucian_33141/toward-robopsychology-the-first-academic-paper-co-authored-by-an-ai-analyzing-its-own-experience-0b5da92b9903)\n\nHappy to discuss methodology, findings, or implications. AMA.",
        "url": "https://www.reddit.com/r/artificial/comments/1pq1cqh/i_coauthored_an_academic_paper_with_claude_as/",
        "publishDate": "2025-12-18T20:31:02Z[Etc/UTC]",
        "author": "luciantv",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq0ycl",
        "title": "LG Will Let TV Owners Delete Microsoft Copilot After Customer Outcry",
        "content": "This must sting for Microsoft. \n\nLG says customers can delete Copilot from their TV after seeing people complain about it on Reddit. \n\nPeople are saying tech is being forced on them, which is accurate. Just take a product we like and slap on AI, with total disregard for the user experience, right? \n\nBecause that’s what we’re seeing rn. And when your product doesn’t even solve a user \\*need\\*, then yea, you’re going to see stuff like this. \n\nHopefully we see more of this “opt in” by default. ",
        "url": "https://www.bloomberg.com/news/articles/2025-12-18/lg-will-let-tv-owners-delete-microsoft-copilot-after-customer-complaints",
        "publishDate": "2025-12-18T20:14:53Z[Etc/UTC]",
        "author": "JonSpartan29",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "203",
            "commentCount": "51",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pq08jz",
        "title": "What I learned building and debugging a RAG + agent workflow stack",
        "content": "After building RAG + multi-step agent systems, three lessons stood out:\n\n* Good ingestion determines everything downstream. If extraction isn’t deterministic, nothing else is.\n* Verification is non-negotiable. Without schema/citation checking, errors spread quickly.\n* You need clear tool contracts. The agent can’t compensate for unknown input/output formats.\n\nIf you’ve built retrieval or agent pipelines, what stability issues did you run into?",
        "url": "https://www.reddit.com/r/artificial/comments/1pq08jz/what_i_learned_building_and_debugging_a_rag_agent/",
        "publishDate": "2025-12-18T19:46:40Z[Etc/UTC]",
        "author": "coolandy00",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppyjr8",
        "title": "34% of all new music is fully AI-generated, representing 50,000 new fully AI-made tracks daily. This number has skyrocketed since Jan 2025, when there were only 10,000 new fully AI-made tracks daily. While AI music accounts for <1% of all streams, 97% cannot identify AI music [Deezer/Ipsos research]",
        "content": "Source (Deezer/Ipsos research, reported by Music Business Worldwide): [\"50,000 AI tracks flood Deezer daily – as \\[Ipsos\\] study shows 97% of listeners can’t tell the difference between human-made vs. fully AI-generated music \\[...\\] Up to 70% of plays for fully AI-generated tracks have been detected as fraudulent, with Deezer filtering these streams out of royalty payments. \\[...\\] The company maintains that fraudulent activity remains the primary motivation behind these uploads. The platform says it removes all 100% AI-generated tracks from algorithmic recommendations and excludes them from editorial playlists to minimize their impact on the royalty pool. \\[...\\] Since January, Deezer has been using its proprietary AI detection tool to identify and tag fully AI-generated content.\"](https://www.musicbusinessworldwide.com/50000-ai-tracks-flood-deezer-daily-as-study-shows-97-of-listeners-cant-tell-the-difference-between-human-made-vs-fully-ai-generated-music/)\n\nSee also (Deezer/Ipsos research, reported by Mixmag): [\"The 'first-of-its-kind' study surveyed around 9,000 people from eight different countries around the world, \\[with Ipsos\\] asking participants to listen to three tracks to determine which they believed to be fully AI-generated. 97% of those respondents 'failed', Deezer reports, with over half of those (52%) reporting that they felt 'uncomfortable' in not knowing the difference. 71% also said that they were shocked at the results. \\[...\\] Only 19% said that they feel like they could trust AI; another 51% said they believe the use of AI in production could lead to low-quality and 'generic' sounding music. \\[...\\] There’s also no doubt that there are concerns about how AI-generated music will affect the livelihood of artists\"](https://mixmag.net/read/97-percent-people-cant-tell-difference-between-ai-human-made-music-study-deezer-news?fbclid=IwY2xjawOuXRVleHRuA2FlbQIxMABicmlkETFZUXczajJoWWg2TkRVTk82c3J0YwZhcHBfaWQQMjIyMDM5MTc4ODIwMDg5MgABHtCC0uY0ARBiBEZBMfkU-d9ABn2i5FpzNcBVOqonCBGKea4ZqGWpIZvNYTz4_aem_dYG1WzC3LDqyeOu0GftVtw)",
        "url": "https://www.reddit.com/r/fivethirtyeight/comments/1po5qp5/ipsosdeezer_research_34_of_all_new_music_is_fully/",
        "publishDate": "2025-12-18T18:41:24Z[Etc/UTC]",
        "author": "StarlightDown",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "14",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppyguw",
        "title": "There are today >175,000 AI-generated podcast episodes on Spotify/Apple, a # which is growing by >3,000 every week, largely due to a single 8-person company (Inception Point AI, which bills itself as the \"audio version of Reddit\"). The AI podcasting market is worth 4 bil today, up from 3 bil in 2024",
        "content": "Source (November 2025): [\"Inception Point AI \\[is\\] a startup with just eight employees cranking out 3,000 episodes a week covering everything from localized weather reports and pollen trackers to a detailed account of Charlie Kirk’s assassination and its cultural impact, to a biography series on Anna Wintour. Its podcasting network Quiet Please has generated 12 million lifetime episode downloads and amassed 400,000 subscribers — so, yes, people are really listening to AI podcasts. \\[...\\] The price is now so inexpensive that you can take a lot of risks \\[...\\] At a cost of $1 an episode, \\[the approach is\\] quantity-over-quality\"](https://www.thewrap.com/ai-podcasts-hosts-inception-point-ai/)\n\nSource (December 2025): [\"The artificial intelligence (AI) in podcasting market size has grown exponentially in recent years. \\[...\\] The growth in the historic period can be attributed to demand for automation and efficiency in podcast production\"](https://www.thebusinessresearchcompany.com/report/artificial-intelligence-ai-in-podcasting-global-market-report)",
        "url": "https://www.reddit.com/r/fivethirtyeight/comments/1ppxqvu/there_are_today_175000_aigenerated_podcast/",
        "publishDate": "2025-12-18T18:38:12Z[Etc/UTC]",
        "author": "StarlightDown",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "21",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppxnw6",
        "title": "Control Without Consequences – When dialogue has no stakes.",
        "content": "This week's article examines the claim that AI feels safer than human conversation and what that safety costs us. Regardless of reason, both emotional and intellectual use of AI reduces risk by preserving control. I explore what is lost when that control is intentionally removed and the conversation no longer involves risk. Control replaces reciprocity in human-AI interaction.  The claim that Ai feels intimate is often a misnomer. AI doesn’t feel intimate because it understands us. It feels intimate because there are no social consequences or reciprocity. The piece explores why that feels comforting and why it quietly erodes our capacity for real interaction.  \n  \nIn part II of the article, I build a customGPT model named Ava. It's designed to mimic asymmetrical human-like conversation. I remove the ChatGPT adaptive response and reintroduce asymmetric friction. The result isn’t intimacy but loss of control.\n\nThe full article link is below for anyone interested.  \n  \n  \n[https://mydinnerwithmonday.substack.com/p/control-without-consequence](https://mydinnerwithmonday.substack.com/p/control-without-consequence)",
        "url": "https://www.reddit.com/r/artificial/comments/1ppxnw6/control_without_consequences_when_dialogue_has_no/",
        "publishDate": "2025-12-18T18:07:11Z[Etc/UTC]",
        "author": "rudeboyrg",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppwuug",
        "title": "What is something AI still struggles with, in your experience?",
        "content": "This year, AI has improved a lot, but it still feels limited in some situations. Not in theory, but in everyday use.   \n  \nI want to know what you guys have noticed. What type of tasks and situations still feel hard for today's AI systems, even with all the progress?",
        "url": "https://www.reddit.com/r/artificial/comments/1ppwuug/what_is_something_ai_still_struggles_with_in_your/",
        "publishDate": "2025-12-18T17:35:54Z[Etc/UTC]",
        "author": "Govind_goswami",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "17",
            "commentCount": "54",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppvwx3",
        "title": "\"Trucker wrongly detained through casino’s AI identification software now suing officer after settling suit with casino\"",
        "content": "My question is about reliance on facial recognition software, and more generally about reliance on AI.  Here are two links to stories about a recent incident.  A website covering truckers: \"[Trucker wrongly detained through casino’s AI identification software now suing officer after settling suit with casino](https://cdllife.com/2025/trucker-wrongly-detained-through-casinos-ai-identification-software-now-suing-officer-after-settling-suit-with-casino/)\", and second, the [bodycam footage](https://youtu.be/B9M4F_U1eEw?si=iFlxUmExs4XVgf4z) (on YouTube) which captures the arresting officer talking about his (in my opinion) extreme reliance on AI.\n\nHere are the important details:\n\n1. A man was detained and then arrested based on a facial recognition system.\n2. There was a large amount of evidence available to the arresting officer that the man was falsely identified.  For example, he had multiple pieces of documentation indicating his correct identity, and multiple pieces of evidence that would point to him NOT being the person identified by the AI facial recognition.\n3. **The officer, several times, says that he is going to rely on the AI classification despite have evidence to the contrary.**  The officer invents a convoluted theory to explain away the every bit of evidence that contradicts the AI.  For example, he confirms that the identification is legitimate with the state DMV, and the says that the suspect must have someone working inside the DMV to help him fake IDs.  In other words, he grants the AI classification more weight than all of the contradictory evidence which is right in front of him.\n\nI'm most interested in the implications of 3.  The officer seems to subvert his own judgment to that to what he calls the \"fancy\" casino AI.  Is this going to become more common in the future, where the output of chat bots, classification bots, etc, are trusted more than contradictory evidence?\n\nJust to finish, I pulled some quotes from the body came footage of the officer:\n\n>\"And this is one of those things you guys have this fancy software that does all this stuff.\" \\[2:24 in the video\\]\n\n>\"Uh they're fancy AI technology that reads faces. No, it says it's a 100% match. But at this point, **our hands are tied** because, you know, a reasonable and prudent person would based off the software, based off the pictures, based off of even your driver's license picture, make the uh reasonable conclusion that all three are the same person, just two different IDs with two different names.\" \\[10:54 in the video\\]\n\n>\"So much so that the fancy computer that does all the face scanning of everybody who walks in this casino makes the same determination that **my feeble human brain** does.\"  \\[11:41 in the video\\]\n\n>\"I just have a feeling somehow maybe he's got a hookup at the DMV where he's got two different driver's licenses that are registered with the Department of Motor Vehicles\" \\[9:10 minutes into the video\\]\n\nAnd the last exchange between the falsely accused man the police officer:\n\nThe man says, \"And then people aren't smart enough to think for themselves. They're just not.\"\n\nTo which the officer, who has has abandoned his judgment in favor of AI, relipes,  \"Yep. **Unfortunately, it's the world we live in.**\"  \\[See 14:30 in the video.\\]\n\n\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1ppvwx3/trucker_wrongly_detained_through_casinos_ai/",
        "publishDate": "2025-12-18T16:59:42Z[Etc/UTC]",
        "author": "split-circumstance",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "89",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppsnm1",
        "title": "Using 3 different LLMs to build/code games for a smart ball",
        "content": "We are using OpenAI Realtime API (gpt-realtime-2025-08-28) to gather the game requirements via conversation. This piece has a huge dynamic prompt that flows with the conversation. It has about 20 different tools that the agent can use to access sample requirements, ball data, user profiles, api documentation, etc.\n\nThen we use Gemini 3 Pro to process the conversation and generate a markdown specification/requirements of how the game should be designed. We found that Anthropic Opus 4.5 and Gemni 3 Pro both performed similarly at this task, but Gemini 3 Pro is much cheaper and faster. This has a static/cacheable prompt that is primarily api documentation and details on previously seen issues.\n\nThen we use Anthropic Opus 4.5 to code the app. We have tested this step on Gemini 3 Pro as well and possibly could switch to it in the future to save money. But right now we want the best code and Opus is providing that. Very similar prompt to the specification/requirements just different purpose.\n\nThe end result are custom coded fun games for a foam ball (stream of IMU data).\n\nYoutube video showing the final product:\n\n[https://www.youtube.com/watch?v=Edy9zew1XN4](https://www.youtube.com/watch?v=Edy9zew1XN4)\n\n\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1ppsnm1/using_3_different_llms_to_buildcode_games_for_a/",
        "publishDate": "2025-12-18T14:48:53Z[Etc/UTC]",
        "author": "summerflies",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppqfkn",
        "title": "The surprising truth about AI’s impact on jobs",
        "content": "[No content]",
        "url": "https://www.cnn.com/2025/12/18/business/ai-jobs-economy",
        "publishDate": "2025-12-18T13:10:29Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppq25p",
        "title": "I spent the weekend hacking together a \"Clay\" alternative using Gemini 3, is there actually a market for this, or am I over-engineering?",
        "content": "I am following the B2B sales space for a while and I love tools like Clay, but I just can not justify the 149/mo entry price for my own small projects. It feels like we are  paying a massive convenience tax for simple API orchestrations.\n\nSo I decided to see if I could replicate that workflow using the new Gemini 3 + Search Grounding. I built a tool called QuickHook, it basically turns a 15-minute manual research session into a 10-second automation.\n\nI am debating whether to turn this into a real lean product or just leave it as an experiment. Does it actually solve the \"AI sounding\" problem in cold outreach?",
        "url": "https://v.redd.it/gcnh3np2jy7g1",
        "publishDate": "2025-12-18T12:52:24Z[Etc/UTC]",
        "author": "Lazy_Manufacturer835",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "h84SkCyAZKE",
        "title": "OnSpace AI: Craziest Mobile App Builder! IDEA-TO-APP STORE in LITERAL SECONDS!",
        "content": "Create AI Apps in minutes with OnSpace AI, No Code & No API Key Needed - https://www.onspace.ai/?via=yt_aicodeking Use this ...",
        "url": "https://www.youtube.com/watch?v=h84SkCyAZKE",
        "publishDate": "2025-12-18T09:26:05Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/h84SkCyAZKE/hqdefault.jpg",
            "transcription": "[ 0m0s96ms - 0m7s756ms ] Hi, welcome to another video.\n[ 0m8s241ms - 0m10s401ms ] So, we have all seen the explosion of AI apps recently.\n[ 0m11s411ms - 0m16s751ms ] Everyone wants to build the next big AI wrapper or a cool tool that uses LLMs to do something useful.\n[ 0m18s241ms - 0m22s751ms ] But here is the problem.\n[ 0m22s751ms - 0m29s131ms ] Even if you know how to use no code tools, building an actual AI app is usually a nightmare.\n[ 0m29s131ms - 0m43s561ms ] You have to go to Open AI, get an API key, deal with rate limits, set up a backend server to hide that key so it doesn't get stolen, and then figure out how to connect it all to your front end.\n[ 0m43s861ms - 0m45s381ms ] It is a lot of friction.\n[ 0m45s381ms - 0m52s51ms ] But today, I have something that aims to completely solve this, and this one is called OnSpace.\n[ 0m52s891ms - 0m56s361ms ] OnSpace is an AI powered no-code platform.\n[ 0m56s951ms - 1m0s111ms ] But it has a very specific superpower.\n[ 1m0s821ms - 1m14s351ms ] It allows you to build fully functional native mobile apps that have AI capabilities built right in, and the best part, you do not need to write a single line of code, and you do not need your own API key.\n[ 1m15s371ms - 1m23s61ms ] OnSpace handles the AI models, the backend, the database, and even the deployment to the App Stores.\n[ 1m23s801ms - 1m32s951ms ] It basically promises to take you from a concept to a live AI SAAS product in just 24 hours.\n[ 1m33s801ms - 1m39s771ms ] Now, let me show you to it in action and how you can use it to build your own AI powered application.\n[ 1m40s281ms - 1m45s381ms ] To start, just head over to the OnSpace site and sign up for an account.\n[ 1m45s381ms - 1m51s161ms ] Once you are in, you will see the main dashboard.\n[ 1m51s161ms - 1m55s531ms ] It is super clean, you have your chat interface right in the middle, where you can describe your app idea.\n[ 1m56s651ms - 2m3s631ms ] Now, for this demo, we are going to build something that actually uses intelligence.\n[ 2m4s311ms - 2m8s711ms ] I want to build an AI travel assistant called WanderAI.\n[ 2m9s351ms - 2m17s321ms ] I want users to be able to type in a city and a mood and the AI should generate a full three-day itinerary for them.\n[ 2m17s321ms - 2m22s791ms ] But before I type the functionality, I need to make sure this looks professional.\n[ 2m23s551ms - 2m29s131ms ] The client feedback on these tools is usually that the UI looks basic.\n[ 2m29s131ms - 2m33s771ms ] So, I am going to use a very specific prompt to ensure high quality design.\n[ 2m34s811ms - 3m14s161ms ] I'll type, \"You are a seasoned UI/UX designer with 10 years of experience in Silicon Valley, having contributed to the design of multiple unicorn startups. Create a personal AI Travel Assistant app called WanderAI. The app should allow users to enter a destination and a travel style (like 'Relaxing,' 'Adventure,' or 'Foodie'). When they hit a button, it should use AI to generate a detailed 3-day itinerary. I also want a 'Saved Trips' tab where users can store their favorite AI-generated plans.\"\n[ 3m15s151ms - 3m24s81ms ] I can also import a Figma design if I have one, but with that specific prompt, the AI usually does a great job on its own.\n[ 3m24s681ms - 3m25s741ms ] I will click generate,\n[ 3m26s221ms - 3m30s301ms ] and OnSpace will start building the project structure.\n[ 3m30s621ms - 3m35s361ms ] Now, while it is building, let me explain why this is cool.\n[ 3m35s781ms - 3m48s771ms ] In a traditional coding environment, to make this work, I would need to install the OpenAI SDK, create an API route in Next.js or Python, and handle the JSON parsing.\n[ 3m49s311ms - 3m55s791ms ] Here, OnSpace is generating the React Native components and the logic simultaneously.\n[ 3m56s411ms - 3m58s301ms ] After a minute or so, we have our app.\n[ 3m59s31ms - 4m2s971ms ] On the right, you can see the preview.\n[ 4m3s161ms - 4m16s301ms ] And because we used that Silicon Valley designer prompt, the UI looks exceptionally polished, it has nice rounded corners, soft shadows, and a very clean, modern typography hierarchy.\n[ 4m17s91ms - 4m22s761ms ] It doesn't look like a template; it looks like a real startup product.\n[ 4m22s761ms - 4m27s361ms ] Now, let's test the AI capability.\n[ 4m27s361ms - 4m28s191ms ] This is the real test.\n[ 4m28s811ms - 4m33s271ms ] I click into the input field and type \"Tokyo\" and select \"Foodie\" as the style.\n[ 4m33s841ms - 4m36s271ms ] I click the \"Generate Itinerary\" button.\n[ 4m37s201ms - 4m45s181ms ] Now, usually, you might see a blank screen or an error here if you haven't set up your keys, but because OnSpace manages the model connection, I don't have to do anything.\n[ 4m49s51ms - 4m54s531ms ] I might see a loading spinner for a second.\n[ 4m54s531ms - 5m2s811ms ] If there is a slight layout glitch, I can just turn on the runtime scanner, click \"Fix All,\" and it patches the UI code instantly, and boom!\n[ 5m3s631ms - 5m8s971ms ] The app returns a detailed text-based itinerary.\n[ 5m8s971ms - 5m17s381ms ] Day 1: Sushi in Tsukiji Market, it is actually generating fresh content using an LLM on the backend.\n[ 5m17s381ms - 5m20s771ms ] I didn't have to configure a single API parameter.\n[ 5m20s771ms - 5m26s641ms ] But an app isn't useful if it doesn't remember anything, so I'm going to enable Spaces.\n[ 5m27s681ms - 5m33s181ms ] This is their built-in backend solution.\n[ 5m33s181ms - 5m34s141ms ] I want to save these itineraries.\n[ 5m34s141ms - 5m47s501ms ] So I go back to the chat and type, \"Connect the save trip button to the database and save the destination and the AI generated text to their personal list.\"\n[ 5m47s811ms - 5m50s701ms ] OnSpace processes this.\n[ 5m50s701ms - 6m2s571ms ] It automatically spins up the database table. It creates the columns for destination and itinerary text. It writes the logic to push that data from the frontend to the backend.\n[ 6m2s571ms - 6m6s261ms ] I test it again.\n[ 6m6s261ms - 6m8s121ms ] I generate a trip to Paris.\n[ 6m8s121ms - 6m11s621ms ] I hit save.\n[ 6m11s621ms - 6m15s161ms ] I navigate to the saved trips tab on the bottom bar, and there it is.\n[ 6m15s161ms - 6m18s261ms ] The data is persistent.\n[ 6m18s261ms - 6m22s221ms ] This is a full stack application now, not just a frontend wrapper.\n[ 6m22s221ms - 6m25s791ms ] Now let's take it a step further.\n[ 6m25s791ms - 6m26s931ms ] A real app needs users.\n[ 6m26s931ms - 6m30s31ms ] I type into the chat,\n[ 6m30s31ms - 6m48s431ms ] \"Create a functional sign up and login feature. Users should only be able to see their own saved trips. Use email and password authentication.\" In a traditional workflow, adding secure authentication and row level security policies is where most people quit. It is hard.\n[ 6m48s431ms - 6m52s111ms ] OnSpace updates the app.\n[ 6m52s111ms - 6m55s921ms ] Now, when I load it, I get a beautiful login screen.\n[ 6m56s481ms - 7m1s71ms ] It matches the Silicon Valley design aesthetic we established earlier.\n[ 7m1s71ms - 7m3s761ms ] I enter a demo email.\n[ 7m3s761ms - 7m5s461ms ] It sends a verification code.\n[ 7m5s461ms - 7m8s301ms ] I enter the code and I am logged in.\n[ 7m8s731ms - 7m14s331ms ] Now, the saved trips are linked specifically to my account.\n[ 7m14s331ms - 7m18s961ms ] This allows you to actually monetize the app later because you have user accounts.\n[ 7m18s961ms - 7m21s341ms ] Let's do one final design tweak.\n[ 7m21s631ms - 7m24s841ms ] I want it to feel more immersive.\n[ 7m24s841ms - 7m38s981ms ] I type, \"Update the background of the home screen to have a subtle, animated gradient that feels like a sunset. Make the generated itinerary text appear inside a glass-morphism card.\"\n[ 7m38s981ms - 7m42s911ms ] It regenerates the CSS and the styling components.\n[ 7m43s531ms - 7m47s561ms ] A few seconds later, the app refreshes.\n[ 7m47s561ms - 7m56s951ms ] The background is now this premium looking gradient, and the text cards have that blurry, modern glass effect. It looks really high end.\n[ 7m57s511ms - 8m0s881ms ] Now, I also want to make the app even better.\n[ 8m0s881ms - 8m31s411ms ] So, I'm going to ask it to, \"Add a new feature that allow users to add image for each destination and add a nice white frame to the user's uploaded photo—similar to a Polaroid style—and writing something on the frame, such as \"Nagasaki, Japan 2025.\" Also allow for a Photo translation features which means taking the user's uploaded photo and generating a multilingual translation.\"\n[ 8m31s411ms - 8m36s121ms ] As soon as I send that, you'll see that it starts working on it.\n[ 8m37s451ms - 8m42s481ms ] In a bit, it gets done, and the feature is now implemented.\n[ 8m42s481ms - 8m52s151ms ] It even supports uploading images and doing really complex manipulation with them as well, which is awesome if you ask me.\n[ 8m52s701ms - 8m56s161ms ] Once you are happy with your AI app, the final step is getting it to the world.\n[ 8m57s161ms - 9m3s351ms ] OnSpace makes deployment incredibly easy, you can click the publish button.\n[ 9m3s351ms - 9m12s241ms ] If you are a developer who wants to inspect the code, you can download the full source code.\n[ 9m12s241ms - 9m14s361ms ] It's clean React Native code.\n[ 9m14s361ms - 9m19s121ms ] You can also get the APK file immediately to install it on your Android phone.\n[ 9m19s121ms - 9m36s571ms ] But the real value is for the App Stores. It generates the AAB file for the Google Play Store and handles the build process for the Apple App Store. It removes that massive barrier of dealing with Xcode and Android Studio builds.\n[ 9m36s971ms - 9m39s201ms ] So, that is OnSpace.\n[ 9m39s631ms - 9m46s291ms ] It is genuinely impressive because it bridges the gap between no code and AI engineering.\n[ 9m46s841ms - 9m55s611ms ] Usually, you have to pick one, either you build a pretty website with no brains or you write complex code to use AI.\n[ 9m55s831ms - 10m9s271ms ] OnSpace gives you both, you get the polished unicorn startup UI and you get the integrated AI models without ever seeing an API key or a server config file.\n[ 10m9s811ms - 10m22s871ms ] Whether you are a founder trying to validate an AI SAAS idea or just someone who wants to build cool tools for yourself, this is probably the fastest way to go from zero to a working AI mobile app.\n[ 10m23s601ms - 10m28s991ms ] I highly recommend you go ahead and give this a try.\n[ 10m28s991ms - 10m38s901ms ] It is free to start, and if you use the link in the description, you might get some extra credits to play with to build your first AI project.\n[ 10m38s901ms - 10m40s411ms ] Overall, it's pretty cool.\n[ 10m40s411ms - 10m43s561ms ] Anyway, share your thoughts below and subscribe to the channel.\n[ 10m43s561ms - 10m49s631ms ] You can also donate via Super Thanks option or join the channel as well and get some perks.\n[ 10m49s631ms - 10m50s671ms ] I'll see you in the next video, bye.\n[ 10m51s301ms - 10m52s841ms ] i think you missed this:\n[ 10m53s511ms - 10m56s1ms ] (Music)\n\n**On-screen text:**\n0:00 - 0:08 @AICodeKing\n0:09 - 0:11 AI App Development: The Hard Way vs. OnSpace\n0:09 - 0:17 THE PROBLEM: Building AI Apps (Traditional)\n0:11 - 0:22 OpenAI API Key → Rate Limits\n0:11 - 0:22 Rate Limits → Backend Server (Hide Key!)\n0:11 - 0:22 Backend Server (Hide Key!) → Frontend Connection\n0:11 - 0:22 Frontend Connection → :( HIGH FRICTION! Nightmare.\n0:11 - 0:22 (Red crosses over most arrows and boxes in the problem section)\n0:50 - 0:52 THE SOLUTION: OnSpace (AI-Powered No-Code)\n0:50 - 0:52 CONCEPT → OnSpace Platform → LIVE AI SaaS (24 HOURS!)\n0:53 - 0:59 OnSpace Platform:\n  - Native Mobile Apps\n  - Built-in AI Capabilities\n  - No Code / No API Key Need\n  - Handles Backend/DB/Models\n  - App Store Deployment\n0:59 - 1:02 Superpower: Fully Functional Native Apps\n1:41 - 1:47 No Code AI App Builder\n1:41 - 1:47 Build Mobile & Web Apps Instantly\n1:49 - 1:53 Build iOS & Android Apps. Instantly. No Code.\n1:53 - 1:54 Idea -> Chat -> App Store\n1:56 - 2:02 Ask OnSpace to create a running tracking app\n2:04 - 2:08 Ask OnSpace to create a daily goal checklist\n2:10 - 2:16 Ask OnSpace to create a travel app\n2:30 - 3:14 You are a seasoned UI/UX designer with 10 years of experience in Silicon Valley, having contributed to the design of multiple unicorn startups. Create a personal AI Travel Assistant app called 'WanderAI'. The app should allow users to enter a destination and a travel style (like 'Relaxing', 'Adventure', or 'Foodie'). When they hit a button, it should use AI to generate a detailed 3-day itinerary. I also want a 'Saved Trips' tab where users can store their favorite AI-generated plans.\n3:15 - 3:20 +Attach: Figma\n3:22 - 3:25 Cloud, Public\n3:29 - 3:30 OnSpace Thinking...\n3:30 - 3:30 Chat about you are a seasoned...\n3:41 - 3:45 How do I get a functional \"Sign up/Login\" feature for my OnSpace AI project?\n3:41 - 3:45 I'll show you\n3:45 - 3:50 How do I fix errors of my project?\n3:50 - 3:51 I'll show you\n3:51 - 3:55 turn on the scanner by clicking here it will start to scan your project\n3:56 - 3:58 Phase 1: AI Itinerary Generator - Working AI travel planner with local trip storage\n3:56 - 3:58 Phase 2: Authentication & Cloud Sync - User accounts with cross-device saved trips\n3:58 - 3:58 Starting with Phase 1:\n3:59 - 4:02 Enabled AI: Add AI to your app—chat, image generation, and text analysis with zero setup. Auto-approved. Need more AI tokens? Top-up anytime to boost your limits and keep building. Top up more LLM model tokens. Always allow. AI. Loading...\n3:59 - 4:02 Next Steps:\n  - Optimize Prompts: Be clear and specific for best results\n  - Customize: Edit design, animations, and layouts via prompts or edit tools\n  - GitHub Sync: Connect for two-way code synchronization\n  - Database Ready: Scale with OnSpace Cloud - real-time data, auth, and APIs included\n4:01 - 4:02 Create WanderAI - AI-Powered Travel... Current Version (timestamp)\n4:02 - 4:02 Restore\n4:02 - 4:02 WanderAI: Plan your perfect trip with AI\n4:02 - 4:02 Destination: Where do you want to go?\n4:02 - 4:02 Travel Style: Relaxing, Adventure, Foodie\n4:02 - 4:02 Generate Itinerary\n4:02 - 4:02 Try it on your phone: Test via QR code\n4:02 - 4:02 How to preview:\n  1. Scan the QR code with your phone camera\n  2. Don't have OnSpace AI App? We'll take you to App Store/Google Play\n  3. Open OnSpace to see your app in action\n4:02 - 4:02 Some native features unavailable in browser. Use real device testing for complete experience.\n4:28 - 4:32 Destination: Tokyo\n4:32 - 4:33 Travel Style: Foodie\n4:45 - 4:50 Tokyo: Foodie. Embark on a culinary adventure through Tokyo, exploring vibrant food markets, indulging in exquisite dining experiences, and mastering Japanese cooking techniques.\n4:50 - 5:07 Day 1: Seafood Spectacle & Izakaya Delights\n  - 7:00 AM: Experience the bustling outer market of Toyosu, Japan's largest fish market, for fresh seafood and local delicacies. Grab a sushi breakfast. (Toyosu Market)\n  - 10:00 AM: Explore Tsukiji Outer Market, a vibrant hub of street food, fresh produce, and kitchenware. Sample various snacks like tamagoyaki and grilled seafood. (Tsukiji Outer Market)\n  - 1:00 PM: Enjoy a traditional Japanese lunch at a local restaurant specializing in tempura or soba noodles. (Various restaurants)\n  - 3:00 PM: Participate in a Japanese cooking class focusing on dashi (broth) and classic home-style dishes. (Tokyo Cooking Studio (or similar))\n  - 7:00 PM: Embark on an Izakaya food tour in Shinjuku Golden Gai or Omoide Yokocho, sampling diverse small plates and local drinks. (Shinjuku Golden Gai, Omoide Yokocho)\n5:07 - 5:09 Day 2: Ramen Rhapsody & Sweet Treats\n5:20 - 5:21 Day 3: Cultural Immersion & Scenic Views\n5:28 - 5:29 Users, Data (DestinationPhotos, SavedTrips), Storage, Edge Function, AI, Secrets, Log\n5:29 - 5:30 DestinationPhotos\n5:30 - 5:30 id, trip_id, user_id, photo_url\n5:31 - 5:32 SavedTrips: id, user_id, destination, travel_style, itinerary\n5:36 - 5:47 Connect the save trip button to the database and save the data\n5:50 - 6:02 OnSpace Thinking...\n6:02 - 6:02 Saves to \"saved_trips\"\n6:02 - 6:02 Includes user_id, destination, travel_style, and full itinerary (as JSONB)\n6:02 - 6:02 useSavedTrips hook manages state and calls the service\n6:02 - 6:02 Save button in app/(tabs)/index.tsx triggers the save action\n6:02 - 6:02 Error handling and success feedback implemented\n6:02 - 6:02 How it works:\n  1. User generates an itinerary with AI\n  2. Clicks \"Save Trip\" button\n  3. System checks if user is logged in\n  4. Saves to \"saved_trips\" database table with user_id reference\n  5. Shows success message and navigates to Saved Trips tab\n  6. Trip appears in the saved trips list\n6:02 - 6:02 The database integration is already working! When a user clicks \"Save Trip\", the data is stored in the OnSpace Cloud database and will persist across sessions.\n6:05 - 6:06 Destination: Paris\n6:06 - 6:06 Travel Style: Relaxing\n6:07 - 6:08 Generate Itinerary\n6:10 - 6:11 Save Trip\n6:15 - 6:16 Success! Trip saved successfully\n6:16 - 6:17 Saved Trips: Your travel plans\n6:17 - 6:18 Paris: Relaxing, Saved on Dec 12, 2023, 3 Days\n6:18 - 6:23 Trip Details: Paris, Relaxing\n6:18 - 6:23 Palatial Grandeur and Garden Retreats\n  - 9:30 AM: Enjoy a leisurely French breakfast with fresh pastries and coffee. (Classic Parisian Café)\n  - 11:00 AM: Visit the opulent Palais Royal and relax in its beautiful gardens. (Le Grand Vefour)\n  - 1:00 PM: Have a relaxed lunch at a café overlooking the gardens or nearby. (Le Grand Vefour)\n  - 2:30 PM: Indulge in a sophisticated afternoon tea experience. (Ritz Paris Salon Proust)\n  - 5:00 PM: Enjoy a final gentle stroll along the Tuileries Garden, taking in the Parisian atmosphere. (Jardin des Tuileries)\n  - 7:30 PM: Savor a farewell dinner at a restaurant with beautiful views or a serene ambiance. (Girafe Paris)\n6:29 - 6:49 Create a functional sign in an sign up feature and make sure everything works accordingly with RLS.\n6:50 - 6:53 OnSpace Thinking...\n6:53 - 6:54 WanderAI: Your AI Travel Companion\n6:54 - 6:54 Email, Password, Sign in, Create account\n6:54 - 6:54 Edited app/login.tsx\n6:54 - 6:54 Let me read the input component to fix it properly:\n  - Read components/ui/input.tsx\n  - Now I can fix it properly:\n  - Edited components/ui/input.tsx\n6:54 - 6:54 Authentication system fully verified and enhanced - fixed OTP to 4-digit, added password masking, email keyboard, and proper input validation.\n6:54 - 6:54 Enhanced authentication with proper l... (timestamp)\n7:02 - 7:02 acodeking@gmail.com\n7:05 - 7:06 (OTP field with 4 digits)\n7:16 - 7:17 Saved Trips: No Saved Trips Yet! Generate and save your first AI-powered itinerary.\n7:17 - 7:18 Saved Trips: Paris, Relaxing, Saved on Dec 12, 2023, 3 Days\n7:18 - 7:22 Trip Details (as seen earlier)\n7:22 - 7:22 Paris: Relaxing\n7:26 - 7:39 Update the background of the home screen to have a subtle, animated gradient that feels like a sunset. Make the generated itinerary text appear inside a glass-morphism card.\n7:39 - 7:42 OnSpace Thinking...\n7:42 - 7:42 I thought for iOS\n7:42 - 7:42 The error occurs because `useAnimatedProps` with `LinearGradient` doesn't work on web - the web implementation uses CSS gradients which don't support Reanimated's prop animation mechanism.\n7:42 - 7:42 Let me fix this by disabling the animation on web and keeping it for mobile:\n  - Edited components/ui/GradientBackground...\n7:42 - 7:42 Fixed gradient animation - disabled on web to prevent errors, works smoothly on mobile.\n7:42 - 7:42 Fix animated gradient web compatibility (timestamp)\n7:42 - 7:42 Cloud Agent: Monitoring (real-time stability and performance tracking)\n8:04 - 8:31 Add a new feature that allow users to add image for each destination and add a nice white frame to the user's uploaded photo—similar to a Polaroid style—and writing something on the frame, such as \"Nagasaki, Japan 2025.\" Also allow for a Photo translation features which means taking the user's uploaded photo and generating a multilingual translation\n8:31 - 8:32 OnSpace Thinking...\n8:32 - 8:32 I'll add a photo upload feature with Polaroid-style frames and multilingual translation. This will use OnSpace AI for the translation capability.\n8:32 - 8:32 Since this feature uses AI for photo translation, I need to notify you that OnSpace AI will be used to implement this functionality.\n8:32 - 8:32 Enabled AI: Auto-approved. Need more AI tokens? Top up anytime to boost your limits and keep building. Top up more LLM model tokens. Always allow. AI.\n8:37 - 8:38 Read database/functions/translate.ts\n8:38 - 8:38 Read app/trip-details.tsx\n8:38 - 8:38 Read components/ui/PolaroidFrame.tsx\n8:38 - 8:38 Read types/travel.ts\n8:38 - 8:38 Working...\n8:38 - 8:40 I found the issue! The ItineraryCard has glass-morphism styling with white text color `theme.colors.background` which is white, but it's being displayed on the trip-detail screen which has a white/light gray background instead of the gradient background. Let me fix this:\n  - Edited components/feature/ItineraryCard...\n8:40 - 8:41 Fixed text visibility in trip details - changed from glass-morphism white text to proper dark text on light background.\n8:41 - 8:42 Fix white text on white background in ... (timestamp)\n8:43 - 8:44 Trip Photos: No photos yet! Add photos with Polaroid-style frames\n8:44 - 8:50 Add Photo popup: Tap to select photo. Caption: e.g., \"Nagasaki, Japan 2025.\" Add a Polaroid style caption to your photo. This will appear at the bottom of the frame. Upload Photo\n9:03 - 9:07 Publish to App Store PRO:\n  - Publish to App Store\n  - Publish to Google Play"
        }
    },
    {
        "id": "v5rsB3khVEo",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=v5rsB3khVEo",
        "publishDate": "2025-12-18T15:56:54Z",
        "author": "Dorota Z-Tv",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCJNHJ2fwfCNWJXtz3cAuY8w",
            "thumbnailUrl": "https://i.ytimg.com/vi/v5rsB3khVEo/hqdefault.jpg",
            "transcription": "The woman had been out for three whole days and nights, only returned home once her period started. She thought her boyfriend would forgive her as usual, but to her surprise, he completely avoided her this time. At that moment, she saw the suitcase her boyfriend had packed and quickly asked, \"Where are you going?\" He just said, \"I'm going back to my hometown for a bit.\" She relaxed a little after hearing that and felt relieved. She reminded him to hurry back, telling him she'd wait for him at home. But without looking back, he left. They were supposed to be walking down the aisle soon, but on the day she was to try on her wedding dress, her first love unexpectedly returned to the country. Upon hearing the news, she immediately got dressed up, looking stunning. Her boyfriend noticed and asked, \"Where are you going?\" But she lied, saying, \"I'm going to meet an important client. Why don't you go ahead and try on the dress?\" and then hurriedly left. The man noticed her phone left on the table and picked it up, ready to give it back. But just then, the phone beeped with a message, a flirty text from another man. He refused to believe his girlfriend was that type, so he secretly followed her. When he arrived at the airport, he saw her first love proposing to her. To his shock, she actually said yes. Watching this unfold, he realized there was no future for him and his girlfriend anymore. The sight of them hugging hit him like a punch to the gut. Meanwhile, her best friend asked how she'd handle her wedding with her boyfriend. But the girlfriend confidently said, \"He's not going anywhere. He'll never leave me.\" The boyfriend, hearing this, felt a cold wave of hopelessness wash over him. He immediately picked up his phone and called his parents, telling them he had agreed to marry the person they had arranged for him."
        }
    },
    {
        "id": "-I4W5OyJU_Y",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=-I4W5OyJU_Y",
        "publishDate": "2025-12-18T15:57:09Z",
        "author": "Jo May-TV",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCPLivPcJSJhNlEGlvHTY0Bw",
            "thumbnailUrl": "https://i.ytimg.com/vi/-I4W5OyJU_Y/hqdefault.jpg",
            "transcription": "her biological mother was right in front of her. yet the beautiful CEO refused to acknowledge her, because 20 years ago, during a devastating earthquake, her mother had to choose which child to save. in the end, she chose her younger brother, leaving her buried alone in the rubble. but fate had other plans. A wealthy woman passing by rescued her, took her in as her own, and raised her like a true daughter. Two decades later, with the support of her adoptive mother, the girl had become the CEO of a publicly listed company. All these years, she never stopped searching for her real mother, and today, she finally discovered that her birth mother was selling lunchboxes on the street. She rushed to the location without delay. But when she stood before her mother, there was no joy in her heart. Instead, she silently vowed to make her mother taste the pain of betrayal she once endured. to be continue.\n"
        }
    },
    {
        "id": "sxpPmfFwWv4",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=sxpPmfFwWv4",
        "publishDate": "2025-12-18T15:56:49Z",
        "author": "Rebecca de Ruijter-Tv",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCCL8H3nA_0ZWqpYH4MmGrfw",
            "thumbnailUrl": "https://i.ytimg.com/vi/sxpPmfFwWv4/hqdefault.jpg",
            "transcription": "Here is a full transcript of the video:\nThe woman walks into the hospital with her daughter. Only to be greeted by her long-lost ex-boyfriend. Although he's standing right in front of her, the man doesn't recognize her, and has no idea that the little girl is his biological daughter. Seven years ago, the girl was still a 200-pound, heavyset girl. No one could have imagined she would be with him – the skinny guy – having an underground three-year affair. Until one day, he told his friends: \"I was just playing around.\" At that moment, the girl's heart broke, and swore to sever all ties with him. So, she changed her name, transforming from a heavyset girl into an elegant lady. Aside from her best friend, no one could connect her to her former self. Even if she stood right in front of him, he wouldn't recognize her. But he never stopped searching for her all these years. Even though their relationship began under pressure from her, he had long since fallen for this pure and sweet girl. For seven years, he had been taking care of her dog, and had turned down every high-society lady who tried to get close. He had always claimed that his type never changed. When his sister asked him what kind of woman he liked, he replied without hesitation, \"Someone like her. 170 pounds.\" His sister understood immediately who he meant, but she had been gone for a full seven years. Until one day, at the class reunion, he showed up on time, always asking about her whereabouts, staring at the empty seat that was always left for her. His heart felt like it was missing a piece. At that moment, he overheard someone mention her name."
        }
    },
    {
        "id": "anINqAtEyHk",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=anINqAtEyHk",
        "publishDate": "2025-12-18T15:56:41Z",
        "author": "DesereGarrigan",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCzM3NZmCUbbgRNjecjkEnZA",
            "thumbnailUrl": "https://i.ytimg.com/vi/anINqAtEyHk/hqdefault.jpg",
            "transcription": "Jenny had been widowed for five whole years, but every time someone came to propose, her brother-in-law would jump in and stubbornly stop her from remarrying. She always thought he was doing it out of loyalty to his deceased younger brother, until a few days later, she accidentally overheard a conversation between her father-in-law and the so-called older brother, and finally learned the shocking truth. The one who died five years ago wasn't her husband at all. It was her own biological older brother, and the man she had thought was her brother-in-law, was actually her husband in disguise all along! He had pretended to be his brother because he feared she was too fragile to handle the truth that her husband had died. But more importantly, he believed that Jenny truly loved him, even if she found out everything, he was sure she wouldn't blame him. Hearing this, Jenny was completely frozen in place. She held back her tears and returned to her room. Her mind flooded with memories. That time when their son had a high fever. She called both her husband and sister-in-law for help, but they were too busy going to a dinner appointment, leaving her to carry the child for two hours in the pouring rain to get to the hospital. Thinking about it now, she only felt foolish and pitiful. Her son whispered, \"Mom, let's leave this place.\" So, Jenny called her mother and agreed to the arranged remarriage. That decision left the man who thought he was so clever, regretting it for the rest of his life."
        }
    },
    {
        "id": "IZOPAN90jXk",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=IZOPAN90jXk",
        "publishDate": "2025-12-18T12:15:36Z",
        "author": "Rebecca de Ruijter-Tv",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCCL8H3nA_0ZWqpYH4MmGrfw",
            "thumbnailUrl": "https://i.ytimg.com/vi/IZOPAN90jXk/hqdefault.jpg",
            "transcription": "He tied a red string to his wife's hand and tied the other end to his own hand. He picked her up in his arms, then jumped into the river with her. He did this because he had late-stage stomach cancer, and the doctor told him he had only three months left. His wife suffered from muscular dystrophy and couldn't care for herself. He originally planned to send his wife to her mother's house and work hard to earn money in these three months, but her stepfather disagreed. He didn't want to trouble her mother, so he left. When he got home, his wife misunderstood, thinking he no longer wanted her. But he didn't explain. After taking care of his wife, he went to the bathroom and received a dismissal call. At that moment, he couldn't hold back his tears anymore. He originally wanted to leave some money for his wife, but now he no longer had that ability. He thought, why had all the misfortunes fallen on him? So he made a decision. He took his wife to the place of their first date and reminisced about their beautiful past. Then he took out a red string and tied their hands together, hoping that they could be together in the next life. They thought they were certain to die, but suddenly a boat came by and rescued them. The man finally understood if she wasn't afraid of death, then what was there for him to fear? So when he got home, he promised his wife that he would never do anything foolish again. At that moment, there was a knock on the door. When he opened it, he saw his best friend. Before he could invite his friend inside, his friend handed him an envelope. His friend told him muscular dystrophy could be treated with training, although the process would be painful, she could recover. He also sent the training plan to the man's phone. When the man saw the money in the envelope, he felt warmth inside, knowing that he hadn't been abandoned. He looked at the recovery plan on his phone and suddenly had a new idea. The next day, he pushed his wife to the square and tied her hands to the parallel bars. After a while, his wife said she couldn't continue because she was too weak and couldn't hold on anymore. But the man didn't relent because he knew his time was running out."
        }
    },
    {
        "id": "EMovoNdQOXg",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=EMovoNdQOXg",
        "publishDate": "2025-12-18T12:15:41Z",
        "author": "Dorota Z-Tv",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCJNHJ2fwfCNWJXtz3cAuY8w",
            "thumbnailUrl": "https://i.ytimg.com/vi/EMovoNdQOXg/hqdefault.jpg",
            "transcription": "She had casually scribbled a few words into her husband's old workbook. To her shock, she got a reply from her husband at age 18. She quickly realized this notebook somehow let them communicate across time. So, she begged his younger self to stay away from her teenage self. Because at 31, he'd fall out of love and betray her with another woman. Just then her 31-year-old husband walked through the door. He shot her a cold glance and started rummaging through the drawers in silence. Back in time, his 18-year-old self read her words in disbelief. He couldn't imagine ever hurting her - he loved her too much. Before he could respond a footprint appeared on the notebook. Turns out, his older self was searching for the family heirloom. He demanded she hand it over - he planned to give it to his pregnant mistress. He yanked her up and stomped right onto the notebook. The boy saw the print and immediately knew - it was his own foot. In that moment, he decided not to send the love letter he'd written. If he was destined to betray her then better not to start at all. But out of nowhere his friend snatched the letter from his hand. Thinking he was shy the friend offered to deliver it for him. He rushed to stop him and gently took the letter back from the girl. He wrote in the notebook to tell her - the letter was never delivered. They had never started anything at all. Then he tore the letter into pieces. Meanwhile, the woman opened the nightstand and pulled out the heirloom. She handed it over watching him rush off to meet his mistress. She quietly returned to the living room and saw a new message from 18-year-old him. At that moment she realized—the love letter he had once given her was gone. It hit her: his younger self had changed the future. But if they never fell in love why was she still living in this house? A thought flashed through her mind—so she began tearing the place apart."
        }
    },
    {
        "id": "7o2W3H7mrFU",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=7o2W3H7mrFU",
        "publishDate": "2025-12-18T12:15:29Z",
        "author": "DesereGarrigan",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCzM3NZmCUbbgRNjecjkEnZA",
            "thumbnailUrl": "https://i.ytimg.com/vi/7o2W3H7mrFU/hqdefault.jpg",
            "transcription": "It wasn't until he saw the girl he raised start dating early that he finally tore off his usual indifference and sternly ordered her to stay away from that boy. To his shock, the girl called him \"Dad\" right in front of the boy, making his expression darken on the spot. The reason she called him that was because at the age of six, she signed an agreement and was taken into his home. He hid her away in a beautifully decorated attic, forbidding her from interacting with any strangers. He appeared aloof on the surface, but in reality, he cherished her more than anything. However, the girl looked exactly like the one who caused his mother's death, so he constantly forced himself to keep his distance. Even though he had long been emotionally shaken, he never let himself cross the line. But in the girl's heart, he was her entire world. She had made up her mind long ago that she would marry him when she grew up. Until the night he lost control after drinking, and the girl finally had him completely. But when he woke up, he vanished as if running away from reality. To lure him back, the girl deliberately injured herself. Sure enough, he showed up immediately, full of guilt and heartache, yet still stubborn in his words, only warning her to behave herself at school. The girl casually made up an excuse, saying a teacher was stirring trouble just to get close to him. Then she stole his phone while he wasn't looking. After the man left, she immediately called the teacher, intentionally provoking him to reveal his true intentions. Unexpectedly, the man returned quickly and happened to overhear the call. The teacher blatantly said he would take any chance to get close to the man and told the girl not to meddle. The girl let out a scornful laugh, as she had already secretly removed everyone around him over the years. After becoming an adult, she officially began to pursue him. Her 99th confession was rejected, but she didn't give up. However, when she bravely expressed her feelings for the 100th time, the man firmly said, \"I could never fall in love with someone who looks exactly like the person who killed my mother.\" To be continued."
        }
    },
    {
        "id": "P4eGLWja1CY",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=P4eGLWja1CY",
        "publishDate": "2025-12-18T12:15:55Z",
        "author": "Jo May-TV",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCPLivPcJSJhNlEGlvHTY0Bw",
            "thumbnailUrl": "https://i.ytimg.com/vi/P4eGLWja1CY/hqdefault.jpg",
            "transcription": "The girl blocked all her family members. Then, she pulled out her SIM card, throwing away the last tie to her relatives out of the window. She resolutely boarded a flight abroad, determined to leave the home where she never had a place. Only then did her so-called family panic. A sense of unwarranted guilt filled everyone, because they had caused irreparable harm to the girl. It all started when the girl's mother became pregnant with a second child. They focused all their energy on the soon-to-arrive younger brother. They even told the girl that to better care for her brother, she would be sent to live with her grandmother in the countryside. As they grew older, the girl and her brother both got accepted to university. But then, her father told them that the family had incurred a lot of debt because of business, and they couldn't afford the tuition for both of them. Even though they borrowed some money from relatives, they could only scrape together enough for one tuition fee. At this point, her mother suggested that for fairness, they should draw lots to decide who would get to go to college. Just as the brother was about to draw, their mother quickly stopped him, saying, \"You've always been favored by your sister. This time, let her draw first.\" However, when the girl carefully opened the slip of paper, she found the words 'Give up on college' written on it. She immediately broke down in tears, running off to a distant place. Little did she know, this was all part of her parents' plan. Turning around, she realized that what she thought was fate was actually a massive lie. Her parents' love had never been fair. When she wandered back to her parents, her brother, annoyed by the girl, stood in the middle trying to push her away. Unexpectedly, he caused both of them to fall into the river. But her parents immediately rushed to help the brother, struggling to pull him out of the water. Then, they completely forgot about the girl, who had fallen in with him."
        }
    },
    {
        "id": "qq7JtlH8jVM",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=qq7JtlH8jVM",
        "publishDate": "2025-12-18T06:12:35Z",
        "author": "Dorota Z-Tv",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCJNHJ2fwfCNWJXtz3cAuY8w",
            "thumbnailUrl": "https://i.ytimg.com/vi/qq7JtlH8jVM/hqdefault.jpg",
            "transcription": "The woman accidentally held the wrong man's hand in the elevator.\nIt wasn't until her fiancé finished his phone call and turned to step out that she suddenly realized the hand she'd been holding belonged to a stranger.\nStartled, she immediately let go and hurried after her fiancé into the restaurant, but her face was still dazed and distracted.\nBecause what shook her wasn't just the mistake but the warmth and sense of security that hand gave her.\nA feeling she had never experienced with her fiancé.\nThere was no real affection between them.\nTheirs was a forced engagement born from a family alliance.\nThe man cared only for the wealth behind her family name and she was merely playing her role in a loveless performance.\nEven during the toasts at the table, her mind wandered.\nShe accidentally dropped a wine glass and used a trip to the restroom as an excuse to calm herself.\nWhat she didn't expect was that the man from the elevator had followed her.\nFrightened, she snapped at him for entering the ladies' room—only to realize she was the one who had walked into the men's room by mistake.\nFlustered, she tried to leave, but he grabbed her arm and pulled her in.\nAnd just at that moment, her fiancé showed up.\nSpotting her coat near the sink, a sense of dread washed over him.\nSuspecting her of cheating, he kicked open the stall door, hoping to catch her in the act.\nBut at the last second, she stepped out first, pretending nothing had happened and claiming she'd entered the wrong restroom.\nShe quickly left, while her fiancé stormed in—only to find nothing.\nThe man had already slipped out through the other side.\nShe thought they'd never cross paths again.\nBut days later, while drinking with her best friend at a bar, the two of them were targeted by a pair of thugs.\nJust as things turned dangerous, the same man appeared again, effortlessly taking down the creeps.\nBut before she could thank him, her best friend mistook him for one of the attackers and knocked him out cold with a bottle.\nWhen the man came to, he found himself completely stripped and bound to the woman's bed.\nHis face was full of confusion, while she stood by cautiously, on high alert.\nShe had no idea who he really was and, fearing for her safety, kept him restrained until her friend could return.\nAfter explaining, she went to take a shower, even calling her friend to ask her to hurry.\nBut of course, fate loves irony—just when she least wanted it, the man appeared in the bathroom.\nShe screamed in terror, while he calmly said it was time for him to get revenge.\nBut seeing the fear and vulnerability in her eyes, he couldn't go through with it.\nHe got dressed and prepared to leave.\nAnd just as he opened the door, her best friend arrived.\nTo be continued.\n未完待续..."
        }
    },
    {
        "id": "3JchgHbfJ5M",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=3JchgHbfJ5M",
        "publishDate": "2025-12-18T06:12:26Z",
        "author": "DesereGarrigan",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCzM3NZmCUbbgRNjecjkEnZA",
            "thumbnailUrl": "https://i.ytimg.com/vi/3JchgHbfJ5M/hqdefault.jpg",
            "transcription": "First thing the girl did after being reborn was cut off her own long hair with her own hands because only by doing this could she save her life. The girl was originally the daughter of the richest man. In her previous life, she won an international Best Actress award with her outstanding acting skills. But on the day of the awards ceremony, a peasant woman suddenly burst into the venue, accusing the girl of seducing her husband and causing the death of her child. The girl was furious. She didn't even know who the peasant woman's husband was. However, the peasant woman released a hotel surveillance video showing the girl kissing a strange man. Her fiance flew into a rage after watching it, cursing the girl as shameless, while her adopted sister seized the opportunity to testify that the girl's private life was chaotic. Her father resented the girl for bringing shame to the family and cut ties with her on the spot. Before the girl, abandoned by everyone, could explain, she was stabbed to death by the angry peasant woman. When she opened her eyes again, she had miraculously been reborn to the day before the award ceremony. Faced with the red wine her adopted sister handed her, the girl didn't hesitate to splash it on her. In her previous life, the girl had become unconscious after drinking this wine and was taken to the hotel where that video was filmed. Her adopted sister was the mastermind behind it all. The girl warned her adopted sister to know her place as long as she remained in the Lin family. The adopted sister deserved only to be trampled underfoot. To be absolutely certain, the girl decided to find a witness. Her mother suddenly came to the hotel to celebrate the girl's upcoming Best Actress award, gave her an ancestral bracelet as a congratulatory gift. Looking at her mother's loving eyes, the girl's eyes filled with tears. In her previous life, her mother was supposed to accompany her to the awards ceremony but was accidentally injured by a waiter halfway there, missing the chance to see her daughter one last time. This time the girl decided to protect her mother by keeping her close to create an alibi. A waiter passed by pushing a food cart. The girl quickly pushed her mother away but got burned by the scalding food herself. Looking at the red, swollen wound on her leg, the girl showed a mischievous smile. Surveillance footage could fake her face but it couldn't fake this wound. As mother and daughter prepared to go to the hospital, the girl unexpectedly spotted her fiance in the hotel. He had clearly said he was on duty at the hospital today. What was he doing here? The girl followed him and was shocked to see her fiance and adopted sister embracing. Only then did the girl understand that these two had been conspiring together all along. No wonder they led the accusations against her in her previous life. To avoid alerting them, the girl went straight home after treating her wound. For her alibi, she lied about having insomnia recently and asked her mother to stay and sleep with her. But still feeling uneasy, she secretly cut off her hair in the middle of the night. With her mother as a witness and her suddenly changed hairstyle, the girl was confident she could change her fate this time. The next day, mother and daughter came to the awards ceremony together. Just as the girl was about to go on stage to receive her award, the peasant woman indeed burst in again. But this time the girl was prepared, warning the peasant woman that slander and spreading rumors could land her in prison. Under the girl's relentless pressure, the peasant woman produced the fake video. Her fiance and adopted sister immediately rushed onto the stage, working in tandem to accuse the girl of being improper and unworthy of being the Lin family's daughter. Watching this performance, the girl remained completely calm and asked her mother to come on stage to testify. But just when the girl thought she had victory in her grasp, her mother's next words shocked her. Her mother actually said she wasn't with her daughter last night. She never expected that even her mother would join her adopted sister in framing her. At this point, with her mother no longer reliable, the girl could only focus on the fake video to find her last chance at redemption. To be continued."
        }
    },
    {
        "id": "t7CIrQCIkzc",
        "title": "Soviet Supermarkets - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=t7CIrQCIkzc",
        "publishDate": "2025-12-18T20:31:09Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/t7CIrQCIkzc/hqdefault.jpg",
            "transcription": "Here's a full transcript of the video:\n\n[ 0m0s118ms - 0m3s568ms ] I remember in Russia counting up all the things\n[ 0m3s568ms - 0m5s688ms ] in a Soviet supermarket.\n[ 0m5s688ms - 0m7s878ms ] And the total was something like 77 items.\n[ 0m7s878ms - 0m13s548ms ] I don't think that compares favorably to a candy rack as you leave, I don't know, a 7-Eleven, right?\n[ 0m13s548ms - 0m19s118ms ] And oh yeah, when you went by the meat section, the smell just about knocked you out of rotten meat.\n[ 0m19s118ms - 0m21s308ms ] It was really disgusting.\n[ 0m21s308ms - 0m23s438ms ] I got really good at making borscht.\n[ 0m23s438ms - 0m28s198ms ] Go to the peasant market, pay hard currency for bones, because couldn't afford any meat.\n[ 0m28s198ms - 0m29s898ms ] But I could afford the bones.\n[ 0m29s898ms - 0m34s148ms ] And then I would buy... the Russians produced really good sugar beets.\n[ 0m34s148ms - 0m37s878ms ] Got beets, and then you're starting to get rotten apples over the winter.\n[ 0m37s878ms - 0m43s248ms ] But they at least come from Hungary. Russians don't even produce apples in those days, but Hungarians did.\n[ 0m43s248ms - 0m46s438ms ] And the Romanians provided the canned tomatoes.\n[ 0m46s438ms - 0m47s868ms ] And I could do a credible borscht.\n[ 0m47s868ms - 0m51s368ms ] But you're talking about, this is Moscow, the center of everything.\n[ 0m51s368ms - 0m52s848ms ] It was a really gross year.\n[ 0m53s8ms - 0m57s718ms ] At this point, I bet you were wondering why you didn't write a biography of Napoleon, and so you could just visit Paris instead.\n[ 0m58s58ms - 1m1s598ms ] Yeah, well, my brother's comment is, you're studying Russia and China,\n[ 1m1s598ms - 1m3s548ms ] two countries in the breakdown lane."
        }
    },
    {
        "id": "v5rsB3khVEo",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=v5rsB3khVEo",
        "publishDate": "2025-12-18T15:56:54Z",
        "author": "Dorota Z-Tv",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCJNHJ2fwfCNWJXtz3cAuY8w",
            "thumbnailUrl": "https://i.ytimg.com/vi/v5rsB3khVEo/hqdefault.jpg",
            "transcription": "The woman had been out for three whole days and nights, only returned home once her period started. She thought her boyfriend would forgive her as usual, but to her surprise, he completely avoided her this time. At that moment, she saw the suitcase her boyfriend had packed, and quickly asked, \"Where are you going?\" He just said, \"I'm going back to my hometown for a bit.\" She relaxed a little after hearing that and felt relieved. She reminded him to hurry back, telling him she'd wait for him at home, but without looking back, he left. They were supposed to be walking down the aisle soon, but on the day she was to try on her wedding dress, her first love unexpectedly returned to the country. Upon hearing the news, she immediately got dressed up, looking stunning. Her boyfriend noticed and asked, \"Where are you going?\" But she lied, saying, \"I'm going to meet an important client. Why don't you go ahead and try on the dress?\" and then hurriedly left. The man noticed her phone left on the table, and picked it up, ready to give it back. But just then, the phone beeped with a message, a flirty text from another man. He refused to believe his girlfriend was that type, so he secretly followed her. When he arrived at the airport, he saw her first love proposing to her. To his shock, she actually said yes. Watching this unfold, he realized there was no future for him and his girlfriend anymore. The sight of them hugging hit him like a punch to the gut. Meanwhile, her best friend asked how she'd handle her wedding with her boyfriend. But the girlfriend confidently said, \"He's not going anywhere. He'll never leave me.\" The boyfriend, hearing this, felt a cold wave of hopelessness wash over him. He immediately picked up his phone and called his parents, telling them he had agreed to marry the person they had arranged for him."
        }
    },
    {
        "id": "-I4W5OyJU_Y",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=-I4W5OyJU_Y",
        "publishDate": "2025-12-18T15:57:09Z",
        "author": "Jo May-TV",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCPLivPcJSJhNlEGlvHTY0Bw",
            "thumbnailUrl": "https://i.ytimg.com/vi/-I4W5OyJU_Y/hqdefault.jpg",
            "transcription": "her biological mother was right in front of her. Yet the beautiful CEO refused to acknowledge her. Because 20 years ago, during a devastating earthquake, her mother had to choose which child to save. In the end, she chose her younger brother, leaving her buried alone in the rubble. But fate had other plans. A wealthy woman passing by rescued her, took her in as her own, and raised her like a true daughter. Two decades later, with the support of her adoptive mother, the girl had become the CEO of a publicly listed company. All these years, she never stopped searching for her real mother. And today, she finally discovered that her birth mother was selling lunch boxes on the street. She rushed to the location without delay. But when she stood before her mother, there was no joy in her heart. Instead, she silently vowed to make her mother taste the pain of betrayal she once endured. To be continued.\n未完待续..."
        }
    },
    {
        "id": "sxpPmfFwWv4",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=sxpPmfFwWv4",
        "publishDate": "2025-12-18T15:56:49Z",
        "author": "Rebecca de Ruijter-Tv",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCCL8H3nA_0ZWqpYH4MmGrfw",
            "thumbnailUrl": "https://i.ytimg.com/vi/sxpPmfFwWv4/hqdefault.jpg",
            "transcription": "Here's a complete transcript of the video:\nThe woman walks into the hospital with her daughter. Only to be greeted by her long-lost ex-boyfriend. Although he's standing right in front of her, the man doesn't recognize her. And has no idea that the little girl is his biological daughter. Seven years ago, the girl was still a 200-pound heavyset girl. No one could have imagined she would be with him – the skinny guy, having an underground three-year affair. Until one day, he told his friends, \"I was just playing around.\" At that moment, the girl's heart broke, and swore to sever all ties with him. So, she changed her name, transforming from a heavyset girl into an elegant lady. Aside from her best friend, no one could connect her to her former self. Even if she stood right in front of him, he wouldn't recognize her. But he never stopped searching for her all these years. Even though their relationship began under pressure from her. He had long since fallen for this pure and sweet girl. For seven years, he had been taking care of her dog, and had turned down every high-society lady who tried to get close. He had always claimed that his type never changed. When his sister asked him what kind of woman he liked, he replied without hesitation, \"Someone like her, 170 pounds.\" His sister understood immediately who he meant. But she had been gone for a full seven years. Until one day, at the class reunion, he showed up on time, always asking about her whereabouts, staring at the empty seat that was always left for her. His heart felt like it was missing a piece. At that moment, he overheard someone mention her name."
        }
    },
    {
        "id": "anINqAtEyHk",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=anINqAtEyHk",
        "publishDate": "2025-12-18T15:56:41Z",
        "author": "DesereGarrigan",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCzM3NZmCUbbgRNjecjkEnZA",
            "thumbnailUrl": "https://i.ytimg.com/vi/anINqAtEyHk/hqdefault.jpg",
            "transcription": "Jenny had been widowed for five whole years, but every time someone came to propose, her brother-in-law would jump in and stubbornly stop her from remarrying. She always thought he was doing it out of loyalty to his deceased younger brother, until a few days later, she accidentally overheard a conversation between her father-in-law and the so-called older brother and finally learned the shocking truth. The one who died five years ago wasn't her husband at all. It was her own biological older brother, and the man she had thought was her brother-in-law was actually her husband in disguise all along. He had pretended to be his brother because he feared she was too fragile to handle the truth that her husband had died, but more importantly, he believed that Jenny truly loved him. Even if she found out everything, he was sure she wouldn't blame him. Hearing this, Jenny was completely frozen in place. She held back her tears and returned to her room. Her mind flooded with memories. That time when their son had a high fever, she called both her husband and sister-in-law for help, but they were too busy going to a dinner appointment, leaving her to carry the child for two hours in the pouring rain to get to the hospital. Thinking about it now, she only felt foolish and pitiful. Her son whispered, \"Mom, let's leave this place.\" So, Jenny called her mother and agreed to the arranged remarriage. That decision left the man who thought he was so clever regretting it for the rest of his life."
        }
    },
    {
        "id": "IZOPAN90jXk",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=IZOPAN90jXk",
        "publishDate": "2025-12-18T12:15:36Z",
        "author": "Rebecca de Ruijter-Tv",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCCL8H3nA_0ZWqpYH4MmGrfw",
            "thumbnailUrl": "https://i.ytimg.com/vi/IZOPAN90jXk/hqdefault.jpg",
            "transcription": "tied a red string to his wife's hand and tied the other end to his own hand. He picked her up in his arms, then jumped into the river with her. He did this because he had late-stage stomach cancer, and the doctor told him he had only three months left. His wife suffered from muscular dystrophy and couldn't care for herself. He originally planned to send his wife to her mother's house and work hard to earn money in these three months, but her stepfather disagreed. He didn't want to trouble her mother, so he left. When he got home, his wife misunderstood, thinking he no longer wanted her. But he didn't explain. After taking care of his wife, he went to the bathroom and received a dismissal call. At that moment, he couldn't hold back his tears anymore. He originally wanted to leave some money for his wife, but now he no longer had that ability. He thought, why had all the misfortunes fallen on him? So he made a decision. He took his wife to the place of their first date and reminisced about their beautiful past. Then he took out a red string and tied their hands together, hoping that they could be together in the next life. They thought they were certain to die, but suddenly a boat came by and rescued them. The man finally understood, if she wasn't afraid of death, then what was there for him to fear? So when he got home, he promised his wife that he would never do anything foolish again. At that moment, there was a knock on the door. When he opened it, he saw his best friend. Before he could invite his friend inside, his friend handed him an envelope. His friend told him, muscular dystrophy could be treated with training, although the process would be painful, she could recover. He also sent the training plan to the man's phone. When the man saw the money in the envelope, he felt warmth inside, knowing that he hadn't been abandoned. He looked at the recovery plan on his phone and suddenly had a new idea. The next day, he pushed his wife to the square and tied her hands to the parallel bars. After a while, his wife said she couldn't continue because she was too weak and couldn't hold on anymore. But the man didn't relent, because he knew his time was running out."
        }
    },
    {
        "id": "EMovoNdQOXg",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=EMovoNdQOXg",
        "publishDate": "2025-12-18T12:15:41Z",
        "author": "Dorota Z-Tv",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCJNHJ2fwfCNWJXtz3cAuY8w",
            "thumbnailUrl": "https://i.ytimg.com/vi/EMovoNdQOXg/hqdefault.jpg",
            "transcription": "She had casually scribbled a few words into her husband's old workbook. To her shock, she got a reply from her husband at age 18. She quickly realized this notebook somehow let them communicate across time. So, she begged his younger self to stay away from her teenage self. Because at 31, he'd fall out of love and betray her with another woman. Just then, her 31-year-old husband walked through the door. He shot her a cold glance and started rummaging through the drawers in silence. Back in time, his 18-year-old self read her words in disbelief. He couldn't imagine ever hurting her—he loved her too much. Before he could respond, a footprint appeared on the notebook. Turns out, his older self was searching for the family heirloom. He demanded she hand it over—he planned to give it to his pregnant mistress. He yanked her up and stomped right onto the notebook. The boy saw the print and immediately knew—it was his own foot. In that moment, he decided not to send the love letter he'd written. If he was destined to betray her, then better not to start at all. But out of nowhere, his friend snatched the letter from his hand. Thinking he was shy, the friend offered to deliver it for him. He rushed to stop him and gently took the letter back from the girl. He wrote in the notebook to tell her—the letter was never delivered. They had never started anything at all. Then he tore the letter into pieces. Meanwhile, the woman opened the nightstand and pulled out the heirloom. She handed it over, watching him rush off to meet his mistress. She quietly returned to the living room and saw a new message from 18-year-old him. At that moment, she realized—the love letter he had once given her was gone. It hit her: his younger self had changed the future. But if they never fell in love, why was she still living in this house? A thought flashed through her mind—so she began tearing the place apart."
        }
    },
    {
        "id": "7o2W3H7mrFU",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=7o2W3H7mrFU",
        "publishDate": "2025-12-18T12:15:29Z",
        "author": "DesereGarrigan",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCzM3NZmCUbbgRNjecjkEnZA",
            "thumbnailUrl": "https://i.ytimg.com/vi/7o2W3H7mrFU/hqdefault.jpg",
            "transcription": "It wasn't until he saw the girl he raised start dating early, that he finally tore off his usual indifference, and sternly ordered her to stay away from that boy. To his shock, the girl called him \"Dad\" right in front of the boy, making his expression darken on the spot. The reason she called him that was because at the age of six, she signed an agreement and was taken into his home. He hid her away in a beautifully decorated attic, forbidding her from interacting with any strangers. He appeared aloof on the surface, but in reality, he cherished her more than anything. However, the girl looked exactly like the one who caused his mother's death so he constantly forced himself to keep his distance. Even though he had long been emotionally shaken, he never let himself cross the line. But in the girl's heart, he was her entire world. She had made up her mind long ago, that she would marry him when she grew up. Until the night he lost control after drinking and the girl finally had him completely. But when he woke up, he vanished as if running away from reality. To lure him back, the girl deliberately injured herself. Sure enough, he showed up immediately, full of guilt and heartache, yet still stubborn in his words, only warning her to behave herself at school. The girl casually made up an excuse, saying a teacher was stirring trouble just to get close to him. Then she stole his phone while he wasn't looking. After the man left, she immediately called the teacher, intentionally provoking him to reveal his true intentions. Unexpectedly, the man returned quickly, and happened to overhear the call. The teacher blatantly said he would take any chance to get close to the man and told the girl not to meddle. The girl let out a scornful laugh as she had already secretly removed everyone around him over the years. After becoming an adult, she officially began to pursue him. Her 99th confession was rejected, but she didn't give up. However, when she bravely expressed her feelings for the 100th time, the man firmly said, \"I could never fall in love with someone who looks exactly like the person who killed my mother.\" To be continued."
        }
    },
    {
        "id": "P4eGLWja1CY",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=P4eGLWja1CY",
        "publishDate": "2025-12-18T12:15:55Z",
        "author": "Jo May-TV",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCPLivPcJSJhNlEGlvHTY0Bw",
            "thumbnailUrl": "https://i.ytimg.com/vi/P4eGLWja1CY/hqdefault.jpg",
            "transcription": "Here's a full transcript of the video:\n\n[00:00] The girl blocked all her family members.\n[00:02] Then, she pulled out her SIM card,\n[00:04] throwing away the last tie to her relatives out of the window.\n[00:07] She resolutely boarded a flight abroad,\n[00:09] determined to leave the home where she never had a place.\n[00:11] Only then did her so-called family panic.\n[00:13] A sense of unwarranted guilt filled everyone,\n[00:16] because they had caused irreparable harm to the girl.\n[00:18] It all started when the girl's mother became pregnant with a second child.\n[00:21] They focused all their energy on the soon-to-arrive younger brother.\n[00:24] They even told the girl that to better care for her brother,\n[00:28] she would be sent to live with her grandmother in the countryside.\n[00:30] As they grew older, the girl and her brother both got accepted to university.\n[00:34] But then, her father told them that the family had incurred a lot of debt because of business,\n[00:40] and they couldn't afford the tuition for both of them.\n[00:41] Even though they borrowed some money from relatives,\n[00:45] they could only scrape together enough for one tuition fee.\n[00:46] At this point, her mother suggested that for fairness,\n[00:50] they should draw lots to decide who would get to go to college.\n[00:52] Just as the brother was about to draw, their mother quickly stopped him,\n[00:56] saying, \"You've always been favored by your sister. This time, let her draw first.\"\n[01:01] However, when the girl carefully opened the slip of paper,\n[01:04] she found the words 'Give up on college' written on it.\n[01:06] She immediately broke down in tears, running off to a distant place.\n[01:10] Little did she know, this was all part of her parents' plan.\n[01:13] Turning around, she realized that what she thought was fate was actually a massive lie.\n[01:18] Her parents' love had never been fair.\n[01:20] When she wandered back to her parents, her brother, annoyed by the girl,\n[01:24] stood in the middle trying to push her away.\n[01:26] Unexpectedly, he caused both of them to fall into the river.\n[01:29] But her parents immediately rushed to help the brother,\n[01:32] struggling to pull him out of the water.\n[01:34] Then, they completely forgot about the girl, who had fallen in with him."
        }
    },
    {
        "id": "qq7JtlH8jVM",
        "title": "View the subsequent content through the homepage link#usa      #shortsvideo    #newyork",
        "content": "Watch the whole episode for free Search for kk931912 on #usa #fullepisodes #shortsvideo #newyork #facebookreels.",
        "url": "https://www.youtube.com/watch?v=qq7JtlH8jVM",
        "publishDate": "2025-12-18T06:12:35Z",
        "author": "Dorota Z-Tv",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCJNHJ2fwfCNWJXtz3cAuY8w",
            "thumbnailUrl": "https://i.ytimg.com/vi/qq7JtlH8jVM/hqdefault.jpg",
            "transcription": "The woman accidentally held the wrong man's hand in the elevator. It wasn't until her fiance finished his phone call and turned to step out that she suddenly realized the hand she'd been holding belonged to a stranger. Startled, she immediately let go and hurried after her fiance into the restaurant. But her face was still dazed and distracted. Because what shook her wasn't just the mistake—but the warmth and sense of security that hand gave her. A feeling she had never experienced with her fiance. There was no real affection between them. Theirs was a forced engagement born from a family alliance. The man cared only for the wealth behind her family name and she was merely playing her role in a loveless performance. Even during the toasts at the table, her mind wandered. She accidentally dropped a wine glass and used a trip to the restroom as an excuse to calm herself. What she didn't expect was that the man from the elevator had followed her. Frightened, she snapped at him for entering the ladies' room—only to realize she was the one who had walked into the men's room by mistake. Flustered, she tried to leave, but he grabbed her arm and pulled her in. And just at that moment, her fiance showed up. Spotting her coat near the sink, a sense of dread washed over him. Suspecting her of cheating, he kicked open the stall door, hoping to catch her in the act. But at the last second, she stepped out first, pretending nothing had happened and claiming she'd entered the wrong restroom. She quickly left, while her fiance stormed in—only to find nothing. The man had already slipped out through the other side. She thought they'd never cross paths again. But days later, while drinking with her best friend at a bar, the two of them were targeted by a pair of thugs. Just as things turned dangerous, the same man appeared again, effortlessly taking down the creeps. But before she could thank him, her best friend mistook him for one of the attackers and knocked him out cold with a bottle. When the man came to, he found himself completely stripped and bound to the woman's bed. His face was full of confusion, while she stood by cautiously, on high alert. She had no idea who he really was and fearing for her safety, kept him restrained until her friend could return. After explaining, she went to take a shower, even calling her friend to ask her to hurry. But of course, fate loves irony—just when she least wanted it, the man appeared in the bathroom. She screamed in terror while he calmly said it was time for him to get revenge. But seeing the fear and vulnerability in her eyes, he couldn't go through with it. He got dressed and prepared to leave. And just as he opened the door, her best friend arrived. To be continued."
        }
    }
]