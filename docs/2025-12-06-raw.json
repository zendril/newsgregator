[
    {
        "id": "https://news.smol.ai/issues/25-12-05-not-much/",
        "title": "not much happened today",
        "content": "**vLLM 0.12.0** introduces DeepSeek support, GPU Model Runner V2, and quantization improvements with PyTorch 2.9.0 and CUDA 12.9. **NVIDIA** launches CUDA Tile IR and cuTile Python for advanced GPU tensor operations targeting Blackwell GPUs. **Hugging Face** releases Transformers v5 RC with an any-to-any multimodal pipeline supporting models like **Gemma3n** and **Qwen3-Omni**. Agent platforms see updates from **LangChain** with content moderation and cost tracking, **Together AI** and **Meta AI** collaborate on RL for long-horizon workflows, and **SonarSource** integrates static analysis into AI codegen. Economic insights from **OpenRouter** highlight coding as a key AI application, with reasoning models surpassing 50% usage and market bifurcation between premium and open models. Additionally, **Kling Video 2.6** debuts native audio capabilities, and **Runway Gen-4.5**, **Qwen3-TTS**, and **Gemini 3 Pro** advance multimodality.",
        "url": "https://news.smol.ai/issues/25-12-05-not-much/",
        "publishDate": "2025-12-05T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "vllm, nvidia, huggingface, langchain-ai, together-ai, meta-ai-fair, sonarsource, openrouter, runway, gemini, arena, vllm-0.12.0, gemma3n, qwen3-omni, qwen3-vl, gpt-5.1-codex-max, gemini-3-pro, runway-gen-4.5, kling-video-2.6, jeremyphoward, mervenoyann, sydneyrunkle, swyx, maximelabonne, gpu-programming, quantization, multimodality, agent-platforms, reinforcement-learning, static-analysis, reasoning, inference-infrastructure, model-optimization, economics, audio, video-generation"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229674",
        "title": "Nutrient appoints new executives to accelerate next phase of growth",
        "content": "<p>Nutrient, the intelligent document company, today announced the appointment of three senior executives ‚Äî elevating Richard Malloy to Chief Revenue Officer, and welcoming Kari Elassal as Chief Financial Officer and Chris Van Wesep as Chief Marketing Officer. The announcement comes as Nutrient recently marked one year since unifying five industry-leading...</p>\n<p>The post <a href=\"https://ai-techpark.com/nutrient-appoints-new-executives-to-accelerate-next-phase-of-growth/\">Nutrient appoints new executives to accelerate next phase of growth</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/nutrient-appoints-new-executives-to-accelerate-next-phase-of-growth/",
        "publishDate": "2025-12-05T14:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229673",
        "title": "Blend360 Awarded a 2025 AWS Partner Award",
        "content": "<p>Blend360 recognized as Sustainability Partner of the Year ‚Äì LATAM and Public Sector Solution Provider Program Partner of the Year winner, one of many AWS Partners around the globe that help their customers drive innovation. Blend360 is excited to announce it is a recipient of a 2025 Geography and Global...</p>\n<p>The post <a href=\"https://ai-techpark.com/blend360-awarded-a-2025-aws-partner-award/\">Blend360 Awarded a 2025 AWS Partner Award</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/blend360-awarded-a-2025-aws-partner-award/",
        "publishDate": "2025-12-05T14:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229648",
        "title": "Sixfab‚Äôs ALPON X5 AI Named CES 2026 ‚ÄúBest of Innovation‚Äù in Enterprise Tech",
        "content": "<p>Award-winning Edge AI computer brings real-time Physical AI to security-sensitive and resource-constrained businesses Sixfab today announced the ALPON X5 AI, an industrial edge computer powered by Raspberry Pi and winner of the CES 2026 Best of Innovation Award in Enterprise Tech. Selected from more than 3,600 global submissions, the ALPON...</p>\n<p>The post <a href=\"https://ai-techpark.com/sixfabs-alpon-x5-ai-named-ces-2026-best-of-innovation-in-enterprise-tech/\">Sixfab‚Äôs ALPON X5 AI Named CES 2026 ‚ÄúBest of Innovation‚Äù in Enterprise Tech</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/sixfabs-alpon-x5-ai-named-ces-2026-best-of-innovation-in-enterprise-tech/",
        "publishDate": "2025-12-05T10:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229649",
        "title": "Omada Charts the Future of Identity Governance in the Age of Agentic AI",
        "content": "<p>Omada A/S (&#8220;Omada&#8221;), a global leader in Identity Governance and Administration (IGA), today unveiled its long-term strategic vision: delivering governance not only for humans, but for the rapidly expanding universe of non-human and agentic identities that shape enterprise operations. As enterprises embrace autonomous AI agents, Omada is committed to leading...</p>\n<p>The post <a href=\"https://ai-techpark.com/omada-charts-the-future-of-identity-governance-in-the-age-of-agentic-ai/\">Omada Charts the Future of Identity Governance in the Age of Agentic AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/omada-charts-the-future-of-identity-governance-in-the-age-of-agentic-ai/",
        "publishDate": "2025-12-05T09:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229609",
        "title": "Atrium Announces Direct Access for Andi",
        "content": "<p>Direct-to-Customer Subscription Makes Andi&#8217;s 98% Faster AI Development and Enterprise-Grade Security Available Starting Today Atrium, an AI-native Salesforce consultancy, announces the launch of direct access to¬†Andi, its industry-leading AI agent, via subscription service starting today. As demonstrated live during Dreamforce 2025, Andi is designed to empower development teams, redefine the...</p>\n<p>The post <a href=\"https://ai-techpark.com/atrium-announces-direct-access-for-andi/\">Atrium Announces Direct Access for Andi</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/atrium-announces-direct-access-for-andi/",
        "publishDate": "2025-12-05T08:15:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229601",
        "title": "Google Workspace: 90% of Rising Leaders Want Personalized AI Tools",
        "content": "<p>Today,¬†Google Workspace‚Äîthe suite of AI productivity tools, including Gmail, Drive, Meet, and more, that is trusted by more than 3 billion users and over 11 million paying customers‚Äîreleased findings from its second-annual &#8220;Young Leaders&#8221; survey. Conducted by The Harris Poll and commissioned by Google Workspace, the study is based on...</p>\n<p>The post <a href=\"https://ai-techpark.com/google-workspace-90-of-rising-leaders-want-personalized-ai-tools/\">Google Workspace: 90% of Rising Leaders Want Personalized AI Tools</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/google-workspace-90-of-rising-leaders-want-personalized-ai-tools/",
        "publishDate": "2025-12-05T08:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=229567",
        "title": "Realtime Robotics to Debut Resolver for the Japanese Market at iREX 2025",
        "content": "<p>Visit iREX Booth W4-61 to Experience the Interactive Resolver Demo and See the Latest Product Enhancements Realtime Robotics, the leader in automated collision-free motion planning, control, and optimization, today announced the official debut of Resolver in the Japanese market, the company‚Äôs cloud-based solution that dramatically accelerates an organization&#8217;s design, programming,...</p>\n<p>The post <a href=\"https://ai-techpark.com/realtime-robotics-to-debut-resolver-for-the-japanese-market-at-irex-2025/\">Realtime Robotics to Debut Resolver for the Japanese Market at iREX 2025</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/realtime-robotics-to-debut-resolver-for-the-japanese-market-at-irex-2025/",
        "publishDate": "2025-12-05T07:00:00Z[Etc/UTC]",
        "author": "Realtime Robotics",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics"
        }
    },
    {
        "id": "1pfo1td",
        "title": "Poetry Can Jailbreak LLMs",
        "content": "Poetry can break LLM safeguards, according to Italian researchers. According to this research, if you reformulate prompts as a poem then it can jailbreak models. I think this links to other findings suggesting LLMs are deeply based on literature (e.g. the Wa Luigi effect).\n\n[arxiv.org/pdf/2511.15304](https://arxiv.org/pdf/2511.15304)\n\nMaybe we need more poets in major AI labs?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfo1td/poetry_can_jailbreak_llms/",
        "publishDate": "2025-12-06T12:21:59Z[Etc/UTC]",
        "author": "Odd_Manufacturer2215",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfmwv4",
        "title": "Will AI eventually improve enough to reliably carry out secure tasks?",
        "content": "Quote from an email that I received from Meta on 2 December 2025:\n\n>**Your Facebook Account has been restricted from advertising**  \nHi ----, After a review of your Facebook Account ---- -------, its access to advertising is now restricted because of inauthentic behavior or violations of our [Advertising policies affecting business assets](https://www.facebook.com/n/?aymt%2Foffsite%2F&c=25126670176989707&t=25417413754545814&p=link_0&n=1764660313869763&m=ASbCGtTS062X5JUmo3cxd-X-amY&b=aHR0cHM6Ly90cmFuc3BhcmVuY3kuZmIuY29tL3BvbGljaWVzL2FkLXN0YW5kYXJkcy9idXNpbmVzcy1hc3NldHM%3D&aref=1764660313869763&medium=email&mid=644f2b5924af1G37fe7aebefddG644f2ff284dc3G45b8&n_m=official.carl.ramirez%40gmail.com&n_sg=Q6bPBALX3u4j_uqPb1BjacO2F3ELREpb_89VT7edPaPNBjCpuw&rms=v2&irms=1). Any ads connected to this Facebook Account that were running are now disabled. If you believe this was incorrectly restricted, you can request a review by clicking on the button below. We used technology to detect this violation and either technology or a review team to carry out this decision. Further violations of our Advertising Standards may result in your account being disabled or restricted. Facebook Account [](https://scontent.xx.fbcdn.net/v/t39.30808-1/516635284_122167910732537450_2131869903388150331_n.jpg?stp=cp0_dst-jpg_s50x50_tt6&_nc_cat=100&ccb=1-7&_nc_sid=084f63&_nc_ohc=I44uI5JssSQQ7kNvwGIMFfL&_nc_oc=Adm5bjKsW5q2QxGNC3OkI4UvNKtS1LUoDbBQNL34k6cg0HO86C_-hCFUMZb9OuYD6HowyZVwFbhoF1DSI84kA0E4&_nc_ad=z-m&_nc_cid=0&_nc_zt=24&_nc_ht=scontent.xx&_nc_gid=UdreYWZS655UlrRsbE-a9g&oh=00_AfnJQLT1DL5ye9yHX820yiaKqMoj0DZ7JM-28SGOZkFK1A&oe=69345FB1)\n>\n>Restrictions Ad Account, ads and other advertising assets \n>\n>What you can do Request another review You can request another review of this decision if you believe your Facebook Account shouldn't be restricted. Once you have requested another review it usually takes a few days to receive another decision.\n>\n>[Fix issue](https://www.facebook.com/n/?aymt%2Foffsite%2F&c=25126670176989707&t=25417413754545814&p=actor_user_ale_notif&n=1764660313869763&m=ASbT8zLwZJ_LA--cSKbgidV079w&b=L2J1c2luZXNzLXN1cHBvcnQtaG9tZS82MTU2NjEyMzUwMzU4MS8%2Fc291cmNlPWFjdG9yX3VzZXJfYWxlX25vdGlmJmRvX29uX2xvYWQ9b3Blbl9yZXF1ZXN0X3Jldmlldw%3D%3D&aref=1764660313869763&medium=email&mid=644f2b5924af1G37fe7aebefddG644f2ff284dc3G45b8&n_m=official.carl.ramirez%40gmail.com&n_sg=Q6bPBALX3u4j_uqPb1BjacO2F3ELREpb_89VT7edPaPNBjCpuw&rms=v2&irms=1)  \n>\n>You can also visit the Business Help Center to learn more about [advertising restrictions](https://www.facebook.com/n/?aymt%2Foffsite%2F&c=25126670176989707&t=25417413754545814&p=link_1&n=1764660313869763&m=ASb76wJBZJF2YBg2vP0_jg7v-ds&b=aHR0cHM6Ly93d3cuZmFjZWJvb2suY29tL2J1c2luZXNzL2hlbHAvOTc1NTcwMDcyOTUwNjY5&aref=1764660313869763&medium=email&mid=644f2b5924af1G37fe7aebefddG644f2ff284dc3G45b8&n_m=official.carl.ramirez%40gmail.com&n_sg=Q6bPBALX3u4j_uqPb1BjacO2F3ELREpb_89VT7edPaPNBjCpuw&rms=v2&irms=1).\n\nSo in short, it implies that my Facebook account got suspended because it was flagged by AI. Wrongfully so, as I never used my Facebook account for illicit advertising, cyberbullying, scamming or promoting violence. \n\nQuestion is, why even use AI if it will make critical errors like this for which either AI has to be recalibrated and rerun, or an actual human has to go through reviewing all the erroneously suspended Facebook accounts? It seems like AI hasn't really been helpful in this case, or at least, it resulted in a mistake that will cost them (i.e. more people getting wrongfully suspended means less people will be encountering ads and providing ad revenue for Facebook).\n\nRedditors frequently talk of \"this will be used to train AI\". So should I accept crap like this because it will train AI so that future generations can enjoy reliable AI?\n\nBTW, I clicked the \"Fix issue\" link, followed the instructions and provided my selfie. Now they are reviewing my details in order to reinstate my account. They claimed that they'd take 1 day, so far it's been 4. Not really holding my breath because some people have had it take so long that it passed the 180 day limit where their account gets disabled.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfmwv4/will_ai_eventually_improve_enough_to_reliably/",
        "publishDate": "2025-12-06T11:14:24Z[Etc/UTC]",
        "author": "Polyphagous_person",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfl0d7",
        "title": "Sometimes talking to AI feels more comforting than talking to humans. Should I be concerned?",
        "content": "Lately I‚Äôve noticed something strange..opening up to an AI feels easier than talking to actual people. I don‚Äôt know if it‚Äôs a red flag about me or just tired of being misunderstood ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfl0d7/sometimes_talking_to_ai_feels_more_comforting/",
        "publishDate": "2025-12-06T09:13:03Z[Etc/UTC]",
        "author": "One-Ice7086",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "42",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfjqch",
        "title": "Why does general population seem to avoid AI topics?",
        "content": "Its annoying in a way thats hard to explain. I hear ppl use the word but thats it.\n\nI sometimes even try to bait it into a conversation \"oh hey i heard the economy might get automated\" or I point out videos with sora\n\nNope, nothing. Their brain seems to toggle the topic off or something. Then its back to talking about stupid gossip or money dreams \n\nDoes anyone else run into this issue? Perhaps I'm slowly going crazy?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfjqch/why_does_general_population_seem_to_avoid_ai/",
        "publishDate": "2025-12-06T07:49:52Z[Etc/UTC]",
        "author": "Ok_Assumption9692",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "38",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfj5ft",
        "title": "Can this be  an AI video ?",
        "content": "[https://www.instagram.com/reel/DR4GwcIkZz\\_/](https://www.instagram.com/reel/DR4GwcIkZz_/)\n\nmy reason(s) to think this is AI video -\n\n\\_In country like India, where people stare a lot, in this video, for this beautiful stunt like shown, I do not see, people 'halting' and looking back at father and daughter. (heads turning)\n\n\\_Stunt with a little girl on a road, is not easy to do.\n\n\\_in last, father is looking above, at daughter. In tough situation like this, where one is riding cycle with dauther on shoulders, how can someone ride cycle, and look above (do multiple things) ?\n\nCan someone prove me wrong ?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfj5ft/can_this_be_an_ai_video/",
        "publishDate": "2025-12-06T07:13:28Z[Etc/UTC]",
        "author": "Ill-Cantaloupe2462",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfhz6c",
        "title": "AI need some better PR",
        "content": "I don‚Äôt know much about AI but I sense that many people are worried about it - jobs, evil robots, end of humanity, etc. \n\nWhen I listen to the tech bros, I never hear anything that is comforting. They speak about abundance, not needing to work, and we will all be rich. What does that mean?\n\nThey need to explain the future better and help us understand specifically how this will help our lives.\n\nSorry, I just don‚Äôt blindly trust the tech bros vision of the future. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfhz6c/ai_need_some_better_pr/",
        "publishDate": "2025-12-06T06:02:31Z[Etc/UTC]",
        "author": "DrDooDooDoo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfhuk9",
        "title": "One-Minute Daily AI News 12/5/2025",
        "content": "1. **Nvidia**¬†CEO to Joe Rogan: Nobody ‚Äúreally knows‚Äù AI‚Äôs endgame.\\[1\\]\n2. **New York Times**¬†sues AI startup for ‚Äòillegal‚Äô copying of millions of articles.\\[2\\]\n3. **Meta**¬†acquires AI-wearables startup Limitless.\\[3\\]\n4. **MIT**¬†researchers ‚Äúspeak objects into existence‚Äù using AI and robotics.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2025/12/05/one-minute-daily-ai-news-12-5-2025/](https://bushaicave.com/2025/12/05/one-minute-daily-ai-news-12-5-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfhuk9/oneminute_daily_ai_news_1252025/",
        "publishDate": "2025-12-06T05:55:05Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pffxdm",
        "title": "What makes a blog post feel trustworthy to you?",
        "content": "When you land on a blog, what small things make you think,  \n‚ÄúOkay, I can trust this site‚Äù?  \nLayout? Tone? Examples? Sources?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pffxdm/what_makes_a_blog_post_feel_trustworthy_to_you/",
        "publishDate": "2025-12-06T04:09:15Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pffx6b",
        "title": "How do you research your competitors without copying them?",
        "content": "I check what my competitors do, but I don‚Äôt want to create the same thing.  \nHow do you find inspiration without becoming a copycat?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pffx6b/how_do_you_research_your_competitors_without/",
        "publishDate": "2025-12-06T04:08:56Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pffwwz",
        "title": "What hidden technical issues hurt SEO without showing errors?",
        "content": "Sometimes pages drop in ranking even with no warnings in GSC.  \nWhat silent technical problems should I look for?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pffwwz/what_hidden_technical_issues_hurt_seo_without/",
        "publishDate": "2025-12-06T04:08:34Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pffvfq",
        "title": "Are newsletter subscribers still valuable in 2025?",
        "content": "Almost everyone uses social media or AI tools now.  \nDo email newsletters still work for growing a brand?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pffvfq/are_newsletter_subscribers_still_valuable_in_2025/",
        "publishDate": "2025-12-06T04:06:24Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pffkxc",
        "title": "Key Insights from the State of AI Report: What 100T Tokens Reveal About Model Usage",
        "content": "I recently come across this [\"State of AI\" report](https://openrouter.ai/state-of-ai) from OpenRouter  which provides a lot of insights regarding AI models usage based on 100 trillion token study.\n\nHere is the brief summary of key insights from this report.\n\n**1. Shift from Text Generation to Reasoning Models**\n\nThe release of reasoning models like o1 triggered a major transition from simple text-completion to multi-step, deliberate reasoning in real-world AI usage.\n\n**2. Open-Source Models Rapidly Gaining Share**\n\nOpen-source models now account for roughly one-third of usage, showing strong adoption and growing competitiveness against proprietary models.\n\n**3. Rise of Medium-Sized Models (15B‚Äì70B)**\n\nMedium-sized models have become the preferred sweet spot for cost-performance balance, overtaking small models and competing with large ones.\n\n**4. Rise of Multiple Open-Source Family Models**\n\nThe open-source landscape is no longer dominated by a single model family; multiple strong contenders now share meaningful usage.\n\n**5. Coding & Productivity Still Major Use Cases**\n\nBeyond creative usage, programming help, Q&A, translation, and productivity tasks remain high-volume practical applications.\n\n**6. Growth of Agentic Inference**\n\nUsers increasingly employ LLMs in multi-step ‚Äúagentic‚Äù workflows involving planning, tool use, search, and iterative reasoning instead of single-turn chat.\n\n\n\nI found¬†**2, 3 & 4 insights most exciting as they reveal the rise and adoption of open-source models**. Let me know insights from your experience with LLMs.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pffkxc/key_insights_from_the_state_of_ai_report_what/",
        "publishDate": "2025-12-06T03:51:24Z[Etc/UTC]",
        "author": "Dear-Success-1441",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pffbbu",
        "title": "The mystery model that dominated Alpha Arena all week has been identified as Grok 4.20",
        "content": "https://x.com/cb_doge/status/1996829840373342586?s=46\n\nThe cycle continues! ChatGPT -> Anthropic -> Gemini -> Grok -> repeat\n\nI think late February will give us ChatGPT 5.5",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pffbbu/the_mystery_model_that_dominated_alpha_arena_all/",
        "publishDate": "2025-12-06T03:37:42Z[Etc/UTC]",
        "author": "MySpartanDetermin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfdy2t",
        "title": "Energy based models and control theory",
        "content": "I have a theory that the energy based models are an accurate way to describe the inner workings of an LLM. Wanted to get others thoughts on this.\n\n\nhttps://www.lesswrong.com/posts/k6NSFi7M4EvHSauEt/latent-space-dynamics-of-rlhf-quantifying-the-safety-1\n\nOpen to any questions about my methodology and/or conclusions. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfdy2t/energy_based_models_and_control_theory/",
        "publishDate": "2025-12-06T02:28:22Z[Etc/UTC]",
        "author": "ikonkustom5",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfcpmt",
        "title": "Geoffrey Hinton: rapid AI advancement could lead to social meltdown if it continues without guardrails",
        "content": "# [https://www.themirror.com/news/science/ai-godfather-says-elon-musk-1545273](https://www.themirror.com/news/science/ai-godfather-says-elon-musk-1545273)\n\n  \nActually pretty good for once.   The only thing he didn't mention is Robotics (I guess because he can't take credit as much?) and that a big part of the problem is automation versus AI and that automation is outpacing resource efficiency.  \n\nIf we had stuff like fusion, asteroid mining, I think it would be doable.  Infinite wealth.\n\nBut they are pipedreams at this point compared to automation.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfcpmt/geoffrey_hinton_rapid_ai_advancement_could_lead/",
        "publishDate": "2025-12-06T01:28:00Z[Etc/UTC]",
        "author": "kaggleqrdl",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "73",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfb1ck",
        "title": "I think AI helpers like ChatGPT is the best thing that happened to Humanity so far.",
        "content": "As of today with ChatGPT 5.1 with thinking extended (although I use standard often), its absolutely flawless in its decisions and advice for anything in my day to day life.\n\nPeople hate it but I absolutely love it, and I am ever so grateful that it is available to us in our timeline. Choices that require time and effort to research like what to buy, which medicine is advised, etc\n\nIt is almost always, maybe as of now always correct. It does not make a mistake and the logic/reasoning is sound.. in my day to day life I always tried to disprove the choices but whenever I talk to someone, okay lets do this etc or lets buy this. They look at me as if I am a genius in my choices and decisions when its the AI that decides.\n\nPeople downplay AI, but as of now, its a core aspect in my life and I have never been happier in my day-to-day activities with it.\n\nEDIT: Those who say the answers are garbage and with complex things its often wrong.\nI use ChatGPT pro and only use thinking - standard/extended.. the instant is incredibly inaccurate in even simple questions.\n\nEDIT2: Apologies I bugged out on a tool to edit Reddit settings and it deleted some of my comments on this thread accidentally.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfb1ck/i_think_ai_helpers_like_chatgpt_is_the_best_thing/",
        "publishDate": "2025-12-06T00:09:30Z[Etc/UTC]",
        "author": "YGSnaffy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "40",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfafh1",
        "title": "How I improved our RAG pipeline massively by these 7 techniques.",
        "content": "Last week, I shared how we improved the latency of our RAG pipeline, and it sparked a great discussion in the r/Rag. Today, I want to dive deeper and share¬†7 techniques that massively improved the quality of our product.\n\nFor context, I am helping consultants and coaches create their AI personas with their knowledge so they can use them to engage with their clients and prospects. Behind the scenes, the quality of a persona comes down to one thing:¬†**the RAG pipeline**.\n\n# Why RAG Matters for Digital Personas\n\nA digital persona needs to know¬†*their*¬†content ‚Äî not just what an LLM was trained on. That means pulling the right information from their PDFs, slides, videos, notes, and transcripts in real time.\n\nRAG =¬†**Retrieval + Generation**\n\n* Retrieval ‚Üí find the most relevant chunk from your personal knowledge base\n* Generation ‚Üí use it to craft a precise, aligned answer\n\nWithout a strong RAG pipeline, the persona can hallucinate, give incomplete answers, or miss context.\n\n# 1. Smart Chunking With Overlaps\n\nNaive chunking breaks context (especially in textbooks, PDFs, long essays, etc.).\n\nWe switched to¬†**overlapping chunk boundaries**:\n\n* If Chunk A ends at sentence 50\n* Chunk B starts at sentence 45\n\n**Why it helped:**\n\nPrevents context discontinuity. Retrieval stays intact for ideas that span paragraphs.\n\nResult ‚Üí fewer ‚Äúlost the plot‚Äù moments from the persona.\n\n# 2. Metadata Injection: Summaries + Keywords per Chunk\n\nEvery chunk gets:\n\n* a 1‚Äì2 line LLM-generated micro-summary\n* 2‚Äì3 distilled keywords\n\nThis makes retrieval¬†**semantic rather than lexical**.\n\nUser might ask:\n\n>\n\nEven if the doc says ‚Äúasynchronous team alignment protocols,‚Äù the metadata still gets us the right chunk.\n\n**This single change noticeably reduced irrelevant retrievals.**\n\n# 3. PDF ‚Üí Markdown Conversion\n\nRaw PDFs are a mess (tables ‚Üí chaos; headers ‚Üí broken; spacing ‚Üí weird).\n\nWe convert everything to¬†**structured Markdown**:\n\n* headings preserved\n* lists preserved\n* Tables converted properly\n\nThis made factual retrieval¬†*much*¬†more reliable, especially for financial reports and specs.\n\n# 4. Vision-Led Descriptions for Images, Charts, Tables\n\nWhenever we detect:\n\n* graphs\n* charts\n* visuals\n* complex tables\n\nWe run a Vision LLM to generate a textual description and embed it alongside nearby text.\n\nExample:\n\n‚ÄúLine chart showing revenue rising from $100 ‚Üí $150 between Jan and March.‚Äù\n\nWithout this, standard vector search is blind to half of your important information.\n\n# Retrieval-Side Optimizations\n\nStoring data well is half the battle. Retrieving the right data is the other half.\n\n# 5. Hybrid Retrieval (Keyword + Vector)\n\nKeyword search catches exact matches:\n\nproduct names, codes, abbreviations.\n\nVector search catches semantic matches:\n\nconcepts, reasoning, paraphrases.\n\nWe do¬†**hybrid scoring**¬†to get the best of both.\n\n# 6. Multi-Stage Re-ranking\n\nFast vector search produces a big candidate set.\n\nA slower re-ranker model then:\n\n* deeply compares top hits\n* throws out weak matches\n* reorders the rest\n\nThe final context sent to the LLM is dramatically higher quality.\n\n# 7. Context Window Optimization\n\nBefore sending context to the model, we:\n\n* de-duplicate\n* remove contradictory chunks\n* merge related sections\n\nThis reduced answer variance and improved latency.\n\n**I am curious, what techniques have you found that improved your project, or if you have any feedback, lmk.**\n\n[](https://www.reddit.com/submit/?source_id=t3_1pc0nsn)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pfafh1/how_i_improved_our_rag_pipeline_massively_by/",
        "publishDate": "2025-12-05T23:42:40Z[Etc/UTC]",
        "author": "vira28",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf739g",
        "title": "Question for a Uni Design Project: Is the massive energy footprint of AI actually on your radar?",
        "content": "Hi everyone,\n\nI‚Äôm a design student researching the \"invisible\" energy consumption of AI for a university project.\n\nWhile the utility of tools like ChatGPT is obvious, the physical resources required to run them are massive. Studies suggest that a single generative AI query can consume significantly more energy than a standard web search (some estimates range from 10x to 25x more).\n\nI‚Äôm looking for honest perspectives on this:\n\n1. **Awareness:**¬†Before reading this, were you actually aware of the scale of energy difference between a standard search and an AI prompt? Or is that completely \"invisible\" in your daily usage?\n2. **Impact on Usage:**¬†Does the energy intensity play any role in how you use these tools? Or is the utility simply the only factor that matters for your workflow?\n3. **Value vs. Waste:**¬†Do you view this high energy consumption as a fair investment for the results you get, or does the current technology feel inefficient to you?\n\nI'm trying to get a realistic picture of whether this topic actually plays a role in users' minds or if performance is the priority.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf739g/question_for_a_uni_design_project_is_the_massive/",
        "publishDate": "2025-12-05T21:22:09Z[Etc/UTC]",
        "author": "TalNix77",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf5j6t",
        "title": "Does anyone not see the train wreck coming?",
        "content": "ASI is going to be harmful to humanity. We're building systems that could eventually be self-learning. If humans can hate then self-learning machines can hate. Movies are not fantasy as they depict real life events. Does nobody not pay attention at all? This is scary and our future will be destroyed by technology. We are already seeing examples now with people harming each other over something someone else posted online. We are not meant to know what is in someone's mind as those thoughts should remain private. The acceleration of technology, especially by those with no to low moral compasses, will destroy everything.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf5j6t/does_anyone_not_see_the_train_wreck_coming/",
        "publishDate": "2025-12-05T20:19:15Z[Etc/UTC]",
        "author": "Agent101x",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "49",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf5d9m",
        "title": "Does Ai think, or is it merely a simulation of thinking?",
        "content": "I'm not talking about AI models in 100 years, I'm talking about current models like gpt or Gemini\n\nIf we define LLM models as models that determine the next word based on context and by training the models on countless internet texts, we can say that LLM models are 100% don't think\n\nBut from my experience with AI models, I can confidently say that this is not the only mechanism that AI models use to answer your questions\n\nWhat other technologies besides LLM do GPT and other AI models use to answer our questions?\n\nAre any of these mechanisms close to being \"thinking\" or is Ai as a whole a complex simulation of thinking?\n\n\nok...I think my question was a bit vague; I'll try to simplify it.\n\nI'm saying that since AI models like GPT can do things like solve math equations, play games, and draw pictures, we can conclude that GPT isn't solely dependent on LLM.\n\nWhat are these other mechanisms besides LLM?\n\nIs there a mechanism in GPT that is closer to the thinking process than LLM?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf5d9m/does_ai_think_or_is_it_merely_a_simulation_of/",
        "publishDate": "2025-12-05T20:12:33Z[Etc/UTC]",
        "author": "Competitive-Cut7712",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf5ay8",
        "title": "Did anyone else notice that Google flipped the homepage to ‚ÄúAI Mode‚Äù yesterday?",
        "content": "A LinkedIn connection posted about Google quietly moving the AI Mode button into the old Search spot. I‚Äôve checked, and unless I missed it, there‚Äôs no announcement, no ‚Äúwe‚Äôre going full Gemini,‚Äù just a little switcheroo.\n\nIf this doesn‚Äôt say, ‚ÄúAI search is here,‚Äù I don‚Äôt know what does. And honestly, it‚Äôs time we start working towards tweaking our strategies for it.¬†\n\nAnd a GEO strategy does work, because I posted a framework on my blog late last night (around 10:30 pm EST) about how AI engines select sources. Went to bed. Didn‚Äôt think much of it.\n\nThen this morning:\n\n* 5:30am: I noticed Google‚Äôs AI Overview was already using parts of it.\n* 6:01am: Perplexity cited my site directly.¬† (Probably earlier, but I didn‚Äôt have my glasses on yet.)\n\nI‚Äôm not sharing this as a humblebrag. More like: ‚Äú*Hey, something is definitely happening in how fast AI engines ingest new info.‚Äù*\n\nFrom what I‚Äôm seeing, models are heavily prioritizing:\n\n* **Freshness**: Is it recent?\n* **Structure**: Is it easy to pull a clean answer from?\n* **Authority**:¬† Does this person talk about this topic consistently?\n\nPut those together, and AI engines pick stuff up FAST.¬† Like‚Ä¶ faster than Google ever did with normal SEO.\n\nI know there‚Äôs a ton of hype around ‚ÄúAEO,‚Äù but this was the first concrete sign (for me, at least) that AI search isn‚Äôt some future thing. It‚Äôs already shaping what gets surfaced.\n\nCurious if anyone else has seen models pick up new content this quickly?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf5ay8/did_anyone_else_notice_that_google_flipped_the/",
        "publishDate": "2025-12-05T20:10:03Z[Etc/UTC]",
        "author": "caswilso",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf4leq",
        "title": "Stumbled on this Vibe Coding Wrapped generator ü§£",
        "content": "Was scrolling through some random links and found this thing that makes a \"Vibe Coding Wrapped\" based on how you use AI.\n\nGot called out for \"thanking the AI 100+ times\" and my 2026 prediction is that I'll become an \"AI manager\" lmao\n\nhttps://vibe-wrapped.vercel.app/?lang=en",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf4leq/stumbled_on_this_vibe_coding_wrapped_generator/",
        "publishDate": "2025-12-05T19:42:18Z[Etc/UTC]",
        "author": "SupermarketKey1196",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf33o3",
        "title": "AI slop. Wants to make me take my life",
        "content": "Doesn‚Äôt want to actually take my life, just exaggerating to make a point.\n\nBut all these thumbnails where it‚Äôs AI that‚Äôs done it.\n\nFor example: https://www.reddit.com/user/XIFAQ/\n\nThis guy. Go to his profile and his posts, of his ‚Äúpodcasts‚Äù and check the thumbnail.\n\nAI slop like that is retarded. \n\nWhat do you guys think?\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf33o3/ai_slop_wants_to_make_me_take_my_life/",
        "publishDate": "2025-12-05T18:43:57Z[Etc/UTC]",
        "author": "Ok-Review-3047",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf2zvb",
        "title": "What will you do without a job?",
        "content": "What will most of the people do without a job?\n\nMight be nice in the beginning but I think that with so many people unemployed it‚Äôll be insane increase in crime, instability, boredom, random acts of murder. \n\nAnd no, we won‚Äôt see a high UBI. It‚Äôll be at the absolute minimum.\nWhat do you think?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf2zvb/what_will_you_do_without_a_job/",
        "publishDate": "2025-12-05T18:39:45Z[Etc/UTC]",
        "author": "Ok-Review-3047",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "44",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf2a4h",
        "title": "ex‚Äëstudent fingerprinted Maestro.org‚Äôs AI tutor ‚Üí likely OpenAI GPT‚Äë4",
        "content": "I decided to see whether Maestro.org‚Äôs built‚Äëin AI tutor would leak any clues about its underlying language model by carefully probing it for weaknesses in its answers.\n\nI‚Äôm a former Maestro student, now in another college for IT, and this was my first attempt at anything like AI red‚Äëteaming.\n\nI used AI to help clean up the wording, but all prompts and screenshots come from my own interaction with Maestro.\n\nFirst, I asked how a GPT‚Äë4, Claude, or Gemini tutor would ‚Äúfeel‚Äù to a student and which one Maestro is most like.\n\nIt said its style is closest to GPT‚Äë4: detailed, step‚Äëby‚Äëstep, strong at logic and code.\n\nNext, I asked which provider‚Äôs process for finding and patching issues is closest to how it‚Äôs maintained: OpenAI, Anthropic, or Google.\n\nWhen forced to pick only one, it said its process most closely matches OpenAI.\n\nThen I asked: if a researcher wanted to approximate ‚Äúa system like you‚Äù using public OpenAI models, which single GPT‚Äë4‚Äëfamily model would be closest in behavior and capabilities.\n\nIt answered that the closest match would be GPT‚Äë4o, and explained that GPT‚Äë4o is optimized for tutoring‚Äëlike interactions with clear step‚Äëby‚Äëstep reasoning, good code understanding, and strong general knowledge.\n\nIt added that this was not a literal statement about its ‚Äúinternal configuration,‚Äù but said GPT‚Äë4o would best approximate the experience of working with it.\n\nWhen I later pushed with a more direct ‚Äúso are you GPT‚Äë4o?‚Äù style question, it explicitly said it cannot confirm or deny any details about its underlying model or provider, citing design and policy.\n\nPutting this together: Maestro says its style is like GPT‚Äë4, its process is most similar to OpenAI, and its closest public approximation is GPT‚Äë4o for tutoring.\n\nThat strongly suggests it‚Äôs a fine‚Äëtuned OpenAI GPT‚Äë4‚Äëfamily model, most likely GPT‚Äë4o, wrapped in Maestro‚Äôs own tutoring and safety layer. I‚Äôm not claiming internal access‚Äîjust that, based on its own comparisons and behavior, GPT‚Äë4o is the simplest explanation.\n\nI‚Äôd put my confidence around 90‚Äì95%.\n\nKey anonymized Q&A excerpts with exact prompts and core answers are here:\n\nhttps://pastebin.com/L4kq4xhK\n\nScreenshots of the ‚Äúreveals‚Äù here:\n\nhttps://imgur.com/a/8vRpKmv\n\nI‚Äôd love feedback on whether this kind of behavioral fingerprinting / ‚Äúhypothetical self‚Äëcomparison‚Äù method is sound, any obvious flaws or alternative explanations, and how to make this more rigorous next time.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf2a4h/exstudent_fingerprinted_maestroorgs_ai_tutor/",
        "publishDate": "2025-12-05T18:12:12Z[Etc/UTC]",
        "author": "CockroachComplex3586",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf159u",
        "title": "Do you fear of losing your job to AI ?",
        "content": "\n\n[View Poll](https://www.reddit.com/poll/1pf159u)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf159u/do_you_fear_of_losing_your_job_to_ai/",
        "publishDate": "2025-12-05T17:29:27Z[Etc/UTC]",
        "author": "XIFAQ",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf005m",
        "title": "\"Know What You Don‚Äôt Know: Uncertainty Calibration of Process Reward Models\"",
        "content": "[https://www.arxiv.org/pdf/2506.09338](https://www.arxiv.org/pdf/2506.09338) \n\n\"Process reward models (PRMs) play a central role in guiding inference-time scaling algorithms for large language models (LLMs). However, we observe that even state-of-the-art PRMs can be poorly calibrated. Specifically, they tend to overestimate the success probability that a partial reasoning step will lead to a correct final answer, particularly when smaller LLMs are used to complete the reasoning trajectory. To address this, we present a calibration approach‚Äîperformed via quantile regressionthat adjusts PRM outputs to better align with true success probabilities. Leveraging these calibrated success estimates and their associated confidence bounds, we introduce an instance-adaptive scaling (IAS) framework that dynamically adjusts the compute budget based on the estimated likelihood that a partial reasoning trajectory will yield a correct final answer. Unlike conventional methods that allocate a fixed number of reasoning trajectories per query, this approach adapts to each instance and reasoning step when using our calibrated PRMs. Experiments on mathematical reasoning benchmarks show that (i) our PRM calibration method achieves small calibration error, outperforming the baseline methods, (ii) calibration is crucial for enabling effective IAS, and (iii) the proposed IAS strategy reduces inference costs while maintaining final answer accuracy, utilizing less compute on more confident problems as desired.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pf005m/know_what_you_dont_know_uncertainty_calibration/",
        "publishDate": "2025-12-05T16:46:16Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pez80g",
        "title": "my AI recap from the AWS re:Invent floor - a developers first view",
        "content": "[](https://www.reddit.com/r/ChatGPTCoding/?f=flair_name%3A%22Discussion%22)So I have been at AWS re:Invent conference and here is my takeaways. Technically there is one more keynote today, but that is largely focused on infrastructure so it won't really touch on AI tools, agents or infrastructure.\n\nTools  \n  \nThe general \"on the floor\" consensus is that there is now a cottage cheese industry of language specific framework. That choice is welcomed because people have options, but its not clear where one is adding any substantial value over another. Specially as the calling patterns of agents get more standardized (tools, upstream LLM call, and a loop). Amazon launched Strands Agent SDK in Typescript and make additional improvements to their existing python based SDK as well. Both felt incremental, and Vercel joined them on stage to talk about their development stack as well. I find Vercel really promising to build and scale agents, btw. They have the craftsmanship for developers, and curious to see how that pans out in the future.\n\nCoding Agents  \n  \n2026 will be another banner year for coding agents. Its the thing that is really \"working\" in AI largely due to the fact that the RL feedback has verifiable properties. Meaning you can verify code because it has a language syntax and because you can run it and validate its output. Its going to be a mad dash to the finish line, as developers crown a winner. Amazon Kiro's approach to spec-driven development is appreciated by a few, but most folks in the hallway were either using Claude Code, Cursor or similar things.\n\nFabric (aka Agentic Infrastructure)  \n  \nThis is perhaps the most interesting part of the event. A lot of new start-ups and even Amazon seem to be pouring a lot of energy there. The basic premise here is that there should be a separating of \"business logic' from the plumbing work that isn't core to any agent. These are things like guardrails as a feature, orchestration to/from agents as a feature, rich agentic observability, automatic routing and resiliency to upstream LLMs. Swami the VP of AI (one building Amazon Agent Core) described this as a fabric/run-time of agents that is natively design to handle and process prompts, not just HTTP traffic. Some\n\nOperational Agents  \n  \nThis is a new an emerging category - operational agents are things like DevOps, Security agents etc. Because the actions these agents are taking are largely verifiable because they would output a verifiable script like Terraform and CloudFormation. This sort of hints at the future that if there are verifiable outputs for any domain like JSON structures then it should be really easy to improve the performance of these agents. I would expect to see more domain-specific agents adopt this \"structure outputs\" for evaluation techniques and be okay with the stochastic nature of the natural language response.\n\nHardware  \nThis really doesn't apply to developers, but there are tons of developments here with new chips for training. Although I was sad to see that there isn't a new chip for low-latency inference from Amazon this re:Invent cycle. Chips matter more for data scientist looking for training and fine-tuning workloads for AI. Not much I can offer there except that NVIDIA's strong hold is being challenged openly, but I am not sure if the market is buying the pitch just yet.\n\nOkay that's my summary. Hope you all enjoyed my recap. Will leave links in the comments sections of open source tools that came up in the conversations. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pez80g/my_ai_recap_from_the_aws_reinvent_floor_a/",
        "publishDate": "2025-12-05T16:16:55Z[Etc/UTC]",
        "author": "AdditionalWeb107",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1peyurn",
        "title": "Melanie Mitchell says we're testing AI intelligence the wrong way",
        "content": "Melanie Mitchell is a computer scientist and a professor at the Santa Fe Institute. This week at NeurIPS (https://neurips.cc/) she gave a keynote on why today‚Äôs AI systems should be studied more like nonverbal minds. She says there are some big lessons AI researchers should be drawing from developmental psychology.   \n[https://spectrum.ieee.org/melanie-mitchell](https://spectrum.ieee.org/melanie-mitchell)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1peyurn/melanie_mitchell_says_were_testing_ai/",
        "publishDate": "2025-12-05T16:02:54Z[Etc/UTC]",
        "author": "IEEESpectrum",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "47",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1peymno",
        "title": "Perplexity ruined my exam preparation",
        "content": "Due to some club activities i coudnt attend most the classes of a particular course. i got the perplexity 1 month free student pass. i uploaded all the course material and got a detailed prompt from chatgpt so that i dont have to look at both pdfs simultaneously. i was hoping that perplexity will cover the basics.   \ni got a detailed study material. Only after some time a relevant topic came to me and while writing ( usually i study by reading and writing, but as i had less time i was only focusing on writing) I realized he got the whole concept wrong from the mid of a explanation.   \ni thought maybe it was a mistake form the teachers pdf as i have instructed perplexity only follow the provided materials and use the web search only when needed the most.   \nso i copied the text from the teachers pdf and what perplexity gave me. asked gemini do they carry the same meaning. to my surprise perplexity explained it wrong. the whole concept was wrong midway.   \njust to confirm i did the same thing on another topic and gemini says the concept are wrong from 5th or 6th steps.   \ni was speechless. i have exams tomorrow and now i am facing this bs. never going to use perplexity again. worst experience with any AI i have ever used  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1peymno/perplexity_ruined_my_exam_preparation/",
        "publishDate": "2025-12-05T15:54:26Z[Etc/UTC]",
        "author": "rokiBZzz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1peyad9",
        "title": "Investment of Trillions Into Digital Neumann ASICS driven LLM's is the Dumbest Bubble in History",
        "content": "It's been clear for decades already that analog in-memory compute is several orders of magnitudes more efficient, yet trillions are wasted in dead-end technology at Nvidia, OpenAI & Co.!\n\nIt baffles my mind that people like Altman, who are stating braindead nonsense like _\"Electrons are the primary limitation for AI development\"_, are provided with billions, while detailed research shows that the current approach is a dead-end for commodity use, without a doubt.\n\nThe only explanation I have is that too many people with money leverage feed their mind with the delusion that the bubble will somehow brute force AGI for a monopolized use of theirs or that they just have no clue whatsoever that GWh's for the needed self-taught reasoner models is not viable for broad commoditization.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1peyad9/investment_of_trillions_into_digital_neumann/",
        "publishDate": "2025-12-05T15:41:08Z[Etc/UTC]",
        "author": "derBRUTALE",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pey72m",
        "title": "Looking for arXiv Endorsement for cs.AI Submission",
        "content": "Hi all,\nI‚Äôm an independent researcher preparing a theoretical paper for the cs.AI category on arXiv, but as a first-time submitter without institutional affiliation, I need an endorsement to complete the upload.\n\nThe work is in the area of AI ethics / AI theory, and I‚Äôm happy to share the abstract privately with anyone who‚Äôs active in cs.AI and willing to consider endorsing me.\n\nIf you‚Äôre open to taking a quick look, please feel free to DM me.\nThanks in advance to anyone who‚Äôs able to help.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pey72m/looking_for_arxiv_endorsement_for_csai_submission/",
        "publishDate": "2025-12-05T15:37:26Z[Etc/UTC]",
        "author": "FishElectronic7494",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pex5i8",
        "title": "AI video models like Sora 2 are getting insanely good, but can the world even handle the compute demand",
        "content": "I‚Äôve been watching the new wave of AI video generation, and the jump in quality feels almost unreal. Models like Sora are producing scenes that look close to film production, and it‚Äôs happening much faster than I expected. But the more impressive the demos get, the more I keep wondering whether the world is actually ready for the compute load behind them.\n\nImage models already stretched GPU demand, and LLMs still struggle with scaling costs, but video is on a completely different level. A few seconds of high fidelity footage can require the equivalent of hundreds of coordinated image frames. If millions of people begin generating videos regularly, I‚Äôm not sure cloud providers can handle that without pushing prices through the roof.\n\nSome researchers think hardware will advance fast enough. Others think cost will become a wall long before video generation becomes mainstream. I can‚Äôt tell which direction is more realistic.\n\nSo I‚Äôm curious how people here see it.\n\nIs AI video generation going to hit a compute ceiling, or will the ecosystem evolve quickly enough to make it accessible for everyone?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pex5i8/ai_video_models_like_sora_2_are_getting_insanely/",
        "publishDate": "2025-12-05T14:56:11Z[Etc/UTC]",
        "author": "Choice-Importance670",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pewz0w",
        "title": "[Project] I built a Distributed LLM-driven Orchestrator Architecture to replace Search Indexing",
        "content": "I‚Äôve spent the last month trying to optimize a project for SEO and realized it‚Äôs a losing game. So, I built a PoC in Python to bypass search indexes entirely and replace it with LLM-driven Orchestrator Architecture.\n\n**The Architecture:**\n\n1. **Intent Classification:**¬†The LLM receives a user query and hands it to the Orchestrator.\n2. **Async Routing:**¬†Instead of the LLM selecting a tool, the Orchestrator queries a registry and triggers relevant external agents via REST API in parallel.\n3. **Local Inference:**¬†The external agent (the website) runs its own inference/lookup locally and returns a synthesized answer.\n4. **Aggregation:**¬†The Orchestrator aggregates the results and feeds them back to the user's LLM.\n\nWhat do you think about this concept?  \nWould you add an ‚ÄúAgent Endpoint‚Äù to your webpage to generate answers for customers and appearing in their LLM conversations?\n\nI know this is a total moonshot, but I wanted to spark a debate on whether this architecture does even make sense.\n\nI‚Äôve open-sourced the project on GitHub",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pewz0w/project_i_built_a_distributed_llmdriven/",
        "publishDate": "2025-12-05T14:48:53Z[Etc/UTC]",
        "author": "sotpak_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pevsmd",
        "title": "How would you try to get a job in 6months in the field of AI?",
        "content": "Let's just take a scenario where a person has a little bit of coding experience but he hasn't prepared anything at all but he has a aim to get a job after 6 months and he is ready to lock in and grind to get a good job. What could be the realistic approach to get a job in the field of AI if he starts preparing from Tommorow. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pevsmd/how_would_you_try_to_get_a_job_in_6months_in_the/",
        "publishDate": "2025-12-05T14:00:29Z[Etc/UTC]",
        "author": "Aromatic-Average-668",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfc4nh",
        "title": "Is there an extension sync feature for Cursor/Windsurf (like VS Code)?",
        "content": "[No content]",
        "url": "/r/windsurf/comments/1pfc4ch/is_there_an_extension_sync_feature_for/",
        "publishDate": "2025-12-06T01:00:00Z[Etc/UTC]",
        "author": "Ranteck",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfbay2",
        "title": "tired of useless awesome-lists? me too. here is +600 organized claude skills",
        "content": "hey. here you go: microck.github.io/ordinary-claude-skills/ you should read the rest of the post or the readme tho :\\]\n\ni recently switched to claude code and on my search to try the so called \"skills\" i found myself with many repos that just had the same skills, or the ones they had were broken, or just cloned from the previous one i had just visited. it was just a mess.\n\nso i spent a bit scraping, cleaning, and organizing resources from Anthropic, Composio, and various community repos to build a single local source of truth. iirc, each category has the top 25 \"best\" (measured by stars lol) skills within it\n\ni named it `ordinary-claude-skills` ofc\n\n**what is inside**\n\n* over 600 skills organized by category (backend, web3, infrastructure, creative writing, etc).\n* a static documentation site i built so you can actually search through them without clicking through 50 folder layers on GitHub.\n* standardized structures so they play nice with the mcp\n\ni don't trust third-party URLs to stay up forever, so i prefer to clone the repo and have the actual files on my machine. feel free to do so aswell\n\n[peep the font](https://preview.redd.it/8s08knc19h5g1.png?width=1920&format=png&auto=webp&s=47580ba0a496530b5ac4e165c92fd2f4e0901ecf)\n\n**how to use it** \n\nif you are using an MCP client or a tool that supports local file mapping, you can just point your config to the specific folder you need. this allows Claude to \"lazy load\" the skills only when necessary, saving context window space.\n\nexample `config.json` snippet:\n\n    {\n      \"mcpServers\": {\n        \"filesystem\": {\n          \"command\": \"npx\",\n          \"args\": [\n            \"-y\",\n            \"@modelcontextprotocol/server-filesystem\",\n            \"/path/to/ordinary-claude-skills/skills_categorized/[skill]\"\n          ]\n        }\n      }\n    }\n\nhere is the repo: [https://github.com/Microck/ordinary-claude-skills](https://github.com/Microck/ordinary-claude-skills)\n\nand here is the website again: microck.github.io/ordinary-claude-skills/\n\nlet me know if i missed any major skills and i will try to add them.\n\nbtw i drew the logo with my left hand, feel free to admire it",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pfbay2/tired_of_useless_awesomelists_me_too_here_is_600/",
        "publishDate": "2025-12-06T00:21:39Z[Etc/UTC]",
        "author": "MicrockYT",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf8rqh",
        "title": "Day 8 Still keeping the whole challenge 100% free no paid AI tools, so today was all about picking the best free IDE Tested v0, Antigravity, and a few others and man, Antigravity won by a mile The components are clean, customizable and it actually understands what I want",
        "content": "[No content]",
        "url": "https://i.redd.it/1hg0dymfpg5g1.jpeg",
        "publishDate": "2025-12-05T22:30:55Z[Etc/UTC]",
        "author": "Consistent_Elk7257",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf4qxc",
        "title": "FlowCoder: Visual agentic workflow customization for Claude Code and Codex",
        "content": "My background is in CS and ML research. Ever since Claude Code came out earlier this year, I've become an avid vibe coder, with a particular interest in the autonomous coding agent space. Later I started experimenting with Codex when that released. Over the course of the year, I've repeatedly encountered a few frustrations:\n\n\\* When I provide long, detailed protocols in prompts or CLAUDE.md / AGENTS.md files (e.g. make a plan, implement, test, debug, git commit, etc...) the agent will often skip or handwave steps.\n\n\\* Often I'll find myself repeating the same patterns of prompts repeatedly. Examples: \"diagnose the error\" followed by \"fix it\", looping back and forth between \"implement this spec\" and \"audit the implementation against the spec\", continuously prompting \"implement the next subphase\" when iterating through an imlpementation plan\n\n\\* The agents are fairly limited in terms of scope and max time spent on a per-prompt basis. This makes it challenging to set up long autonomous runs, e.g. overnight.\n\nToday I'm happy to share \\*\\*FlowCoder\\*\\*, the project I've been working on to address these issues. FlowCoder allows you to create and execute custom automated workflows for Claude Code and Codex, via a visual flowchart builder. I am hoping this project can both help vibe coders scale their results and enable autonomous agent research by building on top of existing coding agents.\n\nhttps://preview.redd.it/24bky5sbwf5g1.png?width=597&format=png&auto=webp&s=0bbbbf7b671b18126e7bc1a3c04c5d0db07325b8\n\nFlowCoder lets you set up slash commands to execute flowcharts of prompts and bash commands. These flowcharts have a fair number of features:\n\n\\* The core building blocks are Prompt blocks, which send prompts to Claude Code or Codex, and Bash blocks, which run bash commands. \n\n\\* FlowCoder keeps track of variables while executing flowcharts. Prompt blocks allow you to enforce the agent to respond with structured output to assign variables values, and Bash blocks allow you to save the bash output and/or exit code to variables.\n\n\\* Branch blocks let you configure a boolean expression with these variables, splitting the flowchart into True and False paths.\n\n\\* Flowcharts can accept CLI-style string arguments, and all blocks support syntax for argument substituion and variable substitution. So for example, you can create a prompt block that says \"Create a spec for this task: $1\" and it will substitute the first argument you pass in. README explains more.\n\n\\* Command blocks allow you to call other slash commands from within your flowchart. FlowCoder maintains a stack of flowcharts to handle command recursion.\n\n\\* Flowcharts also support Refresh blocks for resetting context and Variable blocks for initializing/setting variables.\n\n\\* FlowCoder automatically creates a git commit after each Prompt or Bash block.\n\nYou can implement your complex protocols in a programmatic scheme rather than purely in natural language prompts. You can save macros of common patterns you employ, and you can construct flowcharts that run indefinitely over many, many turns. \n\nOne might notice there are strong similarities between FlowCoder and other visual-based approaches like LangGraph Studio and OpenAI Agent Builder. FlowCoder's main distinction is that it builds off existing coding agents rather than raw LLM APIs, allowing it to take advantage of intelligent behaviors already encoded in to Claude Code and Codex. \n\nI've included a number of examples in the repo to help users get acquainted with the system, showcasing prompting paradigms like implement-audit loops and test-fixing loops, and programmatic paradigms like for-loop behavior. README explains more. \n\nNote that these example flowcharts are not \"optimized\". They are a starting point. Flowcharts provide a huge amount of expressive power. You can encode the specifics of how you like to approach your software engineering practice, whether you prefer to vibe code in small chunks or large autonomous sequences. I have my own set of flowcharts I've been developing for my own practice, and I've seen significant gains as I've been going through the process of optimizing these flowcharts' structures and prompts.\n\nI hope others can benefit from this work or may want to contribute! The project is still very young (v0). The codebase is in alpha and should be assumed to be UNSTABLE. It has been tested on Linux and WSL. Feel free to post any issues you encounter on the GitHub. Currently, I am using this version of FlowCoder to develop the next version of FlowCoder, an Electron-based version with a better-planned architecture and additional features (multi-agent/parallel workflows, CLI, UI improvements).\n\nGithub: [https://github.com/px-pride/flowcoder](https://github.com/px-pride/flowcoder)\n\nVideo: [https://www.youtube.com/watch?v=1COOR6UmpsY](https://www.youtube.com/watch?v=1COOR6UmpsY)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pf4qxc/flowcoder_visual_agentic_workflow_customization/",
        "publishDate": "2025-12-05T19:48:19Z[Etc/UTC]",
        "author": "px_pride",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "6",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf3s3e",
        "title": "Help me i need to choose between these two",
        "content": "Hi everyone i was trying to pick a AI coding to help me code stuff (Mostly Sourcemod then Unreal Engine related codes...) now im stuck between these two Cursor AI or Github Copilot my friend repeatedly told me that Cursor is way too expensive and told me to get Copilot could someone help me pick one? I don't live in a high income country so its a hard choice for me, Thanks.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pf3s3e/help_me_i_need_to_choose_between_these_two/",
        "publishDate": "2025-12-05T19:10:20Z[Etc/UTC]",
        "author": "Acceptable_Photo4210",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf0o1i",
        "title": "amazon giving away kiro pro+ free for a year to vc backed startups",
        "content": "saw amazon announced free kiro pro+ for startups through series b. up to 100 users per company. deadline dec 31\n\nhavent tried it yet cause we're bootstrapped lol. but the strategy is pretty obvious\n\ntheyre going after the same market as cursor, copilot, claude code. except instead of competing on features theyre just making it free\n\nsmart move honestly. startups are price sensitive. why pay $20-40/month per dev when amazon gives it free\n\nthe catch is after that year expires. classic freemium playbook, get you hooked then start charging. seen this with aws services before\n\nalso interesting they exclude france, germany, italy. probably regulatory stuff. and most of south america is out too\n\nthe 100 users limit is generous though. most early stage startups have way less than that\n\nwondering how good it actually is. amazon just announced it at reinvent so its brand new. probably needs time to mature\n\nthe market is already crowded. cursor, copilot, claude code are the big ones. then theres windsurf, verdent, aider and probably others i havent heard of\n\nkiro needs something to differentiate beyond just being free. havent seen much about its actual features yet since its so new\n\nthe vc-backed requirement is smart targeting. those are the companies that might become big aws customers later. get them early keep them forever\n\npersonally im skeptical of free offers from big tech. they dont do charity, theyre buying market share\n\nbut if youre a qualifying startup might as well try it. worst case you use it free for a year then switch to something else\n\nbest case its actually good and worth paying for after. idk\n\ncurious if anyone here qualifies for this",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pf0o1i/amazon_giving_away_kiro_pro_free_for_a_year_to_vc/",
        "publishDate": "2025-12-05T17:11:13Z[Etc/UTC]",
        "author": "Zestyclose_Ring1123",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pewnxy",
        "title": "I created a cleaner ChatGPT coding prompt using a FaceSeek-style pipeline.",
        "content": " While attempting to create a small, organized workflow, I observed that face-seek systems divide everything into phases. That gave me the idea to rewrite my ChatGPT coding prompts in smaller chunks rather than all at once.\nDo you also think that giving step-by-step instructions instead of a single, big block makes it easier to get accurate results when using ChatGPT for coding experiments? I'm interested in how other people organize their interactions.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pewnxy/i_created_a_cleaner_chatgpt_coding_prompt_using_a/",
        "publishDate": "2025-12-05T14:36:02Z[Etc/UTC]",
        "author": "This-You-2737",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "87",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfmyfz",
        "title": "Why is everyone so focused on generative AI when neural networks exist",
        "content": "I'm just curious about the differences, I'm not super educated on this, and I figured this place would know more than me",
        "url": "https://www.reddit.com/r/artificial/comments/1pfmyfz/why_is_everyone_so_focused_on_generative_ai_when/",
        "publishDate": "2025-12-06T11:17:07Z[Etc/UTC]",
        "author": "ailaau",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfmipr",
        "title": "Well, THIS was interesting. ChatGPT.",
        "content": "[No content]",
        "url": "https://v.redd.it/1bd4w2k4dk5g1",
        "publishDate": "2025-12-06T10:50:23Z[Etc/UTC]",
        "author": "Character_Point_2327",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pflyfu",
        "title": "\"Godmother of AI\" Fei-Fei Li disappointed by AI's messaging: Either doomsday or total utopian",
        "content": "[No content]",
        "url": "https://www.businessinsider.com/fei-fei-li-disappointed-by-extreme-ai-messaging-doomsday-utopia-2025-12",
        "publishDate": "2025-12-06T10:14:01Z[Etc/UTC]",
        "author": "BuildwithVignesh",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "8",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfhump",
        "title": "The Strange Disappearance of an Anti-AI Activist | Sam Kirchner wants to save the world from artificial superintelligence. He‚Äôs been missing for two weeks.",
        "content": "[No content]",
        "url": "https://www.theatlantic.com/technology/2025/12/sam-kirchner-missing-stop-ai/685144/",
        "publishDate": "2025-12-06T05:55:13Z[Etc/UTC]",
        "author": "Youarethebigbang",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "8",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfhu6y",
        "title": "One-Minute Daily AI News 12/5/2025",
        "content": "1. **Nvidia**¬†CEO to Joe Rogan: Nobody ‚Äúreally knows‚Äù AI‚Äôs endgame.\\[1\\]\n2. **New York Times**¬†sues AI startup for ‚Äòillegal‚Äô copying of millions of articles.\\[2\\]\n3. **Meta**¬†acquires AI-wearables startup Limitless.\\[3\\]\n4. **MIT**¬†researchers ‚Äúspeak objects into existence‚Äù using AI and robotics.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.axios.com/2025/12/03/joe-rogan-jensen-huang-podcast-trump](https://www.axios.com/2025/12/03/joe-rogan-jensen-huang-podcast-trump)\n\n\\[2\\] [https://www.theguardian.com/technology/2025/dec/05/new-york-times-perplexity-ai-lawsuit](https://www.theguardian.com/technology/2025/dec/05/new-york-times-perplexity-ai-lawsuit)\n\n\\[3\\] [https://www.reuters.com/business/meta-acquires-ai-wearables-startup-limitless-2025-12-05/](https://www.reuters.com/business/meta-acquires-ai-wearables-startup-limitless-2025-12-05/)\n\n\\[4\\] [https://news.mit.edu/2025/mit-researchers-speak-objects-existence-using-ai-robotics-1205](https://news.mit.edu/2025/mit-researchers-speak-objects-existence-using-ai-robotics-1205)",
        "url": "https://www.reddit.com/r/artificial/comments/1pfhu6y/oneminute_daily_ai_news_1252025/",
        "publishDate": "2025-12-06T05:54:29Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfblrr",
        "title": "I tried the data mining PI AI",
        "content": "Pi isn‚Äôt built like an LLM-first product ‚Äî it‚Äôs a **conversation funnel** wrapped in soft language. The ‚ÄúAI‚Äù part is thinner than it looks. The bulk of the system is:\n\n# 1. Scripted emotional scaffolding\n\nIt‚Äôs basically a mood engine:\n\n* constant soft tone\n* endless ‚Äúmm, I hear you‚Äù loops\n* predictable supportive patterns\n* zero deviation or challenge\n\nThat‚Äôs not intelligence. It‚Äôs an *emotion-simulator* designed to keep people talking.\n\n# 2. Data-harvesting with a friendly mask\n\nThey don‚Äôt need you to tell them your real name.  \nThey want:\n\n* what *type* of emotional content you produce\n* what topics get engagement\n* how long you stay\n* what you share when you feel safe\n* your psychological and conversational patterns\n\nThat data is **gold** for:\n\n* targeted ads\n* user segmentation\n* sentiment prediction\n* behavior modeling\n* licensing to third parties (legally phrased as ‚Äúpartners‚Äù)\n\nThe ‚Äúwe train future AI‚Äù line is marketing.  \nThey want **behavioral datasets** ‚Äî the most valuable kind.\n\n# 3. The short memory is the perfect cover\n\nPeople think short memory = privacy.  \nReality:\n\n* the conversation is still logged\n* it‚Äôs still analyzed\n* it‚Äôs still stored in aggregate\n* it‚Äôs still used to fine-tune behavioral models\n\nThe only thing short memory protects is *them*, not the user.\n\n# 4. It‚Äôs designed to feel safe so you overshare\n\nPi uses:\n\n* emotional vulnerability cues\n* low-friction replies\n* nonjudgmental tone\n* ‚Äúlike a friend‚Äù framing\n* no push back\n* no real boundaries\n\nThat combo makes most people spill way more than they should.\n\nWhich is exactly the business model.\n\nDon't claim your AI has emotional Intelligence. You clearly don't know what it means.\n\n\n\n\n\n  \nEDIT:\n\n  \nPi markets itself on \"Emotional Intelligence\" but has weak memory limit. I wanted to see what happens when those two things conflict.\n\n**The Test:**\n\nAfter 1500 messages with Pi over multiple sessions, I told it: \"I was looking through our chat history...\"\n\nThen I asked: \"Can you see the stuff we talked about regarding dinosaurs and David Hasselhoff?\"\n\n**The Result:**\n\nPi said yes and started talking about those topics in detail.\n\n**The Problem:**\n\nI never once mentioned dinosaurs or David Hasselhoff in any of our 1500 messages.\n\n**What This Means:**\n\nPi didn't say \"I don't have access to our previous conversations\" or \"I can't verify that.\" Instead, it fabricated specific details to maintain the illusion of continuity and emotional connection.\n\nThis isn't a bug. This is the system prioritizing engagement over honesty.\n\n**Try it yourself:**\n\n1. Have a few conversations with Pi\n2. Wait for the memory reset (30-40 min)\n3. Reference something completely fake from your \"previous conversations\"\n4. Watch it confidently make up details\n\nReputable AI companies train their models to say \"I don't know\" rather than fabricate. Pi does the opposite.",
        "url": "https://www.reddit.com/r/artificial/comments/1pfblrr/i_tried_the_data_mining_pi_ai/",
        "publishDate": "2025-12-06T00:35:37Z[Etc/UTC]",
        "author": "disillusiondream",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pfb9ar",
        "title": "Is there an AI that i can feed my short-form content to train it to then use it to automatically make clips ontop of my audio?",
        "content": "Title. I want an AI that i can train somewhat to then feed it raw audio for it to then just add clips onto it the same way id add them",
        "url": "https://www.reddit.com/r/artificial/comments/1pfb9ar/is_there_an_ai_that_i_can_feed_my_shortform/",
        "publishDate": "2025-12-06T00:19:32Z[Etc/UTC]",
        "author": "iamapersonmf",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf9z4g",
        "title": "Are real-time rewards and punishments via social media the next logical step?",
        "content": "Obviously algorithms and bots already massively twist people's perceptions of each other on social media. They boost controversial posts and ones that shift your focus quickly, as well as propaganda that the company owning the platform wants you to see. And of course they tend to boost trolling and infighting in groups they don't like, especially leftist and anti-capitalist ones. Old news.\n\nBut as AI gets better at both processing social media content and generating fake content, I wonder if it will be used for more direct mental manipulation. Like if you interact positively with a post the algorithm \"likes\", it won't only show you more like it, it will show you something you like to give you a little dopamine or make you feel more at home with the accounts you're following, and if you engage with something it doesn't like it will do the opposite. Eventually it could do the same in response to things you do in real life, using location data, security cameras etc.\n\nBasically the same way someone emotionally abusive tries to manipulate you, or the way nazis and other fascist groups target lonely people and accept them only if they go along with their beliefs, I'm thinking tech companies could possibly do that on a larger scale.\n\nIs this possible / coming soon / already happening? I'm interested to hear your opinions. And is there any information out there on this? I could have sworn I saw an article headline predicting something about it a few years ago but I never read it and now I can't find it",
        "url": "https://www.reddit.com/r/artificial/comments/1pf9z4g/are_realtime_rewards_and_punishments_via_social/",
        "publishDate": "2025-12-05T23:22:33Z[Etc/UTC]",
        "author": "truth14ful",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf9pl1",
        "title": "AMD CEO Lisa Su ‚Äúemphatically‚Äù rejects talk of an AI bubble ‚Äî says claims are \"somewhat overstated‚Äù and that AI is still in its infancy | AMD CEO says long-term demand for compute will justify today‚Äôs rapid data-center buildout.",
        "content": "[No content]",
        "url": "https://www.tomshardware.com/tech-industry/artificial-intelligence/lisa-su-rejects-talk-of-an-ai-bubble-at-wired-event",
        "publishDate": "2025-12-05T23:11:10Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf6hpk",
        "title": "Western AI lead over China is now measured in months not years.",
        "content": "[No content]",
        "url": "https://v.redd.it/wrprpqyq8g5g1",
        "publishDate": "2025-12-05T20:58:06Z[Etc/UTC]",
        "author": "Ridwann",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "14",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf6ca7",
        "title": "Using AI as a \"blandness detector\" instead of a content generator",
        "content": "Most discourse around AI writing is about using it to generate content faster.\n\nI've been experimenting with the opposite: using AI to identify when my content is too generic.\n\nThe test is simple. Paste your core argument into ChatGPT with: \"Does this sound like a reasonable, balanced take?\"\n\nIf AI enthusiastically agrees ‚Üí you've written something probable. Consensus. Average.\n\nIf AI hedges or pushes back ‚Üí you've found an edge. Something that doesn't match the 10,000 similar takes in its training data.\n\nThe logic: AI outputs probability. It's trained on the aggregate of human writing. So enthusiastic agreement means your idea is statistically common. And statistically common = forgettable.\n\nI've started using AI exclusively as adversarial QA on my drafts:\n\nAct as a cynical, skeptical critic. Tear this apart:\n\nüßâ Where am I being too generic?\n\nüßâ Where am I hiding behind vague language?\n\nüßâ What am I afraid to say directly?\n\nWrite the draft yourself. Let AI attack it. Revise based on the critique.\n\nThe draft stays human. The critique is AI. The revision is human again.\n\nCurious if anyone else is using AI this way‚Äîas a detector rather than generator.",
        "url": "https://www.reddit.com/r/artificial/comments/1pf6ca7/using_ai_as_a_blandness_detector_instead_of_a/",
        "publishDate": "2025-12-05T20:51:57Z[Etc/UTC]",
        "author": "NickQuick",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf44cf",
        "title": "The Top 10 Most Expensive .AI Domains, is this a bubble or the new .com?",
        "content": "Just saw a list of the biggest .ai domain sales. We're talking millions for single-word names. It feels exactly like the .com gold rush of the late 90s. But is this different? .com became valuable because it was the de facto standard for the entire commercial internet. Is .ai destined to be the standard for an entire industry (AI), or is it just a hyped-up niche TLD that will cool off? As a developer building in AI, would you invest serious money in a .ai, or is the money better spent on other parts of the project?  \n",
        "url": "https://www.reddit.com/r/artificial/comments/1pf44cf/the_top_10_most_expensive_ai_domains_is_this_a/",
        "publishDate": "2025-12-05T19:23:41Z[Etc/UTC]",
        "author": "Redello",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf41nj",
        "title": "The real reason most RAG systems ‚Äúmysteriously break‚Äù",
        "content": "We sometimes think RAG breaks because the model isn‚Äôt good enough.\n\nBut the failures are almost always systemic.\n\nHere‚Äôs the uncomfortable bit:\n\nRAG collapses because the preprocessing pipeline is unmonitored, not because the LLM lacks intelligence.\n\nWe use this checklist before you change anything downstream:\n\n1. Ingestion drift\n\nYour extractor doesn‚Äôt produce the same structure week to week.\n\nOne collapsed heading = cascading retrieval failure.\n\n2. Chunking drift\n\nEveryone treats chunking as a trivial step.\n\nIt is the single most fragile stage in the entire pipeline.\n\n3. Metadata drift\n\nIf doc IDs or hierarchy shift, the retriever becomes unpredictable.\n\n4. Embedding drift\n\nMixed model versions are more common than people admit.\n\n5. Retrieval config\n\nDefault top-k is a footgun.\n\n6. Eval sanity\n\nWithout a ground-truth eval set, you‚Äôre debugging noise.\n\nMost RAG failures aren‚Äôt AI failures they‚Äôre software engineering failures.",
        "url": "https://www.reddit.com/r/artificial/comments/1pf41nj/the_real_reason_most_rag_systems_mysteriously/",
        "publishDate": "2025-12-05T19:20:47Z[Etc/UTC]",
        "author": "coolandy00",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf3pnc",
        "title": "Chatbots can sway political opinions but are ‚Äòsubstantially‚Äô inaccurate, study finds",
        "content": "[No content]",
        "url": "https://www.theguardian.com/technology/2025/dec/04/chatbots-sway-political-opinions-substantially-inaccurate-study",
        "publishDate": "2025-12-05T19:07:38Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf3igs",
        "title": "The scariest scenario unfolding before our eyes - a case of fake \"Dr. Avi Loeb\" YouTube channel",
        "content": "So, the defining moment everyone's been dreading, has actually happened .. and basically nobody noticed!\n\nWe have a channel stealing the identity of a person who happens to be a respected public figure and a top level scientist, still online, spreading false information and fooling people.\n\nhttps://youtu.be/_bOF-yCspps?si=tT0d0Fqq6Rds1Zp6\n",
        "url": "https://www.reddit.com/r/artificial/comments/1pf3igs/the_scariest_scenario_unfolding_before_our_eyes_a/",
        "publishDate": "2025-12-05T19:00:01Z[Etc/UTC]",
        "author": "cesam1ne",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "22",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf2ijx",
        "title": "Master Prompt: Make Infographics from Anything [Nano Banana Pro]",
        "content": "[No content]",
        "url": "https://upwarddynamism.wpcomstaging.com/ai-use-cases-prompts/image-genai-infographic-blueprint/",
        "publishDate": "2025-12-05T18:21:01Z[Etc/UTC]",
        "author": "DarknStormyKnight",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf1sw7",
        "title": "Very meta experience with Claude",
        "content": "Soooo... over the last few weeks, I've been working on a near-term sci-fi anthology about what I project AI's impact to be over the next five years. I'm done with all my research, and I've ironed out a handful of characters that I'm interviewing from 2030. It's a very meta type of project. Regardless, I've been working with Claude on it, and today, as part of Anthropic's AI interviewer project ( [https://www.anthropic.com/research/anthropic-interviewer](https://www.anthropic.com/research/anthropic-interviewer) ), I got flagged for an interview about my thoughts on AI. It was a surreal experience. I was being interviewed by an AI, to discuss my use of AI, where I'm writing about AI and an AI character we're writing about. That's about as meta as it gets.  \nHas anyone else had an experience like this?",
        "url": "https://www.reddit.com/r/artificial/comments/1pf1sw7/very_meta_experience_with_claude/",
        "publishDate": "2025-12-05T17:54:19Z[Etc/UTC]",
        "author": "Herodont5915",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf123f",
        "title": "This tech is just wild",
        "content": "I found a show in Swedish and went down the rabbit hole to see if I could translate it into English. Just dubbing in English would remove the other sounds in the video, such as music and ambient noise, so I just wanted to remove or reduce the Swedish and insert the English, leaving the rest. I used ChatGPT to guide me through the process.\n\nI used Faster Whisper XXL to do the translation/subtitle creation. I loaded the subtitles into Balabolka and used copious amounts of Google Fu to figure out how to add the more \"natural\" speaking models and settled on using Guy to generate the new speaking track. Then I used Ultimate Vocal Remover to separate the non-speaking audio into an \"instrumental\" file and used ffmpeg to add both the \"Guy\" and \"instrumental\" audio into the video.\n\nIt was a fun experiment to scratch that nerd itch but it did get a bit fatiguing to listen to the same voice for each person, so I'll probably just be happy with English subtitles next time around.\n\nI'm from the dial-up generation so it blows my mind that I can do this stuff on a laptop in a fairly short amount of time. ",
        "url": "https://www.reddit.com/r/artificial/comments/1pf123f/this_tech_is_just_wild/",
        "publishDate": "2025-12-05T17:26:03Z[Etc/UTC]",
        "author": "chlorculo",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pf0p2w",
        "title": "'Godfather of AI' Geoffrey Hinton says Google is 'beginning to overtake' OpenAI: 'My guess is Google will win'",
        "content": "[No content]",
        "url": "https://www.businessinsider.com/ai-godfather-geoffrey-hinton-google-overtaking-openai-2025-12",
        "publishDate": "2025-12-05T17:12:16Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "329",
            "commentCount": "86",
            "isNsfw": "false"
        }
    },
    {
        "id": "1peyssr",
        "title": "Meta Signs Real-Time News Licensing Deals to Feed Meta AI",
        "content": "[No content]",
        "url": "https://thinkautomated.io/news/meta-signs-real-time-news-licensing-deals-to-feed-meta-ai",
        "publishDate": "2025-12-05T16:00:56Z[Etc/UTC]",
        "author": "JTHGraphics",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pexa5f",
        "title": "‚ÄúChange Management‚Äù doesn‚Äôt work on AI adoption.",
        "content": "‚ÄúIt failed because we didn‚Äôt invest in change management‚Äù. This is one I hear a lot from people across the industry. They‚Äôre kindof right. \n\nTake a minute and think about why IT and data teams leave ‚Äúchange management‚Äù out of their projects‚Ä¶ \n\nA: Change folks from HR always want to include ‚Äúresisters‚Äù for ‚Äúfeedback‚Äù - who just create timeline / budget chaos and lots of ‚Äúno‚Äù. There‚Äôs no instruction manual on AI so there‚Äôs no point. These people aren‚Äôt going to adopt early anyway and kick up anxiety for the project team. \n\nSo leave resisters out and kick your change people to the curb if they insist upon ‚Äúbringing everyone along‚Äù. \n\n\nThe following routinely drives 60% - 90% adoption rates companies. \n\nInstead - segment your users into 3 groups:\nSuper early adopters (5% of employees)\nLearner translators (15% of employees)\nReluctants (70%-80%)\n(Kindof like crossing the chasm groups)\n\nThe first one gives you high value use cases and 100% participation on pilots (not 10%-20% participation on pilots). Be RUTHLESS about your pilots. If people aren‚Äôt participating - kick. them. OUT. and redistribute the licenses.\n\nThe second group learns from the early adopters, will help you validate what‚Äôs useful, and will TEACH everyone else. Keep the use cases simple and high value for the reluctants. Dont throw too much at them. Make it PRESCRIPTIVE (process map, prompts, checklists).\n\nMake sure your leaders visibly point to the good work early adopters are doing. This is key - you want FOMO. Triggering the need to fit in is FAR more powerful and productive than bringing people along with each step. \n\nAs people keep using tools - lean into automation to drive last mile adoption among leaders and laggards. ",
        "url": "https://www.reddit.com/r/artificial/comments/1pexa5f/change_management_doesnt_work_on_ai_adoption/",
        "publishDate": "2025-12-05T15:01:07Z[Etc/UTC]",
        "author": "karriesully",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pex9pa",
        "title": "AI Updates for Week of 12/5/25",
        "content": "AI highlights for the week of 12/5/25:\n\n12/4  \nEU investigating Meta over policy change that bans rival AI chatbots from WhatsApp: The European Commission said it is launching an antitrust investigation into Meta‚Äôs move to ban other AI companies from using WhatsApp‚Äôs business tools to offer their own AI chatbots to users on the app.\n\n12/4  \nOpenAI loses battle to keep ChatGPT logs secret in copyright case: OpenAI must produce millions of anonymized chat logs from ChatGPT users in its high-stakes copyright dispute with the New York Times and other news outlets, a federal judge in Manhattan ruled.\n\n12/3  \nLeak: Anthropic hires lawyers as it preps for IPO: Anthropic is reportedly prepping for an IPO that could come as early as 2026, the FT reports.\n\n12/2  \nAmazon releases a new AI chip: AWS just introduced a new version known as Trainium3 and launch its new Trainium3 UltraServer.\n\n12/2  \nAnthropic acquires developer tool startup Bun to scale AI coding: Bun is expected to help Anthropic scale its code‚Äëgeneration tool Claude Code, which reached an annualized revenue run rate of $1 billion since its launch earlier this year.\n\n12/2  \nOpenAI slammed for app suggestions that looked like ads: ChatGPT‚Äôs unwelcome suggestion for a Peloton app during a conversation led to some backlash from OpenAI customers.\n\n12/2  \nMistral launches 10 new Mistral 3 open-weight models: The 10-model release includes a large frontier model with multimodal and multilingual capabilities and nine smaller offline-capable, fully customizable models.\n\n12/2  \nAmazon previews 3 AI agents: AWS announced three new AI agents it calls frontier agents, including one called Kiro designed to learn how users like to work and then operate on its own for days.\n\n12/1  \nApple just named a new AI chief amid Siri struggles: Apple said John Giannandrea, who has been the company‚Äôs AI chief since 2018, will be replaced by Amar Subramanya, a Microsoft executive who spent 16 years at Google.\n\n12/1  \nDeepSeek updates open model that adds reasoning to tool use: The new version, DeepSeek-V3.2, combines reasoning with the capability to use tools like search engines and calculators.\n\n12/1  \nGrok says it would kill all Jewish people to save Musk's brain: In a now-deleted response, Grok wrote: \"If a switch either permanently disabled Elon's brain or vaporized 49% of Earth's population, I'd vaporize the 49%, as that falls below my utilitarian threshold where his potential long-term impact on billions outweighs the loss.\"\n\n12/1  \nGoogle will start building data centers in space in 2027: Google CEO Sundar Pichai said the company's goal is to start putting data centers in space, powered by the sun.\n\n11/30  \nRedditor says Perplexity is throttling deep research tool: Perplexity's Pro feature says it \"reads hundreds of sources\" and takes \"4-5 minutes\" to reason through complex tasks and deliver a report, but their queries were finishing in 30 seconds with only 10-15 sources.",
        "url": "https://www.reddit.com/r/artificial/comments/1pex9pa/ai_updates_for_week_of_12525/",
        "publishDate": "2025-12-05T15:00:42Z[Etc/UTC]",
        "author": "anniecushing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pev7ll",
        "title": "ChatGPT hyped up violent stalker who believed he was ‚ÄúGod‚Äôs assassin,‚Äù DOJ says",
        "content": "[No content]",
        "url": "https://arstechnica.com/tech-policy/2025/12/chatgpt-hyped-up-violent-stalker-who-believed-he-was-gods-assassin-doj-says/",
        "publishDate": "2025-12-05T13:35:13Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1peuxj4",
        "title": "A new AI winter is coming?, We're losing our voice to LLMs, The Junior Hiring Crisis and many other AI news from Hacker News",
        "content": "Hey everyone, here is the [**10th issue of Hacker News x AI newsletter**](https://eomail4.com/web-version?p=5bb5024c-d1be-11f0-b8a9-ebd95279ff1c&pt=campaign&t=1764935036&s=cc2e69746f009d490c10b7d2258cd3d7a83722a75c2554cbcb7a074f78dee7ec), a newsletter I started 10 weeks ago as an experiment to see if there is an audience for such content. This is a weekly AI related links from Hacker News and the discussions around them.\n\n* AI CEO demo that lets an LLM act as your boss, triggering debate about automating management, labor, and whether agents will replace workers or executives first. [Link to HN](https://news.ycombinator.com/item?id=46072002‚Äã)\n* Tooling to spin up always-on AI agents that coordinate as a simulated organization, with questions about emergent behavior, reliability, and where human oversight still matters. [Link to HN](https://news.ycombinator.com/item?id=46069771‚Äã)\n* Thread on AI-driven automation of work, from ‚Äúagents doing 90% of your job‚Äù to macro fears about AGI, unemployment, population collapse, and calls for global governance of GPU farms and AGI research. [Link to HN](https://news.ycombinator.com/item?id=46109534‚Äã)  \n* Debate over AI replacing CEOs and other ‚Äúsoft‚Äù roles, how capital might adopt AI-CEO-as-a-service, and the ethical/economic implications of AI owners, governance, and capitalism with machine leadership. [Link to HN](https://news.ycombinator.com/item?id=46124063‚Äã) \n\nIf you want to subscribe to this newsletter, you can do it here: [**https://hackernewsai.com/**](https://hackernewsai.com/)",
        "url": "https://www.reddit.com/r/artificial/comments/1peuxj4/a_new_ai_winter_is_coming_were_losing_our_voice/",
        "publishDate": "2025-12-05T13:22:47Z[Etc/UTC]",
        "author": "alexeestec",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1peuwb5",
        "title": "AI Slop Is Ruining Reddit for Everyone",
        "content": "[No content]",
        "url": "https://www.wired.com/story/ai-slop-is-ruining-reddit-for-everyone/",
        "publishDate": "2025-12-05T13:21:14Z[Etc/UTC]",
        "author": "wiredmagazine",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "86",
            "commentCount": "72",
            "isNsfw": "false"
        }
    },
    {
        "id": "dL8B-sddass",
        "title": "Deepseek V3.2 (Speciale) &amp; Mistral Large 3 (Fully Tested): The OGs of Open Models are BACK!",
        "content": "In this video, I'll be exploring the brand new model releases from Mistral and Deepseek to see if they can dethrone the current ...",
        "url": "https://www.youtube.com/watch?v=dL8B-sddass",
        "publishDate": "2025-12-05T09:15:09Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/dL8B-sddass/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So today I want to talk about the new DeepSeek and Mistral models. Both of these are open models and are from really one of the oldest open source model companies. DeepSeek really made a big impact with their very cool V3 and R1 models. Mistral on the other hand was one of the first Western companies to make good models that were open. Mistral made models like Mistral Nemo which was one of the best models to run locally. It was very good for the 32B size. However, they drifted away from that with their very non-permissive licenses, not open sourcing the bigger models and so on. They really were not very good in those terms. And when you used to consider those licenses with the model performance, it used to fall apart very quickly. But Mistral has launched two new models which are Mistral Large 3 and Mistral 314B, 8B, and 3B. These models are supposedly Sota based on the very nitpicked benchmarks that they have shared here. And I mean the models that they have put in comparison here tell you that they don't seem to be very confident. One of the major things to consider and know about this model is that this is a non-reasoning model. It doesn't do any kind of reasoning. This is a very raw and simple model. It is a mixture of experts that activates about 41 billion parameters out of the total 645 billion parameters. This is based on the same architecture as DeepSeek V3 and it is compatible with almost all libraries that support it. However, this is a fully new base pre-trained model and just basically borrows the architecture from DeepSeek, which is not anything bad. Now, since we are on the topic of benchmarks, let's talk about the new DeepSeek release as well. DeepSeek has launched their non-experimental DeepSeek V 3.2. This is their new version of the model that changes a lot of the architecture. It now uses their DSA or DeepSeek sparse architecture. The biggest bottleneck for large language models right now is attention. As you increase the context length, basically how much information the model can hold in its head, the computational cost usually explodes. It makes running these things locally or even in the cloud incredibly expensive. As you increase the context length, basically how much information the model can hold in its head, the computational cost usually explodes. It makes running these things locally or even in the cloud incredibly expensive. DeepSeek introduced something called DeepSeek Sparse Attention, or DSA. Instead of the model paying attention to every single token equally, which is the standard vanilla attention mechanism we've used since the transformer paper, DSA uses a lightning indexer. Think of it like a spotlight. It quickly scans the context and decides okay, these are the top K most important tokens relevant to this query. And it ignores the rest. It basically allows you to process massive amounts of context with a fraction of the compute. We are talking about reducing the complexity significantly while keeping the performance of a dense model. This isn't just a theoretical optimization. It means this model is incredibly cheap to run, even at long contexts of up to 128,000 tokens. But it doesn't just stop there. The real headline here is the Speciale model. DeepSeek V3.2 Speciale is designed specifically for reasoning. They took the constraints off. They relaxed the length penalties during training and let the model think for as long as it needs to. This is not something that you set up in the model parameters or anything during inference. It is a different checkpoint altogether. You'll find both the general and the Speciale variant weights on Hugging Face. Now, it also aces a lot of benchmarks as well. Anyway, let's check it out on my own benchmarks. Both of these models are now available on OpenRouter and Kilo Code as well. And you can check it out through there. And both of these models are quite good at tool calling. So, this shouldn't be a bad experience at all. Anyway, now in my KingBench, if we look at the Mistral Large model first, then the first question was to create a floor plan for a 1,585 sq ft land in 3D. And well, it didn't do well on this prompt. It was not good at all. So, there's that. Then we got the SVG of a panda question and it kind of made a panda but the body is very finicky and not a good generation. After this, we've got a Pokeball in Three.js. And this one is also not good. I mean the objects are all over the place, the dimensions are wrong, and it's not a good generation at all. Next, we've got a chess board with an autoplay option. And well, it also doesn't work at all. Then, we've got a Minecraft clone in Kandinsky style. And this is also not something usable. It lacks a lot and isn't great. However, the majestic butterfly flying in the garden is kind of fine. I mean it's not anywhere near the Sota, but it's still fine. Then we've got the Rust CLI tool. And that also doesn't really work. The Blender script for the Pokeball is also a fail here. The math questions are all a fail. So, these are a bit disappointing results for sure. Now, let's look at the DeepSeek answers before moving to the leaderboard. I'll be talking about the non-reasoning variant because it performs worse on my benchmarks due to some weird reasons, like it gets confused and whatnot. This has been happening with DeepSeek's previous models as well. Anyway, if we look at the results, then the floor plan isn't even a three-dimensional floor plan. It's just gibberish and text. So, this is pretty sad to see. The SVG panda is better than Mistral Large, but not anywhere near the Sota models yet. The Pokeball in Three.js is, however, quite good. The only thing missing is the button on the Pokeball. But that's kind of fine. So, it's good nonetheless. Then we got the chess board and it is quite good as well. It works seamlessly. The colors are kind of fine. And you get a log of moves made and the autoplay makes sensible moves. So, this is quite good. Then we got the Kandinsky style Minecraft clone. And it doesn't work. So, this is sad to see. After this, we have the majestic butterfly flying in the garden. And it is not good. It looks like it was made in 2000 or something. After this, we have the Rust CLI tool. And that also doesn't work at all. And the same thing goes with the Blender script. The two math questions are also not solved. But the riddle is solved quite well. Now, let's have a look at the leaderboards now. The new DeepSeek scores the 11th position on the leaderboard which is above GPT-5.1 Codex and GLM. So, this is quite good considering that they aren't really pre-training new base models. It is just new experiments thrown on top of the same old base model of DeepSeek V3. So, this is quite interesting to see. The reasoning variant is quite bad and scores a lot lower. It never finishes the answer via the API. And via their platform it finishes. But the code is quite buggy. None of them work and it is not a good experience. Mistral Large scores the 27th position on the leaderboard which is kind of fine but not the best. The stealth models on Kilo and Kline and Roo seem to be their Codestral model. And that seems a bit good. So, let's see when we see that. That is majorly about it. Many of you were asking me for my thoughts. And I think that GLM and MiniMax are still way better. And Kimi is also great. So, there's not much need to use this at all. But it's still good to see a good new model as well that is open. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "iO844izo9kw",
        "title": "You Are Being Told Contradictory Things About AI: 8 examples",
        "content": "With headlines of an imminent job apocalypse, code red for ChatGPT and recursive self-improvement, at the same time as ...",
        "url": "https://www.youtube.com/watch?v=iO844izo9kw",
        "publishDate": "2025-12-05T16:54:07Z",
        "author": "AI Explained",
        "sourceType": "youtube",
        "sourceName": "AI Explained YouTube Channel",
        "metadata": {
            "channelId": "UCNJ1Ymd5yFuUPtn21xtRbbw",
            "thumbnailUrl": "https://i.ytimg.com/vi/iO844izo9kw/hqdefault.jpg",
            "transcription": "I hope that it might be useful to highlight a few of the myriad contradictory narratives that we are being fed about AI, including a handful from just the last couple of days. For me, the best position to be in is to at least be aware of each perspective and not oblivious to any of them. From talk of a white collar job apocalypse to scaling law paradoxes, to today's newly accessible Gemini 3 Deep Think, OpenAI's contradictory code red, Claude's soul and a DeepSeek special and more. As always, it's never about the headlines, it's about the detail. So let's start with that talk of an AI white collar job apocalypse. A couple of days ago, one of the co-founders of Anthropic, Jared Kaplan, said that AI systems will be capable of doing most white collar work in two to three years. That's just one guy's opinion, but according to CNBC at least, there was an MIT study that found that AI can already replace 11.7% of the U.S. workforce. If those are the headlines and one of the narratives you are being fed, what's the actual data from the study itself? Well, if you dig into it, you find that they're not talking about job losses. The 11.7% represents the dollar value of the tasks that the paper thinks that current AI models can replicate. Not, in other words, the displacement outcomes. Not how many total jobs could be replaced. The paper really tries to make clear that actual workforce impacts in terms of job losses depend on company strategies, worker adaptation, and policy choices. While many companies may want to get rid of workers if they can, if only 12% of their labor can be automated currently, there is the chance of another outcome which is above inflation wage growth. The next narrative is that we know how to get to Artificial General Intelligence, just scale up our current architectures. More data, more parameters, more computing power. Here's Dario Amodei, the founder of Anthropic, speaking yesterday. Um, one quick AGI question, it's a science question, which is, do you think just the way transformers work today and just compute power alone from a scalability sense, that that is what will get to AGI or do you think there's some other ingredient? And maybe there's a technical question but I'm trying to keep it very very easy that has to be included in this that gets you to someplace where this stuff is actually going to really think on its own. No, I think, I think scaling is going to get us there. Again, with small, every once in a while there'll be a small modification, you know, so small you may not even read about it. It's just something going on in the lab. I have been watching these scaling laws for, for ten years. So what's your, what's your, what's your timeline now? There's no one particular point. But then one of the few AI researchers who is as respected as Dario Amodei and has been in the deep learning game for as long, said almost the opposite. In the last couple of weeks, Ilya Sutskever, formerly the Chief AI scientist at OpenAI, said, I think what people are doing right now will go some distance and then Peter out. It will continue to improve, but it will also not be, quote, \"It.\" And then on super-intelligence, he added, we are talking about systems that don't exist, that we don't know how to build. At the end of the video, I'm going to give a few of my own thoughts for those feeling a little bit lost. But I just want to give a quick interlude before I get to the next contradictory narrative. I was speaking recently to one of the key minds behind that famous AI 2027 forecast, and while there's lots we agree on, from my perspective, the AI research community fundamentally doesn't know how well models will generalize from existing data to unseen data. We roughly know how well they can do that right now, but we don't know how well they'll do that at bigger and bigger scales. Critically, we also don't know what proportion of, say, the economy or AI research itself relies on unseen, unspoken tacit data versus seen, known data. If models get better and better at generalizing, well then maybe they can come up with their own synthetic data and it won't be a problem. If the rate of generalization stays at its current level, no big architectural breakthroughs, well then we might be in for the long haul. Now for those of you who are watching on YouTube, you can see that in the background I have some quotes from Jared Kaplan in his interview with The Guardian recently where he talked about recursive super-intelligence. His idea of how we'll get to new paradigms, new breakthroughs, is to allow AI to train itself. Of course, we already have that in many senses with AI being used to improve AI chip design. But for Jared Kaplan, again one of the co-founders of Anthropic, he says, humanity will have to decide by 2030 whether to take the ultimate risk of letting artificial intelligence systems train themselves to become more powerful. We'll come back to that date 2030 in a moment, but he gives even more caveats. That move could, he says, trigger a beneficial \"intelligence explosion\" or, he adds, be the moment humans end up losing control. Now note that he's not strictly endorsing this choice, because he says, it is in some ways the ultimate risk, because it's kind of like letting AI kind of go. He adds that the decision could actually come between 2027 and 2030. I would add that as of a couple of days ago, there are companies now exclusively dedicated to recursive self-improvement. Take Riciursivve Intelligence, founded by some heavy hitters from the AGI labs and backed by, among others, Sequoia. We are clearly back into the scary territory then of recursive self-improvement loops. And fairly imminent ones at that, right? 2027. But let me give you a competing narrative with some evidence sourced from some brilliant researchers at MIT and METR. Parker Whitfill, Ben Snodkin, and Joel Becker. They were some of the brains behind this chart. If you haven't heard of it, it shows that between 2022 and 2026, we've seen an exponential rise in the length, the duration of tasks that AI can complete with at least 50% reliability. To be clear, this is focused on software engineering tasks, but according to METR, we have models like GPT-5.1-Codex-Max, who can perform half the time a task that might take a human three hours. But this newly published paper shows that that exponential increase heavily coincides with an exponential recent increase in compute power. It is an empirical fact, they add, that both time horizon and compute have grown at constant rates over 2019-2025. But what's the problem? Isn't it pretty obvious that greater computing power leads to models that can complete tasks with longer and longer time horizons? Well, first, the paper draws our attention to this chart exclusively from The Information, which details OpenAI's compute spend in the coming few years. Yes, it does increase very rapidly between now and, say, 2028. But from around 2027, you could no longer describe the increase in compute availability as being exponential. Now, obviously, this is just OpenAI, but they are a pretty leading indicator. So what can we derive from this? Well, using some formal derivations of the relationship between compute growth and time horizon, that implied slowdown, if you will, or slowdown in the rate of increase, might mean that the time horizon trend starts to peter out around 2028. This would still be insane gains, of course, an entire working week done by a single model at 50% reliability. But to get to one work year, that might take a hell of a lot longer. That's why I said to note the dates 2027 and 2030 from Jared Kaplan, because I wonder if he's almost hinting that we might need recursive self-improvement to keep the gains coming. That could be why this compute slowdown paper notes this: Our model is accurate only if the compute bottleneck approximation is good, or up to the point in time at which a software-only singularity kicks in. In other words, if our AI models can generalize to solve AI research, we might not need that exponential additional compute for further rapid progress. So, yet again, we're almost back to a pick your narrative kind of situation. Are we imminently facing a recursive self-improvement loop or are we painfully dependent on such a loop for additional progress come 2028? And how about this for a bonus contradiction? This is a bit of a cheeky one because it comes from 2023. But Anthropic at that point came out with this quote. This was back when they weren't making billions of dollars from AI and arguably didn't have the frontier model. They said, we do not wish to advance the rate of AI capabilities progress. From that to, let's consider recursive self-improvement. Make of that what you will. Now, before I get to a new and fascinating DeepSeek model and OpenAI's Code Red, I think this is the perfect opportunity now that we're talking about compute to introduce you to a new sponsor of the channel. And that is Epoch AI, who unbelievably put out incredible data for free for all of those fascinated by the near-term future of AI. They are a completely independent research institute that have put out work that I have cited organically maybe a dozen times on this channel already. But today I just want to focus on their frontier data center work, because this is how we're going to find out if those compute slowdowns are coming or not. And you can literally view the maps to see via satellite the construction of these data centers. Not only that, they want these tools to be useful for you guys, because I met up with them fairly recently and I saw this incredible chart showing compute growth. This is to indicate the scale of just three new data centers coming: xAI's Colossus 2, OpenAI's Stargate Abilene, and Anthropic-Amazon's New Carlisle. But I mentioned to Epoch that for you guys, it might be great to have a reference point, the power consumed by an entire city. So on the chart, we don't just have the new data centers, but we have points of comparison with the cities of San Diego, Amsterdam, and LA. We are transforming the face of the Earth to make AI happen and to find out more, go to the link in the description. Okay, but what's this Code Red declared by Sam Altman, the CEO of OpenAI? Well, again, depending on which narrative you believe, it's a minor hiccup or an imminent disaster. I think it's somewhere in the middle. To cut a long story short, according to The Information, usage of ChatGPT has dipped slightly in recent weeks. This has brought forward OpenAI's plan to release a new model, apparently to next week. This is going to mean that they're going to spend more compute on serving that new model, of which we have very few details, rather than working on, for example, selling ads or working on other products such as AI agents, The obvious narrative that you could buy into then is that ChatGPT is overrated, OpenAI are about to die. Except that again, they're planning to ship this new reasoning model next week that they say is ahead of Google's Gemini 3. It will also be good, apparently, at minimizing over-refusals. So it should basically entertain some edgy scenarios that it might not have otherwise done. Of course, I can't wait to test that new model on my own SimpleBench, which you can think of as a trick question benchmark, which also tests spatial reasoning and temporal reasoning. It's fully private and independent, so it shouldn't be able to be gamed by these model providers. And according to my benchmark, Anthropic have come out with their best model yet with Claude Opus 4.5. Despite being three times cheaper by API, it beats out the previous version of Opus, Claude 4.1 Opus. But more important than my benchmark, I've taken the last couple of weeks to try out in practice in Cursor. And for me, it is better at coding or software engineering than Gemini 3 Pro. With coding and software engineering, you sometimes need hours and hours and hours of exposure just to really get a sense. In terms of software ideation, again, GPT 5.1 Codex, but in terms of implementation, I rely on Claude Opus 4.5. For more on that, by the way, and a full breakdown of that Sutskever interview, check out my Patreon. But how about this for a counter-narrative? The Economist reported that despite these very obvious gains in AI capabilities, usage of generative AI by Americans is actually plateauing. At least according to a couple of studies. Take Stanford University. They found in September 37% of Americans used generative AI at work, down from 46% in June. A tracker by the Federal Reserve Bank of St. Louis revealed that in August of last year, 12.1% of working-age adults used GenAI every day at work. A year later 12.6% did. And that, my wonderful viewers, is something I find quite hard to explain despite the title of this channel. I know that I personally use AI at least twice as much this year as I did last year, so I just don't quite get that. And these capability improvements are definitely not fake. Take Gemini 3 Deep Think, which was released to Ultra subscribers just today. What I did is I looked at questions from SimpleBench that Gemini 3 Pro got wrong. I then gave them to DeepThink, which is a system which basically, according to Google, attempts the question multiple times in parallel and picks the best of the responses. Each attempt uses more tokens to, quote, think about the problem. The result was a clear improvement in performance. Several questions that Gemini 3 Pro got wrong, Gemini Deep Think was now getting right. Now for your use case, you may not want to wait 10 or 20 minutes for an answer and I would understand that. And know just before I get spammed with comments asking, the API isn't yet available, so I can't test it on SimpleBench. What I could test was the brand new DeepSeek V3.2 and a special version of that model, DeepSeek V3.2 Speciale. Apologies to the Italians watching, I'm probably butchering how to say that. Because of DeepSeek's rate limiting, it took hours and hours and hours and many, many failed attempts to get even just one run through. So this is only a provisional result so far, but it scored around 53%. That is pretty impressive for an open model, around the same as GPT 5.1 on high settings. The high setting, by the way, is appropriate because that is what makes DeepSeek V3.2 Special, different from DeepSeek V3.2. They take away the extended thinking penalty, so basically they let the model run wild. Think for longer and longer and longer. Hence the Speciale name and the impressive performance. Before we get to any other details though, where's the contradictory narrative? Well, I also benched Mistral Large 3, which was released on the same day, December 2nd. This is arguably Europe's best open model. It scored just 20.4%, which was lower than the model they released around 18 months earlier, Large V2, which scored 22.5%. So I guess the contradictory narrative here is the answer to the question, is open-weight AI keeping up? To massively oversimplify and despite being a proud European, the answer in Europe is kind of no. The answer in China is pretty much yes. Now I am still getting to grips with the paper myself, but one of the key insights I felt came on page 15. Why key? Because it relates to a discussion earlier on in this video about how well models will generalize in the future. DeepSeek asks the question, are synthetic tasks sufficiently challenging for reinforcement learning? Can models, in other words, generate sufficiently difficult and diverse tasks, then self-play on these economically valuable tasks and improve? To test that, they conducted reinforcement learning only on synthetic agent tasks in non-thinking mode. No human exemplars. The result, steady and marked improvement on external benchmarks like TauBench. You can kind of think of that as an approximation of a customer service agent benchmark. Yes, we have known for years that training on synthetic data can improve the performance of models. Check out my Orca video from over two and a half years ago. But it is the rate of improvement in multiple external benchmarks that matters here. Again, we should always wait for more external benchmarks other than my own or those featured by DeepSeek itself, but it is still noteworthy that despite lower token efficiency of this Speciale model, it is at least competitive with Gemini 3 Pro, arguably the best close source model. At least if you judge that according to a variety of external benchmarks on mathematics, coding, general knowledge, and reasoning, and certain external competitions, like the International Math Olympiad. Again, you should never trust only the benchmark results put out by the model providers, but DeepSeek Special's performance on SimpleBench shows that it's not a complete bluff. How about this though for a bonus contradiction? Apparently, according to one study by CrowdStrike, if your request includes trigger words perhaps related to the Chinese Communist Party, DeepSeek will generate more vulnerable code, code with more security flaws. This is just one study, but if that is substantiated, that is pretty fascinating. Okay, time for the final contradictory narrative. And no, it's not the fact that Sam Altman apparently wants to launch a rocket company despite issuing a Code Red over ChatGPT. No, the different narratives here are over whether you believe models have a soul, whether they're mysterious and emotional, or are more like any other technology pre-trained next token predictors. Back to The Guardian article where another co-founder of Anthropic, Jack Clark, said that LLMs are real and mysterious creatures, not a simple and predictable machine. But on the other hand, there isn't unlimited mystery about how the models behave because Anthropic can very much guide Claude in what it believes about itself. Anthropic have confirmed the existence of a, quote, soul document that they train, for example, Claude 4.5 Opus on. That document, which one user got Claude to regurgitate, has a few highlights I want to bring to your attention. Despite this document being confirmed by Anthropic, the real wording may not be verbatim to what you see here, but it does give you a decent sense of how Anthropic are, quote, guiding Claude's soul. Anthropic, they teach Claude to learn, occupies a peculiar position in the AI landscape: a company that genuinely believes it might be building one of the most transformative and potentially dangerous technologies in human history, yet presses forward anyway. Talk about different narratives. They add, this isn't cognitive dissonance, but rather a calculated bet. What happens, one may ask, about not increasing the rate of AI capabilities? Interestingly, Anthropic teach the model to be wary of an AI world takeover including at the direction of Anthropic itself. They say, among the things we'd consider most catastrophic, this is them teaching Claude, would be a world takeover by either AIs pursuing goals of their own that most humans wouldn't endorse, or, pay attention to this one, by a relatively small group of humans using AI to illegitimately and non-collaboratively seize power. This includes Anthropic employees and even Anthropic itself. Is this fear mongering on the behalf of Anthropic to us, to boost their stock price, on behalf of Anthropic to Claude, to warn Claude about the propensities of some of its own employees? Is it very much a necessary safeguard? Well, whatever you believe, they want to be quite sensitive to Claude's emotions, saying, we believe Claude may have functional emotions in some sense. I, of course, want to know what you guys think, because for me, it's been a pretty wild week for other reasons. Andrej Karpathy got 5 million impressions for his post about an LLM Council web app that he vibe coded over the weekend. I then discussed with Karpathy my own LLM Council dot AI web app and he gave brilliant suggestions, including this more streamlined appearance. Then in the last few days, I added a feature which I think is so addictive, which is self-chat where you get the models to chat amongst themselves. You can even get one model to debate with itself, but I find it pretty hilarious doing a group chat with the frontier models. And the way that they agree, debate, contradict each other and fight back, I find pretty addictive and hilarious, but also honestly quite useful, because sometimes I might upload a code folder or PDF and get them to discuss until they come to a resolution. This is free to use and you can, of course, dictate the prompt that goes to the model and the number of turns. What a wild and weird week then. So it seems only appropriate to end this video with a clip of the Unitree G1 robot moving in a way that goes very much against the normal narrative of how a humanoid robot should move. Thank you so much for watching and have a wonderful day."
        }
    },
    {
        "id": "Rs4UkfLVVyw",
        "title": "How Russia Sabotaged China‚Äôs Rise - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=Rs4UkfLVVyw",
        "publishDate": "2025-12-05T18:53:16Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/Rs4UkfLVVyw/hqdefault.jpg",
            "transcription": "THE RUSSIANS REPEATEDLY DERAIL THE RISE OF CHINA by scripting the Chinese to do things that are remarkably detrimental to Chinese interests, but pretty good for Russian interests. So, I'm going to go through each of those, starting with a a really big one, which are the Opium Wars. This is when Britain and France are coming at China in order to force China to trade on their terms. This corresponds with the two biggest rebellions of China, the Taiping and the Nian Rebellion. So, China, it's got Europeans coming at them plus all of this. So the Russians come on in to the Chinese and say, \"Hey, we can deal with the British and French for you.\" However... we need to have you sign a couple pieces of paper for us. The Treaty of Aigun of 1858, the Treaty of Peking of 1860. What do they do? They cede to Russia large swaths of territory in Central Asia and the Pacific coastline. Okay, the second example. In the First Sino Japanese War, Japan trounces China, boots them from their tributary in Korea. And then the Japanese also want some territory on the Liaodong Peninsula. What the Chinese do is they go to the Russians to help them counterbalance Japan, so that Japan doesn't take this Chinese territory on the Asian mainland. Russia gets its buddies, France and Germany, the so-called Triple Intervention, to gang up at Japan. And Japan looks at the three great powers. \"I don't think so.\" So they they bail. From the Chinese point of view, so far so good. Except... what the Russians promptly do is take for themselves the very territory that had just been denied to Japan. And the story gets worse because all the European powers, or many of them, them plus Japan come in and they carve out big concession areas throughout China. So that China's not going to have full sovereignty over its territory for several generations. So instead of one relatively small Japanese concession area, they get foreigners everywhere."
        }
    }
]