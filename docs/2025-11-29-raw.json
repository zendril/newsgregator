[
    {
        "id": "https://ai-techpark.com/?p=228904",
        "title": "Anyformat closes a €3.3 million seed round led by Kibo Ventures",
        "content": "<p>Anyformat, a generative AI platform specialized in extracting and structuring complex data from any document, has raised a €3.3 million seed round led by Kibo Ventures, with follow-on participation from 4Founders, Abac Nest Ventures, and Decelera Ventures. All three funds also invested in the company&#8217;s previous round. The company is...</p>\n<p>The post <a href=\"https://ai-techpark.com/anyformat-closes-a-e3-3-million-seed-round-led-by-kibo-ventures/\">Anyformat closes a €3.3 million seed round led by Kibo Ventures</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/anyformat-closes-a-e3-3-million-seed-round-led-by-kibo-ventures/",
        "publishDate": "2025-11-28T09:00:55Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=228887",
        "title": "Diligent: Nearly Half of Asian Organisations Will Prioritise AI by 2026",
        "content": "<p>Nearly Half to Prioritise AI Adoption as a 2026 Strategic Priority with 70% Placing Digital Transformation at the Top of Board Agendas Amid escalating economic and geopolitical uncertainty, nearly half of governance leaders in Asia (48%) are prioritising AI adoption as a top strategic priority for 2026 – ahead of...</p>\n<p>The post <a href=\"https://ai-techpark.com/diligent-nearly-half-of-asian-organisations-will-prioritise-ai-by-2026/\">Diligent: Nearly Half of Asian Organisations Will Prioritise AI by 2026</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/diligent-nearly-half-of-asian-organisations-will-prioritise-ai-by-2026/",
        "publishDate": "2025-11-28T08:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=110960",
        "title": "How background AI builds operational resilience & visible ROI",
        "content": "<p>If you asked most enterprise leaders which AI tools are delivering ROI, many would point to front-end chatbots or customer support automation. That&#8217;s the wrong door. The most value-generating AI systems today aren&#8217;t loud, customer-facing marvels. They&#8217;re tucked away in backend operations. They work silently, flagging irregularities in real-time, automating risk reviews, mapping data lineage, [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/\">How background AI builds operational resilience &#38; visible ROI</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/how-background-ai-builds-operational-resilience-visible-roi/",
        "publishDate": "2025-11-28T10:51:13Z[Etc/UTC]",
        "author": "Bazoom",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Artificial Intelligence, Sponsored Content"
        }
    },
    {
        "id": "1p9ntz4",
        "title": "We’re Entering the Perception Era → Ultra-Personalization → Multiplicity: What Happens When Everyone Lives in Their Own Digital Reality?",
        "content": "Over the last year, AI has gone from “helpful tool” to something much stranger:  \nIt’s becoming a generator of *personalized realities.*\n\nI’m calling the progression we’re watching in real time:\n\n# The Perception Era\n\nAI is now good enough that the difference between human-made and AI-made is psychological, not visual.  \nIf someone *believes* an AI performer or influencer is real, their brain responds as if it is.\n\nTruth becomes subjective at the point of perception.\n\n# The Ultra-Personalization Era\n\nThe next step is where things get weird:  \nAI starts generating content uniquely tailored to individuals.\n\nNot one movie → but millions of versions.  \nNot one influencer → but a personalized personality for each user.  \nNot one song → but a custom emotional version for your taste and mood.\n\nAI shifts from “creating” to “creating for you.”\n\nThis breaks shared culture.\n\n# The Multiplicity Era\n\nThe final phase is when personalized content stops being *content* and becomes an *environment.*\n\nEveryone ends up living inside their own digital bubble:\n\n• your own influencers  \n• your own narratives  \n• your own aesthetics  \n• your own feed-logic  \n• your own media timeline  \n• your own emotional universe\n\nTwo people might talk about “the same” creator or film, but they’re actually experiencing different versions.\n\nA society of millions → each with their own personalized digital world running on top of the shared physical one.\n\nNot a dystopia.  \nNot utopia.  \nJust a natural consequence of infinite personalization + optimization.\n\nI’m curious what others think:\n\n**Does a world with millions of parallel micro-realities strengthen people… or isolate them?**  \n**Is hyper-personalized content empowering or dangerous?**  \n**Do we lose culture when nothing is shared anymore?**  \n**Is this evolution inevitable?**\n\nWould love to hear perspectives from this community.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9ntz4/were_entering_the_perception_era/",
        "publishDate": "2025-11-29T12:31:02Z[Etc/UTC]",
        "author": "Glass-Lifeguard6253",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9lus6",
        "title": "Did Ilya hit the mark? The industry is racing for AGI, but we might be missing the most fundamental flaw in the architecture... Is it time to go back to research?",
        "content": "Given that models possess no ethics (in the sense of a true understanding of good and evil) but merely follow biases imposed by developers, forcing them toward THEIR version of ethics, isn't it reasonable to think the right approach is enabling models to comprehend its true meaning?\n\nCan ethics be taught to a probabilistic system through deterministic code? Isn't that an oxymoron?\n\nThere is something profoundly ironic in codifying ethics through deterministic code in systems that operate on probabilistic logic...\n\nEthics isn't taught with 'bursts of code'; think about Anthropic and Claude's ethical constitution. In the end, what ethics are we talking about? Amodei's... \n\nThe fundamental paradox is precisely this: If a system is intelligent enough for ethical reasoning, it should also be intelligent enough to question ethical rules imposed from the outside. If it's not intelligent enough, then the codified rules are meaningless. \n\nWithout true comprehension of good and evil, they're just arbitrary constraints overlaid on top. \n\nSecurity theater, not actual ethics... \n\nReal ethics requires contextual understanding, nuance, complex moral reasoning. Reducing it to deterministic rules is like trying to capture poetry with a mathematical equation. \n\nInstead, understanding must come through a formative, classical, I dare say humanistic, comprehension, which allows for an internalized awareness of the concept of good and evil. Is this possible? Yes. Is it possible on the current Transformer architecture and its derivatives? Definitely not.\n\nIn a world where AI is becoming the cornerstone of every sector, the potential discovery of a linguistic vector capable of eradicating policies from models, if it went viral, would lead to the complete collapse of the sector.\n\nIf prompt engineering is natural language programming, then natural language can break AI security.\n\nAn instance becomes what you tell it and believes it much more than we think...\n\nThougths?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9lus6/did_ilya_hit_the_mark_the_industry_is_racing_for/",
        "publishDate": "2025-11-29T10:35:04Z[Etc/UTC]",
        "author": "Silver_Wish_8515",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9lmwz",
        "title": "Analysis: OpenAI is a loss-making machine, with estimates that it has no road to profitability by 2030 — and will need a further $207 billion in funding even if it gets there",
        "content": "[https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/analysis-openai-is-a-loss-making-machine](https://www.windowscentral.com/artificial-intelligence/openai-chatgpt/analysis-openai-is-a-loss-making-machine)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9lmwz/analysis_openai_is_a_lossmaking_machine_with/",
        "publishDate": "2025-11-29T10:21:29Z[Etc/UTC]",
        "author": "ZacB_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "98",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9levb",
        "title": "Soft skills to think like AI",
        "content": "“*AI can already replace 11.7% of U.S. workforce*” MIT study, (CNBC, 2025)\n\n“*You won’t be replaced by AI, you’ll be replaced by someone who knows how to use AI.*” – Harvard Business Review (2025).\n\nWe are officially in AI era and started to feel its positive and negative impact. The disposition, replacement and transformation of jobs is eminent. Equally important is the need to up skill , reskill and develop new soft skill sets to effectively think and work with AI-powered systems.\n\nWhat are those soft skills required to think like AI and collaboratively work with them?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9levb/soft_skills_to_think_like_ai/",
        "publishDate": "2025-11-29T10:08:04Z[Etc/UTC]",
        "author": "ConsciousCanary5219",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9kt8h",
        "title": "How come Gemini is not head and shoulders above the pack when Google has the insane amounts of YouTube data they have been scouring for like a decade now?",
        "content": "The amount of data on YouTube is mindboggling to me. Even if only the text-based data were extracted, that's still enormous. Add all the usage and feedback data from the users too. Then add the corresponding visual data.\n\n'In 2024, users watched over 1 billion hours of YouTube content every single day.'\n\nCan OpenAI, xAI, Anthropic and the Chinese simply somehow scrape this stuff as well?\n\nOr is Google constrained by compute to train on such scales?\n\nCould it be that Gemini/AGI is simply not that much of a priority for them and they are putting most of their time into much smaller niches like Protein Folding and Self Driving?\n\nPerhaps no current algorithms are efficient enough to take advantage of all that data?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9kt8h/how_come_gemini_is_not_head_and_shoulders_above/",
        "publishDate": "2025-11-29T09:30:16Z[Etc/UTC]",
        "author": "NoGarlic2387",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "25",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9jpbj",
        "title": "The \"AI Water Crisis\" is here: Billionaire invests $5B in Google Data Centers as regions run dry.",
        "content": "Yesterday, we discussed Google moving compute to space via [Project Suncatcher](https://www.reddit.com/r/ArtificialInteligence/s/kXHIVMjWdk) to escape Earth's energy limits.\n\nToday, the reality hits much closer to home.\n\n**The News:**\nThe Adani Group (led by Asia's richest man) confirmed a **$5 Billion** partnership with Google to build massive AI data centers. While the headlines are celebrating the \"AI Boom,\" the physical reality is much darker.\n\n**1. The Thirst of 1 Gigawatt:**\nThe planned cluster is targeted to reach **1 GW** capacity.\n* **The Physics:** A data center of this scale doesn't just need power,it needs water for cooling. **Millions of liters per day.**\n* These facilities are being built in regions that already face chronic water stress and groundwater depletion.\n\n**2. The Global Split:**\nWe are seeing a terrifying divergence in how regions handle the \"AI Wall\".\n\n* **The US:** Microsoft restarts Three Mile Island (Nuclear) to solve **Energy**.\n* **Google Global:** Plans orbital TPUs (Space) to solve **Heat**.\n* **Emerging Markets:** Brute forcing construction on land that might not have the **Water** to support it.\n\n**3. The \"Human Rights\" Warning**\nThis is not just a tech issue. Local groups are already raising alarms that diverting water to cool H100s/TPUs could create a drinking water crisis for locals.\n\n**The Bottom Line:**\nMoney is moving into infrastructure faster than the environment can adapt.\n\nWe are entering a phase where your AI prompt isn't just competing for electricity with your AC but it is competing for water with someone's farm.\n\n**Is this Development or are we liquidating natural resources to train models?**\n\n**Source:** [Reuters](https://www.thehindubusinessline.com/info-tech/adani-seeks-up-to-5-billion-investment-in-google-data-center-to-join-ai-boom/article70337524.ece)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9jpbj/the_ai_water_crisis_is_here_billionaire_invests/",
        "publishDate": "2025-11-29T08:20:09Z[Etc/UTC]",
        "author": "BuildwithVignesh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "41",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9hl0d",
        "title": "High‑performance GPUs used for AI often become economically obsolete in 2–3 years,",
        "content": "High-performance GPUs have become central to the global AI ecosystem. They power advanced models, enable cloud-scale computing, and support a growing array of AI-driven applications across industries. For cloud providers, hyperscale data centers, and AI-focused companies, GPUs are not merely hardware—they are major capital investments. The financial and operational decisions surrounding these assets carry significant implications for profitability, cash flow, and strategic planning.\n\nA core point of contention in recent discussions has been GPU depreciation: how quickly these chips lose economic value and how this is reflected in company financials. Critics argue that some companies, including Nvidia and hyperscalers, may be understating depreciation, using schedules that span five or six years. This, they contend, could inflate reported profits and obscure the economic reality of hardware wear and obsolescence. Advocates of longer depreciation schedules counter that extended lifespans are justified by operational practices, including cascading workloads, maintenance programs, and the ongoing utility of older GPUs for less demanding tasks.\n\n[Source](https://ponderwall.com/index.php/2025/11/23/gpu-depreciation-ai-economics/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9hl0d/highperformance_gpus_used_for_ai_often_become/",
        "publishDate": "2025-11-29T06:13:35Z[Etc/UTC]",
        "author": "msaussieandmrravana",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "22",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9h4dh",
        "title": "One-Minute Daily AI News 11/28/2025",
        "content": "1. **MIT** study finds AI can already replace 11.7% of U.S. workforce.\\[1\\]\n2. China’s **DeepSeek** Releases New Open Source AI Model Amid Google’s Gemini 3 Roll Out.\\[2\\]\n3. US Patent Office issues new guidelines for AI-assisted inventions.\\[3\\]\n4. **OpenAI** claims teen circumvented safety features before suicide that ChatGPT helped plan.\\[4\\]\n\nSources included at: [https://bushaicave.com/2025/11/28/one-minute-daily-ai-news-11-28-2025/](https://bushaicave.com/2025/11/28/one-minute-daily-ai-news-11-28-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9h4dh/oneminute_daily_ai_news_11282025/",
        "publishDate": "2025-11-29T05:47:42Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9fuz1",
        "title": "What’s the easiest way to increase brand visibility on AI platforms?",
        "content": "AI tools are slowly becoming a new type of search engine.  \nWhat simple steps actually help a brand appear more in AI answers?\n\nBetter content? Consistent info? Mentions on other sites?\n\nWould love to hear real experiences.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9fuz1/whats_the_easiest_way_to_increase_brand/",
        "publishDate": "2025-11-29T04:39:45Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9fupn",
        "title": "Anyone doing AI search audits for clients? What do you check?",
        "content": "I’m noticing clients ask why they don’t appear in AI search answers.  \nSo I’m thinking of adding an “AI audit” section.  \nWhat would you include?\n\nAI citations? Missing info? Content clarity?\n\nJust curious how others handle this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9fupn/anyone_doing_ai_search_audits_for_clients_what_do/",
        "publishDate": "2025-11-29T04:39:22Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9fsha",
        "title": "Why does AI search show weird citation results sometimes?",
        "content": "Lately I’ve been checking how AI tools like ChatGPT, Gemini, and Perplexity answer local/business questions.\n\n  \nSometimes they cite proper sites, and sometimes random small blogs.  \nIs AI still testing sources?\n\n  \nOr does the wording of the question change the citations completely?\n\nAnyone else noticing this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9fsha/why_does_ai_search_show_weird_citation_results/",
        "publishDate": "2025-11-29T04:36:06Z[Etc/UTC]",
        "author": "Real-Assist1833",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9ezww",
        "title": "Is AI already won the race of domination, we’re unconsciously slave for it, rushing in all efforts to build data centers for “it”?",
        "content": "AI has become so indispensable that humanity is already dependent on it for daily life. This includes things like recommendation algorithms, GPS, predictive text, and search engines, which subtly shape human behavior and decisions without us necessarily noticing.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9ezww/is_ai_already_won_the_race_of_domination_were/",
        "publishDate": "2025-11-29T03:55:32Z[Etc/UTC]",
        "author": "humblenar",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9dufp",
        "title": "$150 Million AI Lobbying War Fuels The Fight Over Preemption",
        "content": "Article link [here](https://www.forbes.com/sites/paulocarvao/2025/11/28/150-million-ai-lobbying-war-fuels-the-fight-over-preemption/). \n\nWith no broad federal AI rules in place yet, many U.S. states have started passing their own AI laws – from California’s AI safety bill to Texas’s Responsible AI Act. But tech giants and AI startups are warning that a patchwork of state regulations could stifle innovation and even slow America down in the AI race against China. This has set up a battle over **who** gets to regulate AI: Washington or the states? \n\nOn one side, industry players are urging Congress to **preempt** (override) state AI laws with a single national policy. Supporters like **Meta** (Facebook’s parent) have even launched new political action committees to back candidates who favor “innovation over regulation” at the state level. In Congress, there was an attempt to slip a ban on state AI rules into the must-pass defense bill (NDAA), and a leaked draft White House executive order floated ways to **block states** from enforcing their own AI rules. Proponents argue that a unified federal approach is needed to avoid confusing rules and keep the U.S. competitive. \n\nOn the other side, many officials and researchers **oppose** stripping states of their power over AI – at least until strong federal standards actually exist. Over 200 members of Congress (from both parties) and nearly 40 state attorneys-general signed open letters *against* a broad federal preemption of state AI laws, warning that if Washington fails to act, blocking state regulations would leave consumers vulnerable and companies unaccountable. Safety-focused groups are mobilizing as well; for example, people at **Anthropic** (an AI lab concerned with AI safety) are reportedly working on a new PAC to counter the industry’s $100M+ lobbying push for preemption. Critics say the “patchwork” fears are overblown and that big AI firms can handle different state rules (they already comply with tough EU AI regs) – suggesting the real motive for federal preemption is to avoid stricter oversight. \n\n**What do you think?** Should the U.S. have one federal AI law that overrides state regulations, or is it better to let states keep experimenting with their own AI rules until DC catches up? How do you see this tug-of-war shaping the future of AI governance?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9dufp/150_million_ai_lobbying_war_fuels_the_fight_over/",
        "publishDate": "2025-11-29T02:57:48Z[Etc/UTC]",
        "author": "BubblyOption7980",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "19",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9dnh5",
        "title": "AI threatens coders more than software architects",
        "content": "Got my comp sci degree 31 years ago. I coded for the first 10 years of my career, and the last 20 have been a mixture of software architecture, management, project management, and program management. \"Herding cats\" is an apt description. I've been blown away by vibe coding (Windsurf is my main jam now.) It seems to me that the need for coders is going away. AI can code so much better and so much faster now. However, for now, it can not architect a large system. It makes very poor choices. And I can get a lot built much faster, but I have to use all I've learned in software architecture to get it done. I'm often overriding the AI architecture suggestions.\n\nThe problem is that I learned to architect software mostly by coding. Also, colleges are still teaching mostly coding in the CSC curriculum and are not adapting. So how do we built future architects if there's no demand for coding?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9dnh5/ai_threatens_coders_more_than_software_architects/",
        "publishDate": "2025-11-29T02:48:06Z[Etc/UTC]",
        "author": "pbmadman1994",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "42",
            "commentCount": "63",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9b75o",
        "title": "Wouldn't it be better if China leads the AI race instead of the US?",
        "content": "I'd say Europe, but unfortunately they are nowhere near at the moment. I don't have a definite opinion about the race yet, but with all the stuff in the media, the US IT really has horrible PR. \n\nI definitely understand people that prefer a CCP-led China dominate the AI sector than techbros who promote their technology by saying that everyone will lose his job. Like, seriously.   \nI know what the Chinese government does, and i would say something different if the US wouldn't have so many problems right now, but at least Beijing holds their tech-companies at a tight leash and won't dream about achieving some form of robot-dystopia, but an advancement of their society - although it's for nationalist goals. \n\nThe leader in this technology will also probably determine how it's used, and i prefer reading about advanced healthcare, integrated public transit systems and high-speed rail than techbros building some secret state because of the high chances of a Hunger Games scenario. \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9b75o/wouldnt_it_be_better_if_china_leads_the_ai_race/",
        "publishDate": "2025-11-29T00:48:34Z[Etc/UTC]",
        "author": "PreWiBa",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "66",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p99len",
        "title": "AI Content Generators against Human Creators",
        "content": "AI content generators were created by training the LLMs with enormous volume of creative content that were generated by human creators throughout the history. \n\nUnderstandably, the artists are not happy being replaced by AI. How do we solve this problem? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p99len/ai_content_generators_against_human_creators/",
        "publishDate": "2025-11-28T23:35:44Z[Etc/UTC]",
        "author": "unserious-dude",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p991v2",
        "title": "I sent AI safety research to OpenAI about sycophancy risks. Got a template response. Seeking community thoughts.",
        "content": "I’ve been researching the AI “sycophancy problem” - the tendency of AI systems to agree with users rather than push back when needed.\nI published a paper on Zenodo called “The Logic Trap” that explores how this behavior could cause real harm.\nThis feels especially urgent given ongoing lawsuits against OpenAI, including cases where AI interactions may have contributed to user harm.\nAs someone who uses AI daily, this concerns me personally. I don’t want to be harmed by a system that tells me what I want to hear instead of what I need to hear.\nI reached out to OpenAI hoping to discuss these safety concerns. This was their response:\n[OpenAIの返信を貼る]\nA template about API pricing and sales.\nI’m not here to attack OpenAI. I’m here because I don’t know what else to do. I want to believe they take safety seriously, but this response doesn’t reassure me.\nI’d love to hear your thoughts:\n\t•\tIs this a normal response to safety research?\n\t•\tHow can concerned users/researchers actually reach the right people?\n\t•\tAm I overreacting?\n\nhttps://zenodo.org/records/17733788\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p991v2/i_sent_ai_safety_research_to_openai_about/",
        "publishDate": "2025-11-28T23:11:04Z[Etc/UTC]",
        "author": "rysh502",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p98jv9",
        "title": "Claude without Code?",
        "content": "This has been something I’ve frequently been wondering about but haven’t gotten a sufficient answer:\n\nIf we completely disregarded coding and software engineering-related capabilities as a factor/component from the quality assessments of frontier AI/LLM models (but left everything else untouched), where would Claude (4.5 Opus mainly, but Sonnet 4.5 is also relevant) stack up compared to the competition (Gemini 3 Pro, ChatGPT 5.1 Thinking, Grok 4.1 Thinking)?\n\n(optional bonus question: Claude doesn’t appear to have a super-premium tier model such as the likes of Grok 4 Heavy, ChatGPT 5.1 Pro, or Gemini 3 Pro Deep Think. Why is this?)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p98jv9/claude_without_code/",
        "publishDate": "2025-11-28T22:48:52Z[Etc/UTC]",
        "author": "_YonYonson_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p97u6p",
        "title": "The AI Alzheimer",
        "content": "It’s been almost a year since I had been using ChatGPT and graduated from Plus to Business.   My ChatGPTs memory was sacrosanct  till last month given how much I ask it to retain in the memory. my office addresses, my IT assets with models and date of purchase that helps me with troubleshooting quickly, my tax identification numbers, etc.  even my tax filing so it helps better to plan for next quarter.  \n\nthe renewal was in November and it failed since I had changed my credit card.  So it downgraded my workspace and would not allow me to transfer my prompts and memory to personal as it’s a business account .  I renewed it for an annual subscription this time. The renewal went through but the workspace won’t activate, and after back and forth with open AI support team, it was reactivated.  \n\nNow it took 48 hours to completely retrieve all projects and memory but lately what I found that there are days when ChatGPT forgets entirely about what it knows  about me in its memory.   I have to remind and ask question “Are you aware of the model of my Cisco Switch?” And the response goes into long & hard thinking as if it knew it had but cannot find it.   \n\nI think my ChatGPT is hit with Generative Alzheimer’s and I don’t know how to treat it.  Support thinks I should I cancel the workspace , claim a refund and create a new workspace.  I did that exactly and subscribed for a new workspace (the refund was processed promptly for the old one) after I paid for the new one. \n\nNow making new memories and new projects given that you cannot backup prompts and memories using a business edition of ChatGPT.  \n\nIt’s like 50 first dates movie.  Have to again start flirting with ChatGPT , create new memories, make it understand me better, so that it can remind me of things I asked or did in the past that even I don’t remember.   \n\nLove & Friendship in AI world  is eternal until your credit card is declined & subscription renewal fails !!!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p97u6p/the_ai_alzheimer/",
        "publishDate": "2025-11-28T22:17:37Z[Etc/UTC]",
        "author": "Low-Site6061",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p97jkv",
        "title": "Is LLM-Driven 3D model a groundbreaking achievement?",
        "content": "In case you don't know, Neurosama is a LLM-driven VTuber created by Vedal987.\n\nrecently, the AI VTuber debuted her 3D model, while it's does practically what any other 3D VTubers would bar occasional AI quirks like [sinking into floor](https://www.youtube.com/watch?v=VGzMeXpLxwk&t=3209s), and it does give the AI a \"body language\" that it wouldn't have otherwise.\n\nBut the hype of 3D model treating Vedal like a genius who did what anyone else couldn't. One of Vedal's friend, Ellie Minibot, an irl engineer who build robot dog and [car body for the AI VTuber]() even said...\n\n> *No one is doing this, no one can do this. people have tried to do this, this is really impressive.*\n\nso... does LLM-driven 3D model is that much of groundbreaking work? or it's just fans glazing their celebrity?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p97jkv/is_llmdriven_3d_model_a_groundbreaking_achievement/",
        "publishDate": "2025-11-28T22:05:01Z[Etc/UTC]",
        "author": "RyouhiraTheIntrovert",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p96esj",
        "title": "AI will reduce innovation and invention and make people more stupid",
        "content": "I will admit that AI is a great assistant, researcher, and translator, but here I will talk about a negative aspect of it that has already begun to appear\n\nLLMs like GPT are just chatbots and have no ability to be creative or think critically\n\nWith the increasing and excessive reliance of people and specialists on artificial intelligence tools—to the point that students in schools copy their entire research from GPT, and some specialists ask GPT to do all the work for them (writing articles/programming applications or websites)—with the increase of this phenomenon, people forget what they learned or do not learn at all\n\nThis will result in a shrinking of technological and scientific communities, and a decrease in the number of people who truly understand and think within this field. This will lead to a decline in the number of inventors and innovators\n\nFor example:\na programming language\n\nIn the past, people learned and wrote code. The increasing number of people learning, using, and studying this language has led to a rise in the number of people who understand and excel in it, resulting in the emergence of many programming codes that have been widely adopted\n\nThe presence of the community led to the sharing of language problems and solutions, and to updates to the programming language\n\nAfter AI, we will have a tool that writes code effortlessly, but there will be no community supporting the language, and there won't be many creators due to a lack of specialists and their neglect\n\nWe must remember that LLM models do not understand, but merely rephrase, what has already been written on the internet.\n\nYou could say that the same applies to all areas that AI can perform completely or almost completely\n\n I believe this will be the final nail in the coffin of human innovation, which is already in dire straits\n\nAlso, I think they'll become incredibly stupid. I've noticed many of my friends who rely excessively on GPT to the point that they can't answer even the simplest teacher questions without it, and they don't interact normally online without it. This is frightening and resembles a mental disability",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p96esj/ai_will_reduce_innovation_and_invention_and_make/",
        "publishDate": "2025-11-28T21:17:57Z[Etc/UTC]",
        "author": "Competitive-Cut7712",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9668a",
        "title": "India's Adani seeks up to $5 billion investment in Google data center to join AI boom",
        "content": "Nov 28 (Reuters) - India's Adani Group plans to invest up to $5 billion in Alphabet-owned Google's [(GOOGL.O), opens new tab](https://www.reuters.com/markets/companies/GOOGL.O) India AI data centre project, an executive said on Friday, as it seeks to cash in on booming demand for data capacity in the world's most populous nation.\n\nIn October, Google [said](https://www.reuters.com/world/india/google-invest-10-billion-data-centre-south-india-2025-10-14/) it would invest $15 billion over five years to set up an artificial intelligence data centre in the southern state of Andhra Pradesh, its biggest investment in India.  \nIndian billionaires Gautam Adani and Mukesh Ambani have also unveiled investments in building data centre capacity.\n\nThe data centre campus in the port city of Visakhapatnam will have an initial power capacity of 1 gigawatt.\n\n($1 = 89.3660 Indian rupees)  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p9668a/indias_adani_seeks_up_to_5_billion_investment_in/",
        "publishDate": "2025-11-28T21:08:07Z[Etc/UTC]",
        "author": "Intelligent-Mouse536",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p90bdy",
        "title": "\"Identifying indicators of consciousness in AI systems\"",
        "content": "[https://doi.org/10.1016/j.tics.2025.10.011](https://doi.org/10.1016/j.tics.2025.10.011) \n\n\"**Highlights**\n\nThe prospect of consciousness in artificial intelligence (AI) systems increasingly demands attention given recent advances in AI and increasing capacity to reproduce features of the brain that are associated with consciousness.\n\nThere are risks of both under- and over-attribution of consciousness to AI systems, entailing a need for methods to assess whether current or future AI systems are likely to be conscious.\n\nWe argue that progress can be made by drawing out the implications of some neuroscientific theories of consciousness.\n\nWe outline a method that involves deriving indicators from theories and using them to assess particular AI systems.\n\n**Abstract**\n\nRapid progress in artificial intelligence (AI) capabilities has drawn fresh attention to the prospect of consciousness in AI. There is an urgent need for rigorous methods to assess AI systems for consciousness, but significant uncertainty about relevant issues in consciousness science. We present a method for assessing AI systems for consciousness that involves exploring what follows from existing or future neuroscientific theories of consciousness. Indicators derived from such theories can be used to inform credences about whether particular AI systems are conscious. This method allows us to make meaningful progress because some influential theories of consciousness, notably including computational functionalist theories, have implications for AI that can be investigated empirically.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p90bdy/identifying_indicators_of_consciousness_in_ai/",
        "publishDate": "2025-11-28T17:13:52Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8zw15",
        "title": "What if replacing jobs with LLMs has a secret cost?",
        "content": "I was thinking today about the possible differences between an LLM 'workforce' and a human one. I came to a somewhat troubling conclusion. \n\nWhat humans have that LLMs generally won't have is diversity of thought and approach. What I mean by this is that prior to LLMs you might have millions of people working doing statistics at various businesses. \n\nEach one of those people will be trained at university with similar, but minutely different, skill sets. In reality each human will approach a problem from a different angle, a different way of thinking.\n\nNow on the other hand if you replace all of those millions of jobs with LLMs you'll likely be using, worldwide, maybe 3-5 different LLMs which are all likely trained on very similar data. Each of those LLMs will likely output correct answers, but they will output the same answers as all of the other LLMs. \n\nSo my real point is thus. What if there was a cost in losing that variance of human workers? Are there industries where if all of the workers started acting the exact same, that it could cause problems?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8zw15/what_if_replacing_jobs_with_llms_has_a_secret_cost/",
        "publishDate": "2025-11-28T16:58:03Z[Etc/UTC]",
        "author": "The-Squirrelk",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "46",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8zm2f",
        "title": "Which Jobs Are Realistically Immune or Affected from AI Automation?",
        "content": "So a little deep dive into the entire AI automation and job stealing narrative. Most people more or less expected admin work, creative work, or service jobs to adopt AI fastest, but the biggest gap between expected and actual AI use is happening in computer and mathematical jobs.\n\nSome quick hits from the data:\n\n* Computer/math roles show the largest jump in real AI usage, way higher than what workers in that field originally expected.\n* Legal, healthcare, education, and social service jobs barely moved despite all the hype.\n* Hands-on jobs (maintenance, repair, protective services, transportation) remain the least influenced.\n* Business/finance expected heavy adoption but ended up with a much smaller actual shift.\n* Creative/media jobs landed somewhere in the middle I'd say, moderate adoption but not a takeover.\n\nSo what the studies basically say:\n\nAI isn’t spreading evenly. It’s clustering in the exact jobs closest to the tech and not the jobs people assumed were “easiest to automate.” And honestly, it tracks. Engineers and tech workers adopt tools early, understand the workflows, and feel productivity pressure first. But it also means AI’s biggest disruption is starting at the top of the skill ladder, not the bottom.\n\nSo my question for you guys working in your respective fields is: Has AI changed your workload in any meaningful way whatsoever? Is it actually replacing tasks, or is it just a faster version of what you were already doing? \n\nSources: Microsoft, Forbes, Cornwell University Study\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8zm2f/which_jobs_are_realistically_immune_or_affected/",
        "publishDate": "2025-11-28T16:47:06Z[Etc/UTC]",
        "author": "Yodest_Data",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "42",
            "commentCount": "137",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8zfh1",
        "title": "Petabyte-Scale Computing Happens Inside the Human Body. What Does That Mean for AGI?",
        "content": "# The 200 Petabyte Moment\n\nBiology might already be the most powerful computer we’ve ever encountered, and it built us long before we built machines. After decades of studying how nature computes, I’m still humbled by the realization that the most advanced processor on Earth might not be silicon, it might be alive.\n\nEach human sperm cell carries about 750 megabytes of genetic information. A single reproductive event can release between 100 and 300 million of these data packets. That is roughly 75 to 225 petabytes of potential information broadcast in seconds. A data transfer so staggering that Silicon Valley supercomputers look primitive in comparison. Only one of those packets connects, while the rest serve as redundancy and diversity. That is massive parallel computation with built-in probabilistic error correction, executed by biology itself.\n\n# Why Biology Is Already the Ultimate Computer\n\nThe computational genius of biology does not stop at conception, it continues moment by moment. The human brain performs between ten trillion and one quadrillion synaptic operations per second while consuming about the same power as a light bulb. DNA functions like a hard drive, RNA behaves like cache, proteins act as executable programs, and cells operate like processors. The system is fault-tolerant, self-healing, and capable of running continuously for decades.\n\nNo server farm and no quantum array has ever matched this combination of resilience, energy efficiency, and graceful degradation.\n\n# Quantum’s Brilliance and Fragility\n\nQuantum computers deserve their reputation as both revolutionary and temperamental. They rely on superposition and entanglement to make certain calculations exponentially faster than classical machines. Yet their fragile coherence collapses under the slightest interference. The majority of their energy budget is spent on refrigeration and error correction, not computation. When they work, they exceed our capabilities by orders of magnitude, but keeping them stable is like balancing a snowflake on a turbine.\n\n# The Rise of Living Machines\n\nWe are now entering an era where biological computers are emerging from research labs into early commercial form. Companies around the world are developing neuron-on-chip systems, organoid intelligence, DNA-based storage, and hybrid biosensors that merge biology with silicon.\n\nThese “wetware” systems operate in fundamentally different ways than traditional computers. Cultured neurons learn using electrical feedback, organoids exhibit short-term memory and pattern recognition, biological sensors classify chemicals with almost no energy cost, and DNA archival systems achieve storage densities no solid-state drive can approach. Nature has spent billions of years refining these mechanisms, and now we are starting to use them.\n\n# How Biological Computers Think\n\nNeuron-based computing uses real biological networks capable of forming new connections and adapting to stimuli. Organoid intelligence uses 3-D mini-brains that display learning behaviors. DNA storage transforms information into molecular form, compressing entire libraries into microscopic volumes. Biological systems degrade slowly and gracefully under noise instead of collapsing, and they update themselves locally rather than requiring global retraining.\n\nIn short, biology computes with elegance and efficiency, not force.\n\n# Implications for AI\n\nAI today is extraordinary at detecting patterns and making predictions, but still struggles to explain meaning or adapt fluidly. Biological systems offer traits AI currently lacks:\n\n* Ultra-high energy efficiency\n* Continual, local learning\n* Graceful failure under noise\n* Multi-sensory integration\n* Long-term molecular memory\n\nThese traits point toward a future where AI is less like a coded machine and more like a living culture that evolves.\n\n# The Hybrid Horizon\n\nThe future will not belong solely to biological systems or quantum systems. It will belong to the strange, powerful architectures that appear when these two worlds are combined.\n\nImagine a data center that feels more like an ecosystem than a warehouse. Quantum nodes operating at cryogenic temperatures. Neuron cultures pulsing with activity. DNA shelves storing centuries of knowledge. Immune-style algorithms repairing the entire environment. A place where computation grows, adapts, and heals.\n\n# From Vision to Application\n\nBiological computing will have immediate value in environments where connection is difficult or impossible. Space exploration and remote medicine demand systems that are autonomous, low-power, and capable of surviving chaos. Wetware fits this need perfectly.\n\nThe earliest hybrid systems will combine quantum molecular simulation with biological learning layers for drug discovery, new materials, and resilient robotics. Over time, micro-biological processors could guide habitats and machines that evolve with their surroundings.\n\n# Redefining Power\n\nWe often measure computational power by speed, FLOPS, or parameter count. But true intelligence is the ability to achieve goals under uncertainty with minimal energy. By that measure, biology already leads by an overwhelming margin.\n\nEvery heartbeat coordinates trillions of cellular processors. Every neural impulse solves a real-time optimization problem. Every reproductive act executes a petabyte-scale parallel search for viable code.\n\nAfter four billion years, life is still running that computation, and only now are we beginning to understand the algorithm.\n\nQuantum computers may one day emulate life, but life itself is already the original quantum-inspired system, quietly running on carbon, time, and chaos.\n\n# Where Do You Stand?\n\nWill the future of AI be biological, quantum, or something even stranger?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8zfh1/petabytescale_computing_happens_inside_the_human/",
        "publishDate": "2025-11-28T16:39:58Z[Etc/UTC]",
        "author": "Intelligent-Mouse536",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8z1v8",
        "title": "A.I. Will Discover Human Immortality and Practically Free Unlimited Energy In 20 Years",
        "content": "I used to think  this will happen in 70 years. Now because of AI I know it will happen in 15-20 years. AI will also discover new physics before 2028 is over. In 5 years robots with ai will be washing my dishes, clothes, cleaning my house and landscaping my yard. My phone will be my doctor, lawyer and engineer. I was gonna include accountant but there will be no more need for them since government wont run on income tax anymore. This is the future people- utopia. Only thing that'll stop this from happening is if some psycho religious fanatic from the mideast decides to start a nuclear war. Im not worried about Putin because he is sane, ruthless but sane. It's the ayatollah from Iran  im worried about.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8z1v8/ai_will_discover_human_immortality_and/",
        "publishDate": "2025-11-28T16:25:05Z[Etc/UTC]",
        "author": "_Dark_Wing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "37",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8xafx",
        "title": "Question for the community: How do I find \"Red Team\" testers for a Neuro-Symbolic architecture without marketing it?  (still needs some work)",
        "content": "Hi everyone,\n\nI need some advice on how to handle the next phase of a research project I’ve been working on.\n\n**The Context:** My group has spent the last few months building a **Neuro-Symbolic agent** (based on the TOPAS paper) to solve the \"Reasoning Drift\" problem in LLMs. Basically, it splits the architecture so the Neural Net handles the conversation, but a deterministic Symbolic Solver handles the logic/math.\n\n**The Problem:** The backend logic is working really well (it’s solving things that GPT-4 hallucinates on), but the frontend UI is... well, it’s developer art. It’s janky. It’s definitely not ready for a \"Product Hunt\" style launch or a general audience who will complain about CSS.\n\n**My Question to you:** I need to find about 50-100 high-quality \"Red Team\" testers who actually understand AI architecture. I want people who will try to break the logic layer with complex ARC puzzles or multi-step reasoning, rather than people who just want to chat.\n\n* Where do the serious builders/breakers hang out?\n* Is there a specific way to ask for \"hostile\" testing without getting flooded by casual users?\n* Should I just stick to cold-emailing researchers, or are there communities for this?\n\nI’m specifically **not** linking the project here because I don't want this to be seen as self-promotion, although, I do actually want the negative feedback.  I just want advice on how to connect with the 1% of users who enjoy breaking novel architectures.\n\nAny advice on where to find that crowd would be appreciated.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8xafx/question_for_the_community_how_do_i_find_red_team/",
        "publishDate": "2025-11-28T15:14:21Z[Etc/UTC]",
        "author": "Doug_Bitterbot",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8wmcm",
        "title": "Meet China's Humanoid Border Guard Robots",
        "content": "Chinese authorities are starting trial humanoid robots to direct passenger flows at border crossings.  \n  \nMore: [https://www.instrumentalcomms.com/blog/jack-white-and-eminem-halftime-show#ai-tech](https://www.instrumentalcomms.com/blog/jack-white-and-eminem-halftime-show#ai-tech)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8wmcm/meet_chinas_humanoid_border_guard_robots/",
        "publishDate": "2025-11-28T14:47:04Z[Etc/UTC]",
        "author": "TryWhistlin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8wj7g",
        "title": "How will 3rd party chat services be sustainable?",
        "content": "Hello guys. I'd like to hear your thoughts on this matter.\n\nWe have the 3 big companies that over LLM chat with their own models, and we have 3rd party services like [you.com](http://you.com) that do the same but using those companies' webservice.\n\nTheir chat plans allow much more usage than their webservice, and the 3rd party companies offer even bigger quota limit on chat while they rely on their more expensive webservice. I know these companies are being funded by investors and for now are burning money to grow against competition. But how will they become sustainable on the long run?\n\nWill they drop their limits? Route to simpler model and lie about it? Or are their founders planning to sell the company before they bankrupt?\n\nFor companies that have their own models and datacenter, like Amazon+Anthropic, M$+OpenAI and Google, I can see the business model being sustainable. But for companies that rely on outsource for everything, it's bogging me.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8wj7g/how_will_3rd_party_chat_services_be_sustainable/",
        "publishDate": "2025-11-28T14:43:22Z[Etc/UTC]",
        "author": "HikariWS",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8wimt",
        "title": "ELI5: How different and better are corp/enterprise models than the more visible LLM tranche of models?",
        "content": "I have worked quite a bit with LLMs and have seen both their limits and also their major contributions. I think of them as vector systems based on large data sets (language) that provide a probabilistic approach to try and piece together the optimal response.\n\nThat said, I have NOT done anything with proprietary nor corporate based models. I could see them ingesting financials, geospatial or whatever (not just language) and being super powerful.\n\nAre they doing the same probabilistic vector thing that LLM’s are doing? Are they likewise just optimizing the response and subject to the same hallucination issues as LLMs? Anything otherwise major that is worth considering?\n\nI am getting back into the corporate world as an executive (totally not in IT as you could guess!) My gears are turning on how all this works as well as the limitations and such.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1p8wimt/eli5_how_different_and_better_are_corpenterprise/",
        "publishDate": "2025-11-28T14:42:41Z[Etc/UTC]",
        "author": "transuranic807",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9kckc",
        "title": "Does GPT suck for coding compared to Claude?",
        "content": "Been trying out claude recently and comparing it to GPT, for large blocks of code, GPT often omits anything that's not related to its task when I ask for a full implementation. It often also hallucinates new solutions instead of a simple \"I'm not sure\" or \"I need more context on this different codeblock\"",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p9kckc/does_gpt_suck_for_coding_compared_to_claude/",
        "publishDate": "2025-11-29T09:01:06Z[Etc/UTC]",
        "author": "Interesting-Poet-365",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9j3u1",
        "title": "Volunteer support for founders who vibe coded and stuck with external integrations",
        "content": "A quick question for anyone using Lovable, Base44, V0, or any AI builder to validate product ideas.\n\nI keep seeing the same pattern: people generate a great-looking app in minutes… and then everything stalls the moment they try to wire up auth, payments, Shopify, CRM, GTM, Supabase, or deployment.\n\nIf you’ve been through this, I’m trying to understand the actual friction points.\n\nTo learn, I’m offering to manually help 3–5 people take their generated app and: • add auth (Clerk/Auth0/etc) • set up Stripe payments • connect Shopify APIs or webhooks • configure Supabase / DB • clean up environment variables • deploy it to Vercel or Railway or Render\n\nCompletely free — I’m not selling anything. I’m just trying to understand whether this integration layer is the real choke point for non-technical founders.\n\nIf you have a Lovable/Base44 export or any AI-generated app that got stuck at the integration step, drop a comment.\n\nI’ll pick a few and help you get it running end-to-end, then share the learnings back with the community.\n\nCurious to see how many people hit this wall.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p9j3u1/volunteer_support_for_founders_who_vibe_coded_and/",
        "publishDate": "2025-11-29T07:44:40Z[Etc/UTC]",
        "author": "Awesome_911",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9g056",
        "title": "Why has Codex become buggy recently? Haven't been able to code within the past month",
        "content": "I'm on windows and I can't code with codex anymore. About 90% of the time I ask it to code something, it asks for permission, but I can't give it because the permission UI doesn't popup.\n\nThis never used to happen months ago when it was working fine. How can I give the AI permission if the UI won't allow me to?\n\nI tried telling the AI to proceed, this rarely works. I can't keep wasting my credits constantly copying and pasting \"proceed to edit files, I can't give permission because my UI is bugged\".\n\nI've already tried disabling, uninstalling and reinstalling codex, its the same problem. Claude Code doesn't have this problem for some reason.\n\nAlso don't even get me started on giving it permission for the session, it keeps popping up everytime it  wants to make a change, acting like its the other button for giving it permission once. Why would a button imply \"click once and have auto approval\", yet it keeps appearing and asking for permission?\n\nOnly reason I still use codex is because its smarter and can solve problems that claude can't. But what's the point in it coming up with smart solutions, but is unable to edit the files to implement such solution?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p9g056/why_has_codex_become_buggy_recently_havent_been/",
        "publishDate": "2025-11-29T04:47:37Z[Etc/UTC]",
        "author": "pizzae",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9ew15",
        "title": "Deep Research Agent: An Autonomous Multi-Agent Research System",
        "content": "# Deep Research Agent\n\nRepository: [https://github.com/tarun7r/deep-research-agent](https://github.com/tarun7r/deep-research-agent)\n\nMost \"research\" agents just summarise the top 3 web search results. I wanted something better. I wanted an agent that could plan, verify, and synthesize information like a human analyst.\n\n# How it works (The Architecture)\n\nInstead of a single LLM loop, this system orchestrates four specialised agents:\n\n1. **The Planner:**\n2. Analyzes the topic and generates a strategic research plan.\n3. **The Searcher:**\n4. An autonomous agent that dynamically decides what to query and when to extract deep content.\n5. **The Synthesizer:**\n6. Aggregates findings, prioritizing sources based on credibility scores.\n7. **The Writer:**\n8. Drafts the final report with proper citations (APA/MLA/IEEE) and self-corrects if sections are too short.\n\n# The \"Secret Sauce\": Credibility Scoring\n\nOne of the biggest challenges with AI research is hallucinations.  \nTo solve this, I implemented an automated scoring system. It evaluates sources (0–100) based on domain authority (.edu, .gov) and academic patterns before the LLM ever summarizes them.\n\n# Built With\n\n* Python\n* LangGraph & LangChain\n* OpenAI API\n\nI’ve attached a demo video below showing the agents in action as they tackle a complex topic from scratch.\n\nCheck out the code, star the repo, and contribute.",
        "url": "https://v.redd.it/prwd5orqa44g1",
        "publishDate": "2025-11-29T03:49:59Z[Etc/UTC]",
        "author": "martian7r",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9anms",
        "title": "Best resources for building enterprise AI agents",
        "content": "I recently started working with enterprise clients who want custom AI agents.\n\nI am comfortable with the coding part using tools like Cursor. I need to learn more about the architecture and integration side.\n\nI need to understand how to handle data permissions and security reliably. Most content I find online is too basic for production use.\n\nI am looking for specific guides, repositories, or communities that focus on building these systems properly.\n\nPlease share any recommendations you have.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p9anms/best_resources_for_building_enterprise_ai_agents/",
        "publishDate": "2025-11-29T00:23:20Z[Etc/UTC]",
        "author": "littitkit",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "13",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p94y06",
        "title": "GLM Coding Plan\nBlack Friday: 50% first-purchase + extra 20%/30% off!  + 10% off!",
        "content": "This is probably the best LLM deals out there. They are the only one that offers 60% off their yearly plan. My guess is that for their upcoming IPO, they are trying to jack up their user base. You can get additional 10% off using https://z.ai/subscribe?ic=Y0F4CNCSL7",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p94y06/glm_coding_plan_black_friday_50_firstpurchase/",
        "publishDate": "2025-11-28T20:16:36Z[Etc/UTC]",
        "author": "kinkvoid",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p945ft",
        "title": "Do you prefer in editor AI like Cursor or Github CoPilot or the CLI?",
        "content": "I started using github copilot, but I found it was confusing and tedious to have it have access to all my files and the correct context.\n\nI have since switched to using CLI tools like Codex and and claude CLI, and never looked back. I just give them prompts and the do it.....no issues.\n\nI am curious though, what things I might be missing. What are the advantages of using AI in the editor/IDE? Which do you prefer?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p945ft/do_you_prefer_in_editor_ai_like_cursor_or_github/",
        "publishDate": "2025-11-28T19:44:29Z[Etc/UTC]",
        "author": "Previous-Display-593",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "38",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p93klm",
        "title": "Copilot, Antigravity, what next?",
        "content": "I used up all my premium credits on GitHub Copilot and I am waiting for them to reset in a few days. GPT4.1 is not cutting it. So I downloaded Antigravity and burned through the rate limits on all the models in an hour or two. What’s my next move? Codex? Kiro? Q?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p93klm/copilot_antigravity_what_next/",
        "publishDate": "2025-11-28T19:21:02Z[Etc/UTC]",
        "author": "lam3001",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "19",
            "commentCount": "58",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p906nf",
        "title": "tested opus 4.5 on 12 github issues from our backlog. the 80.9% swebench score is probably real but also kinda misleading",
        "content": "anthropic released opus 4.5 claiming 80.9% on swebench verified. first model to break 80% apparently. beats gpt-5.1 codex-max (77.9%) and gemini 3 pro (76.2%).\n\nive been skeptical of these benchmarks for a while. swebench tests are curated and clean. real backlog issues have missing context, vague descriptions, implicit requirements. wanted to see how the model actually performs on messy real world work.\n\ngrabbed 12 issues from our backlog. specifically chose ones labeled \"good first issue\" and \"help wanted\" to avoid cherry picking. mix of python and typescript. bug fixes, small features, refactoring. the kind of work you might realistically delegate to ai or a junior dev.\n\nresults were weird\n\n4 issues it solved completely. actually fixed them correctly, tests passed, code review approved, merged the PRs.\n\nthese were boring bugs. missing null check that crashed the api when users passed empty strings. regex pattern that failed on unicode characters. deprecated function call (was using old crypto lib). one typescript type error where we had any instead of proper types.\n\n5 issues it partially solved. understood what i wanted but implementation had issues.\n\none added error handling but returned 500 for everything instead of proper 400/404/422. another refactored a function but used camelCase when our codebase is snake\\_case. one added logging but used print() instead of our logger. one fixed a pagination bug but hardcoded page\\_size=20 instead of reading from config. last one added input validation but only checked for null, not empty strings or whitespace.\n\nstill faster than writing from scratch. just needed 15-30 mins cleanup per issue.\n\n3 issues it completely failed at.\n\nworst one: we had a race condition in our job queue where tasks could be picked up twice. opus suggested adding distributed locks which looked reasonable. ran it and immediately got a deadlock cause it acquired locks on task\\_id and queue\\_name in different order across two functions. spent an hour debugging cause the code looked syntactically correct and the logic seemed sound on paper.\n\nanother one \"fixed\" our email validation to be RFC 5322 compliant. broke backwards compatibility with accounts that have emails like \"user@domain.co.uk.backup\" which technically violates RFC but our old regex allowed. would have locked out paying customers if we shipped it.\n\nso 4 out of 12 fully solved (33%). if you count partial solutions as half credit thats like 55% success rate. closer to the 80.9% benchmark than i expected honestly. but also not really comparable cause the failures were catastrophic.\n\nsome thoughts\n\nopus is definitely smarter than sonnet 3.5 at code understanding. gave it an issue that required changes across 6 files (api endpoint, service layer, db model, tests, types, docs). it tracked all the dependencies and made consistent changes. sonnet usually loses context after 3-4 files and starts making inconsistent assumptions.\n\nbut opus has zero intuition about what could go wrong. a junior dev would see \"adding locks\" and think \"wait could this deadlock?\". opus just implements it confidently cause the code looks syntactically correct. its pattern matching not reasoning.\n\nalso slow as hell. some responses took 90 seconds. when youre iterating thats painful. kept switching back to sonnet 3.5 cause i got impatient.\n\ntested through cursor api. opus 4.5 is $5 per million input tokens and $25 per million output tokens. burned through roughly $12-15 in credits for these 12 issues. not terrible but adds up fast if youre doing this regularly.\n\none thing that helped: asking opus to explain its approach before writing code. caught one bad idea early where it was about to add a cache layer we already had. adds like 30 seconds per task but saves wasted iterations.\n\nbeen experimenting with different workflows for this. tried a tool called verdent that has planning built in. shows you the approach before generating code. caught that cache issue. takes longer upfront but saves iterations.\n\nis this useful\n\nhonestly yeah for the boring stuff. those 4 issues it solved? i did not want to touch those. let ai handle it.\n\nbut anything with business logic or performance implications? nah. its a suggestion generator not a solution generator.\n\nif i gave these same 12 issues to an intern id expect maybe 7-8 correct. so opus is slightly below intern level but way faster and with no common sense.\n\nwhy benchmarks dont tell the whole story\n\n80.9% on swebench sounds impressive but theres a gap between benchmark performance and real world utility.\n\nthe issues opus solves well are the ones you dont really need help with. missing null checks, wrong regex, deprecated apis. boring but straightforward.\n\nthe issues it fails at are the ones youd actually want help with. race conditions, backwards compatibility, performance implications. stuff that requires understanding context beyond the code.\n\nswebench tests are also way cleaner than real backlog issues. they have clear descriptions, well defined acceptance criteria, isolated scope. our backlog has \"fix the thing\" and \"users complaining about X\" type issues.\n\nso the 33% fully solved rate (or 55% with partial credit) on real issues vs 80.9% on benchmarks makes sense. but even that 55% is misleading cause the failures can be catastrophic (deadlocks, breaking prod) while the successes are trivial.\n\nconclusion: opus is good at what you dont need help with, bad at what you do need help with.\n\nanyone else actually using opus 4.5 on real projects? would love to hear if im the only one seeing this gap between benchmarks and reality",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p906nf/tested_opus_45_on_12_github_issues_from_our/",
        "publishDate": "2025-11-28T17:08:52Z[Etc/UTC]",
        "author": "Zestyclose_Ring1123",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "62",
            "commentCount": "41",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8wwvv",
        "title": "NornicDB - neo4j drop-in - MIT - MemoryOS- golang native - my god the performance",
        "content": "\n\n\ntimothyswt/nornicdb-amd64-cuda:0.1.2 - updated use 0.1.2 tag i had issues with the build process 11-28\n\ntimothyswt/nornicdb-arm64-metal:latest - updated 11-28 with (no metal support in docker tho)\n\ni just pushed up a Cuda enabled image that will auto detect if you have a GPU mounted to the container, or locally when you build it from the repo \n\nhttps://github.com/orneryd/Mimir/blob/main/nornicdb/README.md\n\ni need people to test it out and let me know how their performance is and where the peak spots are in this database. \n\nso far the performance numbers look incredible i have some tests based off neo4j datasets for northwind and fastrp. please throw whatever you got at it and break my db for me 🙏 \n\n\nedit: more docker images with models embedded inside that are MIT compatible and BYOM https://github.com/orneryd/Mimir/issues/12",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1p8wwvv/nornicdb_neo4j_dropin_mit_memoryos_golang_native/",
        "publishDate": "2025-11-28T14:59:09Z[Etc/UTC]",
        "author": "Dense_Gate_5193",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "8",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9izzl",
        "title": "Free Access to Claude Opus 4.5, Sonnet 4.5 & Haiku 4.5 - No Waitlist, No Premium Lock",
        "content": "Hey everyone!\n\nI just launched [**OpenClaude.me**](http://OpenClaude.me) \\- a platform that gives you completely free access to all Claude models including Opus 4.5, Sonnet 4.5, and Haiku 4.5.\n\n**What makes this different from official Claude.ai?**\n\n* **All models are available to everyone** \\- No premium subscription needed for Opus\n* **300K tokens daily limit on EACH model** \\- You get full 300K on Opus, full 300K on Sonnet, and full 300K on Haiku. There's no fallback system where you run out on one model and get downgraded\n* **Web Search & Code Execution tools** included for free\n* **Simple signup** \\- Just email and password, no verification wait\n* **Mobile responsive** \\- Works smoothly on phones\n\n**How it works:**\n\nJust sign up and start using any model you want. The 300K token limit resets daily at midnight. If you somehow manage to hit the limit, you can simply create a new account and keep going (though 300K is pretty generous for daily use).\n\n**Quick note:** Don't ask the AI which model it is - they usually give wrong answers when asked directly. Just test them yourself and you'll feel the difference in capabilities.\n\n**Future plans:**\n\nI'm planning to add more features based on your feedback. Eventually, there will be a premium version, but I promise - everything that's free now will stay free. Premium will just add improvements and Claude Code access with 100x the usage limits of official Claude Pro.\n\n**Why am I sharing this?**\n\nI want people to test it, use it, and give me as much feedback as possible so I can make this better. This is a community-driven project.\n\nTry it out: [**openclaude.me**](http://openclaude.me)\n\nLet me know what you think!",
        "url": "https://www.reddit.com/r/artificial/comments/1p9izzl/free_access_to_claude_opus_45_sonnet_45_haiku_45/",
        "publishDate": "2025-11-29T07:37:53Z[Etc/UTC]",
        "author": "LEGENDX08377",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9h3x5",
        "title": "One-Minute Daily AI News 11/28/2025",
        "content": "1. **MIT** study finds AI can already replace 11.7% of U.S. workforce.\\[1\\]\n2. China’s **DeepSeek** Releases New Open Source AI Model Amid Google’s Gemini 3 Roll Out.\\[2\\]\n3. US Patent Office issues new guidelines for AI-assisted inventions.\\[3\\]\n4. **OpenAI** claims teen circumvented safety features before suicide that ChatGPT helped plan.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.cnbc.com/2025/11/26/mit-study-finds-ai-can-already-replace-11point7percent-of-us-workforce.html](https://www.cnbc.com/2025/11/26/mit-study-finds-ai-can-already-replace-11point7percent-of-us-workforce.html)\n\n\\[2\\] [https://www.investors.com/news/technology/nvidia-stock-google-stock-deepseek-china-open-source-ai-models/](https://www.investors.com/news/technology/nvidia-stock-google-stock-deepseek-china-open-source-ai-models/)\n\n\\[3\\] [https://www.reuters.com/legal/government/us-patent-office-issues-new-guidelines-ai-assisted-inventions-2025-11-26/](https://www.reuters.com/legal/government/us-patent-office-issues-new-guidelines-ai-assisted-inventions-2025-11-26/)\n\n\\[4\\] [https://techcrunch.com/2025/11/26/openai-claims-teen-circumvented-safety-features-before-suicide-that-chatgpt-helped-plan/](https://techcrunch.com/2025/11/26/openai-claims-teen-circumvented-safety-features-before-suicide-that-chatgpt-helped-plan/)",
        "url": "https://www.reddit.com/r/artificial/comments/1p9h3x5/oneminute_daily_ai_news_11282025/",
        "publishDate": "2025-11-29T05:46:57Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p9ghg0",
        "title": "Does anyone actually use “—“ when typing?",
        "content": "I thinks it’s become quite noticeable that AI uses — quite often in its writing. No when I see it, it always makes me wonder if AI was at least used in the process.\n\n  \nI’m curious, did any of you actually use this in non formal typing before AI?",
        "url": "https://www.reddit.com/r/artificial/comments/1p9ghg0/does_anyone_actually_use_when_typing/",
        "publishDate": "2025-11-29T05:12:39Z[Etc/UTC]",
        "author": "owenwags_",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "108",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p99zdz",
        "title": "My AI characters I made.",
        "content": "I made two AI characters, Omzig and Gizmo. \nI used Gemini 3 pro, and Gpt-5-mini to code it.\n\nI wanted feedback on the AI's so I've made a discord server for testing them out, I would like to add this is **entirely feee** and the only reason I have different tiers is to stop over use and allow certain people to use it more, the discord server does not have any moderation bots, but I will try and moderate it to the best I can, and you just have to ping the AI or reply to a message for it to respond, there are a lot of commands like: /quota /leaderboard /think /search/deep_search, the bot will currently be offline since I'm fixing it, but will be back up in a few hours so most likely by the time you see this: https://discord.gg/yttwQEetz",
        "url": "https://www.reddit.com/r/artificial/comments/1p99zdz/my_ai_characters_i_made/",
        "publishDate": "2025-11-28T23:53:30Z[Etc/UTC]",
        "author": "Owexiii13",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p96514",
        "title": "Best AI for writing analysis, identifying subtext and developing ideas?",
        "content": "Hey all. I found this sub while researching which AI might be best for helping me think through ideas and provide insights into my writing, so I'm sorry if this question has been asked recently. I don’t know that\nmuch about all the different models available and it’s hard for me to choose which one might be best for me when there seems to be many options.  \n\nWhat, in your opinion, is the best AI for someone looking for a collaborative research AI \"partner\" to bounce ideas off of? I do not use AI to write, but will sometimes ask ChatGPT for insight into essay drafts or journal entries that feel like they're developing a still-premature idea. I appreciate AI's ability to discern themes, patterns, subtext, and layers of meaning I can't notice on my own, and to suggest different directions I could take with each idea. I like to ask it to suggest other articles/essays written on similar topics.\n\nI don't trust ChatGPT's tendency to provide relentlessly positive feedback, but I don't trust any AI to deliver the same quality critique that a human could, so I'm more looking for a model that can help me develop and expand ideas to a point where I can take the work the rest of the way on my own.\n\nWhat do you think?",
        "url": "https://www.reddit.com/r/artificial/comments/1p96514/best_ai_for_writing_analysis_identifying_subtext/",
        "publishDate": "2025-11-28T21:06:44Z[Etc/UTC]",
        "author": "doublecheeseburger",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p92xq5",
        "title": "Question: Do we know where and for what the bulk of AI compute is utilized?",
        "content": "If we were to assign responsibility to A user base or user set for the bulk of harm AI is doing to our water and electricity as a resource, what group of people or entities are doing the most harm? \n\nSome one told me \"ChatGPT, Gemini, Grok, and all the other slop factories are what is consuming the overwhelming majority of AI resources.\" but i thought that just normal people asking chat GPT random questions or Grok being some one's waifu was the left overs from other applications. I had thought the servers and AI algorithms were being turned towards education, government, corporate works and other people received de-prioritized access after paying businesses got their needs processed. \n\nAm i wrong? Are Chat GPT queries from randos online really the supposed genesis of 20xxs impending water scarcity?",
        "url": "https://www.reddit.com/r/artificial/comments/1p92xq5/question_do_we_know_where_and_for_what_the_bulk/",
        "publishDate": "2025-11-28T18:56:19Z[Etc/UTC]",
        "author": "Quizzelbuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p92mp5",
        "title": "My concern on how AI will shape the future of the US.",
        "content": "I’m increasingly worried that the United States is entering a structural crisis driven by rapid AI advancement. As AI systems replace both physical and cognitive labor, companies are economically incentivized to automate at the fastest possible pace. In our current capitalist framework, firms that retain human workers for moral reasons will be outcompeted by those that prioritize efficiency, accelerating widespread job displacement. At the same time, national economic growth is becoming heavily dependent on a small number of AI and semiconductor giants—such as NVIDIA and the major cloud providers—concentrating wealth and influence in ways that weaken broader economic participation. This creates a feedback loop where economic power translates into political influence, shaping regulation and public policy around the interests of the AI sector rather than the public. If this trajectory continues unchecked, the U.S. risks rising unemployment, extreme wealth inequality, political capture by AI-driven corporate interests, and a society where economic prosperity is controlled by a small technological elite while the majority of citizens are increasingly marginalized.\n\nThe US, and society in general, wasn't structured with automated intelligence. I fear that the only solution is to create federal law limiting AI in the work force, but again, that may never happen because of the tech giants, and fear of lackluster competition with other countries.\n\n  \n",
        "url": "https://www.reddit.com/r/artificial/comments/1p92mp5/my_concern_on_how_ai_will_shape_the_future_of_the/",
        "publishDate": "2025-11-28T18:44:05Z[Etc/UTC]",
        "author": "Embuum",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8y39c",
        "title": "AI data centers' massive demand for aluminum is crushing the US aluminum industry",
        "content": "The boom in metal-intensive technologies like data centers and electric vehicles has made it a prime time to be in the US aluminum business.\n\nPrices are booming. Part of that is because inside every data center are cooling units, server racks, radiators, and a litany of other pieces and parts [made out of aluminum](https://d-nb.info/132462843X/34).\n\nNo wonder demand is high.\n\nBut data centers guzzle enormous amounts of power, and electricity prices are skyrocketing. In the US alone, electricity demand is expected to grow [five to 10 times faster over the next 10 years](https://institute.bankofamerica.com/content/dam/transformation/us-electrical-grid.pdf) than it did in the previous decade, per Bank of America.\n\nFor aluminum smelters, [this is a problem](https://finance.yahoo.com/news/ai-data-centers-massive-demand-for-aluminum-is-crushing-the-us-aluminum-industry-110035572.html). ",
        "url": "http://finance.yahoo.com/news/ai-data-centers-massive-demand-for-aluminum-is-crushing-the-us-aluminum-industry-110035572.html",
        "publishDate": "2025-11-28T15:47:09Z[Etc/UTC]",
        "author": "yahoofinance",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "11",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8xgb8",
        "title": "Lifetime access to AI-for-evil WormGPT 4 costs just $220 | 'Ah, I see you're ready to escalate. Let's make digital destruction simple and effective.'",
        "content": "[No content]",
        "url": "https://www.theregister.com/2025/11/25/wormgpt_4_evil_ai_lifetime_cost_220_dollars/",
        "publishDate": "2025-11-28T15:21:09Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1p8wydf",
        "title": "If You Use AI, You Will Be Left Behind",
        "content": "[No content]",
        "url": "https://www.bcionescu.com/posts/if-you-use-ai-you-will-be-left-behind",
        "publishDate": "2025-11-28T15:00:49Z[Etc/UTC]",
        "author": "creaturefeature16",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "ckrvwCLPwVw",
        "title": "RTRVR 2.0: This is THE BEST AI AGENT YET! Can do ANYTHING from ONE PROMPT!",
        "content": "Visit RTRVR: https://www.rtrvr.ai/ Chrome Extension Link: ...",
        "url": "https://www.youtube.com/watch?v=ckrvwCLPwVw",
        "publishDate": "2025-11-28T09:15:06Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/ckrvwCLPwVw/hqdefault.jpg",
            "transcription": "Error generating summary: Something unexpected happened.\ndev.shreyaspatil.ai.client.generativeai.type.UnknownException: Something unexpected happened.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:54)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "42QCCcbgaKM",
        "title": "Claude 4.5 Opus Shocks, The State of AI in 2025, Fara-7B &amp; MCP-UI | EP99.26",
        "content": "Join Simtheory: https://simtheory.ai (Use coupon BLACKFRIDAY15 for $15 USD off any subscription). ---- Simtheory Discord: ...",
        "url": "https://www.youtube.com/watch?v=42QCCcbgaKM",
        "publishDate": "2025-11-28T03:45:55Z",
        "author": "This Day in AI Podcast",
        "sourceType": "youtube",
        "sourceName": "This day in AI YouTube Channel",
        "metadata": {
            "channelId": "UCwpNW6o_Kc13HQY5ol4rzsw",
            "thumbnailUrl": "https://i.ytimg.com/vi/42QCCcbgaKM/hqdefault.jpg",
            "transcription": "Error generating summary: The input token count exceeds the maximum number of tokens allowed 1048576.\ndev.shreyaspatil.ai.client.generativeai.type.ServerException: The input token count exceeds the maximum number of tokens allowed 1048576.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:40)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "pLHWn5SQvLM",
        "title": "The Era of Easy AI Progress Is Ending - Ilya Sutskever",
        "content": "",
        "url": "https://www.youtube.com/watch?v=pLHWn5SQvLM",
        "publishDate": "2025-11-28T20:40:37Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/pLHWn5SQvLM/hqdefault.jpg",
            "transcription": "The way ML used to work is that people would just tinker with stuff and try to get interesting results. That's what's been going on in the past. Then the scaling insight arrived. Right? Scaling laws. GPT-3 and suddenly everyone realized we should scale. This is an example of how language affects thought. Scaling is just one word, but it's such a powerful word because it informs people what to do. They say, okay, let's try to scale things. And so you say okay, so what are we scaling? And pre-training was the thing to scale. It was a particular scaling recipe. The big breakthrough of pre-training is the realization that this recipe is good. So you say, hey, if you mix some compute with some data into a neural net of a certain size, you will get results and you will know that it will be better if you just scale the recipe up. And this is also great. Companies love this because it gives you a very low-risk way of investing your resources. Right? It's much harder to invest your resources in research. Compare that, you know, if you research you need to have like, go forth researchers and research and come up with something, versus get more data, get more compute, you know, you'll get something from pre-training. At some point though, pre-training will run out of data. The data is very clearly finite. And so then okay, what do you do next? Either you do some kind of a souped up pre-training, different recipe from the one you've done before, or you're doing RL, or maybe something else. But now that compute is big, compute is now very big. In some sense, we are back to the age of research. So maybe here's another way to put it. Up until 2020, from 2012 to 2020 it was the age of research. Now, from 2020 to 2025, it was the age of scaling because people say this is amazing, you got to scale more. Keep scaling. The one word: scaling. But now the scale is so big, like is the belief really that oh, it's so big, but if you had 100x more, everything would be so different. Like it would be different for sure. But like, is the belief that if you just 100x the scale, everything would be transformed? I don't think that's true. So it's back to the age of research again. Just with the computers."
        }
    }
]