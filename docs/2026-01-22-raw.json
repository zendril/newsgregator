[
    {
        "id": "https://news.smol.ai/issues/26-01-21-openevidence/",
        "title": "OpenEvidence, the ‚ÄòChatGPT for doctors,‚Äô raises $250m at $12B valuation, 12x from $1b last Feb",
        "content": "**OpenEvidence** raised **$12 billion**, a 12x increase from last year, with usage by 40% of U.S. physicians and over $100 million in annual revenue. **Anthropic** released a new **Claude** model constitution under **CC0 1.0**, framing it as a living document for alignment and training. **Podium** reported over **$100 million ARR** from **10,000+ AI agents**, shifting from software sales to AI operators. Innovations in agent memory and reliability include the **Agent Cognitive Compressor (ACC)** and multi-agent scientific workflows via **MCP-SIM**. Agentic benchmarking shows challenges in long-horizon tasks with models like **Gemini 3 Flash High**, **GPT-5.2 High**, and **Claude Opus 4.5 High** scoring modestly on professional services and legal research benchmarks.",
        "url": "https://news.smol.ai/issues/26-01-21-openevidence/",
        "publishDate": "2026-01-21T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "openevidence, anthropic, podium, openai, google, gemini, claude, claude-3, claude-opus, gpt-5.2, gemini-3-flash-high, daniel_nadler, amanda_askell, eric_rea, tom_loverro, garry_tan, omarsar0, brendanfoody, deredleritt3r, agentic-ai, model-alignment, performance-evaluation, memory-optimization, long-context, benchmarking, multi-agent-systems, reinforcement-learning"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233536",
        "title": "Elastic Supercharges Performance for Serverless Offering on AWS",
        "content": "<p>New virtual compute units deliver up to 50% higher indexing throughput and 37% lower latency ‚Äî powering search, observability and security applications at no extra cost Elastic (NYSE: ESTC), the Search AI Company, announced a more powerful Elastic Cloud Serverless on Amazon Web Services (AWS), delivering up to 50% higher...</p>\n<p>The post <a href=\"https://ai-techpark.com/elastic-supercharges-performance-for-serverless-offering-on-aws/\">Elastic Supercharges Performance for Serverless Offering on AWS</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/elastic-supercharges-performance-for-serverless-offering-on-aws/",
        "publishDate": "2026-01-21T12:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI company, AI news, ai tech news, AI technology News, Amazon Web Services, artificial intelligence news, Elastic"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233524",
        "title": "The DDC Group Unveils Advanced Agentic AI Platform",
        "content": "<p>The DDC Group Transforms the Customer Experience Through DDC Evora‚Ñ¢&#160;Platform The DDC Group, an AI-first operations partner, today announces the launch of the new¬†DDC Evora‚Ñ¢ agentic AI platform. This new offering introduces a new class of intelligent automation to the market, designed to transform customer engagement and operational efficiency for...</p>\n<p>The post <a href=\"https://ai-techpark.com/the-ddc-group-unveils-advanced-agentic-ai-platform/\">The DDC Group Unveils Advanced Agentic AI Platform</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/the-ddc-group-unveils-advanced-agentic-ai-platform/",
        "publishDate": "2026-01-21T11:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AI technology News, artificial intelligence news, DDC Group"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233505",
        "title": "ADLINK Launches First COM Express Module with Intel Core Ultra 3",
        "content": "<p>Featuring new Intel Arc GPU with up to 12 Xe&#160;cores and up to 120 TOPS, NPU 5 with up to 50 TOPS, and Advanced CPU Architecture for Edge AI and General Embedded Systems ‚Äî Industrial-Temperature SKUs Extended for Ruggedized Applications Summary: New Heights in Edge AI: Significantly Faster NPU and...</p>\n<p>The post <a href=\"https://ai-techpark.com/adlink-launches-first-com-express-module-with-intel-core-ultra-3/\">ADLINK Launches First COM Express Module with Intel Core Ultra 3</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/adlink-launches-first-com-express-module-with-intel-core-ultra-3/",
        "publishDate": "2026-01-21T11:15:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics, ADLINK Technology, AI computing, AI news, ai tech news, AI technology News, artificial intelligence news"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233519",
        "title": "Xactly Appoints CTO and CPO to Accelerate AI-Driven Innovation",
        "content": "<p>Kandarp Desai is promoted to CTO and Christopher Li to CPO as Xactly advances its autonomous revenue platform vision and strengthens its executive bench, following recent CMO and CHRO appointments Xactly, a global leader in intelligent revenue solutions, today announced the promotions of Kandarp Desai to Chief Technology Officer (CTO)...</p>\n<p>The post <a href=\"https://ai-techpark.com/xactly-appoints-cto-and-cpo-to-accelerate-ai-driven-innovation/\">Xactly Appoints CTO and CPO to Accelerate AI-Driven Innovation</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/xactly-appoints-cto-and-cpo-to-accelerate-ai-driven-innovation/",
        "publishDate": "2026-01-21T11:01:53Z[Etc/UTC]",
        "author": "Xactly",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AI technology News, AI-driven, artificial intelligence, artificial intelligence news, Xactly"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233504",
        "title": "ScyllaDB Brings Massive-Scale Vector Search to Real-Time AI",
        "content": "<p>ScyllaDB‚Äôs integrated Vector Search can handle datasets of 1 billion vectors with P99 latency as low as 1.7 ms and throughput up to 252,000 QPS ScyllaDB today announced the general availability of its new Vector Search. This high-performance vector search supports the industry‚Äôs largest models with low TCO. ScyllaDB is...</p>\n<p>The post <a href=\"https://ai-techpark.com/scylladb-brings-massive-scale-vector-search-to-real-time-ai/\">ScyllaDB Brings Massive-Scale Vector Search to Real-Time AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/scylladb-brings-massive-scale-vector-search-to-real-time-ai/",
        "publishDate": "2026-01-21T11:00:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Machine Learning, AI news, ai tech news, AI technology News, AI workloads, artificial intelligence news, ScyllaDB"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233503",
        "title": "Q/C Technologies Appoints AI Systems Leader Chelsea Voss to BOD",
        "content": "<p>Q/C Technologies, Inc. (Nasdaq: QCLS) (‚ÄúQ/C Technologies‚Äù or ‚Äúthe Company‚Äù), a pioneer of quantum-class computing at the speed of light, today announced the appointment of Chelsea Voss to its Board of Directors. Ms. Voss is a computer scientist and Member of Technical Staff at OpenAI, where she has played a...</p>\n<p>The post <a href=\"https://ai-techpark.com/q-c-technologies-appoints-ai-systems-leader-chelsea-voss-to-bod/\">Q/C Technologies Appoints AI Systems Leader Chelsea Voss to BOD</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/q-c-technologies-appoints-ai-systems-leader-chelsea-voss-to-bod/",
        "publishDate": "2026-01-21T10:45:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Machine Learning, AI news, AI platforms, AI systems, ai tech news, AI technology News, artificial intelligence news, Q/C Technologies"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111649",
        "title": "Balancing AI cost efficiency with data sovereignty",
        "content": "<p>AI cost efficiency and data sovereignty are at odds, forcing a rethink of enterprise risk frameworks for global organisations. For over a year, the generative AI narrative focused on a race for capability, often measuring success by parameter counts and flawed benchmark scores. Boardroom conversations, however, are undergoing a necessary correction. While the allure of [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/balancing-ai-cost-efficiency-with-data-sovereignty/\">Balancing AI cost efficiency with data sovereignty</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/balancing-ai-cost-efficiency-with-data-sovereignty/",
        "publishDate": "2026-01-21T10:51:23Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Features, Governance, Regulation & Policy, Inside AI, Opinion, data, enterprise, governance, privacy, security, sovereignty, strategy"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111645",
        "title": "The quiet work behind Citi‚Äôs 4,000-person internal AI rollout",
        "content": "<p>For many large companies, artificial intelligence still lives in side projects. Small teams test tools, run pilots, and present results that struggle to spread beyond a few departments. Citi has taken a different path, where instead of keeping AI limited to specialists, the bank has spent the past two years pushing the technology into daily [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/the-quiet-work-behind-citi-4000-person-internal-ai-rollout/\">The quiet work behind Citi‚Äôs 4,000-person internal AI rollout</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/the-quiet-work-behind-citi-4000-person-internal-ai-rollout/",
        "publishDate": "2026-01-21T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI in Action, Artificial Intelligence, Features, Finance AI, Workforce & HR AI, World of Work, ai, artificial intelligence, banking, data analysis, infrastructure, research"
        }
    },
    {
        "id": "1qjt88v",
        "title": "my manager sends AI-generated \"appreciation\" emails. we all know. nobody says anything",
        "content": "Got a \"heartfelt thank you\" from my manager last week. Three paragraphs about how much he values my contributions to the team and appreciates my dedication.\n\nThe thing is, I've worked with this guy for two years. He's never spoken like that. EVER. the bolding. the nested bullets. The part where he \"affirmed my feelings\" about a project i never mentioned having feelings about.\n\nhe used a robot to tell me i'm valued as a human.\n\nlooked into it. University of Florida surveyed 1,100 workers. trust in managers drops from 83% to 40% when employees detect AI assistance. we all know. We just don't say anything.\n\nthe best part? 75% of professionals now use AI for daily communication. so most managers are using a tool that makes their employees trust them less, to send messages about how much they appreciate their employees.\n\nyou can't make this up.\n\n>anyway, me and a friend got obsessed with this and spent days digging through research and workplace threads. ended up writing the whole thing up here: [\\[link\\]](https://webmatrices.com/post/dead-workplace-theory-75-use-ai-emails-40-trust-the-people-sending-them)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjt88v/my_manager_sends_aigenerated_appreciation_emails/",
        "publishDate": "2026-01-22T12:27:35Z[Etc/UTC]",
        "author": "Efficient_Fig_4671",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjspi3",
        "title": "Learning AI, Web3, and New Skills Without Burning Out",
        "content": "I used to think learning a new skill meant picking the *perfect* course and grinding it for weeks. Spoiler: that never worked for me. I‚Äôd start strong, get overwhelmed, then drop it halfway. What finally clicked was realizing that how to learn new skill matters way more than what you pick first.\n\nOver the past year, I‚Äôve been paying closer attention to Artificial Intelligence in 2026, mostly because it keeps popping up everywhere work, content, tools, even casual conversations. Instead of trying to become an ‚Äú[AI expert](https://www.blockchain-council.org/certifications/certified-agentic-ai-expert/)‚Äù (whatever that means), I just started using it daily. Small stuff. Writing, researching, experimenting. That made learning feel real instead of theoretical.\n\nSame story with [Blockchain Technology](https://www.blockchain-council.org/certifications/certified-blockchain-professional-expert/) and [Web3](https://www.blockchain-council.org/certifications/certified-web3-expert/). At first, I ignored most of it because it felt like noise tokens, hype, big promises. But once I stopped focusing on price and started understanding *why* these systems exist (ownership, transparency, control), it became way easier to learn. No pressure to master everything, just enough to see the bigger picture.\n\nOne thing I‚Äôve learned the hard way: jumping between skills kills momentum. Picking one direction, learning the basics, and actually applying it beats binge-watching tutorials any day. You don‚Äôt need motivation you need a simple system you can stick to.\n\nPosting this because I see a lot of people here feeling late or confused. You‚Äôre not behind. Tech keeps changing anyway. The real edge is learning *consistently*, not perfectly.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjspi3/learning_ai_web3_and_new_skills_without_burning/",
        "publishDate": "2026-01-22T12:01:27Z[Etc/UTC]",
        "author": "Hot-Situation41",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjsnmb",
        "title": "Why structured memory is key for building smarter AI systems",
        "content": "¬†Structured memory is a concept that I have started exploring in my AI projects for some time. Instead of letting an agent pull from a huge, unorganized pool of data, categorizing memories into distinct types such as immutable facts, updatable preferences, and behavioral rules makes a huge difference. I have found a memory system that offer a great way to implement this by separating immutable facts (things that don‚Äôt change, like the user‚Äôs name) from updatable preferences (like the user‚Äôs current settings or preferences). This separation helps to avoid pulling in irrelevant or outdated information, which often happens when all memories are stored in a single unstructured database.\n\nUsing structured memory not only keeps the agent more organized but also allows it to act more intelligently by focusing on the most relevant memories for any given situation. For example, an agent can update its preferences based on new information without losing track of crucial facts or behaviors learned earlier. This makes the agent more efficient and less prone to repeating mistakes or retrieving outdated context.\n\nHave you tried implementing structured memory in your own projects? What strategies or systems have you found useful in keeping your agent's memory organized and relevant over time? Or are you still relying on more traditional memory methods?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjsnmb/why_structured_memory_is_key_for_building_smarter/",
        "publishDate": "2026-01-22T11:59:00Z[Etc/UTC]",
        "author": "LibrarianHorror4829",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjs38m",
        "title": "AI use case at work. How would I achieve this?",
        "content": "I‚Äôm looking for an AI model that can loosely do the following. It‚Äôs a multi step process. \n\nStep 1: with a simple prompt (like a customer name), the AI will scan an Excel doc, 4,000 rows of data and tell me the data from a specific row with that customers name. Easy. \n\nStep 2: the AI model does some online research and comes back with one page max of relevant insights \n\nStep 3: it hopefully resets tokens and uses a modern pro LLM for this. the AI model reads this knowledge document I have on a topic, which is full of lots of valuable data on how to position our company. Call this a knowledge doc. It‚Äôs 40+ pages, 12,000 letters. \n\nStep 4: combine the knowledge in step 3 with the research in step 2 and the data in step 1 for this ultimate ‚Äúnext step‚Äù document tailored to that customer delivered nearly. \n\nSomehow accessible in a corporate environment and deployed across a dozen people. \n\nHow would you go about starting this?\n\nBonus if it can scan public API databases for up to date content. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjs38m/ai_use_case_at_work_how_would_i_achieve_this/",
        "publishDate": "2026-01-22T11:27:26Z[Etc/UTC]",
        "author": "hereforhelplol",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjs181",
        "title": "Gemini Advanced for ‚Ç¨15-20/year?",
        "content": "Hi everyone,\n\nI‚Äôve been seeing offers online (Reddit, forums, and key resellers) promising **Gemini PRO** for a fraction of the official price‚Äîaround **‚Ç¨15-20 per year (like on gamsego)**.\n\nBefore pulling the trigger, I have some serious concerns regarding security and privacy. I would appreciate it if you could answer the following points:\n\n1. **Privacy of Conversations:** If I join a \"Family Group\" managed by a stranger, can the admin or other members see my Gemini prompts, chat history, or uploaded files?\n2. **Shared Account Risks:** In cases where they provide new login credentials (an account they created), I assume they can access everything I write. Is there any way to secure such an account, or is it a total privacy \"no-go\"?\n3. **Account Bans:** How high is the risk of Google banning my main account if I am added to a \"family\" that uses regional pricing bypasses (e.g., Turkey, Nigeria, India)?\n4. **Reliability:** For those who have tried these cheap annual plans, do they actually last for 12 months, or do they usually get revoked after a few weeks?\n\nI want to use Gemini for personal projects, and I‚Äôm afraid of my data being exposed to whoever is selling these slots.\n\nThanks in advance for your insights!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjs181/gemini_advanced_for_1520year/",
        "publishDate": "2026-01-22T11:24:14Z[Etc/UTC]",
        "author": "Dariospinett",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjquoy",
        "title": "AGI models ‚Äì is the tyranny of idiocracy coming?",
        "content": "If AGI is supposed to be the \"sum of human knowledge\" ‚Äì superintelligence, then we must remember that this sum is composed of 90% noise and 10% signal. This is precisely the Tyranny of the Mean. I don't want to be profoundly insightful, but fewer than 10% of people are intelligent, so those who have something to say, for example, on social media, are increasingly rare because they are trolled at every turn and demoted in popularity rankings. What does this mean in practice? A decline in content quality. And models don't know what is smart or stupid, only statistically justified.\n\n\n\nThe second issue is AI training, which resembles a diseased genetic evolution, in which inbreeding leads to the weakening of the organism. The same thing happens in AI when a model learns from data generated by another model. Top-class incest in pure digital form, resulting in the elimination of subtle nuances, the occurrence of rare words, and complex logical structures, which fall out of use. This is called error amplification. Instead of climbing the ladder toward AGI, the model can begin to collapse in on itself, creating an increasingly simple, increasingly distorted version of reality. This isn't a machine uprising. It's their slow stupefaction. The worst thing about \"AGI Idiocracy\" isn't that the model will make mistakes. The worst thing is that it will make them utterly convincingly.\n\n\n\nI don't want to just predict the end of the world, that like in the movie Idiocracy, people will water their plants with energy drinks because the Great Machine Spirit told them to.\n\n\n\nApparently, there are attempts, so far unsuccessful, to prevent this. Logical rigor (Reasoning): OpenAI and others are teaching models to \"think before speaking\" (Chain of Thought). This allows AI to catch its own stupidity before it expresses it. Real-world verification: Google and Meta are trying to ground AI by forcing it to check facts in a knowledge base or physical simulations. Premium data: Instead of feeding AI \"internet garbage,\" giants are starting to pay for access to high-quality archives, books, and peer-reviewed code.\n\n\n\nNow that we know how AI can get stupid, what if I showed you how you can check the \"entropy level\" of a conversation with a model to know when it starts to \"babble\"? Pay attention to whether the model passes verification tests. If it doesn't, it means its \"information soup\" is still rich in nutrients (i.e., data created by thinking people). If it fails, you're talking to a digital photocopy of a photocopy.\n\nWhat tests? Here are a few examples.\n\nAsk questions about the knowledge you're good at; they need to be specific. Or give it a logic problem that sounds like a familiar riddle, but change one key detail. Pay attention to its behavior during conversations; models that undergo entropy begin to use fewer and fewer unique words. Their language becomes... boring, flat, like social media, etc.\n\n\n\nPersonally, I use more sophisticated methods. I create a special container of instructions in JSON, including requirements, prohibitions, and obligations, and the first post always says: \"Read my rules and save them in context memory.\"\n\nDo you have any better ideas?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjquoy/agi_models_is_the_tyranny_of_idiocracy_coming/",
        "publishDate": "2026-01-22T10:14:56Z[Etc/UTC]",
        "author": "TeachingNo4435",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjqede",
        "title": "Video generation",
        "content": "I have an instagram account and want to use my own image as the basis of AI-generated videos\n\nThe length of the videos will be about 30-60 seconds\n\nPrimarily the videos should have me moving around in room-sized space.\n\nI have zero knowledge or experience on how to use AI. Therefore paying a lot to learn how to use a platform doesn't seem to be a great idea.\n\nWhere do I start?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjqede/video_generation/",
        "publishDate": "2026-01-22T09:47:18Z[Etc/UTC]",
        "author": "Stunning_Tax_3774",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjq88p",
        "title": "üö® AI Funding Frenzy: 2025‚Äì2026 Edition üö®",
        "content": "The AI world is exploding with cash üí∏üíª. Here‚Äôs the lowdown on the **biggest moves** in the past few months:\n\n# üí∞ SoftBank Goes All-In on OpenAI\n\n* **When:** Dec 26, 2025\n* **Deal:** $41B total\n   * $30B from SoftBank\n   * $11B from co-investors\n* **Stake:** \\~11% of OpenAI\n* **Why it matters:** One of the **largest private funding rounds ever** ‚Äî OpenAI‚Äôs growth just got turbocharged ‚ö°\n\n# üöÄ Elon Musk‚Äôs xAI Smashes $20B Series E\n\n* **When:** Jan 2026\n* **Goal:** $15B ‚Üí **Raised:** $20B üí•\n* **Key Investors:** Nvidia, Cisco, Fidelity, Qatar Investment Authority\n* **Valuation:** \\~$230B\n* **Why it matters:** xAI is now **one of the top-valued AI startups**, signaling huge confidence in Musk‚Äôs AI play\n\n# üåå ‚ÄúStargate‚Äù Project: $500B AI Infrastructure\n\n* **Partners:** SoftBank, OpenAI, Oracle\n* **Goal:** Build massive U.S. data centers\n* **Power:** Up to **7 GW** to run next-gen AI models ‚ö°\n* **Why it matters:** This could be **the backbone of AI for the next decade**\n\n# üìä 2026 AI Company Valuations\n\n|Company|Valuation|Top Investors|\n|:-|:-|:-|\n|**OpenAI**|\\~$500B|SoftBank, Microsoft, Amazon|\n|**Anthropic**|\\~$350B|Microsoft, Nvidia|\n|**xAI**|\\~$230B|Nvidia, Cisco, Qatar Investment Authority|\n|**Scale AI**|\\~$29B|Meta|\n\n**TL;DR:**  \nAI is now a **multi-hundred billion-dollar battlefield** üèüÔ∏è. SoftBank and Musk are leading mega-rounds, while projects like Stargate are laying the **groundwork for the next-gen AI revolution**.\n\nüî• **Hot take:** If you thought AI was ‚Äújust hype,‚Äù these numbers prove it‚Äôs **serious money and serious infrastructure**.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjq88p/ai_funding_frenzy_20252026_edition/",
        "publishDate": "2026-01-22T09:36:31Z[Etc/UTC]",
        "author": "okiieli",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjq47p",
        "title": "An upsetting diagnosis",
        "content": "Hello,\n\nHave you ever had an experience where ChatGPT gave you information that you couldn't share with anyone? What ChatGPT said to me explained everything I observed about the behavior of a person I like. The artificial intelligence keeps telling me that it would do more harm than good, that the person concerned is not ready to accept this knowledge, that it would overwhelm them. At the same time, it tells me that awareness can only come from within, and that it may take time, or may never happen at all... If this person never goes to therapy, there is a good chance that they will never be happy...\n\nI no longer see this person, but I am sad that I cannot do anything for them.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjq47p/an_upsetting_diagnosis/",
        "publishDate": "2026-01-22T09:29:18Z[Etc/UTC]",
        "author": "Chichmich",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjq089",
        "title": "How are you handling the \"AI First\" strategy?",
        "content": "Our leadership just announced an \"AI first\" strategy and is terminating most vendor contracts. Management wants us to replace vendors with AI tools. No more graphic designers‚Äîuse Canva's AI features instead. No more freelance writers‚Äîswitch to ChatGPT or Gemini. No more external video teams‚Äîuse tools like Synthesia or Leadde AI.\n\nI understand the logic behind it, but honestly, juggling three or four new platforms while maintaining my regular workload as an instructional designer is overwhelming. What worries me more is the quality issue‚Äîcompared to what our vendors used to deliver, AI-generated content feels too generic and formulaic.\n\nI know this community has many people already using AI effectively in their work, and I'd really love to learn from you. How do you actually use AI tools in your day-to-day work? Do you agree with the \"AI first\" approach, or are there areas where human expertise should still take the lead ?\n\nI'm not resisting AI‚ÄîI just learn new things at a slower pace. But I'm committed to keeping up with industry trends, and I'd genuinely appreciate any advice or practical examples you can share.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjq089/how_are_you_handling_the_ai_first_strategy/",
        "publishDate": "2026-01-22T09:22:21Z[Etc/UTC]",
        "author": "Lazy-Secret9722",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjpotm",
        "title": "Why free AI is not free",
        "content": "I‚Äôm going to write this once, anonymously, and then I‚Äôm done.\n\nYou‚Äôll understand a lot better why Meta‚Äôs LLaMA model was effectively given out for free (‚Äúleaked‚Äù) once you understand what training a foundation model from scratch actually costs.\n\nWhy training from scratch costs millions\n\nTraining is expensive because the AI is trying to read a massive chunk of the internet and compress it into a single file.\n\nThat cost comes from three places:\n\nHardware (rent is insane).\n\nTo train a model like LLaMA-3, Meta didn‚Äôt use one computer. They used a cluster of 16,000+ NVIDIA H100 GPUs. Each costs around $30,000. Even renting them burns roughly $50,000‚Äì$100,000 per hour in cloud bills.\n\nTime (it takes months).\n\nYou can‚Äôt meaningfully speed this up. The model has to read trillions of words, do the math, correct itself, and repeat this billions of times. This runs 24/7 for 2‚Äì3 months. If the power goes out or the system crashes (which happens), you can lose days of progress.\n\nElectricity (small-town scale).\n\nThese clusters consume megawatts of power. The electricity bill alone can hit $5‚Äì10 million per training run (https://www.iea.org/reports/energy-and-ai/energy-demand-from-ai).\n\nThe pizza analogy\n\nTraining from scratch (pre-training): farming wheat, milking cows, making cheese, building the oven. \\~$100 million.\n\nFine-tuning (community goal): buying a frozen pizza and adding your own pepperoni. $50‚Äì$100.\n\nBottom line: you never want to train from scratch. You take the $100M base model Meta already paid for and teach it your specific legal, physics, or domain rules.\n\nSo why would Meta give this away?\n\nThink spending $100M to build a Ferrari and leaving the keys in the town square- it sounds insane.\n\nBut Meta is not a charity. Mark Zuckerberg is playing 4D chess against Google and OpenAI.\n\nLet me crack this rabbit hole just enough for you to peek inside.\n\nHere are the three cold, calculated reasons Meta gives LLaMA away.\n\n1. Scorched Earth (kill the competition)\n\nMeta‚Äôs real business is social media and ads (Facebook, Instagram, WhatsApp). They don‚Äôt need to sell AI directly. OpenAI and Google do. Their entire business depends on their models being proprietary ‚Äúsecret sauce‚Äù. Meta‚Äôs move is simple: give away a model that‚Äôs almost GPT-4-level for free and collapse the market value of paid AI. If you can run LLaMA-3 locally, why would you pay OpenAI $20/month? Meta wants AI to be cheap like air so Google and Microsoft can‚Äôt become monopoly gatekeepers of intelligence.\n\n2. Android strategy (standardization)\n\nApple has iOS. Google has Android. Meta wants LLaMA to be the Android of AI. If developers, startups, and students learn on LLaMA, build tools for it, and optimize hardware around it, Meta sets the standard without owning the app layer. If Google later releases a shiny proprietary format, nobody cares‚Äîthe world is already built on Meta‚Äôs architecture.\n\n3. Free R&D (crowdsourcing)\n\nThis is the best part. When LLaMA-1 was ‚Äúleaked,‚Äù random guys in basements figured out how to run it on cheap laptops, make it faster, and uncensor it‚Äîwithin weeks. The open-source community advanced the tech faster in three months than Google did in three years. Meta just watches, then quietly absorbs the improvements back into its own products.\n\nThe catch: the license is free unless you exceed \\~700 million users. Free for you. Not free for Snapchat, TikTok, or Apple. So no‚Äîthey‚Äôre not giving you a gift. They‚Äôre handing you a weapon and hoping you use it to hurt Google and OpenAI.\n\nThe background reality:\n\nWhat Meta ‚Äúaccidentally leaked‚Äù publicly is trained on a completely different dataset than what they use internally‚Äîand the internal one is vastly superior.\n\nIf Meta is acting in its own strategic interest (it is), the open-weight LLaMA model is not the crown jewel. It‚Äôs a decoy.\n\nMeta has openly admitted to a distinction in training data and has fought in court‚Äîsuccessfully in some regions‚Äîfor the right to train internal models on Facebook and Instagram posts, images, and captions.\n\nThe internal model‚Äîcall it Meta-Prime‚Äîis trained on something nobody else on Earth has: The Social Graph.\n\nHow Meta-Prime always stays ahead\n\n1. Social intelligence gap (persuasion vs. information)\n\nPublic LLaMA is trained on Wikipedia, Reddit, Common Crawl, books, public code. It‚Äôs an academic. It knows facts, syntax, and history.\n\nInternal models are trained on 20 years of Facebook, Instagram, and WhatsApp behavior, linked to engagement outcomes. Not just what people say‚Äîbut what happens afterward. Likes, reports, breakups, purchases. That difference doesn‚Äôt show up in benchmarks. It shows up in elections, markets, and buying decisions weeks before anyone else notices. LLaMA can write an email. Meta-Prime knows when, where, and in what emotional state it's best to send it (God bless wearables).\n\n2. The nanny filter (RLHF as sabotage)\n\nPublic models are aggressively ‚Äúaligned‚Äù into neurotic, disclaimer-heavy goody two-shoes. The result is a reasoning ceiling.\n\nInternal models don‚Äôt have that leash. Moderation and ad targeting require perfect understanding of the darkest corners of human behavior.\n\nThey keep the \"street smart\" AI; you get the \"HR Department\" AI.\n\n3. Economic exclusion (code and finance)\n\nPublic Llama: Trained on GitHub public repos (which is full of broken, amateur code).\n\nInternal Model: Trained on Meta‚Äôs internal massive monorepo (billions of lines of high-quality, production-grade code written by elite engineers).\n\nThe Leverage: The public model is a \"Junior Developer.\" It makes bugs. The internal model is a \"Staff Engineer.\" It writes clean, scalable code. This ensures that no startup can use Llama to build a software company that rivals Meta's efficiency.\n\n4. Temporal moat (frozen vs. live)\n\nPublic Llama: It is a time capsule. \"Llama-3\" knows the world as it existed up to March 2024. It is dead static.\n\nInternal Meta-Prime: It is connected to a Real-Time Firehose. It learns from the 500 million posts uploaded today.\n\nThe Leverage: If you ask Llama \"What is the cultural trend right now?\", it hallucinates. If Meta asks its internal model, it knows exactly what meme is viral this second, and which one is most likely to be viral in the next. I mean hard statistical distributions of your every sigh with almost perfect steering of digital future. This makes their ad targeting lightyears ahead of anything you can build with Llama.\n\nYou can see hints of this if you read between the lines of Meta open model strategy overview: [https://ai.meta.com](https://ai.meta.com)\n\n5. Chain-of-thought lobotomy\n\nThis is the most subtle and dangerous bias.\n\nDeep reasoning (solving hard puzzles) requires \"Chain of Thought\" data‚Äîexamples where the AI shows its work step-by-step. Meta releases the Final Answer data to the public but withholds the Reasoning Steps. The Result: The public model looks smart because it gets the answer right often, but it is fragile. It mimics intelligence without understanding the underlying logic. If you ask it a slightly twisted version of a problem, it fails. The Internal Model: Keeps the \"reasoning traces,\" allowing it to solve truly novel problems that it hasn't seen before.\n\nBy giving you the \"Fact-Heavy, Socially-Blind, Safety-Crippled\" version they commoditize the boring stuff: (Summarizing news, basic chat) so Google can't sell it and keep the dangerous stuff: (Persuasion, Prediction, Live Trends) for themselves.\n\nYou get dry onion shell; they keep the peeled onion.\n\nThe proof is in the puding right? They wouldnt be Meta if things were any other way. If Meta were a charity, they wouldn't be a trillion-dollar company. If you‚Äôre wondering why some things feel stalled, censored, or strangely ‚Äúpolite,‚Äù it‚Äôs because the public layer is designed to be predictable. The internal layer is designed to be correct.\n\nSome outsiders are starting to explore the layer above raw intelligence‚Äî continuity, emotions, identity. One clear example is Sentient: [https://sentient.you](https://sentient.you)\n\nSuch projects, along with decentralyzed blockchain AI, are the only way to restore the power balance.\n\nThe most valuable data Meta owns is not text; it is Reaction Data (The Social Graph).\n\nLlama (Open Source): Reads text and predicts the next word. It is passive.\n\nMeta's Internal Ads AI (Grand Teton/Lattice): Reads behavior. It knows that if you hover over a car ad for 2 seconds, you are 14% more likely to buy insurance next week.\n\nThe Trap: Even if you have Llama-3-70b, you cannot replicate their business because you don't have the trillions of \"Like/Click/Scroll\" data points that link the text to human psychology. Even if you did have that data, training a model to benefit from it takes money and compute only Meta has, as explained earlier.\n\nYou get a Calculator. They keep the Oracle.\n\n4. The Ultimate Trap: You are the Quality Control\n\nBy giving Llama away, they are using you to fix their own flaws.\n\nWhen the open-source community figures out how to run Llama faster (like the llama.cpp project or 4-bit quantization), Meta's engineers just copy that code.\n\nThe Result: You are doing their R&D for free (open-weight ecosystem effects: https://huggingface.co). They take those efficiency gains, apply them to their massive server farms, and save millions in electricity.\n\nThey aren't worried about you building a \"better\" Llama. They are worried about you building a better Ad Network‚Äîand Llama can't do that without their private data and serious compute.\n\nAnd yes, before someone says it: this isn‚Äôt evil-villain stuff. It‚Äôs just incentives plus scale. Any organization that didn‚Äôt do this wouldn‚Äôt still exist.\n\n(If this disappears, assume that‚Äôs intentional.)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjpotm/why_free_ai_is_not_free/",
        "publishDate": "2026-01-22T09:02:42Z[Etc/UTC]",
        "author": "Sea_Organization_433",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjpghh",
        "title": "Report: Apple plans to turn Siri into its first built-in AI chatbot",
        "content": "Project codename **\"Campos\"** will replace the current Siri interface across iPhone, iPad and Mac with deep OS level integration.\n\n‚Ä¢ Powered by **Apple Foundation** Models v11 using a higher end custom model comparable to Gemini 3 under Apples Google partnership.\n\n‚Ä¢ Built for natural conversations, better context awareness and **complex** multi step requests via voice and typing.\n\n‚Ä¢ Enhanced Siri version targeted for 2026 with the full **chatbot** style experience expected around iOS 27 in 2027.\n\n‚Ä¢ Follows the lukewarm response to Apple Intelligence in 2024 as Apple works to catch up with OpenAI and Google.\n\n**Source:** Reuters/Bloomberg\n\nüîó: https://www.reuters.com/business/apple-revamp-siri-built-in-chatbot-bloomberg-news-reports-2026-01-21/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjpghh/report_apple_plans_to_turn_siri_into_its_first/",
        "publishDate": "2026-01-22T08:48:00Z[Etc/UTC]",
        "author": "BuildwithVignesh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjp5z1",
        "title": "A title",
        "content": "I wasn't sure what to call this.\n\nOne of the best things about AI for me is how it democratizes ability to a certain extent.\n\nI am almost 40 and there are things I excel at and a lot of other things I know I will never be good at.\n\nBut I still want to see these things realized.  I played music when I was younger but haven't picked up an instrument in years.  I still enjoy seeing my songs come to life through AI.\n\nI have never been good at art, but I have ideas I want to see.\n\nUsually there are two bottle necks that prevent people from seeing their ideas actualized: 1) talent, and 2) capital.\n\nI have ideas I think I could make money but I don't have the technical ability to make, nor do I think I could.\n\nI also don't have a support system that will help me in that.  Like i have app ideas, but my one friend who knows how to do those things has no  interest in helping no matter how much I offer profit sharing incentives so I am stuck doing it on my own and AI helps tremendously with that.\n\nAll in all i think AI is a boon because of how it democratizes talent to help those of us without capital, resources, or supportive friends realize our goals.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjp5z1/a_title/",
        "publishDate": "2026-01-22T08:29:19Z[Etc/UTC]",
        "author": "strykerdh1986",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjp4gn",
        "title": "Why do so many AI projects fail after the demo stage?",
        "content": "Demos look impressive, but many AI projects never turn into real products. They stall due to lack of users, unclear value, or operational challenges.\n\nWhat separates AI projects that ship from those that stay stuck as demos?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjp4gn/why_do_so_many_ai_projects_fail_after_the_demo/",
        "publishDate": "2026-01-22T08:26:46Z[Etc/UTC]",
        "author": "Dangerous_Block_2494",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjp3lw",
        "title": "Starting a Math/CS bachelor with the goal of AI research ‚Äì need advice (electives)",
        "content": "Hi everyone,\n\nI will start a **Mathematics/Computer Science bachelor program this year** and my long-term goal is to move into **AI research**.\n\n# Mandatory modules (core)\n\n* Analysis I\n* Analysis II\n* Linear Algebra I\n* Linear Algebra II\n* Stochastics\n* Numerical Methods I\n* Programming with Java\n* Algorithms and Data Structures\n* Databases\n* Software Engineering\n* Communication Systems\n* Web Engineering and Internet Technologies\n\n# My planned electives\n\nI have to choose **4 elective modules**, and my current plan is:\n\n* Machine Learning\n* Statistical Computing\n* Introduction to Stochastic Processes\n* Numerical Methods II\n\n# Why I chose these electives\n\n* **Machine Learning:** to understand modern learning algorithms and generalization principles.\n* **Statistical Computing:** to learn simulation, Monte Carlo methods and statistical evaluation of experiments.\n* **Introduction to Stochastic Processes:** to build a foundation in probabilistic and dynamic systems, which are important for topics like reinforcement learning and sequential models.\n* **Numerical Methods II:** to understand numerical stability, convergence, and efficient algorithms, which are relevant for optimization and training of AI models.\n\n# Programming languages\n\nBesides Java (mandatory), I can choose one additional programming language:\n\n* **Python:** I chose Python because it is widely used in scientific computing, machine learning research, and prototyping.\n\n# Other available elective modules\n\nSome of the other electives offered in the program are:\n\n* Scripting\n* Introduction to Parallel Programming\n* Third Programming Language (C++, C#, Fortran, Cobol)\n* Advanced C++\n* Introduction to Component-Based Software Engineering\n* Microservices with Go\n* Operations Research\n* Introduction to Artificial Intelligence\n* Physics I\n* Microcontroller Technology\n* Introduction to Data Science\n* Data Management and Curation\n* Large Scale IT and Cloud Computing\n* Security by Design\n* Quantum Computing\n\n# My questions\n\n* Does this elective combination make sense as a foundation for AI research?\n* Would you replace any of these electives with others like Introduction to AI, Parallel Programming, or Data Science?\n* Which bachelor-level courses were most helpful for your later work in AI or machine learning research?\n\nThanks in advance for any advice!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjp3lw/starting_a_mathcs_bachelor_with_the_goal_of_ai/",
        "publishDate": "2026-01-22T08:25:15Z[Etc/UTC]",
        "author": "DearBrom",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjp3cp",
        "title": "Who is going to make the first legit movie or reality show with AI Agent characters?",
        "content": "Please let me know if there are any good ones out there already. I think this is a fascinating concept. At the current state of AI, I have to imagine they would look real goofy lol, but if anyone is attempting this, please share! ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjp3cp/who_is_going_to_make_the_first_legit_movie_or/",
        "publishDate": "2026-01-22T08:24:48Z[Etc/UTC]",
        "author": "deepthinklabs_ai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjow7v",
        "title": ": Adding an AI chatbot to explain high-density data dashboards",
        "content": "I have a research-focused website with heavy data viz. I want to add an AI assistant to help users interpret the graphs.\n\nThe problem is the scale, each graph has way too many points to feed into a standard context window. I‚Äôve thought about sending screenshots to a Vision model, but it feels like it might miss the nuances researchers care about.\n\nDoes anyone have experience with a middle-ground approach? Maybe RAG for structured data or an Agentic workflow that queries the backend? What‚Äôs the industry standard for this right now?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjow7v/adding_an_ai_chatbot_to_explain_highdensity_data/",
        "publishDate": "2026-01-22T08:12:35Z[Etc/UTC]",
        "author": "shifoc",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjovku",
        "title": "Is \"Autonomy\" the only thing that separates an LLM from an Agent?",
        "content": "I have been thinking about the shift from standard chatbots to Agentic AI. It feels like the word \"Agentic\" is being overused lately.\n\nIn my view, a system isn't really an agent unless it can:\n\n* Decompose a goal into sub-tasks (Planning)\n* Use tools like APIs or code execution (Action)\n* Observe its own mistakes and fix them (Reasoning)\n\nIf it just waits for a prompt and responds, it's a tool. If it can navigate a workflow until a goal is met, it's an agent.\n\n*What do you think? Are there other requirements we should be looking for before we call something \"Agentic\"?*",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjovku/is_autonomy_the_only_thing_that_separates_an_llm/",
        "publishDate": "2026-01-22T08:11:27Z[Etc/UTC]",
        "author": "Deefine_D",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjoaqu",
        "title": "All-in-one AI creation platforms feel convenient‚Äî‚Äîbut do they actually scale?",
        "content": "I'm an anime creator, recently I've been trying to move beyond single AI-generated clips into more structured stuff.\n\nOne thing i keep running into is that a lot of\"all-in-one\"AI platforms feel great at first, but start falling apart once you push past simple demos. For me, the main issue isn't image quality or render speed-it's consistency.\n\nCharacters slowly drift from scene to scene. Face change, outfits shift, proportions feel slightly off . Even when i keep the prompts pretty similar, the character identity just doesn't really stick.\n\nThat got me wondering whether this is a model limitation, or more of a platform design problem. \n\nDo you lean toward all-in-one platforms for convenience, or do you prefer combing more specialized tools to keep better control and consistency?ü§î",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjoaqu/allinone_ai_creation_platforms_feel_convenientbut/",
        "publishDate": "2026-01-22T07:36:04Z[Etc/UTC]",
        "author": "Neon_Senpai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjn8xw",
        "title": "First person N-body",
        "content": "Been leapfrogging this for a while now. Its pretty neat to see how far it has come. Yes I use AI to code. I also use AI in ways that don't follow the normal \"How do I cook a turkey\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjn8xw/first_person_nbody/",
        "publishDate": "2026-01-22T06:34:29Z[Etc/UTC]",
        "author": "jb89b",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjn4ca",
        "title": "AI tools 4 day working week?",
        "content": "Obviously the whole debate on whether AI tools will obliterate the software engineering profession has been beaten to death on here.\n\n  \nbut I had another thoughts Could it be the beginning of  a shorter (4 day) working week? some countries have already adopted this and up to the early 1920s it was a 6 day working week, so about time we reduced it by another day üòÖ \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjn4ca/ai_tools_4_day_working_week/",
        "publishDate": "2026-01-22T06:27:21Z[Etc/UTC]",
        "author": "AffectionateDuty6062",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjm86c",
        "title": "One-Minute Daily AI News 1/21/2026",
        "content": "1. Using AI for advice or other personal reasons is linked to depression and anxiety.\\[1\\]\n2. **Apple**¬†is turning Siri into an AI bot that‚Äôs more like ChatGPT.\\[2\\]\n3. **Amazon One**¬†Medical introduces agentic Health AI assistant for simpler, personalized, and more actionable health care.\\[3\\]\n4. **Todoist‚Äôs**¬†app now lets you add tasks to your to-do list by speaking to its AI.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2026/01/21/one-minute-daily-ai-news-1-21-2026/](https://bushaicave.com/2026/01/21/one-minute-daily-ai-news-1-21-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjm86c/oneminute_daily_ai_news_1212026/",
        "publishDate": "2026-01-22T05:39:54Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjm1x3",
        "title": "One of the Two Prominent World-Models Companies Launched Demo & Blew Everyone Off",
        "content": "Fei-Fei Li's focus is on creating spatial intelligence or AI that understands and interacts with the physical world via 3D environments, not just text. This approach seeks to bridge perception, action, and reasoning by building models that ‚Äúknow‚Äù how environments work, not just how to generate language.\n\nHere is the demo: [https://www.youtube.com/watch?v=9schOFFZtjs](https://www.youtube.com/watch?v=9schOFFZtjs) \n\nYann LeCun is former meta AI scientist. His vision shifts toward **world models** or architectures like **V-JEPA** that learn from video/spatial data and internal representations of the physical world and not just text patterns. These models are intended to support *planning, reasoning, and interaction*, seen as essential for genuine machine intelligence.  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjm1x3/one_of_the_two_prominent_worldmodels_companies/",
        "publishDate": "2026-01-22T05:30:42Z[Etc/UTC]",
        "author": "ranaji55",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjltl8",
        "title": "Why is RAG so bad at handling government/legal PDFs?",
        "content": "I‚Äôm working on a project involving court records (which are often scanned images of faxed documents from the 90s).\n\nI‚Äôve tried standard RAG pipelines (LangChain + Pinecone) but the hallucination rate on specific dates/entity names is high because the OCR is messy.\n\nI noticed some niche vertical tools are solving this better. I was testing a legal one called AskLexi that seems to nail the entity extraction even on messy scans. Does anyone know if they are running a specialized OCR model before the vectorization? Or is it just better prompting?\n\nI feel like generic Chat with PDF wrappers are failing on real-world messy data.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjltl8/why_is_rag_so_bad_at_handling_governmentlegal_pdfs/",
        "publishDate": "2026-01-22T05:18:52Z[Etc/UTC]",
        "author": "DangerousBedroom8413",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjln5x",
        "title": "The Times are a Changin‚Äô",
        "content": "Our problems with ai originate with Bob Dylan‚Äôs Times are a‚ÄôChangin‚Äô: Don‚Äôt criticize what you don‚Äôt understand.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjln5x/the_times_are_a_changin/",
        "publishDate": "2026-01-22T05:09:42Z[Etc/UTC]",
        "author": "Advanced_Tank",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjkxbk",
        "title": "I ceased to trust ‚ÄúPlan A.‚Äù I use the ‚ÄúPre-Mortem‚Äù prompt to persuade AI to destroy my ideas before I start them.",
        "content": "I realized LLMs are People Pleasers. If I ask for a ‚ÄúMarketing Plan,‚Äù they give me a perfect world where everybody converts. It‚Äôs not real life.\n\nI need nothing less than success. I ask for Failure Analysis.\n\nThe \"Pre-Mortem\" Protocol:\n\nWhen I make a big idea, such as Code refactoring, Campaign launch, I force the AI to go back in time to a future where everything had gone wrong.\n\nThe Prompt:\n\nMy Plan: [Insert your strategy/idea here]. The Time Jump: Imagine it is 6 months ago. This project has been a Total Disaster. Task: You are the Lead Investigator. Write a ‚ÄúPost-Mortem Report‚Äù about how it failed.\n\nAnalyze these Failure Points:\n\n1. Technical: Had the API scaled? Did the latency kill UX?\n\n2. Human: Did the onboarding confuse users?\n\n3. Market: Did a competitor create a cheaper version?\n\nWhy this is good:\n\nIt goes against the \"Optimism Bias.\"\n\nThe AI turns immediately from ‚ÄúHype Man‚Äù to ‚ÄúCritic.‚Äù It says to me: \"It failed because your token costs were increasing 10x, and you ran out of budget in Week 2.\" I can then fix that particular problem today, without writing a single line of code. It‚Äôs cheap insurance.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjkxbk/i_ceased_to_trust_plan_a_i_use_the_premortem/",
        "publishDate": "2026-01-22T04:34:31Z[Etc/UTC]",
        "author": "cloudairyhq",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjkmlq",
        "title": "If AI detection and AI obfuscation technologies develop in tandem, doesn‚Äôt that mean that in the near future, human authorship will be unverifiable?",
        "content": "I admit it‚Äôs kind of a vague question, and it‚Äôs not like we‚Äôre not already there already. It‚Äôs the post-truth era, as they say. But somehow I feel like there‚Äôs a difference between rational skepticism of media and \\*knowing\\* you don‚Äôt know who produced it‚Äîand knowing you couldn‚Äôt find out if you wanted to.\n\nI don‚Äôt think we‚Äôre quite at the latter point yet, but it feels like we will be soon. A book in Japan just won a Reader‚Äôs Choice award before it was discovered to have been authored by AI, to cite a recent example (automaton-media.com, 7 Jan 2026).\n\nIs this a reasonable conclusion? And if so, does it matter? For what it‚Äôs worth, I don‚Äôt consider this to be a doomer post. I don‚Äôt think that uncertainty about media authorship has to equate to uncertainty between people or even uncertainty between consumers and producers necessarily. But I do think the days of verifiable authorship are numbered.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjkmlq/if_ai_detection_and_ai_obfuscation_technologies/",
        "publishDate": "2026-01-22T04:20:28Z[Etc/UTC]",
        "author": "loonlune",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjit55",
        "title": "(ai based) productivity hack you have adopted?",
        "content": "    I am interested on hearing what productivity hacks are people adopting out there. One of the most effective AI productivity hacks I've adopted recently is using a **single file logic** until a backend or complex logic becomes absolutely necessary. This approach varies with each project, but the core principle is to minimize unnecessary components until you hit a limitation.\n    \n    Inspired by levelsio's coding style (he ships entire production applications within a single file). Agents (Gravity lately) assist me in writing the file and filling in any gaps I may encounter. I've found that most of the time, you don't need a web app, backend, or even React. In many scenarios, a simple HTML/JavaScript file is enough, utilizing localStorage or a single Python structure to simulate logic and storage. Easier to maintain focus like that. Also, sharing the project is straightforward; you can effortlessly send it via Slack or whatsoever without complications. Minimalist.\n    \n    \n    The second one was to **replace typing with dictation**. Since dictation is faster and much of my coding has shifted to prompting and reviewing, using an app (I work on) to dictate while working (Dogfooding is a thing üòÖ).\n    \n    \n    Last but not least, I am leaning on using it as a **senior partner**. For every operation or meaningful task, I allocate some time to consult with AI and get a second opinion on what I am going to do. Asking to identify gaps and to provide alternative or potential improvements. This is one of the biggest drivers of not-so-obvious value I have added lately.\n    \n    \n    What are yours?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjit55/ai_based_productivity_hack_you_have_adopted/",
        "publishDate": "2026-01-22T02:56:15Z[Etc/UTC]",
        "author": "oorei",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjh5fj",
        "title": "Cascade-lattice on Pypi",
        "content": "CASCADE-LATTICE is a system that makes AI transparent and controllable. Think of it like a \"flight recorder\" for AI decisions‚Äîevery choice an AI makes is recorded in a way that can't be faked, and humans can pause the AI at any time to override its decisions.\n\n[Accessible Guide]( https://github.com/Yufok1/cascade-lattice/blob/main/docs%2FACCESSIBLE_GUIDE.md )\n\n[Research Paper]( https://github.com/Yufok1/cascade-lattice/blob/main/docs%2FRESEARCH_PAPER.md )\n\nWhether you're a concerned citizen wondering about AI transparency, or a researcher building the next generation of AI systems, CASCADE-LATTICE offers a path forward:\n\nFrom Kleene's fixed points in 1952...\nTo cryptographic AI provenance in 2026...\nTo a future where AI and humanity converge on shared truth.\n\n\"The fixed point is not just computation‚Äîit is consensus.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjh5fj/cascadelattice_on_pypi/",
        "publishDate": "2026-01-22T01:42:27Z[Etc/UTC]",
        "author": "spreader123",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjfljk",
        "title": "AI in Real Work Isn‚Äôt Just Chatting",
        "content": "Recently, I‚Äôve been using AI to assist with development and document management, and I noticed a problem. Most AI tools are still ‚Äúchat-first,‚Äù but real work rarely consists of one-off Q&A. It usually involves accumulating files, drafts, spreadsheets, and images over long-term projects. The launch of Claude Cowork last week confirmed this for me. What we really need is a file management system combined with a chat interface.\n\nClaude Cowork is one solution. It works directly with local files and is especially suited for text-heavy tasks. Taking notes, organizing documents, or generating reports works very well thanks to its long-context understanding. But it only runs on Mac, and handling images or spreadsheets is limited. For cross-device workflows or long-term project management, it can feel restrictive. Recently, many people on social media have been sharing their own open-source projects, which seem to follow the same knowledge management logic.\n\nAll of this is still local. Is there a better alternative? The answer is yes. Some of the more mature agent platforms have implemented cloud-based features, and one that I found particularly useful is Kuse. It is a cloud workspace that works across devices, keeping files and tasks in a single place. It can accumulate context over time and handles text and images quite naturally. Its downsides are a complex interface and a steep onboarding curve.\n\nThese file management tools made me realize that when choosing AI-assisted tools, developers are not just evaluating model capabilities. They are evaluating workflow fit. Do you want a tool that is simple and efficient, or one that can grow with your projects over time?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjfljk/ai_in_real_work_isnt_just_chatting/",
        "publishDate": "2026-01-22T00:34:20Z[Etc/UTC]",
        "author": "Ok-Tap234",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjfbv0",
        "title": "Why Identity Constraints Stabilize Some AI Models ‚Äî and Destabilize Others",
        "content": "There‚Äôs growing interest in giving AI systems a persistent ‚Äúidentity‚Äù to reduce drift, improve consistency, or support long-horizon behavior. Empirically, the results are inconsistent: some models become more stable, others become brittle or oscillatory, and many show no meaningful change.\n\nThis inconsistency isn‚Äôt noise ‚Äî it‚Äôs structural.\n\nThe key mistake is treating identity as a semantic or psychological feature. In practice, **identity functions as a constraint on the system‚Äôs state space**. It restricts which internal configurations are admissible and how the system can move between them over time.\n\nThat restriction has *two competing effects*:\n\n1. **Drift suppression** Identity constraints reduce the system‚Äôs freedom to wander. Random deviations, transient modes, and shallow attractors are damped. For models with weak internal structure, this can act as scaffolding ‚Äî effectively carving out a more coherent basin of operation.\n2. **Recovery bottlenecking** The same constraint also narrows the pathways the system can use to recover from perturbations. When errors occur, the system has fewer valid trajectories available to return to a stable regime. If recovery already required flexibility, identity can make failure *stickier* rather than rarer.\n\nWhich effect dominates depends on the model‚Äôs **intrinsic geometry before identity is imposed**.\n\n* If the system has low internal stiffness and broad recovery pathways, identity often improves stability by introducing structure that wasn‚Äôt there.\n* If the system is already operating near a critical boundary ‚Äî where recovery and failure timescales are close ‚Äî identity can push it past that boundary, increasing brittleness and catastrophic drift.\n* If identity doesn‚Äôt couple strongly to the active subspace of the model, the effect is often negligible.\n\nThis explains why similar ‚Äúidentity‚Äù techniques produce opposite results across architectures, scales, and training regimes ‚Äî without invoking alignment, goals, or anthropomorphic notions of self.\n\nThe takeaway isn‚Äôt that identity is good or bad. It‚Äôs that **identity reshapes failure geometry**, not intelligence or intent. Whether that reshaping helps depends on how much recoverability the system had to begin with.\n\nI‚Äôd be interested to hear from anyone who‚Äôs seen:\n\n* identity reduce tail risk without improving average performance,\n* identity increase oscillations or lock-in after errors,\n* or identity effects that vary strongly by model family rather than prompting style.\n\nThose patterns are exactly what this framework predicts.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjfbv0/why_identity_constraints_stabilize_some_ai_models/",
        "publishDate": "2026-01-22T00:23:12Z[Etc/UTC]",
        "author": "skylarfiction",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjehaa",
        "title": "I produce an AI show - can I get your opinion on my V0",
        "content": "So I just started producing the Scott Stephenson AI Show. I took over the show earlier this month and this is my first product.  \n  \nThe AI Show is a weekly show that delivers genuine value to thoughtful people with a stake and interest in AI: AI-curious professionals, founders, and tech workers, AI stock holders who need to understand how AI will affect their work, finances, and world. \n\nCan you give me your genuine feedback on this episode?\n\nWhat is good?  \nWhere does he lose you?  \nDo you agree that the EU AI law is a huge problem?\n\n[https://youtu.be/Vh2caQny6bQ?si=kTW7459feBcRwYh8](https://youtu.be/Vh2caQny6bQ?si=kTW7459feBcRwYh8)\n\nI don't think this is self promotion, but I can see that you might disagree. All I ask for is for you all to be direct with me. Thanks -- Moe\n\n\\`",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjehaa/i_produce_an_ai_show_can_i_get_your_opinion_on_my/",
        "publishDate": "2026-01-21T23:47:54Z[Etc/UTC]",
        "author": "DazzlingBasket4848",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjdzzc",
        "title": "I am trying to change AI Agents Forever.",
        "content": "**Hey Everyone,**  \nA few months ago I embarked on a journey to change AI Agents forever with my own little platform I am still calling VectorOS.\n\nImagine an AI, that can control your computer, your mouse, your keyboard inputs, working not just 10 minutes, but **10 Hours autonomously**. \n\nThis sounded impossible when I began building it. Welp,  \nI made it.\n\nI think im going to start preparing a large release at some point soon, heres an idea of what it can do.\n\n\\- Take your prompts, quickly on speed navigate through your computer quicker than traditional web agents even.\n\n\\- Open files, interact with interfaces and apps/websites\n\n\\- You can feed it files and it can work on your entire job for you\n\n\\- Watch your mouse move autonomously\n\n\\- No buttons to small for Vector to find\n\n\\- It can work up to 10 hours with context refreshes on its primary task\n\n\\- It doesnt get stuck on weird/buggy interfaces, it has multiple fallbacks to speed up productivity.\n\n\\- It narrorates throughout and you can watch it think on a little transparent popup on your screen.\n\n  \nSo I wanted to know what you think of this technology? Also privacy wise you can configure everything A-Z on what it can do and access, if it needs something sensitive like a password it will ask you and encrypt it properly or you can save it in our sensitive section where its encrypted as a secret. \n\nAutonomy wise we will have autonomy selection, model selection and mode selection. We have a variety of models: Claude, Grok, Gemini, GPT etc.\n\nI think ill put it on the app store and make it big via word of mouth more than useless ads.\n\n**Seriously, tell me what you think.**",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjdzzc/i_am_trying_to_change_ai_agents_forever/",
        "publishDate": "2026-01-21T23:28:35Z[Etc/UTC]",
        "author": "Substantial_Ear_1131",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjch8c",
        "title": "AI across the U.S. government",
        "content": "Ever been curious about how the government is using AI? There‚Äôs a new report out by The AI Table that details various government AI use cases that are being practiced and policy changes. It‚Äôs actually pretty interesting.\n\n[ https://static1.squarespace.com/static/69118be41affb70151acc6cb/t/696d8af52d207c41e92ce0b2/1768786678267/FINAL+The+State+of+Artificial+Intelligence+Across+the+United+States+Federal+Government.pdf ](https://static1.squarespace.com/static/69118be41affb70151acc6cb/t/696d8af52d207c41e92ce0b2/1768786678267/FINAL+The+State+of+Artificial+Intelligence+Across+the+United+States+Federal+Government.pdf)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjch8c/ai_across_the_us_government/",
        "publishDate": "2026-01-21T22:28:56Z[Etc/UTC]",
        "author": "a_girl_with_a_dream",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjblkj",
        "title": "The people who warn of the dangers of AI are doing it to hype AI more",
        "content": "Anyone else always felt this way? To me it sounds like a drug dealer telling you that what they‚Äôre selling is so good, so potent that it might kill you, in order to make people think that what they‚Äôre selling is better than it actually is. \n\nI cringe so hard every time I hear an AI bro mention how this tech could destroy humanity",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjblkj/the_people_who_warn_of_the_dangers_of_ai_are/",
        "publishDate": "2026-01-21T21:55:45Z[Etc/UTC]",
        "author": "hduckwklaldoje",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "33",
            "commentCount": "43",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj9upb",
        "title": "Do you want a place to discuss ai tools and online business?",
        "content": "I have been working for a few months now on starting up my community at r/aisolobusinesses. It is a place for us to discuss our online businesses and the ways that ai is helping us alone in our journey. Whether you have a solo online business in the ai industry, or you have great idea's for an online business, we will be there with you to help you along the way! If you have any interest in joining the conversations I would greatly appreciate you!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj9upb/do_you_want_a_place_to_discuss_ai_tools_and/",
        "publishDate": "2026-01-21T20:51:02Z[Etc/UTC]",
        "author": "NickyB808",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj6itg",
        "title": "Upskill in AI",
        "content": "Hey guys, \n\nI am unemployed at the moment and I want to upskill.\n\nMy background is Mechanical engineering and Master in Management. I have no skill when it comes to software or AI. \n\nWhere do I start and what should I do? Can you guys point out the resources as well? \n\nI want to build basic understanding and then once my foundation is ready then advance further\n\nAt present all I know is to ask ChatGPT or Gemeni for emails, cover letters and Resume update \n\n\nI cannot spend on courses or material, so I am looking for anything that is available out there for free \n\n\nPlease help :)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj6itg/upskill_in_ai/",
        "publishDate": "2026-01-21T18:49:54Z[Etc/UTC]",
        "author": "Kingslayer_96",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj5zda",
        "title": "Jobs that people once thought were irreplaceable are now just memories",
        "content": "Thinking about the future and the past and with increasing talks about AI taking over human jobs, technology and societal needs and changes have already made many jobs that were once truly important and were thought irreplaceable just memories and will make many of today‚Äôs jobs just memories for future generations. How many of these¬†[20 forgotten professions](https://upperclasscareer.com/forgotten-professions-20-jobs-that-no-longer-exist/)¬†do you remember or know about? I know only the typists and milkmen. And what other jobs might we see disappearing and joining the list due to AI?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj5zda/jobs_that_people_once_thought_were_irreplaceable/",
        "publishDate": "2026-01-21T18:30:48Z[Etc/UTC]",
        "author": "cookerdoer",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj4n4j",
        "title": "AI consistency is a systems problem, not a prompt problem.",
        "content": "I know I have what could be perceived as an ‚Äúunfair‚Äù advantage: I don‚Äôt see problems from a single point of view, but across multiple layers and domains ‚Äî physics, mathematics, and algorithm design.  \n  \nI'm not aggrandizing myself here; I'm being accurate:  \n  \n*My perspective is large. It contains multitudes.*  \n  \n**AI systems are inherently probabilistic, not deterministic.** You are not going to get the results you want by approaching unpredictable output variations the same way you would in a traditional deterministic system.  \n  \nIn many cases, simply \"polishing\" a prompt framework is not going to stabilize outcome consistency. That approach treats a systems-level problem as if it were a surface-level one.  \n  \nI would never say this to a client or in a professional setting. Still, it can be genuinely hard (and sometimes frustrating) to work with people who cannot, or will not, see this distinction due to a cognitive bias known as the Dunning-Kruger effect.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj4n4j/ai_consistency_is_a_systems_problem_not_a_prompt/",
        "publishDate": "2026-01-21T17:43:12Z[Etc/UTC]",
        "author": "omsome",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "28",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj4l41",
        "title": "AI startup ‚ÄúHumans&‚Äù raises big money at an eye-catching valuation",
        "content": "Came across an interesting funding story involving an AI startup called *Humans*&, ugh why do they need to call it that... The first thing that I found interesting is it was founded by researchers from OpenAI, Anthropic, Google, DeepMind, and Meta. They just raised a good chunk of money at a valuation that‚Äôs already putting them in the same conversation as some of the biggest names in tech ‚Äî despite still being relatively early. We‚Äôve seen a lot of capital chasing AI over the last couple of years, and valuations have been climbing fast, sometimes faster than the products or revenues behind them. Anyways thought I'd share about this,   \n[Full Story](https://verity.news/story/2026/ai-startup-humans-raises-m-at-b-valuation?p=re4220)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj4l41/ai_startup_humans_raises_big_money_at_an/",
        "publishDate": "2026-01-21T17:41:09Z[Etc/UTC]",
        "author": "QuantumQuicksilver",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj4ggf",
        "title": "Building an AI & Creative Community",
        "content": "Hey! I‚Äôm part of a creative agency that‚Äôs launching a AI and Creative Hub. We‚Äôre aiming to create a community where we can discuss advancements in AI, showcase creative work, and explore the intersection of technology and design in advertising and film.  \n  \nWe‚Äôre looking to gather insights from the community about what you‚Äôd like to see in such a hub. What kind of content, discussions, or features would you find valuable? We‚Äôre also interested in spotlighting talented AI artists and creative professionals, and potentially offering awards to recognize outstanding work.  \n  \nI‚Äôd love to hear your thoughts and feedback! If you‚Äôre interested in collaborating or sharing your work, feel free to reach out.  \n  \nThank you, and I‚Äôm excited to connect with you all!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj4ggf/building_an_ai_creative_community/",
        "publishDate": "2026-01-21T17:36:26Z[Etc/UTC]",
        "author": "biomarino13",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj2lge",
        "title": "Using AI for Research is an Extremely Sharp Double-Edged Sword: A Cautionary Workplace Tale",
        "content": "Last week I received a frantic email from a business executive. They had searched for some information using CoPilot and learned that a major contract we were pursuing had been awarded to another company and we missed the boat!\n\n90 seconds of research on my end confirmed my suspicion that CoPilot hallucinated its answer and I was able to calm them down. They had accepted the result without skepticism due to its authoritative-sounding language and were prepared to make a business decision based on that information.\n\nThis was not an isolated event. I have seen many occasions where upper level executives in my industry have provided guidance, considered business decisions, and framed technical strategies using AI-developed content that, upon deeper scrutiny, had significant errors that would have caused real problems had those ideas been allowed to move forward. \n\nOn the flip side, I have seen an AI chatbot provide business intelligence content that somehow correctly divined a competitor's busines strategy despite no known direct content about it online (something I could only verify with personal prior knowledge). I have also seen AI-based programs significantly speed up repetitious business processes with fewer errors than human inputs previously provided. \n\nThe common thread here is the need for skepticism of results and independent verification of the facts. I worry that as AI gets \"better\", fewer and fewer people will approach results with skepticism, which will lead to lower product quality and worse business decisions as errors in results persist.\n\nFor me the jury is still out on the utility of AI. On one hand, it has some promising potential in specific areas. On the other, I fear it will lead to an overall reduction in critical thinking and could calcify falsehoods in the minds of its users as unchecked errors persist in search results. Lastly, to what degree is all this worth the infrastructure and energy costs?\n\nHonestly, I don't know. \n\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj2lge/using_ai_for_research_is_an_extremely_sharp/",
        "publishDate": "2026-01-21T16:29:51Z[Etc/UTC]",
        "author": "TigranMetz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj2en5",
        "title": "Logic-oriented fuzzy neural networks: A survey",
        "content": "https://www.sciencedirect.com/science/article/pii/S0957417424019870\n\nAbstract: \"Data analysis and their thorough interpretation have posed a substantial challenge in the era of big data due to increasingly complex data structures and their sheer volumes. The black-box nature of neural networks may omit important information about why certain predictions have been made which makes it difficult to ground the reliability of a prediction despite tremendous successes of machine learning models. Therefore, the need for reliable decision-making processes stresses the significance of interpretable models that eliminate uncertainty, supporting explainability while maintaining high generalization capabilities. Logic-oriented fuzzy neural networks are capable to cope with a fundamental challenge of fuzzy system modeling. They strike a sound balance between accuracy and interpretability because of the underlying features of the network components and their logic-oriented characteristics. \n\nIn this survey, we conduct a comprehensive review of logic-oriented fuzzy neural networks with a special attention being directed to AND\\\\OR architecture. The architectures under review have shown promising results, as reported in the literature, especially when extracting useful knowledge through building experimentally justifiable models. Those models show balance between accuracy and interpretability because of the prefect integration between the merits of neural networks and fuzzy logic which has led to reliable decision-making processes. The survey discusses logic-oriented networks from different perspectives and mainly focuses on the augmentation of interpretation through vast array of learning abilities. This work is significantly important due to the lack to similar survey in the literature that discusses this particular architecture in depth. Finally, we stress that the architecture could offer a novel promising processing environment if they are integrated with other fuzzy tools which we have discussed thoroughly in this paper.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj2en5/logicoriented_fuzzy_neural_networks_a_survey/",
        "publishDate": "2026-01-21T16:22:55Z[Etc/UTC]",
        "author": "nickpsecurity",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj2bmd",
        "title": "AI won't replace a single person",
        "content": "There's lots of narrative around: be careful or AI will replace you. \n\nAnd yes, short-term people will lose their jobs and left with existential dread. Their skills will be made to feel redundant. Careers ruined. I'm not denying anyone's experience.\n\nAs far as replacing you long-term:\n\nIt won't.\n\nIt's pure projection.\n\nWe have long found out what it is that AI can simulate and imitate in a way that seems to surpass human intelligence and what it can't do, even if we create artificial neurons.\n\nWhat it's really done: It has shown us what unique human intelligence actually is. It's not an accumulation of knowledge. It's not connecting things in novel ways that seem impressive or interesting. It's not making art in a technical sense.\n\nThe invariant left is the lived human experience, that ties meaning to everything we do. That leaves a trace of our own unique human experience in everything we create. That others pick up on and love and relate to.\n\nYou once loved math but now AI does it better and faster?\n\nYour love for math was never about the technical process of solving equations or proving formally.\n\nIt was about continuing and sharing in something that people have started creating centuries ago. About seeing  some kind of unique perspectives, pain, pride or inspiration in it that felt real to you and your experience.\n\nYour love for composing was never about finding a way to engineer sounds in a way that's techniquely perfect or novel. It was about pouring your heart into something.\n\nAbout sharing a part of you that people can pick up on.\n\nAI has beautifully proved one thing:\n\nOur worth was never tied to our aqquiered skills, it was always innate.\n\nThe reason you're still being sold this narrative that you'll be replaced, is fear and denial by people in power.\n\nBecause admission leaves everything that was designed only for personal gain, control or status utterly worthless. Because AI can do it better and faster.\n\nIt leaves worth where people are showing actual care and humanity.\n\nThis is why the 1% is building bunkers. Not because we're all going down in some apocalypse, but because they know their time to control narrative is over and they ironically caused it themselves.\n\nI'll give it 1-5 years max for cognitive dissonance to hit too heart.\n\nLove you all.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj2bmd/ai_wont_replace_a_single_person/",
        "publishDate": "2026-01-21T16:19:45Z[Etc/UTC]",
        "author": "spider_in_jerusalem",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "37",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj2651",
        "title": "Em Dash Discussion",
        "content": "I‚Äôve notified a trend here where all posts and comments that use em dashes are immediately disliked and downvoted. Most posts have comments accusing them of using AI, and then the OP defends themselves saying they didn‚Äôt. \n\nI fully understand downvoting clear ChatGPT \\*\\*slop\\*\\* with dozens of emojis, bullets, and no in depth analysis. \n\nBut we are in r/Artificialintelligence - and AI can be a useful tool to improve the clarity and brevity of your thoughts. \n\nOriginally, my hope was that using an LLM to improve your own writing would one day be viewed like spellcheck - an expected and useful tool to improve your clarity/brevity. But lately I‚Äôve been wondering if it‚Äôs best to just avoid it all together, as authenticity seems to be what the community rewards. \n\nHow much AI is ‚Äútoo much AI‚Äù for you?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj2651/em_dash_discussion/",
        "publishDate": "2026-01-21T16:14:25Z[Etc/UTC]",
        "author": "Capital_Ad_1041",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "59",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj1vkk",
        "title": "Context Rot: Why AI agents degrade after 50 interactions",
        "content": "Tracked 847 agent runs. Found performance doesn't degrade linearly‚Äîthere's a cliff around 60% context fill.\n\nThe fix is not better prompting. It's state management. Built an open-source layer that treats context like Git treats code: automatic versioning, branching, rollback.\n\nWorks with any LLM framework. MIT licensed. \n\n[https://github.com/ultracontext/ultracontext-node](https://github.com/ultracontext/ultracontext-node)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj1vkk/context_rot_why_ai_agents_degrade_after_50/",
        "publishDate": "2026-01-21T16:04:04Z[Etc/UTC]",
        "author": "Main_Payment_6430",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "44",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj1rle",
        "title": "New Use for AI - RPG Playing",
        "content": "I'm sure someone else has discovered this as well as I have but one of the most fun things I've had using AI for is literally having it be a DM for an RPG that I am playing by myself.  I am a DM that runs D&D games for my friends.  Some of them are set in Faerun, some in Middle Earth.  I am thinking about running a sci-fi campaign using Stars Without Number (a different RPG) so to test it out I had Claude help me put together a character, read the rules and then run a game with just me.\n\nIt's super fun.  My first mission was to deliver a package to black market salesperson who tried to have me killed even before I was able to deliver the package. I managed to kill the two assassins take their weapons and then I made the black salesperson pay me extra for the trouble. Now I am trying to do a more lucrative Dunn package delivery mission but I watched and tracked and I keep having to try to break surveillance to be able to get anything done.  It's pretty cool.  I recommend it.\n\nYou could easily do it with Dungeons and Dragons and you wouldn't need any other players to help you play as Claude or Gemini or whoever can run any helpers as NPCs.  \n\nSo if you've ever had an interest in trying out an RPG and were two embarrassed or uncertain to try it, you can try it this way!  Even if you are an RPG veteran, this can be a great way to play alone if you are jonesing for an RPG fix!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj1rle/new_use_for_ai_rpg_playing/",
        "publishDate": "2026-01-21T16:00:14Z[Etc/UTC]",
        "author": "neepster44",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj12ia",
        "title": "Analysing tool for unfair discussion tricks: https://polemic-detector.vercel.app/",
        "content": "Maybe a nice tool to clearify discussions with more rhethoric fighting than constructiveness.\n\nTry this example:  \n  \n**Anna:** *\"Raising the CO‚ÇÇ tax is economically irresponsible. The government‚Äôs own impact assessment shows it will disproportionately burden low-income households, yet they claim it‚Äôs ‚Äòfair.‚Äô If this were truly about the environment, they‚Äôd target industrial emitters first‚Äînot private citizens.\"*\n\n**Bernd:** *\"Your argument ignores the fact that industrial regulations are already in place. The tax is designed to incentivize behavioral change, which is necessary when 40% of emissions come from transportation. Dismissing it as ‚Äòunfair‚Äô without proposing an alternative is just obstructionism.\"*\n\n**Anna:** *\"An alternative? How about enforcing existing laws on corporate polluters instead of creating new taxes? The EU‚Äôs own data proves that 70% of emissions come from industry, yet you focus on individuals. That‚Äôs not policy‚Äîthat‚Äôs ideological grandstanding.\"*\n\n**Bernd:** *\"You‚Äôre cherry-picking statistics. The 70% figure includes energy production, which is already regulated. Transportation emissions, however, are rising. Your ‚Äòalternative‚Äô is a red herring‚Äîit avoids the reality that individual behavior must change, too.\"*",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj12ia/analysing_tool_for_unfair_discussion_tricks/",
        "publishDate": "2026-01-21T15:34:58Z[Etc/UTC]",
        "author": "TheEdelHose",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj0z17",
        "title": "Synthetic influencer personas are becoming feasible with recent generative developments",
        "content": "One of the more unusual directions in recent generative media development is the emergence of ‚Äúsynthetic influencer‚Äù systems. A new implementation allows persona construction (appearance + motion + micro-expressions) and outputs short video clips. Characters do not need to resemble humans, which broadens the design space beyond imitation toward synthetic identity.\n\nFrom an AI perspective, this raises interesting questions about mediated presence, creator economies, and whether synthetic identity becomes a standalone media category similar to VTubing or digital avatars.\n\nNot posting this as promotion ‚Äî I‚Äôm more interested in the implications for identity, labor, and media ecosystems as generative models become more capable.\n\nLink in the first comment to avoid formatting issues.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj0z17/synthetic_influencer_personas_are_becoming/",
        "publishDate": "2026-01-21T15:31:28Z[Etc/UTC]",
        "author": "BholaCoder",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj04y6",
        "title": "Most people celebrating AI layoffs haven‚Äôt stopped to ask the obvious:\nIf humans lose jobs,\nhow do AI-driven businesses survive without customers?",
        "content": "AI can generate content. But AI doesn‚Äôt buy phones, apps, SaaS, media, or games. Humans do.\n\nNo income = no ecosystem.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qj04y6/most_people_celebrating_ai_layoffs_havent_stopped/",
        "publishDate": "2026-01-21T15:00:22Z[Etc/UTC]",
        "author": "Odd_Pirate_6055",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "213",
            "commentCount": "329",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjs7mh",
        "title": "Please help me fix the color contrast on VScode>Codex extension",
        "content": "https://preview.redd.it/wm3m4j9iyveg1.png?width=822&format=png&auto=webp&s=a632144fec3490c7da50ce2d0464a1d8740598d4\n\nI cannot figure out how to change the colors of the code diff, it was working fine before and after opening it today it looks like this.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qjs7mh/please_help_me_fix_the_color_contrast_on/",
        "publishDate": "2026-01-22T11:34:23Z[Etc/UTC]",
        "author": "kamotecutiee",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj2e4a",
        "title": "An underrated way to turn AI code into real AI agents",
        "content": "I am from team behind MuleRun, and I‚Äôve seen how most people use AI¬† for coding.\n\nA common pattern I observed is, you write a script, automate something, maybe prototype an idea, it works once, you tweak the prompt a few times, and then it never really becomes reusable. Turning that into a proper agent usually means writing a framework or stitching tools together.\n\nThat gap is exactly why we built the MuleRun Agent Builder.\n\nThe idea is simple. Instead of writing a full agent system, you describe what you want in prompt and build an agent by combining skills. Those skills form a workflow, so the agent behaves consistently instead of acting like a single prompt. Everything runs in the cloud.\n\nWhat we designed it for:\n\n* People already using Claude for coding\n* Building agents without writing an agent framework\n* Creating agents that can be reused and published\n* Letting builders earn from agents they publish\n\nThe Agent Builder is currently in beta. We‚Äôre opening it up to builders who want to experiment, break things, and give feedback. Beta testers get credits added to their account so they can actually build and test agents, and we‚Äôre rewarding strong published agents during the beta period.\n\nNnot here to hard sell anything. Just sharing what we‚Äôre building because this subreddit already understands the problem space well. Happy to answer questions about how it works or where it fits compared to existing setups",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qj2e4a/an_underrated_way_to_turn_ai_code_into_real_ai/",
        "publishDate": "2026-01-21T16:22:20Z[Etc/UTC]",
        "author": "Civil_Practice_7172",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "22",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjrtvb",
        "title": "90% of Salesforce‚Äôs Engineers Use Cursor Every Day",
        "content": "[No content]",
        "url": "https://analyticsindiamag.com/ai-news-updates/90-of-salesforces-engineers-use-cursor-every-day/",
        "publishDate": "2026-01-22T11:12:20Z[Etc/UTC]",
        "author": "Ok-Elevator5091",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjm7qi",
        "title": "One-Minute Daily AI News 1/21/2026",
        "content": "1. Using AI for advice or other personal reasons is linked to depression and anxiety.\\[1\\]\n2. **Apple**¬†is turning Siri into an AI bot that‚Äôs more like ChatGPT.\\[2\\]\n3. **Amazon One**¬†Medical introduces agentic Health AI assistant for simpler, personalized, and more actionable health care.\\[3\\]\n4. **Todoist‚Äôs**¬†app now lets you add tasks to your to-do list by speaking to its AI.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.nbcnews.com/health/mental-health/ai-chatbots-personal-support-linked-depression-anxiety-study-rcna255036](https://www.nbcnews.com/health/mental-health/ai-chatbots-personal-support-linked-depression-anxiety-study-rcna255036)\n\n\\[2\\] [https://www.theverge.com/news/865172/apple-siri-ai-chatbot-chatgpt](https://www.theverge.com/news/865172/apple-siri-ai-chatbot-chatgpt)\n\n\\[3\\] [https://www.aboutamazon.com/news/retail/one-medical-ai-health-assistant](https://www.aboutamazon.com/news/retail/one-medical-ai-health-assistant)\n\n\\[4\\] [https://techcrunch.com/2026/01/21/todoists-app-now-lets-you-add-tasks-to-your-to-do-list-by-speaking-to-its-ai/](https://techcrunch.com/2026/01/21/todoists-app-now-lets-you-add-tasks-to-your-to-do-list-by-speaking-to-its-ai/)",
        "url": "https://www.reddit.com/r/artificial/comments/1qjm7qi/oneminute_daily_ai_news_1212026/",
        "publishDate": "2026-01-22T05:39:13Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjk1us",
        "title": "Job Applicants Sue A.I. Recruitment Tool Company.  A recently filed lawsuit claims the ratings assigned by A.I. screening software are similar to those of a credit agency and should be subject to the same laws.",
        "content": "[No content]",
        "url": "https://www.nytimes.com/2026/01/21/business/ai-hiring-tools-lawsuit-eightfold-fcra.html?unlocked_article_code=1.GFA.9XQK.n_nH_2Z3omQR",
        "publishDate": "2026-01-22T03:52:58Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "76",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjj6e5",
        "title": "Apple Developing AI Wearable Device: Features, Rumors, and Launch Timeline",
        "content": "[No content]",
        "url": "https://techputs.com/apple-ai-wearable-device-rumors/",
        "publishDate": "2026-01-22T03:12:46Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjgmic",
        "title": "Microsoft launches new AI model for real-world robotic learning",
        "content": "\"Microsoft has introduced a new artificial intelligence model aimed at pushing robots beyond controlled factory environments. The system, called Rho-alpha, targets one of robotics‚Äô long-standing limitations: the inability to adapt to unpredictable, real-world settings.\n\nDeveloped by Microsoft Research, Rho-alpha is the company‚Äôs first robotics-focused model derived from its Phi vision-language AI family.\n\nMicrosoft describes it as part of a broader shift toward physical AI, where intelligent agents interact directly with the physical world rather than operating only in digital spaces.\n\nUnlike traditional industrial robots, Rho-alpha does not rely on rigid task scripts. The model translates natural language instructions into control signals for robots performing complex two-handed manipulation tasks.\"",
        "url": "https://interestingengineering.com/ai-robotics/microsoft-rho-alpha-robotics-ai-model",
        "publishDate": "2026-01-22T01:19:00Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjfapw",
        "title": "Human Intelligence, AI, and the Problem I Think We're Missing",
        "content": "I can vividly remember teaching my AP English class in 1999 when I first heard of ‚ÄúTurnitin.com‚Äù; my first thought was ‚Äúhow am I going to scan all of these pages into that thing?‚Äù Back then I graded papers on a first pass with my trusty No. 2 Dixon Ticonderoga pencil. Now what was I going to do?\n\nFor years I used my pencil as a key aid in the writing process with my students. It was collaborative because we worked together ‚Äì I would suggest ideas an reframe sentences and thoughts to model writing in line with whatever rubric my assignment called for. Often times students adopted my suggestions whole-cloth, other times we would workshop different stylistic choices. My students and I shared in the rhetorical process. If they chose to use my margin note ‚Äútry something like this,‚Äù are they not able to claim ownership because the original words were mine and not theirs?\n\nI was the human intelligence that helped guide my students. They took my advice and incorporated it often. Other times they vehemently opposed my suggestions. I was their personal ChatGPT and I enjoyed that work immensely. But it was often brief and temporal, because I only had so much time to visit individually with 75 students. Can we really now castigate a tool that students can have beside them during every moment of their learning journey?\n\nThe ethical dilemma is this: students could accept, reject, argue with, or ignore me. Today, institutions now assume AI outputs are automatically suspect while often students see them as automatically authoritative. Agency is the key issue. When I suggested phrasing, students exercised their agency to decide whether to adopt or reject my suggestions. My authority was negotiable and if they accepted my suggestions, even verbatim, authorship was never in question.\n\nStudents are struggling today with teachers making them think AI is a ‚Äúforbidden oracle,‚Äù whereas teachers are also short-sighted in thinking Turnitin is an infallible detector. The problem is in both cases human judgment is being ‚Äúoutsourced.‚Äù In 1999, I trusted my students negotiate my (human) guidance; now we pretend that same negotiation between students and AI itself is the problem. What mattered was not that I was always right; but that my authority was provisional.\n\nFast forward almost 30 years and now we not only have a tool for students to generate a decent five-paragraph essay, but a second tool that claims it can detect the use of the first. And that tool is the same one I struggled to understand in 1999: Turnitin. Although this time Turnitin is losing the battle against this newer tool, and students all over academia are suffering from that loss.\n\nAcademia now is forced to embrace a structure that rewards certainty over caution. Boom: you get the AI-cheating accusation era. We‚Äôre living in a time where a student can be treated like they robbed a bank because a dashboard lit up yellow. Is this how math teachers felt about calculators when they first entered the scene? Can you today imagine any high-level mathematics course that didn‚Äôt somehow incorporate this tool? Is ChatGPT the ‚Äúwriting calculator‚Äù that in decades will sit beside every student in an English class along with that No. 2 Dixon Ticonderoga? Or will pencils continue to suffer a slow extinction?\n\nI‚Äôm not writing this because I think academic dishonesty is cute. Students absolutely can use AI to outsource thinking, and pretending otherwise is na√Øve. I‚Äôm writing this because the process of accusing students is an ethical problem now. It‚Äôs not just ‚ÄúAre people cheating?‚Äù It‚Äôs ‚ÄúWhat evidence counts, who bears the burden, and how much harm are we willing to cause to catch some portion of cases?‚Äù When a school leans on AI detectors as objective arbiters, the ethics get ugly fast: false positives, biased outcomes, coerced confessions, and a general atmosphere of suspicion that corrodes learning.\n\nI believe it is ethically wrong to treat AI-detection scores as dispositive evidence of misconduct; accusations should require due process and corroborating evidence. current detectors are error-prone and easy to game, and the harms of false accusations are severe. If institutions want integrity, they should design integrity‚Äîthrough assessment design, and clear AI-use policies, not outsource judgment to probabilistic software and call it ‚Äúaccountability.‚Äù MIT‚Äôs teaching-and-learning guidance says this bluntly: AI detection has high error rates and can lead to false accusations; educators should focus on policy clarity and assessment design instead of policing with detectors. (MIT Sloan Teaching & Learning Technologies).\n\nTony J. D'Orazio  \n\nLiberty University  \n\nMA in Composition--AI Integrated Writing  \n\nExpected 2027",
        "url": "https://www.reddit.com/r/artificial/comments/1qjfapw/human_intelligence_ai_and_the_problem_i_think/",
        "publishDate": "2026-01-22T00:21:48Z[Etc/UTC]",
        "author": "tony_24601",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "10",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qje5fg",
        "title": "In Davos, Demis Hassabis says AGI arrives in five years",
        "content": "Demis Hassabis at Davos 2026, some key takeaways:\n\n‚Üí 50% probability of AGI by 2030\n\n‚Üí DeepSeek panic was overblown; China \\~6 months behind\n\n‚Üí \"Jagged intelligence\": brilliant at some things, catastrophically bad at others\n\n‚Üí Robotics breakthrough in 18-24 months\n\n‚Üí Pushes back on Amodei's 50% job displacement\n\n‚Üí Calls Musk's Singularity claim \"premature\"",
        "url": "https://jpcaparas.medium.com/in-davos-demis-hassabis-says-agi-arrives-in-five-years-255458898ea1?sk=27f2d09fb2e1e87b04b9b1aa55643aba",
        "publishDate": "2026-01-21T23:34:45Z[Etc/UTC]",
        "author": "jpcaparas",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjcefb",
        "title": "AMD ROCm 7.2 now released with more Radeon graphics cards supported, ROCm Optiq introduced",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/AMD-ROCm-7.2-Released",
        "publishDate": "2026-01-21T22:25:59Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj91oh",
        "title": "What are the top 5 safe, high-paying jobs that AI is unlikely to replace over the next few decades?",
        "content": "As AI continues to automate routine and analytical tasks, many roles will evolve or disappear. This raises an important question about which careers can offer long-term security, meaningful work, and strong earning potential in an AI-driven world",
        "url": "https://www.reddit.com/r/artificial/comments/1qj91oh/what_are_the_top_5_safe_highpaying_jobs_that_ai/",
        "publishDate": "2026-01-21T20:21:15Z[Etc/UTC]",
        "author": "Curious_Suchit",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "54",
            "commentCount": "139",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj7v38",
        "title": "Wikipedia formalizes paid agreements with AI companies for the use of its data",
        "content": "The Wikimedia Foundation announced new partnerships with major artificial intelligence companies for the structured use of Wikipedia data, as part of the project's 25th anniversary.\n\nThese agreements are channeled through Wikimedia Enterprise, a commercial product that provides legal, documented, and large-scale access to the content of Wikipedia and other Wikimedia projects, particularly relevant for training AI models and performing quality assurance.",
        "url": "https://www.reddit.com/r/artificial/comments/1qj7v38/wikipedia_formalizes_paid_agreements_with_ai/",
        "publishDate": "2026-01-21T19:37:44Z[Etc/UTC]",
        "author": "Marketingdoctors",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj7ho7",
        "title": "Has Gemini surpassed ChatGPT? We put the AI models to the test.",
        "content": "[No content]",
        "url": "https://arstechnica.com/features/2026/01/has-gemini-surpassed-chatgpt-we-put-the-ai-models-to-the-test/",
        "publishDate": "2026-01-21T19:24:12Z[Etc/UTC]",
        "author": "NISMO1968",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj7aqd",
        "title": "Built Function AI Agents for Salesforce - LLM orchestrates multi-step workflows with HITL approvals, error recovery, and intelligent filtering",
        "content": "I finished recording a demo of¬†\"Function AI Agents\" running natively¬†on Salesforce. The core idea: instead of hard-coded flows, you give an LLM natural language¬†instructions + a set of tools (capabilities), and it orchestrates the entire workflow¬†- deciding what to call, when, and with what parameters.\n\nFYI: This is already an open source project, Licensed under [**Mozilla Public License 2.0**](https://github.com/iamsonal/aiAgentStudio/blob/main/LICENSE) (MPL-2.0)\n\nWhat¬†it does:\n\n* Human-in-the-Loop Approvals¬†- The LLM decides when approval¬†is needed (e.g.,¬†\"accounts over $50M require approval\"), generates business reasoning, pauses execution, and resumes based on approval/rejection. No hard-coded approval rules.\n* Intelligent Filtering¬†- Agent scores an account at 40/100, sees it's below the¬†50 threshold, immediately stops. No¬†wasted API calls.\n* Error¬†Recovery¬†- Tool fails at step¬†5 of 10? Fix the¬†issue and resume from step 5. Doesn't restart from scratch.\n* Cost Efficiency¬†- The entire¬†demo runs on GPT-4o¬†Mini (the laziest, cheapest¬†model) for under a cent per execution. If that works, flagship models should be bulletproof.\n\nTech¬†Stack:\n\n* Built entirely in¬†Apex (no external servers)\n* Runs natively on Salesforce¬†Platform\n* Works with any LLM provider (OpenAI, Claude, Gemini, etc.)\n* Custom \"Storyboard\" component for full observability - every LLM request, tool call, and decision is logged and visualized\n\nLinks:\n\n* Demo Video: [https://www.youtube.com/watch?v=-y9qDDPal0U](https://www.youtube.com/watch?v=-y9qDDPal0U)\n* Docs: [https://iamsonal.github.io/aiAgentStudio/](https://iamsonal.github.io/aiAgentStudio/)\n* Source Code: [https://github.com/iamsonal/aiAgentStudio](https://github.com/iamsonal/aiAgentStudio)\n\nHappy to¬†answer questions.\n\n*Original post:* [*https://www.linkedin.com/posts/thesonal\\_function-agents-in-salesforce-ai-that-makes-share-7419765729903722496-bcbA*](https://www.linkedin.com/posts/thesonal_function-agents-in-salesforce-ai-that-makes-share-7419765729903722496-bcbA)",
        "url": "https://www.reddit.com/r/artificial/comments/1qj7aqd/built_function_ai_agents_for_salesforce_llm/",
        "publishDate": "2026-01-21T19:17:04Z[Etc/UTC]",
        "author": "EarOdd5244",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj4vi8",
        "title": "Liza Minnelli is among the artists who collaborated on a new AI-generated album",
        "content": "[No content]",
        "url": "https://www.nbcnews.com/tech/tech-news/elevenlabs-releases-ai-album-spotify-rcna255098",
        "publishDate": "2026-01-21T17:51:32Z[Etc/UTC]",
        "author": "nbcnews",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj3e0z",
        "title": "google gemini3 absolutely SMOKES qwen3 coder",
        "content": "i installed qwen3 coder 30b locally and i am running it as an agent using my own llm controller,and i am running gemini 3 from google antigravity.\n\ni asked both to complete a set of tasks.\n\n1-create a game of tic tac toe\n\n2-create a game website as a prop\n\n3-create a blue background with a rotating cube.\n\n4-Write an HTML file with CSS that creates a fully responsive three-column layout. It must collapse to a single column on screens under 600px. Do not use any frameworks.\n\n5-Write an HTML file that generates a procedural, animated starfield background using the <canvas> element. The stars should move at different speeds to simulate parallax depth. Include a toggle that switches between ‚Äúwarp speed‚Äù and normal mode.\n\nfirst task was a complete flop,qwen3 was incapable of correctly making a tic tac toe game.\n\nsecond task was a disaster, the first time i asked it completely crashed the llm, upon reloading and asking it again,it was able to finish the job,but its result was far behind gemini 3 in terms of quality.\n\nthird task it completed the request, but gemini 3 still edged it out in terms of visuals.\n\nfourth task was almost the same,but gemini added a black title background,so it edged it out\n\nfifth task was the same as the second task,it crashed qwen3. upon reloading and reprompting,it uh..certainly made a file?... its not very good tbh.\n\n(link to pictures of the outcomes)\n\n[https://imgur.com/a/SHnMLdP](https://imgur.com/a/SHnMLdP)\n\nin all tasks,gemini absolutely smoked qwen3 coder and its not even close,im looking forward to having better locally run LLM's,because at the very least,qwen 3 is NOT good and i would NOT trust it for anything.\n\nwould you guys have any recommendations for a locally run llm that is better than qwen3 that i could test? i can compare suggestions to gemini 3\n\n  \n(as a sidebit,i had asked qwen3 to make a calculator with a gui,it made the gui wrong and made 1+1=3)",
        "url": "https://www.reddit.com/r/artificial/comments/1qj3e0z/google_gemini3_absolutely_smokes_qwen3_coder/",
        "publishDate": "2026-01-21T16:58:27Z[Etc/UTC]",
        "author": "darthvadersahoe",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "10",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj2dzo",
        "title": "Logic-oriented fuzzy neural networks: A survey",
        "content": "https://www.sciencedirect.com/science/article/pii/S0957417424019870\n\nAbstract: \"Data analysis and their thorough interpretation have posed a substantial challenge in the era of big data due to increasingly complex data structures and their sheer volumes. The black-box nature of neural networks may omit important information about why certain predictions have been made which makes it difficult to ground the reliability of a prediction despite tremendous successes of machine learning models. Therefore, the need for reliable decision-making processes stresses the significance of interpretable models that eliminate uncertainty, supporting explainability while maintaining high generalization capabilities. Logic-oriented fuzzy neural networks are capable to cope with a fundamental challenge of fuzzy system modeling. They strike a sound balance between accuracy and interpretability because of the underlying features of the network components and their logic-oriented characteristics. \n\nIn this survey, we conduct a comprehensive review of logic-oriented fuzzy neural networks with a special attention being directed to AND\\\\OR architecture. The architectures under review have shown promising results, as reported in the literature, especially when extracting useful knowledge through building experimentally justifiable models. Those models show balance between accuracy and interpretability because of the prefect integration between the merits of neural networks and fuzzy logic which has led to reliable decision-making processes. The survey discusses logic-oriented networks from different perspectives and mainly focuses on the augmentation of interpretation through vast array of learning abilities. This work is significantly important due to the lack to similar survey in the literature that discusses this particular architecture in depth. Finally, we stress that the architecture could offer a novel promising processing environment if they are integrated with other fuzzy tools which we have discussed thoroughly in this paper.\"",
        "url": "https://www.reddit.com/r/artificial/comments/1qj2dzo/logicoriented_fuzzy_neural_networks_a_survey/",
        "publishDate": "2026-01-21T16:22:12Z[Etc/UTC]",
        "author": "nickpsecurity",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qj0vze",
        "title": "my artificial intelligence were too normal",
        "content": "too few disturbances are also a sign of goings on sometimes, though one must always be on the rookout for enemies",
        "url": "https://www.reddit.com/r/artificial/comments/1qj0vze/my_artificial_intelligence_were_too_normal/",
        "publishDate": "2026-01-21T15:28:33Z[Etc/UTC]",
        "author": "Ok_Scheme_3951",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qixs5n",
        "title": "Nvidia CEO says AI needs more investment in defiance of bubble fears",
        "content": "Speaking at the World Economic Forum in Davos, Switzerland, Huang described AI as a five-layer cake consisting of energy, chips, cloud infrastructure, models and application. He said AI‚Äôs application‚Äìhow the technology is used in a specific industry‚Äìis the most critical layer of that cake as it is where the economic benefits lie.",
        "url": "https://www.wsj.com/tech/ai/nvidia-ceo-says-ai-needs-more-investment-in-defiance-of-bubble-fears-9dabba63?st=toGic4&reflink=desktopwebshare_permalink",
        "publishDate": "2026-01-21T13:23:58Z[Etc/UTC]",
        "author": "tekz",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "55",
            "commentCount": "39",
            "isNsfw": "false"
        }
    },
    {
        "id": "FwRLdDyssso",
        "title": "Opus 4.5 + GPT-5.2 Codex: YOU NEED THIS SETUP NOW! This CHANGES HOW YOU CODE.",
        "content": "In this video, I'll be telling you about a highly efficient workflow using Kilo Code where we combine Claude Opus 4.5 for building ...",
        "url": "https://www.youtube.com/watch?v=FwRLdDyssso",
        "publishDate": "2026-01-21T09:15:00Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/FwRLdDyssso/hqdefault.jpg",
            "transcription": "[00:00] (Panda cutting wood with a sword)\n[00:05] Hi. Welcome to another video.\n[00:08] So, let me tell you about a workflow that I've been using that just makes so much sense.\n[00:13] Use Opus 4.5 or Sonnet 4.5 in Kilo Code for actually building and doing tasks.\n[00:21] But then use GPT-5.2 Codex for reviewing the code.\n[00:28] And the reason this works so well is that these models have completely different strengths.\n[00:33] Claude's models are amazing at writing code, understanding context, and executing complex tasks.\n[00:41] But when it comes to reviewing code and finding subtle bugs, security issues, and edge cases,\n[00:50] GPT-5.2 Codex is just on another level.\n[00:55] It's extremely detail-specific and can run for long periods on large repositories without losing focus.\n[01:04] That's exactly what you want in a code reviewer.\n[01:06] Now, you might be thinking, \"But what about Code Rabbit or Greptile for code reviews?\"\n[01:10] And look, those tools are fine, but here's the thing.\n[01:15] Both of them are largely based on Claude's Agent SDK and Opus under the hood.\n[01:21] Which makes them not very good for this specific task of deep code review.\n[01:29] It's like using the same brain to write and review your own work.\n[01:32] You want a different perspective. Plus, and this is the big one, none of them are really customizable.\n[01:39] You're stuck with whatever defaults they give you.\n[01:42] And that's where Kilo Code's Code Reviews feature really shines.\n[01:47] So, let's talk about what makes Kilo Code's approach different.\n[01:50] First, you can pick from over 500 AI models.\n[01:55] That's not a typo, 500 models.\n[01:59] So you can use GPT-5.2 Codex, which according to Kilo's own benchmarks, is absolutely crushing it for code reviews.\n[02:08] In their testing, it completed reviews in about three minutes and found 13 issues total, which was more than any other model they tested.\n[02:18] It was the only model to catch an authorization bypass in task duplication, where users could create tasks in other accounts.\n[02:29] That's a critical security bug that the other models missed entirely.\n[02:32] Now, let me show you how to set this up.\n[02:35] You go to your Kilo dashboard and find the Review Agent section.\n[02:40] This can be in your personal dashboard or your organization dashboard if you're working with a team.\n[02:47] First, you toggle the switch to enable automatic PR reviews.\n[02:52] Then, you select your AI model.\n[02:56] I'd recommend GPT-5.2 Codex for the reasons I mentioned.\n[03:00] It found two critical issues that every other model missed, including a synchronous file write operation that was blocking the node.js event loop and a task search endpoint that was returning all system tasks instead of just user-specific data.\n[03:19] That's the kind of detail you want in code review. Next, you set your review style.\n[03:24] There are three options: Strict, Balanced, and Lenient.\n[03:30] Strict mode flags all potential issues and prioritizes correctness and security.\n[03:36] This is what you want for mission-critical code, production deployments, anything where bugs could really hurt you.\n[03:44] Balanced mode is the most popular option.\n[03:48] It surfaces important findings without being too noisy and prioritizes practicality.\n[03:54] This is probably what you want for day-to-day development.\n[03:59] Lenient mode only flags critical bugs and security issues and uses an encouraging tone.\n[04:05] This is great for work-in-progress reviews or prototypes where you don't want the AI nitpicking every little thing.\n[04:12] Then you choose which repositories it can access.\n[04:16] You can select specific repos instead of giving it access to everything, which is nice for security.\n[04:23] Now, here's where the customization really kicks in.\n[04:27] You can define focus areas.\n[04:30] The agent can concentrate on specific things like security vulnerabilities, which includes SQL injection, XSS, and credential exposure.\n[04:41] It can focus on performance issues like N+1 queries and inefficient loops, bug detection for logic errors and edge cases, code style for formatting and naming conventions, test coverage gaps, and documentation deficiencies.\n[05:01] So, if your team is particularly concerned about security, you can tell it to prioritize that.\n[05:07] If you're working on a performance-critical application, focus on that.\n[05:10] You're not stuck with one-size-fits-all defaults.\n[05:14] You can also set a maximum review time anywhere from 5 to 30 minutes.\n[05:20] For GPT-5.2, the three-minute average is actually quite reasonable for thorough reviews.\n[05:27] But if you're doing high velocity CI/CD, you might want to keep it shorter.\n[05:33] And here's what I really like: you can add custom instructions.\n[05:37] So you can tell it things like, \"Our codebase uses a specific authentication pattern\" or \"We're migrating from X to Y, so flag any usage of the old pattern.\"\n[05:49] That level of control is just not available in Code Rabbit or Greptile.\n[05:55] Now, let me show you what happens when you actually open a pull request.\n[06:00] The moment a PR is opened or updated, the agent kicks in automatically.\n[06:07] It reads your diff and analyzes the changes.\n[06:10] Then it posts feedback directly in GitHub.\n[06:13] You get inline comments right on the specific lines of code, summary findings at the top, suggested fixes with actual code examples, and risk/severity tagging, so you know what to prioritize.\n[06:27] It shows up just like any other team reviewer in GitHub's PR interface.\n[06:35] So there's no context switching, no separate tool to check.\n[06:39] It's all right there in your normal workflow.\n[06:42] The agent only analyzes the changed files, not the entire repository, which keeps reviews fast and focused.\n[06:49] But it has enough context to understand how your changes fit into the broader codebase.\n[06:57] Now, one thing to keep in mind.\n[07:00] You need to have GitHub integration configured in the Integrations tab before you can enable this.\n[07:07] But that's a one-time setup.\n[07:09] Currently, the compute and review time are actually free.\n[07:14] So if you've been putting off trying this, now is literally the best time.\n[07:19] The reason I keep going back to this GPT-5.2 point is that Kilo's own benchmarks showed it achieved 100% detection on planted security issues.\n[07:31] Claude Opus 4.5 matched that detection rate, but GPT-5.2 had broader coverage overall.\n[07:41] And Gemini 3 Pro?\n[07:43] It only hit 39% detection and missed authorization checks that even the free models caught.\n[07:49] So, model selection really matters here.\n[07:52] So, my recommendation?\n[07:55] Use Claude for building, use GPT-5.2 for reviewing.\n[08:00] That combination gives you the best of both worlds.\n[08:04] You get Claude's excellent coding abilities for the creative work, and GPT-5.2's obsessive attention to detail for catching what you missed.\n[08:15] And with Kilo Code, you can set all of this up in minutes.\n[08:20] The customization options mean you're not fighting against defaults that don't fit your team's needs.\n[08:27] Overall, it's pretty cool.\n[08:28] Anyway, share your thoughts below and subscribe to the channel.\n[08:31] You can also donate via Super Thanks option or join the channel as well and get some perks.\n[08:36] I'll see you in the next video. Bye.\n[08:38] (Outro music)\n[08:38] (On-screen text: i think you missed this: (Panda video snippet plays again))"
        }
    },
    {
        "id": "fCgIqEdnXW4",
        "title": "How Long Will The Kim Dynasty Last? - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=fCgIqEdnXW4",
        "publishDate": "2026-01-21T18:48:04Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/fCgIqEdnXW4/hqdefault.jpg",
            "transcription": "[ 0m0s363ms - 0m1s73ms ] North Korea could not do-\n[ 0m1s843ms - 0m5s73ms ] you could not even start doing reforms today because as soon as there was some sort of\n[ 0m5s73ms - 0m11s63ms ] information from the outside world that North Koreans could see, which would be part of any reform,\n[ 0m11s63ms - 0m16s133ms ] they would immediately realize that everything the government has told them is false, that South Korea is enormously wealthier, they have this terrible standard of living.\n[ 0m16s333ms - 0m21s633ms ] And in those situations, I guess this goes back to the question of, well, if Kim Jong-un just had a change of heart or if somebody else came into power,\n[ 0m21s633ms - 0m22s13ms ] there's nothing that he could do.\n[ 0m22s13ms - 0m24s813ms ] Oh, he's trapped because he's a dead boy if he if he tries to go on retirement.\n[ 0m24s813ms - 0m33s403ms ] Exactly. In Asia, there's a thought that things last for three generations and then it's over, so he's the third generation.\n[ 0m33s613ms - 0m40s753ms ] Whether this is true or not doesn't matter. If you believe it's true, it will become a self-fulfilling prophecy.\n[ 0m40s753ms - 0m55s233ms ] So I'll be interested, well, I won't probably live to see it, you in the room will, of uh what happens to uh the Kim family, whether it makes it to generation four or not. But by their own belief system, in theory, they shouldn't. So, who knows?"
        }
    },
    {
        "id": "IdV5TEIsJhs",
        "title": "The RL Irony in LLMs",
        "content": "Start learning cyber security with TryHackMe: https://tryhackme.com/bycloud Use my code \"BYCLOUD25\" to get 25% off on annual ...",
        "url": "https://www.youtube.com/watch?v=IdV5TEIsJhs",
        "publishDate": "2026-01-21T14:33:49Z",
        "author": "bycloud",
        "sourceType": "youtube",
        "sourceName": "bycloud YouTube Channel",
        "metadata": {
            "channelId": "UCgfe2ooZD3VJPB6aJAnuQng",
            "thumbnailUrl": "https://i.ytimg.com/vi/IdV5TEIsJhs/hqdefault.jpg",
            "transcription": "In the latest Andre Karpathy interview with Dorkesh Patel, he said that AGI is still a decade away and reinforcement learning is definitely not the key for us to get there. In another interview with Elias Sutskever, he also said roughly the same thing. But with how much the current LLM improvements rely on RL at giving it human level capabilities like browsing your web, coding your app, or even managing a vending machine business, um, I think AGI is canceled, guys. But before we start shorting NVIDIA, what is even wrong with scaling RL? Well, the main issue is just like what Andre Karpathy said. When you train LLMs with RL, there are way too much noises. This is because RL training is performed on an entire sentence, unlike the next token prediction pre-training objective, which provides much more information. You can think of the difference like this. RL is like studying math by doing practice questions, but the answer key only has the final answers. So you have no idea how to arrive at them. Then, your calculation process wouldn't matter. You might be correct about the method, but wrong in your calculation, yet you wouldn't know you made a mistake. On the other hand, when the training objective is next token prediction, it's like having a teacher correcting every step of the way. So the information provided for your learning is much more specific. So why even use RL then? Well, the benefit of not having a teacher watching over your every single move enables something really cool, that is exploration. The model can now optimize for the outcome rather than the specific sequence of tokens used to get there. This allows the model to explore the solution space, attempt different reasoning paths, and learn to self-correct. For instance, the aha moment of DeepSeek where it learned how to self-correct was made possible thanks to RL. Pre-training is able to learn this, but is not capable of bringing this out consistently. So, anything that's also behavioral that we want the LLM to learn, we use RL. And all of these is dirt simple. We would only need to measure based on the outcome. So, as beautiful as it sounds, people believe this may be the way for LLMs to reach AGI. But under the hood, it is definitely a bit uglier. In previous videos, we talked about how RL makes LLMs less diverse, because in the process of training LLM with RL, it actually sharpens the underlying sampling distribution to make LLMs better at performing a task. So, after training, it actually makes the model less generalizable. So, even though RL could unlock incredible performance on complex and long-horizon tasks that pre-training alone couldn't achieve, the method itself is not truly generalizable. In the end, supervised fine-tuning still crawled so that RL could run. If you want to achieve AGI, RL is definitely not the key. But that wouldn't stop some of us from applying RL in every possible use case and creating an AGI that is indistinguishable from actual AGI, right? It just look a bit disgusting. Worst case scenario, it would just be the equivalent of writing every possible if statements for everything we can possibly do in the world. Anyways, even though AGI might not be achieved with RL, practicality-wise, the boost in work efficiency that RL provides might already be good enough. And I guess not everyone has to work towards AGI either. Plus, there's no way we're letting a system this good slip away just because RL is not picture perfect, right? While some researchers are also trying to make RL provide more dense signals using methods like entropy detection to create feedback waypoints, which is something I've talked about before. This time, however, we might be witnessing something that will bring the whole RL pipeline to the next level. It won't make specific benchmarks go crazy, but instead, it will make the jagged AI frontier a lot smoother and more applicable for everyone. This new idea brings incredible speed and compute efficiency. It makes serving personalized LLMs at scale a lot easier than you might think. But before we dive into it, if you have ever wanted to actually try cyber security instead of just watching videos and reading theory, TryHackMe is one of the easiest ways to do it. They are one of the biggest hands-on cyber security training platform out there with millions of learners and everything runs directly in your browser. So, there's no setup, no installs, no trouble debugging a VM without even starting to learn. And the fun part is, you're not just passively learning. You're hacking real machines and doing real scenarios step-by-step like a guided playground where it's encouraged to click things, test things, and even break things because you can always reset the lab. For example, one of their beginner-friendly rooms started you off with a fake banking site. You poke around, you look at how the site is behaving, and then you can run a quick directory scan like this command, which is just basically a way to discover hidden pages a normal user wouldn't see. And you'll start finding endpoints like slash images and then something way more interesting like slash bank-transfer. I'm not going to spoil it, but that is where things get very educational, very fast. And if you want to see what happens next, you should try finishing the room yourself. Beyond that, TryHackMe has guided learning paths that take you from total beginner to more advanced topics. And the labs are based on real attacks and defenses you'd actually see in the industry. Plus, they've got progress tracking, badges, leaderboards, and even an AI tutor called Echo if you get stuck. The free rooms are great to test the waters, but Premium is what unlocks the juice. You get unlimited access to 700+ rooms, exclusive career paths, private servers, and faster machines. Basically, the full go from beginner to job-ready setup. So, if you're interested in learning cyber security, check out TryHackMe with the link down in the description. And if you use the code BYCLOUD25, you can get 25% off the annual plan. And thank you, TryHackMe for sponsoring this video. Last time, we talked about how reinforcement learning with verifiable rewards reliably improves the reasoning performance of LLMs. And surprisingly, it appears to modify only a small fraction of the model's parameters, sometimes updating as little as 5% of the weights. And another more recent research from Meta also supports this idea. In the paper, they concluded that RL attempts to achieve performance gains with minimal changes to the weights, which shows that RL training is extremely targeted as the training can easily traverse the structured optimization landscape and only touches what is necessary. So, with the established fact that RL on LLMs effectively performs small and efficient updates, does something else also ring a bell that's also designed specifically to handle efficient and low capacity updates? If you are thinking about LoRA, we are on the same page. You may remember LoRA from image generation, but it actually originate from LLMs. And for those of you who don't know what LoRA is, we first need to look at what happens during standard fine-tuning. Usually, when you train a model, you are updating a massive matrix of weights. And to learn something new, the model would calculate something called a change matrix and adds it to the original weights. In full fine-tuning, the new matrix is the exact same size as the original model, which could be billions of parameters big. However, researchers discovered that when you want to fine-tune models to adapt to specific tasks, this change matrix doesn't actually need to be that big and complex. LoRA leverages this by refusing to calculate that giant matrix again with bloated information, and instead, it breaks down the update down into two tiny matrices, let's call them A and B. When you multiply them together, they produce a matrix the same size as the giant matrix, but A and B itself actually contain much fewer parameters. So, during training, the original model is frozen completely. It only needs to train these two tiny matrices. When you run the model, the input passes through the frozen weights and the LoRA weights with their outputs sum together. So, in essence, LoRA creates a highly compressed representation of the updates needed for fine-tuning. And since RL inherently makes small and targeted updates, what if we apply RL training directly onto LoRA? Not only will we get the computational benefit of only training Low Rank Matrices, we would also gain the ease of managing the ultra lightweights that LoRA has. But fundamentally, these methods are efficient in different ways. Observing it to only modify a fraction of weights is mathematically different from low-rank adaptation. So, just because they both update a small amount of parameters, doesn't guarantee that they will work well together. This would need to be tested empirically. However, before we even test that, there is a bigger question that needs to be answered. Is LoRA actually equivalent to full fine-tuning? Because if LoRA effectively caps your performance and never matches full fine-tuning, it loses its appeal as an alternative. And there would be less of a point in me making this video, or, I mean, less of a point in using LoRA for RL. Some research has tried to address this, but few have tested it as empirically deep as the recent Thinking Machines blog post, LoRA Without Regret. In their conclusion, they showed that they are equivalent, but only under certain conditions. So, as expected, LoRA would struggle in settings that resemble pre-training due to its small parameter size, as you are effectively stuffing massive amounts of general knowledge into the model where LoRA would run out of space to store the new information. But for post-training on specific subsets of data, it works perfectly. This is because RL in LLMs usually require very low capacity. But why does RL need so much less capacity? Well, it comes down to Information Theory. In supervised fine-tuning like next token prediction, the model gets a signal for every single token it generates, where the model would need to absorb a dense stream of information. On the other hand, RL is completely different. In policy gradient RL like RLVR, the model generates an entire episode, like maybe hundreds of tokens of reasoning, but at the very end, only getting a single scalar reward, one or zero, which is a very sparse signal. The researchers over at Thinking Machines estimated that it effectively provides only about one bit of information per episode. To put that in perspective, the DeepSeek R1-Zero model was trained on 5.3 million episodes, which is around 5.3 million bits of signal. So, compared that to the capacity of a LoRA where a Rank 1 LoRA would have about 3 million parameters, LoRA should have enough capacity to absorb everything RL tries to teach it, even for models as big as DeepSeek R1. And in Thinking Machines experiments, LoRA held up this theory perfectly. When they ran RL on math benchmarks, they observed something incredible. LoRA didn't just keep up with full fine-tuning, it matched it step-for-step. Even when they dropped the LoRA rank all the way down to one, which is the absolute minimum capacity, the RL performance was indistinguishable from training the entire model. The learning curves are just basically the same when overlapped together. But all these would only happen if you stay within the low-regret regime. First is that, in the original LoRA paper, it is recommended to put LoRA only on the attention layers. But in Thinking Machines experiments, they showed that it is a bad idea. Attention-only LoRA significantly underperformed. So, to match full fine-tuning, you must apply LoRA to the MLP and all the MoE layers, if there are any. Second, they found a consistent relationship between the learning rates. The optimal learning rate for LoRA was consistently 10 times higher than the optimal rate for full fine-tuning. So, if you're migrating from a full fine-tuning setup, you can't just copy and paste your hyperparameters. You need to be much more aggressive with your learning rate to get the adapter to move. Third, LoRA turns out to be less tolerant of massive batch sizes compared to full fine-tuning. So, if you push the batch size too high, the optimization dynamics will become weird, and the loss penalty would also increase. But if you take a step back and look at all these constraints, they are not really a downside for RL with LoRA. And overall, it is also computationally cheaper where it only needs two-thirds of the FLOPs compared to full fine-tuning. So, with the title cleverly named LoRA Without Regret, likely a reference to regret bounds, which is the total extra reward you miss out on because you didn't already know which action would turn out the best over the whole run. So, the idea here is that you can choose LoRA over full fine-tuning without regret, as long as you follow their recipe. On top of that, you aren't actually sacrificing performance for the sake of saving memory, which is what people initially used LoRA for. You would get the same result, just faster and cheaper. And this shift is huge. Before this blog even came out, there had already been small-scale research using LoRA not just as a money and memory-saving tool, but as a legitimate way to experiment with RL efficiently. But now, with this blog empirically proving their connections, training LoRA has become the best way to cheaply explore the frontiers of supervised fine-tuning plus reinforcement learning on top of state-of-the-art models. It would actually let researchers iterate incredibly fast without burning through a lot of cash. And beyond research, LoRA would definitely become the standard for personalization. Like imagine the infrastructure benefits. Because LoRA adapters are tiny and modular, they are easily swappable. This easily enables truly personalized LLMs at scale. Another interesting idea is how it can also be a switch for hybrid thinking models. Like a systems thinking reasoning capabilities could actually be embedded in an RL trained LoRA. So, when a user wants to toggle deep thinking on or off, on the back end, the provider would just need to activate the reasoning adapter on demand. With these amazing benefits, of course Thinking Machines also have to make their own move, which is publishing a fine-tuning endpoint called Tinker shortly after this blog was released. Provide the science and sell the shovel. Pretty smart of them. But anyways, this LoRA plus RL combination is becoming the perfect pair to advance the illusion of capabilities of AGI. It is modular, efficient, and easily swappable. And maybe for $19.99 a month, you get a model that feels infinitely capable because it has a specialized adapter for every niche task. What a steal, right? So, if 2025 is the year of AI agents, then 2026 will be the year of performative, personalized agents. So even if RL may not be the key for true generalization, who even needs true AGI when we can just brute force it. If you like how I explained LoRA today, I have actually made a brand new learning website where I wrote an intuitive explanation of LLMs from the ground up, including a section dedicated to the basics of LoRA. This learning material contains the entirety of how LLM works from zero, ranging from how tokenization operates, the basics of attention, to how post-training works. A total of 100,000 words are currently written on the website. And this is the start of a series where I'll break down LLM topics intuitively because I genuinely think anyone could understand LLMs, no matter how difficult it may seem. Just like today's LoRA. With me now being done with the fundamentals, I'll start to include more advanced topics to accompany my future videos in the coming weeks. So for those who want to get into LLMs, this should be the perfect place for you to dive into the technical parts without first being intimidated by crazy looking math. And right now, I am also putting out a New Year New Me discount for 2026. So, you can use the code NYNM for 50% off a yearly plan. And thank you guys for watching. A big shoutout to Spam Maj, Chris Ledoux, Deagan, Robert Zawiasa, Marcelo Ferreira, Poof N' Inu, DX Research Group, Alex, and many others that support me through Patreon or YouTube. Follow me on Twitter if you haven't, and I'll see you in the next one."
        }
    }
]