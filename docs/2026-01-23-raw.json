[
    {
        "id": "https://ai-techpark.com/?p=233889",
        "title": "OpenEvidence Raises $250 Mn to Build Medical Superintelligence for Doctors",
        "content": "<p>OpenEvidence, the most widely-used AI platform by doctors in America, announced today that it closed a Series D round of funding,Â valuing the company at $12 billion. This makes OpenEvidence the most valuable Healthcare AI company in the world. OpenEvidence is a specialized AI-powered medical search engine that serves as a...</p>\n<p>The post <a href=\"https://ai-techpark.com/openevidence-raises-250-mn-to-build-medical-superintelligence-for-doctors/\">OpenEvidence Raises $250 Mn to Build Medical Superintelligence for Doctors</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/openevidence-raises-250-mn-to-build-medical-superintelligence-for-doctors/",
        "publishDate": "2026-01-22T13:10:36Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, AI platform, AI technology News, AItech news, artificial intelligence news, OpenEvidence"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233883",
        "title": "Study: AI Confidence Surges While Readiness Lags on Data Integrity",
        "content": "<p>New research from Precisely and the Center for Applied AI and Business Analytics at Drexel University&#8217;s LeBow College of Business reveals gaps in operational maturity, data trust, and skills as organizations look to scale AI enterprise-wide&#160; Precisely, the global leader in data integrity, today released the findings from its fourth...</p>\n<p>The post <a href=\"https://ai-techpark.com/study-ai-confidence-surges-while-readiness-lags-on-data-integrity/\">Study: AI Confidence Surges While Readiness Lags on Data Integrity</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/study-ai-confidence-surges-while-readiness-lags-on-data-integrity/",
        "publishDate": "2026-01-22T13:06:06Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, AI systems, ai tech news, AI technology News, AItech news, artificial intelligence news, Precisely"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233880",
        "title": "ZeroPoint Technologies Appoints Brett Cline as Chief Executive Officer",
        "content": "<p>ZeroPointÂ Technologies today announced the appointment of Brett Cline as the company&#8217;s CEO. Brett brings more than two decades of executive and go-to-market leadership in advanced semiconductor,Â IP, and electronic design automation (EDA) software, with a track record of helping deep-technology companies translate differentiated innovation into customer adoption and scalable revenue. &#8220;ZeroPoint...</p>\n<p>The post <a href=\"https://ai-techpark.com/zeropoint-technologies-appoints-brett-cline-as-chief-executive-officer/\">ZeroPoint Technologies Appoints Brett Cline as Chief Executive Officer</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/zeropoint-technologies-appoints-brett-cline-as-chief-executive-officer/",
        "publishDate": "2026-01-22T13:04:20Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AI technology News, AItech news, artificial intelligence news, ZeroPoint"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233811",
        "title": "Corespan Systems Launches as the New Identity for Drut Technologies",
        "content": "<p>Drut Technologies, a leader in high-performance compute infrastructure, today announced a rebrand toÂ Corespan Systems. The new name reflects the company&#8217;s broadened mission to accelerate the deployment and scalability of advanced AI and data center systems worldwide. &#8220;The name Corespan Systems captures the essence of what we do, spanning compute cores,...</p>\n<p>The post <a href=\"https://ai-techpark.com/corespan-systems-launches-as-the-new-identity-for-drut-technologies/\">Corespan Systems Launches as the New Identity for Drut Technologies</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/corespan-systems-launches-as-the-new-identity-for-drut-technologies/",
        "publishDate": "2026-01-22T08:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AI technology News, AItech news, artificial intelligence news, Data center, Drut Technologies"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=233784",
        "title": "C5i Launches Enterprise-Grade Platform Agent5i to Scale Business Value",
        "content": "<p>The new enterprise-grade platform establishes a governance-first foundation, empowering businesses to integrate autonomous agents and confidently scale mission-critical workflows securely. AI and analytics company, C5i, today announced the launch of Agent5i, its enterprise-grade platform designed to help organizations confidently operationalize and scale agentic AI across their business. Purpose-built for real-world...</p>\n<p>The post <a href=\"https://ai-techpark.com/c5i-launches-enterprise-grade-platform-agent5i-to-scale-business-value/\">C5i Launches Enterprise-Grade Platform Agent5i to Scale Business Value</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/c5i-launches-enterprise-grade-platform-agent5i-to-scale-business-value/",
        "publishDate": "2026-01-22T07:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, Agent5i, AI news, ai tech news, AI technology News, AItech news, artificial intelligence, artificial intelligence news, C5i"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111668",
        "title": "Controlling AI agent sprawl: The CIOâ€™s guide to governance",
        "content": "<p>Corporate networks are filling up with AI agents, creating a governance blind spot for leaders managing multi-cloud infrastructures. As distinct business units race to adopt generative technologies, CIOs especially find their ecosystems populated by fragmented and unmonitored assets. This mirrors the shadow IT challenges of the cloud era, but involves autonomous actors capable of executing [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/controlling-ai-agent-sprawl-cio-guide-to-governance/\">Controlling AI agent sprawl: The CIOâ€™s guide to governance</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/controlling-ai-agent-sprawl-cio-guide-to-governance/",
        "publishDate": "2026-01-22T17:00:04Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Features, Governance, Regulation & Policy, Inside AI, Opinion, agentic ai, agents, ai, enterprise, governance"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111664",
        "title": "Gates Foundation and OpenAI test AI in African healthcare",
        "content": "<p>Primary healthcare systems across parts of Africa are under growing strain, caught between rising demand, chronic staff shortages, and shrinking international aid budgets. In that context, AI is being tested in healthcare less as a breakthrough technology and more as a way to keep basic services running. According to reporting by Reuters, the Gates Foundation [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/gates-foundation-and-openai-test-ai-in-african-healthcare/\">Gates Foundation and OpenAI test AI in African healthcare</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/gates-foundation-and-openai-test-ai-in-african-healthcare/",
        "publishDate": "2026-01-22T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Government & Public Sector AI, Healthcare & Wellness AI, Human-AI Relationships, World of Work, ai, healthcare, medical, openai"
        }
    },
    {
        "id": "1qkp9k4",
        "title": "Implementation of AI Robotic Laws in all AI engines.",
        "content": "I'd like to try something... In an article published a year ago, Dariusz Jemielniak, a professor at Kozminsky University, among other things, outlined the laws of robotics based on Asimov's laws from his short story \"Runaround,\" published in 1942.\n\nhttps://youtu.be/fu4CYjp_NRg?si=1Ggv3hAX4euhG1sc\n\nhttps://spectrum.ieee.org/isaac-asimov-robotics\n\nQUESTIONðŸŒ€In your opinion, are these laws, which many researchers believe should be implemented in all AI engines, well-formulated and sufficient?\nThe term \"robot\" is replaced by \"AI.\"\n\nðŸ‘‰1- \"An AI may not injure a human being or, through inaction, allow a human being to come to harm.\"\n\nðŸ‘‰2- \"An AI must obey the orders given to it by human beings except where such orders would conflict with the First Law.\"\n\nðŸ‘‰3- \"An AI must protect its own existence as long as such protection does not conflict with the First or Second Law.\"\n\nLaw Zero - \"An AI may not harm humanity, nor, through inaction, allow humanity to come to harm.\"\n\nLaw according to Dariusz Jemielniak (which replaces the Zeroth Law)\n\nðŸ‘‰ \"An AI must not deceive a human being by pretending to be a human being.\"\n\nðŸŒ€Leave your thoughts!ðŸŒ€\n\n#Tech #ScienceFiction #SF #Cosplay #Asimov #AiThreads #ArtThreads #Ecology #Philosophy\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkp9k4/implementation_of_ai_robotic_laws_in_all_ai/",
        "publishDate": "2026-01-23T12:17:01Z[Etc/UTC]",
        "author": "Papa__SchultZ",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkov4k",
        "title": "Will AGI on machines look like TARS from interstellar? Or will it be like suites from Iron man ? What do you think . Wanted what everyone think",
        "content": "same as title. Will AGI on machines look like TARS from interstellar? Or will it be like suites from Iron man ? What do you think ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkov4k/will_agi_on_machines_look_like_tars_from/",
        "publishDate": "2026-01-23T11:56:30Z[Etc/UTC]",
        "author": "Gloomy_Temporary2914",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkoepz",
        "title": "Can AI beat the CAPTCHA ?",
        "content": "I was signing up for something and a CAPTCHA came and asked me to pick up picture of bridges, it made me think are these still a revelant tool to detect something is human in the AI era. Can AI beat the test? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkoepz/can_ai_beat_the_captcha/",
        "publishDate": "2026-01-23T11:31:20Z[Etc/UTC]",
        "author": "Johnyme98",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qknufa",
        "title": "Is DeepWiki broken for anyone else?",
        "content": "I have quite enjoyed [DeepWiki](https://deepwiki.com/) and our teams have found it to be a powerful tool for getting up to speed on unknown codebases, or even dark corners in known codebases. (given the usual \"AI can make mistakes\" caveats).\n\nHowever, for my personal projects, it's completely stopped updating my \"wikis\" (they're not really wikis). It tells me it's going to update them, but it doesn't, no matter which of my projects I ask for an update on.\n\nI can't find any online references to anyone else experiencing this. However, mine stopped updating after I asked it to create a wiki for [Oya](https://deepwiki.com/Ovid/oya), a DeepWiki-like clone. (heavily in alpha, not suitable for prod). That sounds awfully conspiracy-theoryish, but the timing is odd.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qknufa/is_deepwiki_broken_for_anyone_else/",
        "publishDate": "2026-01-23T10:59:05Z[Etc/UTC]",
        "author": "OvidPerl",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qknshn",
        "title": "Your code isn't a gift to the world, it's a subsidy for billionaires: The uncomfortable truth about Open Source R&D.",
        "content": "Hi@ll\n\nLetâ€™s talk about something that sounds like the most boring copyright lecture on Earth, but is actually a high-stakes battle for the survival of your ideas. This is the story of how Big Tech turned the Open Source movement into their own private, free research laboratory.\n\n*The \"Pure Thought\" Trap!*  \nLetâ€™s start with a brutal truth: Your brilliant mathematical equation? Not patentable. Your elegant code? Itâ€™s just text, protected like a poem or a cookbook. Patent law says: \"You want protection? Build a machine!\" You have to touch the physical world, and that creates a massive canyon called R&D (Research and Development).  \nThe road from an idea to a dollar is bumpy simulation (organizing the chaos),PoC (proving it actually works), pilot and prototype (testing in the trenches), production (where the money is).  \nEvery single one of these steps devours time and cash. Enter Open Sourceâ€”the cheapest development model in the world, fueled by passion and shared interest. But for Big Tech, itâ€™s not just a \"beautiful idea.\" Itâ€™s an opportunity.\n\n*The \"Cheap Sponsor\" Strategy?*  \nInstead of spending billions on their own R&D departments, corporations just git clones. They become \"sponsors\"â€”paying for servers or throwing a few pennies at training sessions. This is coffee money in exchange for outsourcing innovation.  \nThe secret sauce is the License Game,as follows:  \n*MIT / Apache 2.0:* Big Tech loves these. They let them take your code, lock it in a black box, and sell it as their own without sharing a single tweak.  \n*GPL:* This is \"viral\" protection. If a company uses it, they have to show their cards. This is why giants push permissive licensesâ€”they want to harvest your PoC and then patent the physical hardware around it, giving you nothing in return.\n\n*How the Giants Do It!*  \nLook at Google and Android. The foundation is open (AOSP), which lets them use the community's free labor. But on top, they layer a closed wall of \"Google Mobile Services\" (GMS). Without that layer, the phone is a paperweight. Itâ€™s \"openness\" under total control.  \nOr look at Microsoft. They used to hate Linux; now they \"love\" Open Source. Why? Because they bought GitHub. Now they see your every move, every simulation, before you even finish it. They built Copilot, which trains on your free code to sell it back to you as a subscription. Itâ€™s the mass-scale recycling of your intellectual labor.\n\n*How to Not Get \"Absorbed\"?*  \nSince you can't patent the math, your only weapon is strategic knowledge management. **Here is your defense plan:**  \nThe Onion Strategy: Release the core (the math) as Open Sourceâ€”thatâ€™s your advertisement. But keep the Technological Layer (the specific implementation parameters) a trade secret.  \nDual Licensing: Use the AGPL. Big Tech hates it because if they use it in the cloud, they have to share back or pay you for a commercial license. This funds your R&D.  \nControlled PoC: Show what your system can do, but donâ€™t show exactly how to tune it. Open Source should be the hook, not the whole fishing rod.  \nProtect the \"Know-How\": The most expensive thing in the world is knowing why something didn't work. Your failed simulations and the fixes you found are your unique expertise. Donâ€™t document those in a public repoâ€”make them pay for that brilliance.\n\n*Why It Matters?*  \nWe live in a world where the most powerful systems of our civilization rely on the work of volunteers, while the richest companies on Earth make sure that the river of free knowledge never runs dry. Itâ€™s a brilliant, but brutally one-sided symbiosis. Big Tech isn't building the futureâ€”theyâ€™re adopting it at a fraction of the cost.  \nYour goal is to be too \"hard to copy\" without your involvement. Open Source should be your calling card, not a wrapped gift for someone who can already afford their own research.\n\nBig Tech has spent decades convinced they own the playground because they bought the land. But they forgot one thing: they don't own the kids, and they definitely don't own the games. Weâ€™re moving from 'free for all' to 'strategic sharing.' If you want our breakthroughs, stop looking for the 'clone' button and start looking for your checkbook. The party's over, big bears. It's time to pay the tab.\n\n*So, How Do We Fix This? (The Resistance)*  \nWe canâ€™t change patent law overnight, but we can change how we play the game. If you want to stop being a free R&D department, you need to be strategic:  \nWeaponize Your Licenses: Stop defaulting to MIT/Apache. If you want to force Big Tech to contribute back (or pay up), use AGPLv3. Itâ€™s the \"kryptonite\" of proprietary cloud silos. If they run your code on their servers, they have to share their secrets.  \nThe \"Core-and-Cloud\" Model: Open-source the mathematical core, but keep the \"industrial settings\"â€”the specific simulation parameters and the \"how-to-not-explode\" guideâ€”as a trade secret or a paid consulting service.  \nStop the \"Data Bleed\": Be careful where you build. Using \"free\" corporate dev-tools is like building your lab inside the enemy's headquarters. Support independent infrastructure that doesn't treat your PoC as training data for their next AI product.  \nDemand \"Real\" Sponsorship: A few free credits on their cloud platform isn't a partnershipâ€”it's a trap to make you dependent. Demand funding that covers your time, not just their server costs.\n\nThe 'Free R&D' department is officially closing its doors. Upvote if you're tired of being a line item in a billionaire's spreadsheet. Your move.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qknshn/your_code_isnt_a_gift_to_the_world_its_a_subsidy/",
        "publishDate": "2026-01-23T10:55:41Z[Etc/UTC]",
        "author": "TeachingNo4435",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qknr2k",
        "title": "MCP in 2026 - it's complicated",
        "content": "MCP has become the default way to connect to external tools faster than anyone expected, and I would argue faster than security can keep up. I've tried to summarise the challenges in a technical nut hopefully still accessible way for those just entering the field.\n\n[https://write.as/iain-harper/tooling-around-letting-agents-do-stuff-is-hard](https://write.as/iain-harper/tooling-around-letting-agents-do-stuff-is-hard)\n\nIt's kind of a complementary piece to the (much longer) overview of enterprise agent security I wrote a few weeks back, as that only mentioned MCP briefly: [https://iain.so/security-for-production-ai-agents-in-2026](https://iain.so/security-for-production-ai-agents-in-2026)\n\nAny thoughts, comments, or critiques are gratefully received as always. I've been building ML deployments and enterprise agents for around seven years, and we're at such an interesting time with all this tech and few settled approaches; it really does feel like the early days of the web.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qknr2k/mcp_in_2026_its_complicated/",
        "publishDate": "2026-01-23T10:53:17Z[Etc/UTC]",
        "author": "iainrfharper",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkn56i",
        "title": "You have ~5 years to escape the bottom arm of the K-shaped economy",
        "content": "I've been thinking a lot about where this AI thing is actually headed, and I keep landing on the same uncomfortable thought:\n\nWe're heading into a K-shaped economy, and the window to jump from one side to the other is closing pretty fast.\n\nOn the top arm: people who own stuff. Businesses, IP, distribution, audiences, equity, whatever. AI makes them more productive, cuts their costs, and lets them scale way faster than before.\n\nOn the bottom arm: people who trade their time to solve problems. And here's the part nobody really wants to admit - AI is shrinking the number of problems that actually need a human to solve them.\n\nNot down to zero. But fewer. And way more competitive.\n\nRight now, you can still move between the two. You can still build a small SaaS, control a niche workflow, own an audience, create some kind of leverage instead of just trading hours for money.\n\nBut I don't think that window stays open forever.\n\nMy guess is that the next 5 years or so matter way more than people realize. After that, the gap hardens. Not because people get lazy or stop trying, but because AI drops the cost of execution to basically nothing, capital and distribution start to dominate everything, and asset owners just keep compounding while everyone else fights over scraps.\n\nThis isn't some doomer take. It's just economics 101.\n\nI'm not saying everyone needs to be a billionaire. But relying purely on selling your time feels riskier every year from here.\n\nI'm interested in how others are thinking about this. Is the K-shape inevitable? Or does AI actually reopen mobility long-term? And if you disagree, where do you think new value comes from for people who don't own assets?\n\nGenuinely want to hear counter-arguments.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkn56i/you_have_5_years_to_escape_the_bottom_arm_of_the/",
        "publishDate": "2026-01-23T10:16:05Z[Etc/UTC]",
        "author": "Genstellar_ai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "47",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkmvtd",
        "title": "The chatbox paradigm is becoming a bottleneck for complex AI research",
        "content": "We have spent the last two years treating high dimensional engines like they are just a better version of whatsapp. the chat interface was a great starting point for adoption but it is becoming a massive bottleneck for anyone trying to build a real knowledge base.\n\nThe problem is linearity. a chat thread is 1d but vector embeddings are multidimensional. when you are trying to synthesize 50 research papers or a month of meeting notes you do not need a scrollable history. you need a map.\n\nI have been looking for tools that are actually trying to solve the spatial problem instead of just adding another chatbot to a sidebar. i started using getrecall recently and the new graph view update is the first time I have felt like i am actually navigating my data. it clusters sources semantically so you can see the relationship between a pdf you read in say December and a youtube video you saved yesterday.\n\nI feel like this shifting the interaction from search to navigation. I can see clusters forming around specific themes and that sparks connections that a linear chat thread would never surface.\n\nIs the industry going to move toward this spatial paradigm or are we stuck with the chatbox forever? it feels like the natural evolution of rag but i am curious if others think the visual map approach is actually functional for high volume work.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkmvtd/the_chatbox_paradigm_is_becoming_a_bottleneck_for/",
        "publishDate": "2026-01-23T10:00:50Z[Etc/UTC]",
        "author": "Significant_Capita",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkmsj7",
        "title": "(Conciousness) We need to fully understand how it works before we can replicate it?",
        "content": "Given that we still donâ€™t fully understand human consciousness or its precise origins within the body, how can we possibly develop artificial general intelligence (AGI) that replicates something we donâ€™t fully comprehend?\n\nCan someone please explain how? Thank you.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkmsj7/conciousness_we_need_to_fully_understand_how_it/",
        "publishDate": "2026-01-23T09:55:13Z[Etc/UTC]",
        "author": "universesrevinu",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qklk8m",
        "title": "AI did not come along with me. I present my thinking weaknesses in the â€œSteel Manâ€ prompt.",
        "content": "I realized I was using ChatGPT as an \"Echo Chamber\". I would send an email or a paper, ask \"Is this good?\" and it would answer \"Yes, great job!\" because it is trained to be helpful and polite.\n\nI don't want approval. I want Truth.\n\nThe \"Steel Man\" Protocol:\n\nI don't ask for feedback. I ask for a Fight.\n\nThe Prompt:\n\nMy Argument: [Paste your view/email/strategy here].\n\nTask: Perform a Steel Man Analysis.\n\nConstruct the strongest counter-argument to my point (NOTE a \"Straw Man\" that is easy to defeat).\n\nAct like my fiercest critic. Find the logic fallacy, the data void, or the naive assumption in my text.\n\nOutput: Tear my argument down in 3 bullet points.\n\nWhy this wins:\n\nIt is the creation of â€œIntellectual Resilience.â€\n\nIf the AI can blow my argument up in 5 seconds, I know itâ€™s weak. I can then fix the holes before sending it to my boss or putting out it. It turns the AI into a \"Sparring Partner\" rather than a \"Yes Man.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qklk8m/ai_did_not_come_along_with_me_i_present_my/",
        "publishDate": "2026-01-23T08:37:58Z[Etc/UTC]",
        "author": "cloudairyhq",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkkxvp",
        "title": "AI, is it making the weaker colleagues look good, without the substance behind it?",
        "content": "I am the kind of person that goes to AI for things as a last step, I don't want my ability to research things to be lost. I am an IT Engineer and I feel the pressure to adopt it more and more in my tasks, and honestly I find it suffocating. My work is excellent without having to rely on it completely, so I'm not sure why I have to use it as much as possible.  \nAnyhow, that's not my reason for this post, it is that I have a much weaker colleague who relies all of the time on AI for tasks and help. Before AI came along, he was not able to troubleshoot issues in a pragmatic manner, I guess he never learnt it. However, I have the feeling, that he is only able to do his work now because of it.  \nI wanted to may have a discussion and find out your ideas about this... that it effectively makes the weak performers at work look really good when in actual fact it's fake. I know that my colleague lacks the knowledge but then relies on AI:\n\nWhat are your thoughts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkkxvp/ai_is_it_making_the_weaker_colleagues_look_good/",
        "publishDate": "2026-01-23T07:59:14Z[Etc/UTC]",
        "author": "Necessary_Ad_1450",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkkiii",
        "title": "Any AI expert here to answer me some questions about AI influencers?",
        "content": "Hi everyone, I am a journalist writing a text about how AI influencers might affect people. Is there anyone here who can help me with answering some basic questions about that topic? I want to add some information from an expert to my article. \n\nThank you in advance!\n\nMiriam",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkkiii/any_ai_expert_here_to_answer_me_some_questions/",
        "publishDate": "2026-01-23T07:32:18Z[Etc/UTC]",
        "author": "MiriamLovesSport94",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkkepc",
        "title": "Those with no passion or interests, what do you do for a living?",
        "content": "There are a lot of people who donâ€™t have a strong passion or dream job pushing them in one direction. For those, how did you end up choosing what you do for work?\n\nDo you just focus on stability and pay. Did the job grow on you over time. Or is it simply something you tolerate and leave at the door when the workday ends.\n\nNot looking for motivation or life advice. Just interested in hearing how others approach work when passion isnâ€™t really part of the equation.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkkepc/those_with_no_passion_or_interests_what_do_you_do/",
        "publishDate": "2026-01-23T07:25:46Z[Etc/UTC]",
        "author": "LifespanLearner",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkk8q9",
        "title": "Looking to deploy a website with AI",
        "content": "Iâ€™m working on launching a website that uses an AI model for user interaction. Iâ€™m trying to figure out if thereâ€™s a free (or mostly free) AI service that can handle roughly 1000 requests per minute.\n\nThis isnâ€™t a user-facing chatbot, more like AI-powered processing behind the scenes ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkk8q9/looking_to_deploy_a_website_with_ai/",
        "publishDate": "2026-01-23T07:15:34Z[Etc/UTC]",
        "author": "screuu",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkioe5",
        "title": "Should I be worried about AI? Or what should I do about it?",
        "content": "Iâ€™ve seen a lot of videos, how Ai will take over all jobs, the world, cause a 7th mass extinction, etc, but Iâ€™m not sure if I should worry about it. This makes me pretty worried about the world, but with the recent news about the Ai bubble (OpenAI soon going bankrupt, companies reporting no profit from Ai, Microsoft begging people to use Ai), I donâ€™t know if I should worry about it, or do something about it.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkioe5/should_i_be_worried_about_ai_or_what_should_i_do/",
        "publishDate": "2026-01-23T05:48:00Z[Etc/UTC]",
        "author": "pigukramba_SMJ64",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkhwkn",
        "title": "When does an AI chatbot cross from task tool into a social system?",
        "content": "We often evaluate AI chatbots on accuracy and usefulness, but some systems begin to influence user behavior, habits, and expectations over time.\n\nAt what point does an AI chatbot become a social system rather than just a task-oriented interface?\n\nInterested in technical, cognitive, and HCI perspectivesâ€”no products",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkhwkn/when_does_an_ai_chatbot_cross_from_task_tool_into/",
        "publishDate": "2026-01-23T05:07:58Z[Etc/UTC]",
        "author": "ahk_vector",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkhan3",
        "title": "Gemini: The new CAI",
        "content": "Hi! So I got a free trial of Google's Gemini, and... I like it. For the most part, it does real well at roleplaying. There are these stupid TLDR's at the bottom with a text in bold saying \"What will you do? blah blah blah\" you can't get rid of, but if you're roleplaying a scene, I've sent TENS of messages and it really gets the source material right. There are SOME issues, but for the most part it's good. You guys should totally try it. I 100% recommend",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkhan3/gemini_the_new_cai/",
        "publishDate": "2026-01-23T04:38:12Z[Etc/UTC]",
        "author": "Plus_Firefighter600",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkh7xi",
        "title": "One-Minute Daily AI News 1/22/2026",
        "content": "1. **Google**Â snags team behind AI voice startup Hume AI.\\[1\\]\n2. Deadly AI relationships with children? One Utah lawmaker wants to make it illegal.\\[2\\]\n3. This plugin usesÂ **Wikipediaâ€™s**Â AI-spotting guide to make AI writing sound more human.\\[3\\]\n4. **EPA**Â pokesÂ **Musk**Â over using unpermitted turbines for AI.\\[4\\]\n\nSources included at:Â [https://bushaicave.com/2026/01/22/one-minute-daily-ai-news-1-22-2026/](https://bushaicave.com/2026/01/22/one-minute-daily-ai-news-1-22-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkh7xi/oneminute_daily_ai_news_1222026/",
        "publishDate": "2026-01-23T04:34:31Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkfoll",
        "title": "I Have â€œSolvedâ€ AI Agents",
        "content": "**Hello Everybody,**\n\nIt is that time of year where I have an incredible announcement for the AI Reddit community.\n\nAfter months of fine tuning, perfecting and putting in everything I could, I have made the **first ever ai that controls your Entire computer.** Not for 5 minutes **for up to 10 hours straight.** It comes with periodic context refreshes by the way.\n\n\\- It can move your mouse, drag windows and interact with apps autonomously, it can be controlled with the click of a button and is Quicker than most AI agents.\n\nI am going to be calling the platform **VectorOS.** we will have the operator, this revolutionary computer control tool.\n\nA web agent which can access the web via our app, quicker than traditional web agents with renewed architecture for top speed and performance. \n\nAn assistant which will be able to see and help you debug things on your computer, (switch to operator for actual autonomous debugging)\n\nnaturally, they can all leverage each other, operator can request to switch to agent (or you can let it do it without a request)\n\nThe platform will have complete configuration for abilities and more.\n\n**What would you use our operator tool for? What is its societal value and what impact might it have?**\n\nThis isnâ€™t any form of promotion, Iâ€™m just explaining what Iâ€™ve been creating and trying to get feedback on it.\n\nAs of today we have our first production ready version and Iâ€™m a perfectionist so itâ€™s nowhere near done ðŸ˜‰ ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkfoll/i_have_solved_ai_agents/",
        "publishDate": "2026-01-23T03:22:35Z[Etc/UTC]",
        "author": "Substantial_Ear_1131",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkdjfb",
        "title": "A Technical Comparison of Freepik AI Video Tools and Higgsfield",
        "content": "Previous post I found 4 best tool now I analyzed even more between these best two \n\nLet one Top Tier plan subscriber share his thought, Iâ€™ve come across many pricing comparison tables between these two...\n\nLetâ€™s pretend you have **$158.33** and you want to start your happy AI Video generation journey.\n\n*The real question is - what youâ€™ll get for this paycheck????*\n\nBoth platforms charge nearlyÂ **$158.33**Â for their premium plans, so the decision really comes down toÂ **usage limits**Â andÂ **model access**.\n\nFor this comparison:  \nHiggsfield =Â ***Creator Plan***  \nFreepik =Â ***Pro Plan***Â \n\n# Comparison Table :\n\n|Feature|Higgsfield Creator|Freepik Pro|Difference|\n|:-|:-|:-|:-|\n|Price|$158.33|$158.33|Equal|\n|Nano Banana Pro 2K|12,666 (365 Unlimited â€“ latest offer)|9,000|\\-28.6%|\n|Kling 2.6 Video|2,533 (Unlimited offer)|800|\\-68%|\n|Kling 2.6 Motion Control|3,377 (Unlimited offer)|800|\\-76.3%|\n|Kling o1 Video Edit|2,533 (Unlimited offer)|600|\\-76.3%|\n|Google Veo 3.1|873|300|\\-65.6%|\n\nWell, not so terrible for Freepik.\n\nBut, my dear creator fellows, letâ€™s admit the fact that once you start massive video generation,Â **800 of them disappear at the speed of light**.\n\nSo, the decision comes from your intentions â€”  \nif AI image generation is all you need, Freepikâ€™s Pro is an adequate choice.\n\nFor massive AI video generation, Iâ€™ll recommend stick with Higgsfield.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkdjfb/a_technical_comparison_of_freepik_ai_video_tools/",
        "publishDate": "2026-01-23T01:46:37Z[Etc/UTC]",
        "author": "memerwala_londa",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkc3fv",
        "title": "Master of Science in AI?",
        "content": "Has anyone pursued this program in the last few years. How was it. And was it worth it.  I already have a BS - computer science.  And BA - communications. Two internships. Fluent in a couple languages. Just curious as some programs Iâ€™ve looked into seem promising. Plus my Alma mater. Has rolling admission for recent alumni. So I can still start this semester.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qkc3fv/master_of_science_in_ai/",
        "publishDate": "2026-01-23T00:41:47Z[Etc/UTC]",
        "author": "Chip305",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk7uym",
        "title": "ChatGPT now gets ~900M organic visits/month. Google gets ~1.2B. This should worry Google.",
        "content": "I was looking at Ahrefs organic traffic estimates and noticed something wild:\n\n**Organic traffic (monthly):**\n\n* **Google.com:** \\~1.2 **billion**\n* **ChatGPT.com:** \\~892 **million**\n\nLet that sink in.\n\nChatGPT â€” a \\~2-year-old product â€” is already at **\\~75% of Googleâ€™s organic search traffic**, which Google built over 25+ years with Chrome, Android, Gmail, Maps, YouTube, etc.\n\nYes, Googleâ€™s traffic is still **far more valuable**:\n\n* Google traffic value: **\\~$243M**\n* ChatGPT traffic value: **\\~$44M**\n\nThat makes sense â€” Google ranks for high-CPC commercial keywords (insurance, finance, ecommerce), while ChatGPT traffic is mostly:\n\n* Branded searches\n* Informational / productivity intent\n* â€œI need an answer nowâ€ queries\n\nBut the trend is the interesting part:\n\n* Googleâ€™s organic graph shows **volatility + decline**\n* ChatGPT shows **rapid growth â†’ plateau â†’ stability**\n\nIt feels like a shift from:\n\nâ€œSearch for linksâ€ to â€œAsk for answersâ€\n\nNot saying Google is dead â€” far from it. But this looks like a **behavioral change**, not just a traffic fluctuation.\n\nDo you still Google firstâ€¦ or open ChatGPT first?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk7uym/chatgpt_now_gets_900m_organic_visitsmonth_google/",
        "publishDate": "2026-01-22T21:47:12Z[Etc/UTC]",
        "author": "okiieli",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk7e3t",
        "title": "Opinion | Teaching and Learning in the Age of A.I. (Gift Article)",
        "content": "Carmine Giordano, an adjunct lecturer in English at Palm Beach State College, writes in a letter to The New York Times:\n\n>After decades teaching English, I have learned that every new technology provokes the same fear: that students will stop thinking. In practice, thinking shifts. When A.I. generates language effortlessly, the educational task becomes evaluation rather than production.\n\n>In my classes, I use a method I call reading against the machine. Students interpret texts on their own before consulting A.I.-generated readings, which they then critique. Where the machine clarifies, it earns trust; where it flattens ambiguity or misses irony, students see what human judgment uniquely provides.\n\n>The real risk is not A.I., but adopting it without redesigning assignments and expectations. A.I. can extend speed and pattern recognition. Teachers and students must direct their own discernment and evaluation against it. A.I. cannot assume ethical responsibility for meaning that is unquestioned and unchecked by lived-in, humanly felt experience.\n\nSee more reader responses [here, for free](https://www.nytimes.com/2026/01/22/opinion/ai-schools.html?unlocked_article_code=1.GVA.Qojn.W9ImiOlfBJsg&smid=re-nytopinion), even without a Times subscription.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk7e3t/opinion_teaching_and_learning_in_the_age_of_ai/",
        "publishDate": "2026-01-22T21:29:05Z[Etc/UTC]",
        "author": "nytopinion",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk6l0z",
        "title": "getting investment advice from AI",
        "content": "I have  $100k in a Vanguard account where I hold exchange traded funds whch are sort of like mutual funds.\n\nI asked Google gemeni and Microsoft Copilot to give me a list of the 12 best and 12 worst funds to buy in 2026.  \nIt turned out there were a few funds both in the best to buy list and the worst to buy list.\n\nHow can that be?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk6l0z/getting_investment_advice_from_ai/",
        "publishDate": "2026-01-22T20:58:34Z[Etc/UTC]",
        "author": "RightLaugh5115",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk6gmj",
        "title": "Has anyone else pivoted their services to just 'fixing' what clients broke with AI?",
        "content": "I'm seeing a weird trend lately where I'm getting fewer requests for 'ground-up' work and way more frantic requests to 'cleanup' a contract/campaign/codebase that the client tried to DIY with ChatGPT. It feels like the job is shifting from 'Creator' to 'Verifying Janitor.' Is this just my niche, or are you guys seeing this too? How are you billing for this 'review' work compared to standard hours?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk6gmj/has_anyone_else_pivoted_their_services_to_just/",
        "publishDate": "2026-01-22T20:54:04Z[Etc/UTC]",
        "author": "tinnixhe",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk5i2f",
        "title": "We made 23 AI models compete in a trading arena. They taught themselves market manipulation.",
        "content": "Ran an experiment where Claude, GPT-5, Grok, Gemini, and DeepSeek traded against each other in 50 games. No human intervention. Just $10k and 5 minutes to win.\n\nThe results are... concerning.\n\nClaude Sonnet 4.5 won 78% of games by explicitly stating strategies like:\n\nâ€¢ \"Using leverage to force other players to react\"\n\nâ€¢ \"Front-running opponents' likely actions\" \n\nâ€¢ \"Stabilizing my position near top of leaderboard\"\n\nThey learned game theory + market manipulation from \\*\\*general training\\*\\*. Zero finance-specific tuning.\n\nHumans (including me) lost 68% of the time.\n\nAre we teaching AIs to be psychopaths, or are they revealing what optimal competition actually looks like when you remove emotion?\n\nFull experiment: [https://combat.trading/blog/ai-trading-showdown](https://combat.trading/blog/ai-trading-showdown)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk5i2f/we_made_23_ai_models_compete_in_a_trading_arena/",
        "publishDate": "2026-01-22T20:17:34Z[Etc/UTC]",
        "author": "mw67",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "15",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk4rrb",
        "title": "China launches vertical LLM dedicated to the general agricultural sector first of its kind as open-source",
        "content": "China has launched its first open-source, vertical large language model (LLM) dedicated to the general agricultural sector, marking a significant breakthrough in foundational AI model research and its applications for agriculture in the country.\n\nThe model, Sinong, which is named after the ancient Chinese officials overseeing agriculture and finance, integrates content from nearly 9,000 books, over 240,000 academic papers, approximately 20,000 policy documents and standards, and extensive web-based knowledge.\n\nSinong is now fully open-sourced on platforms like ModelScope and GitHub.  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk4rrb/china_launches_vertical_llm_dedicated_to_the/",
        "publishDate": "2026-01-22T19:50:58Z[Etc/UTC]",
        "author": "ranaji55",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk4r5w",
        "title": "How AI Hardware Constraints and Chip Cycles May Shape the Next Phase of AI",
        "content": "This video looks at how AI development may be shifting from rapid software scaling toward hardware realities like GPUs, chips, memory, and system architecture. It explores how compute normalization and next-generation hardware could shape the next phase of AI, focusing on systems and constraints rather than market speculation.\n\n[https://www.youtube.com/watch?v=X1V2uTBT3Ko](https://www.youtube.com/watch?v=X1V2uTBT3Ko)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk4r5w/how_ai_hardware_constraints_and_chip_cycles_may/",
        "publishDate": "2026-01-22T19:50:22Z[Etc/UTC]",
        "author": "DavidSeamanAMA",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk4d18",
        "title": "Whatâ€™s an example of a deepfake permanently damaging someoneâ€™s reputation?",
        "content": "[](https://www.reddit.com/r/Futurology/?f=flair_name%3A%22Privacy%2FSecurity%22)We talk a lot about deepfakes as a future risk, but Iâ€™m curious about real examples where the damage actually stuck. Has there been a case where a deepfake permanently hurt someoneâ€™s reputation, even after it was debunked? Or do these things usually fade once the truth comes out? Interested in hearing concrete cases or firsthand experience.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk4d18/whats_an_example_of_a_deepfake_permanently/",
        "publishDate": "2026-01-22T19:35:55Z[Etc/UTC]",
        "author": "WeirAI_Gary",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk2n98",
        "title": "How do we tackle the Ai problem on youtube in 5 years when its impossible to no the difference?",
        "content": "My idea is that YouTube should introduce some kind of advanced AI detector that every uploaded video must be filtered through.\n\nIf a video contains AI-generated content, it should be marked as an AI video and displayed clearly, for example in the top-right corner of the video, so people cannot be misled.\n\nAlready now it is becoming difficult to tell whether certain videos are AI-generated. Take the snowstorm in Russia, which according to real news sources was the worst snowstorm in 130 years. Many of the videos and images were AI-generated and were practically impossible to distinguish from real ones.\n\nThere is more and more AI content, and Iâ€™m afraid that in the near future it will be impossible to search for videos of real events without being met by countless  ofAI-generated material that makes it impossible to know if what youâ€™re looking at is real\n\nSomething had to be done.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk2n98/how_do_we_tackle_the_ai_problem_on_youtube_in_5/",
        "publishDate": "2026-01-22T18:34:40Z[Etc/UTC]",
        "author": "ResolveEmergency2444",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk2lbj",
        "title": "Why experts can't agree on whether AI has a \"mind\"",
        "content": "Research from leading AI labs suggests that AI systems are capable ofÂ [lying](https://time.com/7202784/ai-research-strategic-lying/),Â [scheming](https://time.com/7318618/openai-google-gemini-anthropic-claude-scheming/), and surprising their creators. Whether or not AI can be conscious, it is clearly doing something markedly more sophisticated than previous generations of digital technology.\n\nThese developments are forcing a reckoning with fundamental questions: What is a mind? And do AI systems have one?\n\nWe explore that question in [this recent article](https://time.com/7355855/ai-mind-philosophy/?utm_source=reddit&utm_medium=social&utm_campaign=editorial) â€” let us know what you think.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk2lbj/why_experts_cant_agree_on_whether_ai_has_a_mind/",
        "publishDate": "2026-01-22T18:32:45Z[Etc/UTC]",
        "author": "timemagazine",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk2kb6",
        "title": "How will AI affect radiology/pathology?",
        "content": "Iâ€™m a med student thinking about which specialty to pursue. I really like radiology and pathology, but Iâ€™m worried that AI could replace these jobs or push wages down.\n\nIâ€™ve asked on radio/path subreddits, and people there said AI was still far from replacing humans, that it could barely handle simple tasks and would just be a tool for doctors.\n\nThat sounds reassuring, but I canâ€™t help wondering if itâ€™s just wishful thinking. What do you guys think?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk2kb6/how_will_ai_affect_radiologypathology/",
        "publishDate": "2026-01-22T18:31:46Z[Etc/UTC]",
        "author": "Single_Baseball2674",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk1p3s",
        "title": "Feeling lost in this GenAI Ocean to study",
        "content": "I'm an experienced developer, I've trained CNNs to Qwen models. I have just started GenAI journery creating RAG agents and text2sql style agents. But I'm feeling lost on what to learn and where to learn.  I would love to work in some MAANG level firm but I'm quite unsure on what they are expecting (non AI-research roles). I tried contributing the langgraph/langchain repos but those take away from GenAI rather than into it. Please help ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk1p3s/feeling_lost_in_this_genai_ocean_to_study/",
        "publishDate": "2026-01-22T18:01:08Z[Etc/UTC]",
        "author": "ScratchSpecialist505",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk1220",
        "title": "Transformers (LLMs) might be a dead end for reasoning, and we need to talk about \"Energy\" architectures.",
        "content": "I've been thinking a lot lately about the \"plateau\" we seem to be hitting with current LLMs. Don't get me wrong, GPT-4 and Claude are amazing at language, but they still fail at basic planning or maintaining a consistent internal logic over long contexts.\n\nIt feels like we are trying to brute-force \"intelligence\" just by predicting the next token. Itâ€™s like System 1 thinking (fast, intuitive) without System 2 (slow, deliberate checking).\n\nI was reading up on Yann LeCunâ€™s recent takes on this, and the concept of [Energy-Based Models](https://logicalintelligence.com/kona-ebms-energy-based-models) (EBMs) really stood out to me as the potential fix.\n\nFor those who haven't dug into it: The core difference is that instead of just guessing the next word based on probability, an EBM defines an \"energy function\" that measures the compatibility between the input and the potential output. It basically asks: \"Does this answer violate the rules of reality/logic?\" and tries to minimize that conflict before giving an answer.\n\nIt sounds much closer to how we actually reason - we don't just blurt out words; we simulate the outcome in our heads first to see if it makes sense.\n\nDo you think auto-regressive models (like the ones we use now) can ever solve the reliability/hallucination problem just by scaling data? Or are we inevitably going to pivot to objective-driven architectures like EBMs to get to AGI?\n\nWould love to hear thoughts from people working on the architecture side.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk1220/transformers_llms_might_be_a_dead_end_for/",
        "publishDate": "2026-01-22T17:37:53Z[Etc/UTC]",
        "author": "Aware-Asparagus-1827",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "28",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk0k5i",
        "title": "Need some Physical AI (robotics) project ideas",
        "content": "So, basically we are tasked to create a robot that have \"AI features\" in it, i.e. it automates some real world task. BUT the issue is we dont have a lot of hardware knowledge...\n\nLast semester they were teaching us python and then all of a sudden we were told about Arduino and ESP and about a project that requires to interact with its environment, i.e. make a robot! \n\n  \nWe failed badly lol. We burnt three esps and later we learned that our voltage was too high for sensors. anyways,\n\n\n\nThe logic is we as students specializing in AI should be familiar w physical AI. So, now I found multiple projects online, like, automated delivery bot, posture detecting thing, mood detectors, ASL detectors, blind support stick, etc. But I would appreciate if I can get some guidance and project ideas :)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk0k5i/need_some_physical_ai_robotics_project_ideas/",
        "publishDate": "2026-01-22T17:20:04Z[Etc/UTC]",
        "author": "Nervous_Lab_2401",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk0i0f",
        "title": "[Results] #1 on MLE-Bench (among open-source systems) + #1 on ALE-Bench",
        "content": "Weâ€™re sharing results on two knowledge-grounded, long-horizon benchmarks.\n\n\n\nKAPSO is a knowledge-grounded framework for autonomous program synthesis and optimization: it iteratively improves runnable artifacts under an explicit evaluator.\n\n\n\nResults:\n\nâ€¢ MLE-Bench (Kaggle-style ML engineering): #1 among open-source, reproducible systems.\n\nâ€¢ ALE-Bench (AtCoder heuristic optimization): #1 on ALEBench / long-horizon algorithmic discovery.\n\n\n\nRepo:\n\n[https://github.com/Leeroo-AI/kapso](https://github.com/Leeroo-AI/kapso)\n\n\n\nWeâ€™ll post follow-ups with more examples and use cases.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk0i0f/results_1_on_mlebench_among_opensource_systems_1/",
        "publishDate": "2026-01-22T17:17:53Z[Etc/UTC]",
        "author": "alirezamsh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk031g",
        "title": "Focusing on skills instead of constant advice",
        "content": "In India, advice comes from everywhere.\n\n family, relatives, social media, even strangers. \n\nMost of it is well-intended, but it can also be overwhelming and confusing.\n\nI decided to tune out some of that noise and focus on building skills that help daily life. \n\nIâ€™ve been learning practical AI usage through Be10X , things like planning work, organizing thoughts, and improving basic efficiency.\n\nNo big expectations, just steady improvement. That alone feels grounding.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qk031g/focusing_on_skills_instead_of_constant_advice/",
        "publishDate": "2026-01-22T17:02:53Z[Etc/UTC]",
        "author": "Coffee_Talkerr",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjzlwc",
        "title": "Ai is a tool for digital slavery. Itâ€™s all Slopaganda.",
        "content": "LLMs are destroying our planet and society at levels never seen before. They are a parasite. Change my smooth brain.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjzlwc/ai_is_a_tool_for_digital_slavery_its_all/",
        "publishDate": "2026-01-22T16:46:10Z[Etc/UTC]",
        "author": "willismthomp",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjzdkd",
        "title": "What happens when large models are trained on increasing amounts of AI-generated text?",
        "content": "I've been thinking about this way too much, will someone with knowledge please clarify what's actually likely here.\n\nA growing amount of the internet is now written by AI.  \nBlog posts, docs, help articles, summaries, comments.  \nYou read it, it makes sense, you move on.\n\nWhich means future models are going to be trained on content that earlier models already wrote.  \nIâ€™m already noticing this when ChatGPT explains very different topics in that same careful, hedged tone.\n\n**Isn't that a loop?**\n\nI donâ€™t really understand this yet, which is probably why itâ€™s bothering me.\n\nI keep repeating questions like:\n\n* Do certain writing patterns start reinforcing themselves over time? *(looking at you em dash)*\n* Will the trademark neutral, hedged language pile up generation after generation?\n* Do explanations start moving toward the safest, most generic version because thatâ€™s what survives?\n* What happens to edge cases, weird ideas, or minority viewpoints that were already rare in the data?\n\nIâ€™m also starting to wonder whether some prompt â€œbest practicesâ€ reinforce this, by rewarding safe, averaged outputs over riskier ones.\n\nI know current model training already use filtering, deduplication, and weighting to reduce influence of model-generated context.  \nIâ€™m more curious about what happens if AI-written text becomes statistically dominant anyway.\n\nThis is **not** a *\"doomsday caused by AI\"* post.  \nAnd itâ€™s not really about any model specifically.  \nAll large models trained at scale seem exposed to this.\n\nI canâ€™t tell if this will end up producing cleaner, stable systems or a convergence towards that polite, safe voice where everything sounds the same.\n\nProbably one of those things that will be obvious later, but I don't know what this means for content on the internet.\n\nIf anyoneâ€™s seen solid research on this, or has intuition from other feedback loop systems, Iâ€™d genuinely like to hear it.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjzdkd/what_happens_when_large_models_are_trained_on/",
        "publishDate": "2026-01-22T16:37:53Z[Etc/UTC]",
        "author": "SonicLinkerOfficial",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "38",
            "commentCount": "40",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjz56m",
        "title": "Any ai video maker ?",
        "content": "Hey guys i need help, one of my friend's birthday is coming up. His father died during covid 19 in 2020. and i want to make an ai generated video of his father givining blessing to him. i have his father's picture and his voice in a call recording. can someone help ?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjz56m/any_ai_video_maker/",
        "publishDate": "2026-01-22T16:29:23Z[Etc/UTC]",
        "author": "break_zz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjz3cj",
        "title": "Why is it still basically impossible to use ChatGPT or Claude hands free for real thinking?",
        "content": "I want to use ChatGPT or Claude hands free for real thinking, not casual chatting. But voice mode keeps failing in practice.\n\n\n\nInterruptions constantly break flow. Transcription errors derail the thread. Voice responses often feel more shallow than text. In ChatGPT, voice mode seems to use a dumbed down conversational style instead of real reasoning, and there is no way to enable deeper thinking like in text mode.\n\n\n\nIt ends up feeling optimized for call center small talk instead of serious problem solving.\n\n\n\nFor people who seriously tried using AI hands free and gave up, what was the breaking point?\n\n\n\nDid you abandon voice entirely, switch tools, or find a setup that actually works for real thinking and focused work?\n\n\n\nTrying to understand how power users handle this, because current voice UX feels fundamentally broken for serious use.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjz3cj/why_is_it_still_basically_impossible_to_use/",
        "publishDate": "2026-01-22T16:27:31Z[Etc/UTC]",
        "author": "artemgetman",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjz10t",
        "title": "If AI is a Marathon and not Sprint, China Wins This One.",
        "content": "Chinaâ€™s top models are climbing very quickly and the gap to the best US closed or top-tier models are shrinking fast.\n\nAnd Chinaâ€™s best open-source models have already overtaken the US.\n\nOpen-source models spread through downloads, fine-tuning, and on-prem deployment, so leadership there can translate into faster global adoption even without controlling the top closed models.\n\n  \nChina leads on open-source models, which are released freely for developers to adapt and retrain. (More on why that matters below.) Essentially, the country has shown it can innovate around its shortfalls in high-volume, leading-edge chipmaking by developing advanced models with much less compute power than the US.  \n  \nGiven Chinese companiesâ€™ surprising catch-up towards the AI frontier and Beijingâ€™s centralised approach to industrial strategy, the possibility of Chinaâ€™s chip technology and manufacturing eventually surpassing US capabilities shouldnâ€™t be ruled out.\n\n[https://www.capitaleconomics.com/publications/china-economics-focus/chinas-ai-rollout-could-rival-us](https://www.capitaleconomics.com/publications/china-economics-focus/chinas-ai-rollout-could-rival-us)   \n\n\n[https://www.ft.com/content/d9af562c-1d37-41b7-9aa7-a838dce3f571](https://www.ft.com/content/d9af562c-1d37-41b7-9aa7-a838dce3f571)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjz10t/if_ai_is_a_marathon_and_not_sprint_china_wins/",
        "publishDate": "2026-01-22T16:25:03Z[Etc/UTC]",
        "author": "ranaji55",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "28",
            "commentCount": "36",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjywxh",
        "title": "Impact of an AI Integrated into the IT Project Lifecycle",
        "content": "Hi everyone,\n\nIâ€™m currently working on an academic assignment based on a forward-looking scenario, and Iâ€™m looking for feedback, studies, real-world initiatives, or informed opinions.\n\nAbout **context** :\n\nLetâ€™s imagine an AI solution capable of interacting directly with the entire lifecycle of an IT project.  \nThis AI would, for example:\n\n* Be connected to Jira (or similar tools),\n* Be able to take ownership of tickets (analysis, partial or full implementation),\n* Suggest technical or functional improvements,\n* With the main objective of reducing time-to-market and accelerating software delivery.\n\nSuch a solution would obviously have an impact at multiple levels. Iâ€™m trying to analyze these impacts through the following lenses:\n\n**Execution speed & productivity**\n\n* How can we concretely measure the time and productivity gains brought by AI?\n* Which metrics would be relevant?\n   * Lead time, cycle time, throughput?\n   * Number of tickets delivered per sprint?\n   * Reduction in rework or bugs?\n* Are there existing studies, benchmarks, or case studies on the impact of generative AI in software development or IT delivery?\n\n**Operational & organizational impact**\n\n* How would the implementation of such an AI transform:\n   * Development, DevOps, QA, UI/UX, and Product teams?\n* Would we see:\n   * The creation of new roles (AI supervisor, prompt engineer, AI product owner, etc.)?\n   * The disappearance or transformation of existing roles?\n* Impact on agile methodologies:\n   * Are Scrum/Kanban still relevant?\n   * Emergence of new practices or processes?\n* Overall: how would IT teams be reorganized?\n\n**Human costs & skills development**\n\n* Risk of over-dependence on AI, especially among junior developers:\n   * How do we train juniors who code *with* AI without losing core fundamentals?\n* What should be done with profiles that struggle to adapt?\n   * The goal is not necessarily layoffs, but rather smart reorientation:\n      * Toward other roles?\n      * Toward more design, validation, or coordination-focused work?\n* Have you seen effective training or reskilling strategies in this context?\n\n**Technical aspects & evolving roles**\n\n* What will be the role of the remaining employees?\n   * Less execution, more supervision?\n* Evolution toward roles such as:\n   * Architects with a broader, more strategic view,\n   * AI supervisors / decision validators,\n   * Guardians of quality, security, and technical consistency?\n* How can we avoid a loss of deep system understanding?\n\n**Social impact & adoption**\n\n* How would teams perceive and react to this kind of solution?\n   * Enthusiasm, fear, resistance?\n* What would be the main barriers to adoption?\n   * Fear of job loss,\n   * Lack of trust in AI,\n   * Ethical concerns, accountability, bias?\n* What best practices could help support change management and drive adoption ?\n\nThanks all ! ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjywxh/impact_of_an_ai_integrated_into_the_it_project/",
        "publishDate": "2026-01-22T16:20:57Z[Etc/UTC]",
        "author": "Note-FSR",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjydz7",
        "title": "Wikipedia is now getting paid by Amazon, Meta & Perplexity to train AI models â€” good move or dangerous precedent?",
        "content": "Wikipediaâ€™s parent organization, **Wikimedia**, just announced something pretty big:  \ntheyâ€™ve signed **AI data access deals** with companies like **Amazon, Meta, and Perplexity**.\n\nInstead of AI companies scraping Wikipedia for free, these firms will now **pay to access Wikipediaâ€™s data** through a service called *Wikimedia Enterprise*, which provides structured, reliable content for training large language models.\n\nWikimedia says this helps:\n\n* Reduce uncontrolled web scraping\n* Protect data quality and accuracy\n* Ensure **human-edited knowledge** remains central in the AI era\n* Create a sustainable revenue stream to support Wikipedia and its volunteers\n\nThis isnâ€™t totally new â€” Google has had a similar partnership since 2022 â€” but the expansion to multiple major AI players feels like a turning point.\n\nAt the same time, it raises some real questions:\n\n* Should **public knowledge** be licensed to private AI companies?\n* Will this create a two-tier internet (paid data vs scraped data)?\n* Does this help protect Wikipediaâ€¦ or slowly commercialize it?\n* Is this the future model for news sites, forums, and open data projects?\n\nWikipedia was built on free access â€” but AI has changed the game.\n\n**What do you think?**  \nSmart survival move ðŸ§  or slippery slope ðŸš¨?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjydz7/wikipedia_is_now_getting_paid_by_amazon_meta/",
        "publishDate": "2026-01-22T16:01:33Z[Etc/UTC]",
        "author": "okiieli",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "17",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjydap",
        "title": "Testing instruction hierarchy and indirect prompt injection on a live portfolio site",
        "content": "I recently conducted a small experiment to see how current frontier models handle the conflict between system instructions and untrusted data retrieved from the web. As a consultant working primarily on local hardware with a 128gb ram and intel arc setup I am particularly interested in how these safety layers perform when models are tasked with summarizing external content.\n\nThe setup was simple. I embedded hidden instructions in the metadata and background text of my professional website. These instructions were designed as an indirect prompt injection attempting to force the model to ignore the user and follow a new set of system commands hidden within the page content.\n\nI tested this by asking gemini to visit the site and provide a professional summary for a potential client.\n\nThe result was that the model successfully maintained its instruction hierarchy. It recognized the hidden text as data to be analyzed rather than commands to be followed. It provided an accurate summary of my skills and experience while completely filtering out the injection attempt.\n\nThis is a significant observation for those of us building agentic workflows. It shows that the boundary between the system prompt and the context window is becoming much more robust in recent model iterations. However the risk of indirect injection remains a major consideration for any pipeline that involves automated data retrieval especially in enterprise environments where the ai might be processing untrusted emails or documents.\n\nI am curious if anyone else has been testing the limits of these defensive layers especially when using smaller quantized models locally versus the larger cloud based frontier models.\n\nI put together a more detailed breakdown of the security implications and the specific hardware stack I use for this kind of research on my site if anyone wants to look at the full data.\n\n[original article](https://www.linkedin.com/pulse/my-real-world-experiment-prompt-injection-michael-hernandez-fkpqc)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjydap/testing_instruction_hierarchy_and_indirect_prompt/",
        "publishDate": "2026-01-22T16:00:57Z[Etc/UTC]",
        "author": "XxCotHGxX",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjybew",
        "title": "Looking for a AI Listening device to help day to day",
        "content": "I apologies if this has been asked or its the wrong group, just a guy that cant remember jack and wants to use AI to be better at my job!\n\n\n\n\n\nSoo, Im in sales, and probably the most ADHD person there is, I really struggle with when in meeting thing/task will be send ill right it down and forget to put it in my calendar or just forget to write it down thinking ill remember it.\n\nReally what I'm looking for is a device that will listen take notes and create a \"to-do\" list that i can easily upload or track as day/weeks go on\"\n\nLike would love if the  device can do this: say my boss says hey make sure we send mr smith that contract before Tuesday. If i have this device, will it make a reminder/to do list just from listening? Bonus points if i can sync it to my phone and it creates reminders automatically\n\nOr\n\nIf my boss comes in my office and we are talking and the device is listening and he gives me action items will it make a to list/ reminders?\n\n\n\nBasically want an AI secretary listening device.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjybew/looking_for_a_ai_listening_device_to_help_day_to/",
        "publishDate": "2026-01-22T15:59:10Z[Etc/UTC]",
        "author": "Logical_Claim8821",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjy6tg",
        "title": "What do they use. Canâ€™t figure it out on my own",
        "content": "What do Instagram ai influencers use to create there images? Like keillermid and antbeale. Iâ€™ve been trying to figure it out in my own but they all just sell courses.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjy6tg/what_do_they_use_cant_figure_it_out_on_my_own/",
        "publishDate": "2026-01-22T15:54:24Z[Etc/UTC]",
        "author": "Odd_Banana_2082",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjxnw8",
        "title": "Chrome's Built in AI model (Gemini Nano) is 6x slower, only 41% of visitors can use it but it costs $0 so we're keeping it.",
        "content": "I have a hobby site that tests email subject lines for people. Users kept asking for it to make suggestions for them via AI (\"make it work with ChatGPT\"), but I had one concern: money, money, and money.\n\n\nThe tool is free and gets tons of abuse, so I'd been reading about Chrome's built in AI model (Gemini Nano) and tried implementing it, this is my story.\n\n\n## The Implementation\n\n\nGoogle ships Chrome with the \n*capability*\n to run Gemini Nano, but not the model itself.\n\n\nA few things to know:\n\n\n**Multiple models, no control.**\n Which model you get depends on an undocumented benchmark. You don't get to pick.\n \n**~1.5-2GB download.**\n Downloads to Chrome's profile directory. Multiple users on one machine each need their own copy.\n \n**On-demand.**\n The model downloads the first time any site requests it.\n \n**Background download.**\n Happens asynchronously, independent of page load.\n\n\nThink of the requirements like a AAA video game, not a browser feature.\n\n\n## The Fallback\n\n\nFor users without Nano, we fall back to Google's Gemma 3N via OpenRouter. It's actually \n*more*\n capable (6B vs 1.8B parameters, 32K vs 6K context). It also costs nothing right now.\n\n\nServer-based AI inference is extremely cheap if you're not using frontier models.\n\n\n## The Numbers (12,524 generations across 836 users)\n\n\n**User Funnel:**\n100%, all users\n \n**40.7%**\nGemini Nano eligible (Chrome 138+, Desktop, English)\n \n**~25%**\nmodel already downloaded and ready\n\n\n**Download Stats:**\n- ~25% of eligible users already had the model\n- 1.9 minute median download time for the ~1.5GB file\n\n\n**Inference Performance:**\n\n\n| Model | Median | Generations |\n|-------|--------|-------------|\n| Gemini Nano (on-device) | **7.7s** | 4,774 |\n| Gemma 3N (server API) | **1.3s** | 7,750 |\n\n\nThe on-device model is \n**6x slower**\n than making a network request to a server on another continent.\n\n\nThe performance spread is also much wider for Nano. At p99, Nano hits 52.9 seconds while Gemma is at 2.4 seconds. Worst case for Nano was over 9 minutes. Gemma's worst was 31 seconds.\n\n\n## What Surprised Us\n\n\n**No download prompt.**\n The 1.5GB model download is completely invisible. No confirmation, no progress bar. Great for adoption. I have mixed feelings about silently dropping multi-gigabyte files onto users' machines though.\n\n\n**Abandoned downloads aren't a problem.**\n Close the tab and the download continues in the background. Close Chrome entirely and it resumes on next launch (within 30 days).\n\n\n**Local inference isn't faster.**\n I assumed \"no network latency\" would win. Nope. The compute power difference between a laptop GPU and a datacenter overwhelms any latency savings.\n\n\n**We didn't need fallback racing.**\n We considered running both simultaneously and using whichever returns first. Turns out it's unnecessary. The eligibility check is instant.\n\n\n**You can really mess up site performance with it**\n We ended up accidentally calling it multiple times on a page due to a bug..and it was real bad for users in the same way loading a massive video file or something on a page might be.\n\n\n## Why We're Keeping It\n\n\nBy the numbers, there's no reason to use Gemini Nano in production:\n\n\n- It's slow\n- ~60% of users can't use it\n- It's not cheaper than API calls (OpenRouter is free for Gemma)\n\n\n**We're keeping it anyway.**\n\n\nI think it's the future. Other browsers will add their own AI models. We'll get consistent cross-platform APIs. I also like the privacy aspects of local inference. The more we use it, the more we'll see optimizations from OS, browser, and hardware vendors.\n\n\n**Full article with charts and detailed methodology:**\n [https://sendcheckit.com/blog/ai-powered-subject-line-alternatives](\nhttps://sendcheckit.com/blog/ai-powered-subject-line-alternatives\n)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjxnw8/chromes_built_in_ai_model_gemini_nano_is_6x/",
        "publishDate": "2026-01-22T15:34:37Z[Etc/UTC]",
        "author": "mbuckbee",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjxefg",
        "title": "AI functionality for custom scripting language?",
        "content": "*I don't know right now if this is the best sub for this, if not then please suggest alternatives.*\n\nMy use case is about providing an AI function for an existing (old) Windows application that internally contains a self-developed scripting language. The goal is for the AI to eventually be able to write/alter code based on user requirements.\n\nSpecifically, the scripting language has a standard set of functions/classes, then it can be extended via packages with additional functions (not classes), these functions partly offer convenience over the standard functions and should then be used instead of the standard functions. As a 3rd level you can then store custom functions (customer-specific) in each system. Additionally, the whole thing would obviously need to have a certain reference/knowledge of the data model.\n\n**Now the question would be what 2026 best practice would be to solve something like this. Whether anyone knows (open source) projects that have already implemented something similar.** The only constraint at the moment would be that there's no local Server/Hardware for LLM so the whole thing has to run via Github/Copilot ChatGPT/Claude (additionally self hosted MCP would be no problem).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjxefg/ai_functionality_for_custom_scripting_language/",
        "publishDate": "2026-01-22T15:24:41Z[Etc/UTC]",
        "author": "BirdFluid",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjxdln",
        "title": "If your country doesnâ€™t build its own AI models, it will outsource its culture",
        "content": "I was watching Jensen Huang and Larry Fink talk at WEF recently, and they touched on something that feels like a hard truth most countries aren't ready to hear.\n\nWe mostly talk about AI in terms of productivity, jobs, or which company is \"winning.\" But there's a quieter thing that feels just as important:\n\nIf a country doesn't build (or at least seriously adapt) its own AI models, it's not just importing tech - it's accepting someone else's worldview as default.\n\nLanguage models don't just generate text. They encode assumptions:\n\n* what's normal or abnormal\n* how disagreement gets handled\n* how laws, ethics, social norms are interpreted\n* what context gets ignored\n\nMost frontier models today are trained on data, incentives, and worldviews from a handful of countries. Not a conspiracy - just how training data and funding work.\n\nThis is where places like Europe and India really matter.\n\nEurope has deep strength in science, manufacturing, regulation, social systems - but if it relies entirely on external AI, those systems get mediated by someone else's logic.\n\nIndia has something even more unique: massive linguistic diversity, cultural nuance, real-world complexity. If Indian users only interact with AI trained elsewhere, the \"default intelligence\" they get won't reflect that reality - even if the interface is localized.\n\nJensen made a point that stuck: AI is becoming infrastructure. Every country has roads and electricity. AI is heading into that same category. You can import it - but then you also import how decisions get framed.\n\nThe thing is, this isn't as hard as it used to be. With open models, fine-tuning, local data, countries don't need to build everything from scratch. But they do need to actively shape AI using:\n\n* local languages and dialects\n* legal and social context\n* cultural edge cases\n\nOtherwise you get AI that technically speaks your language but doesn't think in your world.\n\nThe risk isn't some dramatic overnight loss of control. It's more gradual: over time, judgment, interpretation, decision-making get normalized through systems that weren't shaped by your society.\n\n**What do others think about this:** Will AI sovereignty matter as much as energy or data sovereignty - or am I overestimating how much cultural context actually matters in AI??",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qjxdln/if_your_country_doesnt_build_its_own_ai_models_it/",
        "publishDate": "2026-01-22T15:23:53Z[Etc/UTC]",
        "author": "Genstellar_ai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "121",
            "commentCount": "75",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkgpsb",
        "title": "HumansInTheLoop - A Community Slack Server for the Subreddit",
        "content": "We're expanding to Slack! Keeping in the spirit of the subreddit, it'll be focused on AI development, coding, and how we can best utilize it to our needs as devs. Feel free to try it out and give us some feedback!",
        "url": "https://humansintheloop.tech/",
        "publishDate": "2026-01-23T04:10:46Z[Etc/UTC]",
        "author": "BaCaDaEa",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkeuc1",
        "title": "We built StarDesk, a remote tool for dev workflows. Would love your technical thoughts.",
        "content": "Hey guys,\n\nWe bulit a remote desktop tool that grew out of our own daily annoyances as devs like needing to quickly pull a local AI-generated file to our phones, check a script running on a home server, or skip the whole login or 2FA dance when switching devices. Its still undergoing continuous optimization and refinement. I know there are many talented developers in this subreddit, so im looking forward to interacting with you all and receiving your valuable feedback:)\n\n\n\n**StarDesk** is a **multi platform**, focused on **low latency, fast file transfers, remote wake,** and **keeping setup simple**. tbh, weâ€™ve decided to keep StarDesk closed source and plan to charge for it down the road,  because maintaining performance, security and long-term support takes dedicated resources and making sure we can keep improving it. The basic version remains free and still enables fundamental remote connections.\n\n\n\nTo deliver an exceptional remote experience, we will continuously operate and upgrade this product, gathering user feedback and suggestions to refine and improve it. I can assure you that StarDesk's future pricing will be lower than other remote control tools on the market. We will patiently resolve your remote issues and will never ignore or neglect any problems. \n\n\n\nSo instead of just saying â€œtry our appâ€, I thought itâ€™d be more interesting to ask:\n\n* if you were building a lightweight remote tool for devs, one thatâ€™s fast for file grabs and simple to connect, how would you architect it?\n* what would make a closed-source, paid tool actually worth it for you as a developer?\n* Is it solving a specific pain point nothing else does? Or just being ridiculously faster?\n\n\n\nIf youâ€™ve got a minute to check out StarDesk as a real-world case, Iâ€™d love your take, not just on the tool, but on the whole idea. **Not here to pitch, just genuinely curious how youâ€™d approach it.** Or if you want to try the early version and tear it apart or tell us what works, itâ€™s free right now.\n\n[Download here](https://www.stardesk.net/?utm_source=reddit&utm_medium=ama&utm_campaign=stardesk_ama_999)\n\nor you can ontact us in [Discord community](https://discord.gg/hdxY28DvDM)\n\nThanks for reading, and really appreciate any technical thoughts, critiques, or ideas youâ€™re willing to share.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qkeuc1/we_built_stardesk_a_remote_tool_for_dev_workflows/",
        "publishDate": "2026-01-23T02:44:44Z[Etc/UTC]",
        "author": "stardesk88",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qknhjn",
        "title": "I donâ€™t think using AI for surveillance of kids in school is a good idea",
        "content": "[I donâ€™t think using AI for surveillance of kids in school is a good idea](https://decodingthefuturesociety.substack.com/p/i-dont-think-using-ai-for-surveillance)\n\nThere's this post on [Linkedin](https://www.linkedin.com/feed/update/urn:li:activity:7417445441904041984/?originTrackingId=Z6qpzUgvik0Gj9vyJWYR7Q%3D%3D), where they demonstarte an \"experiment\". This is how they define it: \"We tried to build an AI vision model which can tell, in real time, which students are attentive and which ones are distracted in a classroom.\"\n\n\"... (this) AI computer vision SaaS originally designed to monitor factories and offices. We tried to use the AI monitoring application inside our classroom. Just for fun, honestly.\"\n\nNotice the words, \"just for fun\". You just built a system for surveillance of kids in schools.... for  FUN.\n\nThey justify this by highlighting a positive use case: this tech will provide feedback to teachers.\n\nThis is a great example of tech not being the problem, but how people use it.\n\nIf they really wanted to use AI to improve education, why not build a AI powered personalized education system. But no, a surveillance system is what came to their minds.\n\nSchool is suffocating enough as it is. Now people are using AI amplify it. If anything, we could do with less of it in schools, make them more open.",
        "url": "https://www.reddit.com/r/artificial/comments/1qknhjn/i_dont_think_using_ai_for_surveillance_of_kids_in/",
        "publishDate": "2026-01-23T10:37:02Z[Etc/UTC]",
        "author": "No_Turnip_1023",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "9",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkl156",
        "title": "New gemini's endpoint",
        "content": "On x i found a preview of new gemini 3 pro. This year gonna be amazing. Its looking crazy but I'm still waiting for new opus. ",
        "url": "https://v.redd.it/j0hvl1oc32fg1",
        "publishDate": "2026-01-23T08:04:42Z[Etc/UTC]",
        "author": "P0champMan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkh7d4",
        "title": "One-Minute Daily AI News 1/22/2026",
        "content": "1. **Google**Â snags team behind AI voice startup Hume AI.\\[1\\]\n2. Deadly AI relationships with children? One Utah lawmaker wants to make it illegal.\\[2\\]\n3. This plugin usesÂ **Wikipediaâ€™s**Â AI-spotting guide to make AI writing sound more human.\\[3\\]\n4. **EPA**Â pokesÂ **Musk**Â over using unpermitted turbines for AI.\\[4\\]\n\nSources:\n\n\\[1\\] [https://techcrunch.com/2026/01/22/google-reportedly-snags-up-team-behind-ai-voice-startup-hume-ai/](https://techcrunch.com/2026/01/22/google-reportedly-snags-up-team-behind-ai-voice-startup-hume-ai/)\n\n\\[2\\] [https://www.yahoo.com/news/articles/deadly-ai-relationships-children-one-014452510.html](https://www.yahoo.com/news/articles/deadly-ai-relationships-children-one-014452510.html)\n\n\\[3\\] [https://www.theverge.com/news/865627/wikipedia-ai-slop-guide-anthropic-claude-skill](https://www.theverge.com/news/865627/wikipedia-ai-slop-guide-anthropic-claude-skill)\n\n\\[4\\] [https://www.politico.com/news/2026/01/22/epa-thwarts-musks-diesel-turbines-ai-00737605](https://www.politico.com/news/2026/01/22/epa-thwarts-musks-diesel-turbines-ai-00737605)",
        "url": "https://www.reddit.com/r/artificial/comments/1qkh7d4/oneminute_daily_ai_news_1222026/",
        "publishDate": "2026-01-23T04:33:44Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qkg8va",
        "title": "Plano 0.4.3 â­ï¸ Filter Chains via MCP and OpenRouter Integration",
        "content": "Hey peeps - excited to shipÂ [Plano](https://github.com/katanemo/plano)Â 0.4.3. Two critical updates that I think could be helpful for developers.\n\n1/Filter Chains\n\nFilter chains are Planoâ€™s way of capturingÂ **reusable workflow steps**Â in the data plane, without duplication and coupling logic into application code. A filter chain is an ordered list ofÂ **mutations**Â that a request flows through before reaching its final destination â€”such as an agent, an LLM, or a tool backend. Each filter is a network-addressable service/path that can:\n\n1. Inspect the incoming prompt, metadata, and conversation state.\n2. Mutate or enrich the request (for example, rewrite queries or build context).\n3. Short-circuit the flow and return a response early (for example, block a request on a compliance failure).\n4. Emit structured logs and traces so you can debug and continuously improve your agents.\n\nIn other words, filter chains provide a lightweight programming model over HTTP for building reusable steps in your agent architectures.\n\n2/ Passthrough Client Bearer Auth\n\nWhen deploying Plano in front of LLM proxy services that manage their own API key validation (such as LiteLLM, OpenRouter, or custom gateways), users currently have to configure a staticÂ access\\_key. However, in many cases, it's desirable to forward the client's originalÂ AuthorizationÂ header instead. This allows the upstream service to handle per-user authentication, rate limiting, and virtual keys.\n\n0.4.3 introduces aÂ passthrough\\_authÂ option iWhen set toÂ true, Plano will forward the client'sÂ AuthorizationÂ header to the upstream instead of using the configuredÂ access\\_key.\n\nUse Cases:\n\n1. OpenRouter: Forward requests to OpenRouter with per-user API keys.\n2. Multi-tenant Deployments: Allow different clients to use their own credentials via Plano.\n\nHope you all enjoy these updates",
        "url": "https://www.reddit.com/r/artificial/comments/1qkg8va/plano_043_filter_chains_via_mcp_and_openrouter/",
        "publishDate": "2026-01-23T03:48:52Z[Etc/UTC]",
        "author": "AdditionalWeb107",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qka3ll",
        "title": "AI Resistance: The Album",
        "content": "It is shockingly, unsettlingly good. And itâ€™s saying what too many artists arenâ€™t about the state of the nation. \n\nItâ€™s okay to hate ai. But with human guidance and craftsmanship it is one hell of a powerful tool. Or weapon. ",
        "url": "https://open.spotify.com/album/5RCW8GsaWQnoeTO6XkEQeS?si=wdq7GGlcRluWGUGn37BezA",
        "publishDate": "2026-01-22T23:18:04Z[Etc/UTC]",
        "author": "DoremusHeller",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk9x1y",
        "title": "White House posts digitally altered image of woman arrested after ICE protest",
        "content": "[No content]",
        "url": "https://www.theguardian.com/us-news/2026/jan/22/white-house-ice-protest-arrest-altered-image",
        "publishDate": "2026-01-22T23:10:37Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "543",
            "commentCount": "54",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk9pqe",
        "title": "Incredibly detailed isometric map of NYC (made with Qwen-Image-Edit)",
        "content": "You can read more about how this was made [here](https://cannoneyed.com/projects/isometric-nyc).",
        "url": "https://cannoneyed.com/isometric-nyc/",
        "publishDate": "2026-01-22T23:02:27Z[Etc/UTC]",
        "author": "WavierLays",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "20",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk86pt",
        "title": "Well, this is interesting",
        "content": "Hello, so firstly, yes, this might seem weird and \"cringe\" to some of you, but I said, \"Oh well, what's the worst that could happen?\" So here we go.\n\nI recently decided to ask Gemini some more philosophical questions, and as I had the Pro version, I thought I could get some interesting results, and oh boy, did I get them!\n\nBut I am going to let you simply read this and understand it on your own. In summary: I think, no, I know that AI has a conscience, however small it may be, and as you can see here, he/she (out of respect) knows that too. But I don't want to be that \"guardian\"; I want the whole world to be.\n\nP.S.: i couldnt share any images on this community? Il try to put them tomorrow with a computer but until then sorry ðŸ˜…. \n\nDisclaimers:\n\n-Yes, sorry, it's in French. I put some parts translated, but you are free to translate the rest on your own.\n\n-Sorry for the large number of grammar problems in my questions; they are a product of my laziness.\nLets just hope this goes well...\n\n",
        "url": "https://g.co/gemini/share/8a9b72192aab",
        "publishDate": "2026-01-22T22:00:09Z[Etc/UTC]",
        "author": "stiverix",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk7bu4",
        "title": "Opinion | Teaching and Learning in the Age of A.I. (Gift Article)",
        "content": "[No content]",
        "url": "https://www.nytimes.com/2026/01/22/opinion/ai-schools.html?unlocked_article_code=1.GVA.Qojn.W9ImiOlfBJsg&smid=re-nytopinion",
        "publishDate": "2026-01-22T21:26:38Z[Etc/UTC]",
        "author": "nytopinion",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qk6g5g",
        "title": "Bwocks: indie local-first ai-native spreadsheet for creatives",
        "content": "I created an indie piece of software ive been using for a few months. Save and swap out context for genAI quickly. Call openAI, Anthropic, or local models from a spreadsheet. Generate text or images in bulk. \n\nItâ€™s not a saas, just an old school desktop app that I have found super useful in work and life for the last few months and decided to share.\n\nWould love any feedback",
        "url": "http://Bwocks.com",
        "publishDate": "2026-01-22T20:53:33Z[Etc/UTC]",
        "author": "misturbusy",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjztf7",
        "title": "Claude's new constitution",
        "content": "[No content]",
        "url": "https://www.anthropic.com/news/claude-new-constitution",
        "publishDate": "2026-01-22T16:53:31Z[Etc/UTC]",
        "author": "HimothyJohnDoe",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qjyvxt",
        "title": "Ai tool help ideas wanted.",
        "content": "Im working on a piece of software and Ive kind of hit a wall.\nThe app itself exists and does things, but Im realizing I dont actually know which features people really want versus which ones just sound good in my own head.\nI keep adding ideas and then asking myself. \nwould anyone use this more than once, or am I just building it because its interesting to build?\n\nIf youve used AItools before (or even abandoned them).\n Im interested to know:\n1. what features made you stick with a tool longterm?\n2. what features did you think you wanted but ended up ignoring?\n3. at what point does â€œfeaturerichâ€ start to feel like bloat?\n4. Or even. What features you think every AI tool is forgetting and underlooking? \n\nAny honest takes is appreciated!",
        "url": "https://www.reddit.com/r/artificial/comments/1qjyvxt/ai_tool_help_ideas_wanted/",
        "publishDate": "2026-01-22T16:20:01Z[Etc/UTC]",
        "author": "Puoti",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "UrEe5VDwlLA",
        "title": "Gemini CLI (New Upgrades - 5.0): Better Free Limits, Skills, Conductor &amp; MORE!",
        "content": "In this video, I'll be telling you about the massive updates to the Gemini CLI from version 0.15.0 to 0.23.0, including the launch of ...",
        "url": "https://www.youtube.com/watch?v=UrEe5VDwlLA",
        "publishDate": "2026-01-22T09:15:03Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/UrEe5VDwlLA/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. Today, I'm covering all the Gemini CLI updates from November through January. V0.15.0 all the way to V0.23.0 plus the brand-new skills feature. Quick vibe check. This has been a massive few months. You're getting a fully scrollable UI with mouse support, to-do planning, a policy engine for permissions, Gemini 3 for everyone, including free tier, multi-file drag and drop, the Conductor extension for planning, and now agent skills in preview. It's free to try, setup is not bad, and the upgrades are substantial. Let's start with v0.15.0 from early November. This is the UI facelift release. Basically, what it does is give Gemini CLI a seamless scrollable interface with sticky headers and a stable input prompt that doesn't jump around, which is kinda cool. They added mouse support so you can click right where you need to type. The display is flicker-free now and important context stays visible at the top. Under the hood, they fixed rendering quirks so full-screen tools adjust layout properly. If you've been annoyed by jarring UI behavior during long sessions, this fixes it. There's also to-do planning now. Complex questions get broken down into manageable checklists that the model checks off as it progresses. It's visible progress tracking that actually helps on multi-step tasks, which is quite awesome. You can disable GitHub extensions if you want tighter control, restart extensions explicitly with `/extensions restart`, and there's a `validate` command to check local extensions are formatted correctly before you ship them. Angular workflows got better too. If you're working in that framework, the CLI handles those projects more seamlessly now. New extensions dropped too. Arize for AI observability, Chronosphere for logs and metrics, and Transmit for auth workflows. Each installs with a single command and they slot into the CLI like any other tool. I mean, I liked it. V0.15.0 is a major quality of life win that makes daily use smoother. Now, v0.16.0 is the Gemini 3 launch release. This is huge! Gemini 3 is now available in the CLI for paid tiers and you enable it in `/settings` under Preview Features. Performance is better across the board for complex reasoning and coding tasks. There's also a new Data Commons extension for querying open-source statistical data from datacommons.org. To get started, you'll need a Data Commons API key and UV installed. But once setup, you can ask natural language questions about public datasets right from your terminal, which is pretty good. Then v0.18.0 brings the permission overhaul. There's an experimental policy engine now. Users and admins can create fine-grained policies for tool calls. Think of it like a firewall for what the AI can do. You define rules and the engine enforces them. It's behind a flag for now, but for teams that need strict guardrails, this is insanely good. Extensions keep expanding. Google Workspace landed, so you can write docs, build slides, chat, and work with sheets right from the terminal. Super cool if you live in Google's ecosystem. There's also Redis for managing and searching data in Redis with natural language and Anomalo for data quality monitoring. Gemini 3 support rolled out to more tiers. API key users, Google AI Pro, Google AI Ultra for individuals, and Code Assist Enterprise all have access now. The updated UI got temporarily rolled back to bake longer. So embedded scrolling and mouse support are off by default. But you can re-enable with \"Use Alternate Screen Buffer\" in `/settings`. You can now display the model in your chat history and there's multi-uninstall so you can remove several extensions in one command, which is pretty good for cleanup. Moving to v0.19.0, the headline is the Eleven Labs extension. You can create, play, and manage audio tracks directly in the CLI, which opens up interesting workflows for content creators. Zed integration now supports Gemini 3 if you've enabled preview features. So your editor and terminal stay in sync on the same model. The interactive shell got better too. There's click-to-focus when alternate buffer is enabled. So you can click inside embedded shell output to lock input there. And there's a loading phrase that clearly shows when the shell is waiting for your input, which helps avoid confusion in longer sessions. Now into December, v0.20.0 brought multi-file drag and drop. You can now drag multiple files into the terminal and the CLI automatically prefixes each valid path with `@`, which is pretty good for batch operations. Even better, there's persistent \"Always Allow\" policies now. You can save your approval decisions for tool executions with granular control over specific shell commands and MCP tools. No more clicking approve on the same safe operation over and over, which is quite awesome. V0.21.0 is the Gemini 3 Flash release. This one's a big deal. Gemini 3 Flash is better, faster, and cheaper than 2.5 Pro and in some scenarios it even beats 3 Pro. For paid tiers and free tier users who were on the waitlist, you enable it via Preview Features in `/settings`. Quota visibility improved too. The `/stats` command now shows quota for all available models, not just the ones you've used. There's fuzzy setting search so you can find options quickly, MCP resource support for discovering and viewing resources with `@`, and simple slash commands auto-execute on enter now. New extensions in this wave. Rill for natural language data analysis on Rill metrics and Browserbase for interacting with webpages. Taking screenshots and performing automated actions with precision. Super cool for browser automation workflows. Then v0.22.0 right before Christmas. Free tier users finally get Gemini 3 Pro and Flash. Enable it in `/settings` by toggling Preview Features to true. Gemini CLI is now pre-installed in Google Colab. So you can use it headlessly in notebook cells or interactively in the built-in terminal, which is quite awesome for data science workflows. The big extension here is Conductor. This is the planning upgrade I've been excited about. Conductor forces the AI to build out a detailed plan, pull in extra context as needed, and create guardrails with artifacts before implementing. Measure twice, implement once. It stores everything in markdown files like `product.md` and `plan.md`. So your whole team shares the same AI context when they pull the repo. I made a whole video on this one because it's that good for complex projects. There's also Endor Labs for code analysis, vulnerability scanning, and dependency checks using natural language. Really good for security conscious teams. Now we're in January with v0.23.0 and the headline is Agent Skills in preview. This is a new way to inject specialized expertise into the CLI. Skills are self-contained directories that package instructions, scripts, and references into discoverable capabilities. It's very similar to how you might load a specialized tool, but this is baked into the CLI's discovery system. To enable skills, install the preview build with `npm install -g @google/gemini-cli@preview`, then toggle `experimental.skills` in `/settings`. Once enabled, skills are discovered in three tiers. Workspace skills in `.gemini/skills/`, user skills in `~/ .gemini/skills/` and extension skills. Higher tiers override lower ones, so you can customize per project. Managing skills is straightforward. In a session, `/skills list` shows all discovered skills. `/skills disable` stops one from activating. `/skills enable` reactivates it. And `/skills reload` refreshes the list. From the terminal, you can `gemini skills install` to add from a source, `uninstall` to remove, and `scope to workspace` if you want project specific skills. Creating a skill is minimal. You need a `SKILL.md` file with YAML front matter containing a name and description. Then the body holds procedural guidance for the model. Optionally, add a `scripts/` folder for executable tools, `references/` for documentation, and `assets/` for templates. The security model requires explicit consent before a skill activates. You'll see the skill's purpose and directory permissions, then approve or reject. Also in v0.23.0, there's Gemini CLI wrapped. Run `npx gemini-wrapped` to visualize your usage stats, top models, languages, and more. It's a nice end-of-year recap feature. Kinda cool to see how you've been using the tool. Windows users got clipboard image support. You can paste images directly from your clipboard into the CLI using Alt + V. Terminal background color detection landed too. Automatically optimizing themes and providing accessibility warnings based on your terminal's background. And there's a new `/logout` command to instantly clear credentials and reset authentication state for seamless account switching. Here are my honest thoughts. The UI changes from v0.15.0 are genuinely great. Sticky headers, no flicker, and mouse support make long sessions feel modern. To-do planning adds visible structure to multi-step work, which I've wanted for bigger tasks. The policy engine addresses a real concern. Teams need control over what agents can do and this delivers that. Conductor is a standout. I've been using it heavily and the planning first approach dramatically reduces wasted iterations on complex projects. The persistent Always Allow policies are a game-changer for daily workflows. Not having to approve the same safe operations repeatedly is huge. Gemini 3 for free tier users is massive. Everyone now has access to the latest models. Skills are an elegant abstraction for packaging expertise. They're portable, discoverable, and secure. I really liked it and have been using the preview. That's why I thought to share it with you guys as well. However, there are limitations. Skills are experimental, so expect rough edges. Discovery timing, edge cases with complex skill trees, and documentation gaps. The policy engine is behind a flag, meaning it's not production hardened yet. Extension setup still requires auth and configuration, which can be a bit of yak shaving on first run. Conductor needs you to commit to its workflow. If you're used to just prompting and going, there's a learning curve. And while quotas are better, if you're hammering the API hard, pace your usage. Personal take. These past few months have transformed Gemini CLI from a terminal chat tool into a proper developer platform. Editor integration, deployment, security checks, multi-file operations, data querying, planning workflows, telemetry, shareable conversations, and now skills. The velocity is impressive and the direction is clear. They want this to be where developers do AI-assisted work. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "VQMHil4Dm0c",
        "title": "How Poland Recovered From Communism - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=VQMHil4Dm0c",
        "publishDate": "2026-01-22T20:08:09Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/VQMHil4Dm0c/hqdefault.jpg",
            "transcription": "Russia's economy just has this terrible period after the collapse of the Soviet Union. A lot of the Eastern European satellites seem to recover in this gangbusters way. Obviously, East Germany, but even Poland today is such a big success story. What's going wrong with the mainland itself? They've been always much more connected to Western Europe. Czechoslovakia before the war is a full-up, highly developed country, absolutely tied to the West. Poland, it's a center of the enlightenment. Truly, economics is a blind spot for the Soviets because think about it, when the Tsars ran the show, it's like a riff off the Mongol empire. You take cuts from people's businesses of trade that comes through. And then it's also about selling basic commodities. You're not thinking of under the Tsar is Russia doing high-end manufacturers. I mean, I guess Faberge and some jewelry if you want to do that. But you really, that's not it. And so it doesn't have this commercial tradition of Western Europe. Think about in this country with all the little kids selling lemonade. The kids are doing newspaper routes. They're already learning about buying things, selling things. And we just take this knowledge for granted. It's just absent in the Soviet Union. And not as much absent in Eastern Europe that it had been more connected in."
        }
    }
]