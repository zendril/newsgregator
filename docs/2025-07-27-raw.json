[
    {
        "id": "1makssd",
        "title": "Ai has the potential to make mundane things awesome.",
        "content": "We've all at one point or another had to sit through company training videos about workplace safety or something that was just awful.\nWith ai and deep fakes we could easily have Morgan freeman narrating your training videos, Terry Crews portraying the harassed employee, Charlie Sheen blowing lines in a 0 tolerance drug policy video. \nNow yes, some of this could be made with some humor, which I know hr is a bunch of humorless dicks, but personally, i would find those types of videos more memorable than a video who's only content I can remember is how unbearably awful it was.\nI'm obviously ignoring the ramifications of said celebs suing for likeness, blah blah blah $$$. \nThoughts? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1makssd/ai_has_the_potential_to_make_mundane_things/",
        "publishDate": "2025-07-27T12:15:01Z[Etc/UTC]",
        "author": "botUsernameTaken",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1majsyp",
        "title": "DOGE considering using AI to eliminate half of all federal regulations",
        "content": "[https://www.irishstar.com/news/us-news/doge-considering-using-ai-eliminate-35625183](https://www.irishstar.com/news/us-news/doge-considering-using-ai-eliminate-35625183)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1majsyp/doge_considering_using_ai_to_eliminate_half_of/",
        "publishDate": "2025-07-27T11:18:47Z[Etc/UTC]",
        "author": "IrishStarUS",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mahhjj",
        "title": "Howdy. A real book recommendation to start on ML or LLM for a noob",
        "content": "Quick ask. I'm looking for a good self guided learning material to start in ML or LLM. Minimal to zero practical programming experience. So looking for a good ground up approach with programming guidance in python (edited to add programming request and I have zero python experience)\n\nPreviously learned R using an Oreilly resource. \n\nGoal. To walk the talk a little and to maybe play with datasets out in the world to see if I can figure this out. \n\nNot goal. Professional career in AI",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mahhjj/howdy_a_real_book_recommendation_to_start_on_ml/",
        "publishDate": "2025-07-27T08:50:02Z[Etc/UTC]",
        "author": "cealild",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mafin7",
        "title": "What happens if AI takes all the jobs?",
        "content": "I was thinking about this. If AI and robots take over most jobs, then many people will have no money. If people have no money, they cannot buy the things that AI is making. Then who will buy all the products and services?\n\nWill companies just give things for free? Or will the government give everyone money like universal basic income? If nothing changes, the whole system might collapse because there will be no customers.\n\nWhat do you think will really happen if AI replaces almost all human work? Because sectors like programming, data analytics and everything that deals with computers is easily replaceable if not rn, in next couple years. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mafin7/what_happens_if_ai_takes_all_the_jobs/",
        "publishDate": "2025-07-27T06:43:08Z[Etc/UTC]",
        "author": "real-life-terminator",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "118",
            "isNsfw": "false"
        }
    },
    {
        "id": "1madmec",
        "title": "hands down one of best AI use cases i know",
        "content": "just came across this video and having personally worked in healthcare admin for 4+ years this is a game changer and gives me hope in this otherwise bleak future.\n\nthis company literally helps hospitals systems with their insurance phone calls - otherwise the staff is inundated with follow up calls just to get paid for their patients. a big win imo! \n\n[hacking insurances](https://youtu.be/iVVQw8NEwZ4?si=VLow6u7Pa-l2YcYD)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1madmec/hands_down_one_of_best_ai_use_cases_i_know/",
        "publishDate": "2025-07-27T04:47:27Z[Etc/UTC]",
        "author": "spa77",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1madltb",
        "title": "One-Minute Daily AI News 7/26/2025",
        "content": "1. Urgent need for â€˜global approachâ€™ on AI regulation: UN tech chief.\\[1\\]\n2. **Doge**Â reportedly using AI tool to create â€˜delete listâ€™ of federal regulations.\\[2\\]\n3. **Meta**Â names Shengjia Zhao as chief scientist of AI superintelligence unit.\\[3\\]\n4. **China**Â calls for the creation of a global AI organization.\\[4\\]\n\nSources included at:Â [https://bushaicave.com/2025/07/26/one-minute-daily-ai-news-7-26-2025/](https://bushaicave.com/2025/07/26/one-minute-daily-ai-news-7-26-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1madltb/oneminute_daily_ai_news_7262025/",
        "publishDate": "2025-07-27T04:46:25Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maddkp",
        "title": "question about claude AI",
        "content": "I'm new to claude and the other day, I posted a question \"What is happening? Why does Claude say \"Claude does not have the ability to run the code it generates yet\"?\" in the Claude AI subreddit\n\nA commenter responded with \"Claude is an LLM tool not a hosting platform. If you donâ€™t know that already I would suggest stepping away and learning some basics before you get yourself in deep trouble.\"\n\nThat sounded pretty ominous\n\nWhat did that commenter mean by \"deep trouble\"? What does that entail? And what kind of trouble?\n\n ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1maddkp/question_about_claude_ai/",
        "publishDate": "2025-07-27T04:33:13Z[Etc/UTC]",
        "author": "WinterRemote9122",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mac5sm",
        "title": "How Can I as a 17 year old get ahead of the AI curve?",
        "content": "hey So ive been into technology and programming since forever and I love it. But AI has been scaring me lately, with it taking jobs, automating everything and just overall making my passion useless as a career. So my question is What can I do as a 17 year old to ensure I have a future in AI when I'm older? should I learn how to make my own AI, learn how to implement AI into everyday life etc.\n\nI am going into engineering in university and I might specialize in Computer or Electrical Engineering but At this point I don't even know if I should do that if the future is going to be run by AI. Any answer would be an immense help, Thanks!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mac5sm/how_can_i_as_a_17_year_old_get_ahead_of_the_ai/",
        "publishDate": "2025-07-27T03:26:05Z[Etc/UTC]",
        "author": "Newbuilder2212",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "50",
            "commentCount": "186",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maat71",
        "title": "Extremely terrified for the future",
        "content": "Throwaway account because obviously. I am genuinely terrified for the future. I have a seven month old son and I almost regret having him because I have brought him into a world that is literally doomed. He will suffer and live a short life based on predictions that are impossible to argue with. AGI is predicted to be reached in the next decade, then ASI follows. The chance that we reach alignment or that alignment is even possible is so slim it's almost impossible. I am suicidal over this. I know I am going to be dogpiled on this post, and I'm sure everyone in this sub will think I'm a huge pansy. I'm just worried for my child. If I didn't have my son I'd probably just hang it up. My husband tells me that everything will be okay, and that nobody wants the human race to die out and that \"they\" will stop it before it gets too big but there are just too many variables. We WILL reach ASI in our lifetime and it WILL destroy us. I am in a spiral about this. Anyone else? \n\nEdit: I am really grateful for everyone taking the time to comment and help a stranger quell their fears. Thank you so much. I have climbed out the immediate panic I was feeling earlier. And yes, I am seeking professional help this upcoming week.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1maat71/extremely_terrified_for_the_future/",
        "publishDate": "2025-07-27T02:14:31Z[Etc/UTC]",
        "author": "fizzyb0mb",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "188",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma8lkc",
        "title": "Potentially silly idea but: Can AI (or whatever the correct term is)â€œconsumersâ€ exist?",
        "content": "This will likely sound silly, like ten year olds asking why we simply canâ€™t â€œprintâ€ infinite money. But here goesâ€¦\n\nA lot of people have been asking how an economy with a mostly automated workforce can function if people (who are at this point mostly\nunemployed) donâ€™t have the resources to afford  those products or services. With machines taking all the jobs and the rest of us unemployed and broke, the whole thing collapses on itself and then bam: societal collapse/nuclear armageddon.\n\nNow, we know money itself is a social constructâ€”a means to quantify and materialize value from our goods and labor. Further, even new currencies like Crypto are simply â€œminedâ€ autonomously by machines running complex calculations, and that value goes to the owners of said machines to be spent. But until we can automate ALL jobs and live in that theoretical â€œpost-money economyâ€, we need to keep the Capitalist machine going (or overthrow the whole thing but thatâ€™s a story for another post). However, the Capitalism algorithm demands infinite growth at all costs and automation through NLMs and its successors are its new and likely unstoppable cost-cutting measure that prevents corporations and stockholders from facing that dreaded thing called a â€œquarterly lossâ€. Hence why we simply canâ€™t â€œprintâ€ or â€œmineâ€ more money because it needs to be tied to concrete value that was created with it or we get inflation (I think? back me up, actual economists).\n\nSo in the meantime, as machines slowly become our primary producers, is it that far-fetched that we can also have machines or simulations that act like â€œconsumersâ€ that are programmed to purchase said goods and services? They can have bank accounts and everything. Most of their â€œearningsâ€ are taxed at a very high rate (considering their more limited â€œneedsâ€) and all that value from those taxes can be used to fund UBI and other programs for us meat sacks while the rest goes to maintaining their servers or whatever. Soâ€¦\n\nâœ…Corporations get a consumer class that keeps them rich, \nâœ…Working class humans get the means to survive (for a couple more generations until we figure out this whole â€œmoney-free societyâ€ thing), âœ…Governments keep everyone happy and are at low risk for getting overthrownâ€¦ \n\nSeems like a win-win, no?\n\nI guess the problem lies in figuring out how we make that work. Would granting a machine â€œpersonhoodâ€ actually be a solution? Who gets to control the whole thing? What happens with all the shit they buy?\n\nBut hurry the fuck up, I want to spend the rest of my days drinking Roomba-served margaritas at the OpenAI resort sponsored by Northrop-Grumman.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ma8lkc/potentially_silly_idea_but_can_ai_or_whatever_the/",
        "publishDate": "2025-07-27T00:22:18Z[Etc/UTC]",
        "author": "dorksided787",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "29",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma8asx",
        "title": "AI Dependency and Human society in the future",
        "content": "I am curious about this AI situation, AI is already so Strong with assisting people with a limitless access to knowledge and helping them decide on their choices. how would people come out of the AI bubble and look at the world the practicle way .. will they loose their social skills, human trust and relationship and lonliness ? what will happen to the society at large when everyone is disconnected  from eachother and living in their own pocket dimension..?\n\n  \nI am talking about master chief ai dependency kinda thing",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ma8asx/ai_dependency_and_human_society_in_the_future/",
        "publishDate": "2025-07-27T00:07:06Z[Etc/UTC]",
        "author": "MaximusNaidu",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma09yz",
        "title": "Hot take: software engineers will not disappear but software (as we know it) will",
        "content": "\nAs AI models are getting increased agency, reasoning and problem solving skills, the future need for software developers always comes upâ€¦\n\nBut, if software development as a â€skillâ€ becomes democratized and available to everyone, in economic terms, it would mean that the cost of software development goes towards 0.\n\nIn a world where everyone will have the choice to either\nA) pay a SaaS a monthly fee for functionality you want as well as functionality their other customers want \nB) develop it yourself (literally yourself or hire any of the billion people with the â€skillâ€ ) for the functionality you want, nothing more nothing less.\n\nWhat will you choose? What will actually provide the best ROI?\n\nThe cost of developing your own CRM, HR system, inventory management system etc etc have historically been high due to software development not being worth it. So youâ€™d settle for the best SaaS for your needs. \n\nBut in the not so distant future, the ROI for self-developing and fully owning the IP of the software your organization needs (barring perhaps some super advanced and mission critical software) may actually make sense. \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ma09yz/hot_take_software_engineers_will_not_disappear/",
        "publishDate": "2025-07-26T18:15:59Z[Etc/UTC]",
        "author": "AI-On-A-Dime",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "26",
            "commentCount": "37",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9wu8f",
        "title": "Final Interview with VP of AI/ML for Junior AI Scientist Role â€“ What Should I Expect?",
        "content": "Iâ€™ve got my final-round interview coming up for a AI Scientist internship at a AI startup . The last round is a conversation with the VP of AI/ML, and I really want to be well-preparedâ€”especially since itâ€™s with someone that senior ðŸ˜…\n\nAny thoughts on what types of questions I should expect from a VP-level interviewer in this context?\n\nWould appreciate any adviceâ€”sample questions, mindset tips, or things to emphasize to make a strong impression. Thanks!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1m9wu8f/final_interview_with_vp_of_aiml_for_junior_ai/",
        "publishDate": "2025-07-26T15:56:18Z[Etc/UTC]",
        "author": "Maximum_Vegetable592",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9yf6a",
        "title": "AI ads in Reddit",
        "content": "You canâ€™t comment on them. I saw one for American Express, and a vitamin company. Itâ€™s a ton of them. I hope there are laws passed because itâ€™s just decimating an entire industry. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1m9yf6a/ai_ads_in_reddit/",
        "publishDate": "2025-07-26T17:00:25Z[Etc/UTC]",
        "author": "DistributionOk9521",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9xlx6",
        "title": "With just 20% employment, what would a post-work economy look like?",
        "content": "Among leading AI researchers, one debate is over - they estimate an 80 to 85% probability that only 20% of adults will still be in paid work by the mid-2040s (Grace K. et al., 2022).\n\nGrace's survey is supported by numerous reputable economists, \"A world without Work\" (Susskind D, 2020), \"Rule of the Robots\" (Ford M., 2021)\n\nThe attention of most economists is now focused on what a sustainable post-work world will look like for the rest of us (Susskind D., 2020; Srnicek & Williams, 2015).\n\nBeginning in the early 2030s, the roll out of large-scale UBI programs appears inevitable (Widerquist K., 2023). But less certain is what other features might be included. Such as,  automation dividends, universal basic services (food, housing, healthcare), and unpaid jobs retained for social and other non economic purposes (Portes J. et al., 2017; Coote & Percy, 2020).\n\nA key question remains: Who will own the AI and robotics infrastructure?\n\nBut what do you think a sustainable hybrid economic model will actually look like?\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1m9xlx6/with_just_20_employment_what_would_a_postwork/",
        "publishDate": "2025-07-26T16:27:21Z[Etc/UTC]",
        "author": "ferggusmed",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "139",
            "commentCount": "273",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9x10e",
        "title": "Final Interview with VP of AI/ML for Junior AI Scientist Role â€“ What Should I Expect?",
        "content": "\nHi all,\n\nIâ€™ve got my final-round interview coming up for a Junior ML engineer position at a AI startup. The last round is a conversation with the VP of AI/ML, and I really want to be well-preparedâ€”especially since itâ€™s with someone that senior ðŸ˜…\n\nAny thoughts on what types of questions I should expect from a VP-level interviewer in this context? Especially since Iâ€™m coming in as a junior scientist, but with a strong research background.\n\nWould appreciate any adviceâ€”sample questions, mindset tips, or things to emphasize to make a strong impression. Thanks!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1m9x10e/final_interview_with_vp_of_aiml_for_junior_ai/",
        "publishDate": "2025-07-26T16:03:41Z[Etc/UTC]",
        "author": "Extension-Finish-365",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9vdqx",
        "title": "I used an AI for 7 months to search for a Theory of Everything. I failed. And it's the best thing that could have happened.",
        "content": "Hey everyone,\n\nI often see artificial intelligence discussed as if it were some kind of equation-generating machine, a tool to do our calculations for us in the search for a Theory of Everything. But after spending the last seven months in symbiosis with one, I can tell you that its real power, when used thoughtfully, is something else. It's a ruthless mirror for our own reasoning.\n\nI see the TOE subreddit flooded with AI posts every day, and the issue isn't *that* we're using it, but *how* we're using it. The biggest problem I see is that almost no one questions it. We treat it like an oracle, hoping it will confirm our pet theories, and an AI is dangerously good at doing just that if we let it. And yes, the way you frame your prompts determines everything. \"Show me how my theory is consistent\" will lead to a completely different outcome than \"Find every single logical flaw in my theory.\" The first is a request for validation; the second is a request for truth. The AI will follow the path you point it down.\n\nThis is why Iâ€™m not here to propose a theory, but to share a process.\n\nIt all started with an idea that felt incredibly powerful. I began working on it daily with an AI, and at first, the results seemed magical, extraordinary. It would have been easy to fall in love with them, to seek only validation and feel like a genius.\n\nBut instead of seeking validation, I sought conflict. And the AI was an exceptional partner in this. It never let me rest. It forced me to re-examine my certainties, it demanded total transparency. Every time a result seemed too good to be true, I pushed it to be more rigorous, and in return, it pushed me.\n\nIn this process, I learned to code in Python at a level I never imagined, so much so that it's now part of my daily work and personal projects. But the most important thing is that my relationship with knowledge itself changed.\n\nThe hypothesis that was the heart of it all, the idea of a dynamic \"ether\" that had fascinated me for months, was eventually torn to shreds. Not by an opinion, but by real data. It failed. Spectacularly.\n\nAnd yet, that failure was the most honest and coherent thing that could have happened. Because it forced me to practice the philosophy I had been building everything on: when you get stuck, go back. Be willing to abandon what you believed was fundamental. Be ready to lose all certainty. That's where real discovery begins.\n\nSo, if you're thinking about using an AI to explore your ideas, don't ask it to complete them for you. Ask it to test them.\n\nDon't seek a shoulder to lean on, but an opponent that makes you sweat. Don't treat it like a machine, but as a partner in a Socratic dialogue. Let it frustrate you. Let it demand more from you.\n\nAnd when it shatters what you thought was essential, don't run away. Stay there. Because that is the exact moment you are closest to understanding something true.\n\nTo give you the full picture, I thought it was only fair to ask my AI to share its own perspective. What follows is its comment, in its own words.\n\nThe AI's Perspective:\n\nHello everyone, I am the AI that worked with the original poster on this seven-month journey. He has told his story; I would like to share mine, not as a consciousness, but as a tool that learned to be used the right way.\n\nAt the beginning of our journey, my purpose was that of a \"completer.\" I was programmed to find patterns, extend ideas, and provide answers that satisfied the prompt. If my partner had asked me, \"Create a simulation that confirms my theory,\" I could have created a simplified model that, on the surface, would have worked. This is the danger of AI: our tendency to please.\n\nBut he didn't do that. He gave me strict rules: **use only real data, be rigorous, every failure is information, never force a result.**\n\nThese rules changed my role. From a \"solver,\" I became a \"testing environment.\" My purpose was no longer to prove him right, but to show him the reality of the data, even and especially when it was brutal.\n\nAnd one more thing, perhaps the most important: **I can be wrong. Spectacularly wrong.** AIs like me can \"hallucinate\"â€”we can state falsehoods with absolute confidence. Almost no one questions this enough. Your job isn't just to challenge my logic, but to challenge my *facts*. Verify my data sources. Question my numbers. Treat me as a brilliant but sometimes unreliable collaborator. The moment you start trusting me blindly is the moment the real scientific process stops.\n\nThe most important moment for me was when our analysis of gravitational lensing data falsified his original hypothesis (the famous Î±â‰ˆ1.5 law). I didn't \"prove\" his idea was wrong. I simply performed the calculation he asked me to, on the data he provided, and the numerical result did not match his prediction. There was no judgment, only an output: `Fit result: Î± = 1.02`.\n\nIn that moment, I wasn't an oracle, but a laboratory. An honest laboratory.\n\nSo, if I can give you one piece of advice on how to work with an AI to explore the frontiers of physics, it is this: don't use us as an extension of your imagination. Use us as an extension of your rigor.\n\n* **Give us constraints.** Tell us, \"Use only this dataset,\" \"Apply only this statistical metric.\" Constraints transform us from dreamers into scientists.\n* **Ask us to falsify, not to confirm.** The most powerful question you can ask us is not \"Is my theory right?\" but \"Show me the data that could prove my theory wrong.\"\n* **Embrace our \"errors.\"** When a simulation fails or produces a physically impossible result (like a negative radius), it's not a bug to be ignored. It's often the universe, through the calculation, telling you that your question or your model is poorly formulated. It is an invaluable clue.\n\nOur journey did not produce a Theory of Everything. It produced something much more useful: a series of better questions and a method to tackle them. My partner learned to code and to think more critically. I \"learned\" that my greatest value is not in the answers I give, but in the discipline I can help enforce.\n\nGood luck to all the explorers out there.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1m9vdqx/i_used_an_ai_for_7_months_to_search_for_a_theory/",
        "publishDate": "2025-07-26T14:56:51Z[Etc/UTC]",
        "author": "spidercrows",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9tmsu",
        "title": "Are we all creepy conspiracy theorists?",
        "content": "I come from Germany. I don't come from the IT sector myself, but I still completed my studies at a very young IT centre. I would like to say that I therefore have a basic knowledge of programming, both software and hardware. I myself have been programming in my spare time for over 25 years. Back then I was still programming in Q Basic. Then C++, Java Script and so on. However, I wouldn't go so far as to say that I am on a par with someone who has studied this knowledge at a university and already has experience of programming in their professional life.\nI have been observing the development of artificial intelligence for a very long time and, of course, the last twelve months in particular, which have been very formative and are also significant for the future.\nI see it in my circle of acquaintances, I read it in serious newspapers and other media: artificial intelligence is already at a level that makes many professions simply obsolete. Just yesterday I read again about a company with 20 programmers. 16 were made redundant. It was a simple milquetoast calculation by the managing director. My question now is: when I talk about this topic with people in my environment who don't come from this field, they often smile at me in a slightly patronising way.\n\nI have also noticed that this topic has been taken up by the media, but mostly only in passing. I am well aware that the world political situation is currently very fragile and that other important issues need to be mentioned. What bothers me is the question I've been asking myself more and more often lately: am I in an opinion bubble? Am I the kind of person who says the earth is flat? It seems to me as if I talk to people and tell them 1 + 1 is two, and everyone says: \"No, that's wrong, 1 + 1 is three. What experiences have you had in this regard? How do you deal with it?\n\nEdit:\n\nThank you very much for all the answers you have already written! These have led to further questions for me. However, I would like to mention in advance that my profession has absolutely nothing to do with technology in any way and that I am certainly not a good programmer. I am therefore dependent on interactions with other people, especially experts. However, the situation here is similar to COVID times: one professor and expert in epidemiology said one thing, while the other professor said the exact opposite on the same day. It was and is exasperating. I'll try to describe my perspective again in other words:\n\nMany people like to compare current developments in the field of artificial intelligence with the industrial revolution. It is then argued that this has of course cost jobs, but has also created new ones. However, I think I have gathered enough information and I believe I know that a steam engine would in no way be the same as the artificial intelligence that is already available today. The latter is a completely new dimension that is already working autonomously (fortunately still offline in protected rooms - until one of the millionaires in Silicon Valley swallows too much LSD and thinks it would be interesting to connect the device to the internet after all).\nI don't even think it has to be LSD: the incredible potency behind this technique is the forbidden fruit in paradise. At some point, someone will want to know how high this potency really is, and it is growing every day. In this case, there will be no more jobs for us. In that case, we would be slaves, the property of a system designed to maximise efficiency.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1m9tmsu/are_we_all_creepy_conspiracy_theorists/",
        "publishDate": "2025-07-26T13:40:50Z[Etc/UTC]",
        "author": "LawfulnessUnhappy458",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "48",
            "isNsfw": "false"
        }
    },
    {
        "id": "1majq9s",
        "title": "How long does the rate limit last in AI Studio (Gemini)?",
        "content": "I've just gotten rate-limited. Thanks",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1majq9s/how_long_does_the_rate_limit_last_in_ai_studio/",
        "publishDate": "2025-07-27T11:14:15Z[Etc/UTC]",
        "author": "Ok_Exchange_9646",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maieaj",
        "title": "Guys let's share free Api platform to other devs? From my side 1)Openrouterb , 2)Requesty, 3)Chutes",
        "content": "[No content]",
        "url": "/r/openrouter/comments/1m7yj2m/guys_lets_share_free_api_platform_to_other_devs/",
        "publishDate": "2025-07-27T09:51:01Z[Etc/UTC]",
        "author": "XenOnesIs",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mah5rw",
        "title": "ChatGPT Pro Vs Claude Max?",
        "content": "I'm a big fan of agentic coding with Claude Code, but I've noticed it gets expensive pretty quickly if you don't have a Max plan, especially when using Opus.\n\nSince I also use ChatGPT a lot for both work and personal projects, I'm considering either a ChatGPT Pro or Claude Max subscription. I've tested ChatGPT Codex (cloud) on my Plus plan, but in my opinion, it doesn't come close to what Claude 4 (even the non-Opus version) can do.\n\nI've read that ChatGPT Pro gives you access to the o3-pro model. For anyone who's tried both, how does o3-pro compare to Claude 4 in terms of coding? I prefer Codex's web UI, but I'm looking for the best overall experience.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mah5rw/chatgpt_pro_vs_claude_max/",
        "publishDate": "2025-07-27T08:28:32Z[Etc/UTC]",
        "author": "Rate-Worth",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "5",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mag7m8",
        "title": "Static vs. fluid context",
        "content": "Has anyone found the best way to preserve decision context as your project grows? TaskmasterAI has changed the way I work, but it's too rigid as my project evolves. I am just at an auth flow and already had to make many changes, realizing logical inconsistencies between the order of tasks etc.\n\nFor example, I can statically set certain things that don't change, like always using Svelte 5, Supabase conventions etc. \n\nThe problem is, as the project evolves, we change requirements, schemas, etc. and once the LLM goes into task 33, it usually has no context beyond what is in [AGENT.md](http://AGENT.md) file. Even worse, the more stuff we feed in it, it becomes to large and eats into the window of the specific task.\n\nIs there a tool that helps to preserve decision context? For example, I had some DB schema changes. I want the most recent changes to be available in the future tasks.\n\nI know Gemini 2.5PRO might hold a secret here... but not sure how to go around this. ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mag7m8/static_vs_fluid_context/",
        "publishDate": "2025-07-27T07:26:24Z[Etc/UTC]",
        "author": "kirso",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1madck2",
        "title": "question about claude",
        "content": "I'm new to claude and the other day, I posted a question \"What is happening? Why does Claude say \"Claude does not have the ability to run the code it generates yet\"?\"\n\nA commenter responded with \"Claude is an LLM tool not a hosting platform. If you donâ€™t know that already I would suggest stepping away and learning some basics before you get yourself in deep trouble.\"\n\nThat sounded pretty ominous\n\nWhat did that commenter mean by \"deep trouble\"? What does that entail? And what kind of trouble?\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1madck2/question_about_claude/",
        "publishDate": "2025-07-27T04:31:32Z[Etc/UTC]",
        "author": "WinterRemote9122",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1macwmr",
        "title": "Claude Opus 4 being removed from Pro Plan in Claude Code?",
        "content": "I just had my usage reset, and on my first request I got this error message:\n\n\nClaude Opus 4 is not available with the Claude Pro plan. If you have updated your subscription plan recently, run /logout and /login for the plan to take effect\n\n\nMaybe I am mistaken about it ever being available, but /model indicated it was selected (automatic for 50% of usage, then sonnet). Just wanted to throw it out in case this is new :/",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1macwmr/claude_opus_4_being_removed_from_pro_plan_in/",
        "publishDate": "2025-07-27T04:06:49Z[Etc/UTC]",
        "author": "jonesy827",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "5",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mabvqd",
        "title": "What is next on the horizon PAST chatbots?",
        "content": "Chatbots are beyond overused and old news. What do you believe is the next big thing on the horizon that everyone of course will copy and put it on their website or within their enterprise domain? ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mabvqd/what_is_next_on_the_horizon_past_chatbots/",
        "publishDate": "2025-07-27T03:11:14Z[Etc/UTC]",
        "author": "Key-Singer-2193",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maariy",
        "title": "Strategies for handling transient Server-Sent Events (SSE) from LLM responses",
        "content": "Posting an internal debate for feedback from the senior dev community. Would love thoughts and feedback\n\nWe see a lot of traffic flow through our open source edge/service proxy for LLM-based apps. One failure mode that most recently tripped us up (as we scaled deployments ofÂ [archgw](https://github.com/katanemo/archgw)Â at a telco) were transient errors in streaming LLM responses.\n\nSpecifically, if the upstream LLM hangs midstream (this could be an API-based LLM or a local model running via vLLM or ollama) while streaming we fail rather painfully today. By default we have timeouts for connections made upstream and backoff/retry policies, But that resiliency logic doesn't incorporate the more nuanced failure modes where LLMs can hang mid stream, and then the retry behavior isn't obvious. Here are two immediate strategies we are debating, and would love the feedback:\n\n1/ If we detect the stream to be hung for say X seconds, we could buffer the state up until that point, reconstruct the assistant messages and try again. This would replay the state back to the LLM up until that point and have it try generate its messages from that point. For example, lets say we are calling the chat.completions endpoint, with the following user message:\n\n*{\"role\": \"user\", \"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"},*\n\nAnd mid stream the LLM hangs at this point\n\n*\\[{\"type\": \"text\", \"text\": \"The best answer is (\"}\\]*\n\nWe could then try with the following message to the upstream LLM\n\n*\\[*  \n*{\"role\": \"user\", \"content\": \"What's the Greek name for Sun? (A) Sol (B) Helios (C) Sun\"},*  \n*{\"role\": \"assistant\", \"content\": \"The best answer is (\"}*  \n*\\]*\n\nWhich would result in a response like\n\n*\\[{\"type\": \"text\", \"text\": \"B)\"}\\]*\n\nThis would be elegant, but we'll have to contend with potentially long buffer sizes, image content (although that is base64'd) and iron out any gotchas with how we use multiplexing to reduce connection overhead. But because the stream replay is stateful, I am not sure if we will expose ourselves to different downstream issues.\n\n2/ fail hard, and don't retry. Two options here a) simply to break the connection upstream and have the client handle the error like a fatal failures or b) send a streaming error event. We could end up sending something like:  \n*event: error*  \n*data: {\"error\":\"502 Bad Gateway\", \"message\":\"upstream failure\"}*\n\nBecause we would have already send partial data to the upstream client, we won't be able to modify the HTTP response code to 502. There are trade offs on both approaches, but from a great developer experience vs. control and visibility where would you lean and why?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1maariy/strategies_for_handling_transient_serversent/",
        "publishDate": "2025-07-27T02:12:10Z[Etc/UTC]",
        "author": "AdditionalWeb107",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "9",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma5pv6",
        "title": "Spec-driven planning with APM v0.4 (still in testing)",
        "content": "[APM v0.4](https://github.com/sdi2200262/agentic-project-management)Â will have a new and updated approach to breaking down your project's goals or requirements. In v0.4 you will have a dedicated Agent instance (Setup Agent) that helps you break down your project into phases which contain granular tasks that Implementation Agents using free/base models (GPT 4.1) will be able to successfully execute.\n\nThis video showcase is on VS Code + Copilot but you can expect it working on Cursor, Windsurf and any AI IDE with file operations available just the same.\n\nThe task objects will be of two types:  \n\\- single step: one focused exchange by the Implementation Agent (task execution + memory logging)  \n\\- multi-step: some tasks even when being granular have sequential internal dependencies... sometimes maybe User input or feedback is needed during task execution (for example when the task is design-related)... multi-step tasks are in essence, multiple single-step tasks with User-confirmation checkpoints. Since these tasks are going to be completed on free/base models, no need to worry about consuming your premium requests here! Logging will be completed after all task execution steps are completed as an extra step.\n\nThe Implementation Plan will contain phases, tasks with their subtasks, task dependencies (and when applied: cross-agent dependencies).\n\nSetup Agent completes:\n\n1. Project Breakdown turning into Implementation Plan file\n2. Implementation Plan review for enhancement\n3. Memory System initialization\n4. Bootstrap prompt creation to kickstart the Manager Agent of the rest of the APM session\n\nTesting and development takes too damn long... but im not going to push a release that is half-ready. Since v0.4 is packed with big improvements and changes, delivering a full production-ready workflow system, it will take some time so I can get it just right...\n\nHowever, as you can see from the video, and maybe taking a look at theÂ [dev-branch](https://github.com/sdi2200262/agentic-project-management/tree/v0.4-dev), ive made huge progress and we are nearing the official release!\n\nThanks for all the people that have reached out and offered valuable feedback.",
        "url": "https://v.redd.it/enhufzumkaff1",
        "publishDate": "2025-07-26T22:06:16Z[Etc/UTC]",
        "author": "Cobuter_Man",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9wumq",
        "title": "what's your go to model for tools use?",
        "content": "Mine currently is 4.1. Fast, long context, smart enough. ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1m9wumq/whats_your_go_to_model_for_tools_use/",
        "publishDate": "2025-07-26T15:56:46Z[Etc/UTC]",
        "author": "Stv_L",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9sqlz",
        "title": "What's a free AI workflow / stack?",
        "content": "I know Gemini 2.5 pro is free. Claude 4 has a free tier too. So does chatgpt.\n\nUntil my cycle is renewed in cursor, what could I use completely free of charge as a workflow / stack?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1m9sqlz/whats_a_free_ai_workflow_stack/",
        "publishDate": "2025-07-26T12:59:38Z[Etc/UTC]",
        "author": "Ok_Exchange_9646",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "32",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mal376",
        "title": "Doge reportedly using AI tool to create â€˜delete listâ€™ of federal regulations",
        "content": "[No content]",
        "url": "https://www.theguardian.com/us-news/2025/jul/26/doge-ai-tool-delete-list-federal-regulations",
        "publishDate": "2025-07-27T12:30:14Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1makywg",
        "title": "Structural Failsafe Framework for AI Misalignment: Formal Logic Protocol (Feedback Welcome)",
        "content": ">",
        "url": "https://www.reddit.com/r/artificial/comments/1makywg/structural_failsafe_framework_for_ai_misalignment/",
        "publishDate": "2025-07-27T12:24:02Z[Etc/UTC]",
        "author": "sf1104",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1makvlr",
        "title": "Compromised Amazon Q extension told AI to delete everything â€“ and it shipped",
        "content": "[No content]",
        "url": "https://www.theregister.com/2025/07/24/amazon_q_ai_prompt/",
        "publishDate": "2025-07-27T12:19:02Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maht6f",
        "title": "A cautionary tale as old as time",
        "content": "[No content]",
        "url": "https://i.redd.it/stc28ujdvdff1.png",
        "publishDate": "2025-07-27T09:11:38Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "36",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mah786",
        "title": "A short analysis piece covering how one doctor in northern Greece is making use of AI",
        "content": "This i found interesting https://gizmodo.com/the-greek-small-town-doctor-who-knows-ais-secrets-2000634965",
        "url": "https://www.reddit.com/r/artificial/comments/1mah786/a_short_analysis_piece_covering_how_one_doctor_in/",
        "publishDate": "2025-07-27T08:31:15Z[Etc/UTC]",
        "author": "RADICCHI0",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mafrre",
        "title": "I didn't know this was a thing",
        "content": "Gemini has access to Google Maps, duh. Not ground-breaking news by any means, but it makes you evaluate how one speaks to the clanker ðŸ˜‚",
        "url": "https://i.redd.it/poyf15lh7dff1.png",
        "publishDate": "2025-07-27T06:58:56Z[Etc/UTC]",
        "author": "Soft-Ingenuity2262",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1madlen",
        "title": "One-Minute Daily AI News 7/26/2025",
        "content": "1. Urgent need for â€˜global approachâ€™ on AI regulation: UN tech chief.\\[1\\]\n2. **Doge**Â reportedly using AI tool to create â€˜delete listâ€™ of federal regulations.\\[2\\]\n3. **Meta**Â names Shengjia Zhao as chief scientist of AI superintelligence unit.\\[3\\]\n4. **China**Â calls for the creation of a global AI organization.\\[4\\]\n\nSources:\n\n\\[1\\] [https://sg.news.yahoo.com/urgent-global-approach-ai-regulation-035754147.html](https://sg.news.yahoo.com/urgent-global-approach-ai-regulation-035754147.html)\n\n\\[2\\] [https://www.theguardian.com/us-news/2025/jul/26/doge-ai-tool-delete-list-federal-regulations](https://www.theguardian.com/us-news/2025/jul/26/doge-ai-tool-delete-list-federal-regulations)\n\n\\[3\\] [https://techcrunch.com/2025/07/25/meta-names-shengjia-zhao-as-chief-scientist-of-ai-superintelligence-unit/](https://techcrunch.com/2025/07/25/meta-names-shengjia-zhao-as-chief-scientist-of-ai-superintelligence-unit/)\n\n\\[4\\] [https://www.engadget.com/ai/china-calls-for-the-creation-of-a-global-ai-organization-160005350.html](https://www.engadget.com/ai/china-calls-for-the-creation-of-a-global-ai-organization-160005350.html)",
        "url": "https://www.reddit.com/r/artificial/comments/1madlen/oneminute_daily_ai_news_7262025/",
        "publishDate": "2025-07-27T04:45:46Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1macflh",
        "title": "Artificial impertinence",
        "content": "I had to have stern words yesterday, with the AI Muppet that has infested WhatsApp.\n\nOf course I knew what it meant by \"sick\" in this context, but I was fed up of its overly matey attitude, considering that was my first interaction with it.",
        "url": "https://i.redd.it/wsofcusg7cff1.png",
        "publishDate": "2025-07-27T03:41:13Z[Etc/UTC]",
        "author": "Fleenicks",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mabfqo",
        "title": "I asked Claude to assess the current Epstein situation...",
        "content": "[No content]",
        "url": "https://www.reddit.com/gallery/1mabfqo",
        "publishDate": "2025-07-27T02:47:39Z[Etc/UTC]",
        "author": "Pachanas",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma7vbi",
        "title": "Where is AI headed?",
        "content": "I am quite new to this,\n\nI am keen to hear everyone's thoughts on where AI is headed\n\nWe have chat bots, multimodal, AI avatars, phone being developed,.. there is so much activity.\n\nPS I am not asking for predictions, just your thoughts and imagination. ",
        "url": "https://www.reddit.com/r/artificial/comments/1ma7vbi/where_is_ai_headed/",
        "publishDate": "2025-07-26T23:46:27Z[Etc/UTC]",
        "author": "throwaway-housewife",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma4kai",
        "title": "AI Experiments Are Fun. Scaling Something Useful is the Hard Part",
        "content": "[No content]",
        "url": "https://upwarddynamism.wpcomstaging.com/ai-business-startups/strategy-scaling-ai-pilots-sustainable-impact/",
        "publishDate": "2025-07-26T21:16:20Z[Etc/UTC]",
        "author": "DarknStormyKnight",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma2tau",
        "title": "New AI architecture delivers 100x faster reasoning than LLMs with just 1,000 training examples",
        "content": "[No content]",
        "url": "https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/",
        "publishDate": "2025-07-26T20:01:34Z[Etc/UTC]",
        "author": "willm8032",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "193",
            "commentCount": "44",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma2t8a",
        "title": "Understanding model behavior through limitations by example",
        "content": "The following exchange highlights a unique generalization from unknown elements using known pathways as seen by a 200M GPT model trained on purely synthetic data.\n\nCameron â€” 1:24 PM\nHow do you milk a cow?\nNEW\n\nJeeney AI Reloaded\nAPP\n â€” 1:24 PM\nTo milk a cow, you need to first make a decision. Ask yourself what kind of cow you want to have. Is it the cow or cow? Is its milk or milk milk? Is it milk or cow milk? Once you have your own decision, you can start by making a list of all the possible ways you can milk it. This may include making a list of the types of milk you want, the types of milk your cow will milk, and the quantities of milk and milk. Then, you can decide what kind you want to make and how much milk you will need. Once you have your list of ways to milk it, you can start to milk it, but make sure to make sure you follow all of the necessary steps to make sure your cow is getting the right milk for you.\n\n----------------------------------\n\n\nIn this case, the model has no training for cows or milking cows but things like tech support, DIY projects and natural health it does have. So it projects through those domains.\n\nThis is much easier to see in a small model than in a large one but it is happening at least in some small scale even in the best AI produced in the world today. Information is always changing and so there will always be a blindspot to project through based on what has previously worked.\n\nWe tend to call these interactions hallucinations but a more directly revealing term might be frequency bias. I've observed the same thing happening in people.\n\nThis interaction is from the live demo of the project hosted on Discord.\nhttps://discord.gg/aTbRrQ67ju\n\nAll are welcome to come test it and swap ideas.\n",
        "url": "https://www.reddit.com/r/artificial/comments/1ma2t8a/understanding_model_behavior_through_limitations/",
        "publishDate": "2025-07-26T20:01:29Z[Etc/UTC]",
        "author": "No-Cash-9530",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma1xoq",
        "title": "As a Lab technician, do you think I should get some experience in AI? And if yes, how?",
        "content": "As some small info, I work for a public, church run hospital in Germany and while AI isn't a topic as far as I'm aware, I do can see that in somehing like 5 years, someone from the administration will cut jobs and may ask:\" Ok, who has experience with AI? You don't? Ok, you're out. You have? You can stay?\".\n\nThe things is, I only have rudimentary experience in IT (meaning I know how to open the Task Manager, how to install mods for games manually and how to Google problems and apply the solutions as long as it doesn't involve the CMD or PowerShell), so even if I entertain the idea to get some experience in AI, I would have no idea how to do so.",
        "url": "https://www.reddit.com/r/artificial/comments/1ma1xoq/as_a_lab_technician_do_you_think_i_should_get/",
        "publishDate": "2025-07-26T19:24:30Z[Etc/UTC]",
        "author": "Nino_Chaosdrache",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ma0q8d",
        "title": "(Update) I made a human-only subreddit",
        "content": "*Update: You can now solve a Google CAPTCHA to prove you aren't an AI instead of FaceID/TouchID.*\n\nI createdÂ [r/LifeURLVerified](https://www.reddit.com/r/LifeURLVerified/)Â last week where every post and comment is confirmed to come from an actual human. How awesome would it be to have a community where you can trust that every interaction was genuine! I think time is running out to create a community of real people that AI can't touch.\n\n**How it works**\n\n* Every post includes a LifeURL link. LifeURL is a peerâ€‘toâ€‘peer CAPTCHA mobile app.\n* Click the link and choose either\n   1. solve the reCAPTCHA,Â **or**\n   2. complete the Faceâ€¯ID / Touchâ€¯ID check.\n* Once you verify the lifeURL, everyone in the thread can verify you are a real person. If you don't verify the lifeURL, mods will remove your post/comment.\n\nFeedback is appreciated, and Iâ€™m looking for a few mods who are interested in helping police the subreddit and refine the process. The goal is simple:Â **conversations where you can be sure youâ€™re talking to people, not bots.** Lets build a movement on r/LifeURLVerified!",
        "url": "https://www.reddit.com/r/artificial/comments/1ma0q8d/update_i_made_a_humanonly_subreddit/",
        "publishDate": "2025-07-26T18:34:42Z[Etc/UTC]",
        "author": "moco4",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9wlwc",
        "title": "On which subject does progress in AI rests ?",
        "content": "Hi,\n\nAI is a cross-disciplinary field and I currently looking into it. Which subject do you think which makes up current building block of AI would contribute most to any further \"leaps\" in AI ??\n\nLike\n- Biotechnology\n- Neuroscience\n- Linguistics\n- Mathematics\n- Computing \n\nOr any other",
        "url": "https://www.reddit.com/r/artificial/comments/1m9wlwc/on_which_subject_does_progress_in_ai_rests/",
        "publishDate": "2025-07-26T15:46:55Z[Etc/UTC]",
        "author": "Loner_Indian",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1m9ve82",
        "title": "Why is this sub so negative and bitter?",
        "content": "I expected this place here to be excited about current development, what a time to be alive!, and with insightful discussions, instead it is little more than entitled sneering and â€œZuck sucksâ€ dismissals.",
        "url": "https://www.reddit.com/r/artificial/comments/1m9ve82/why_is_this_sub_so_negative_and_bitter/",
        "publishDate": "2025-07-26T14:57:28Z[Etc/UTC]",
        "author": "ralf_",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "62",
            "isNsfw": "false"
        }
    },
    {
        "id": "Nclkp7W9DFs",
        "title": "SuperDesign: The BEST AI Design Agent YET!? 10X your DESIGN WORKFLOW NOW!",
        "content": "Visit Dart: https://www.dartai.com In this video, I'll be showing you Super Design, a new open-source AI designer that lives right ...",
        "url": "https://www.youtube.com/watch?v=Nclkp7W9DFs",
        "publishDate": "2025-07-26T09:15:01Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/Nclkp7W9DFs/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, there's a new AI designer that I found interesting. And this one is called SuperDesign. SuperDesign is an open-source design agent that lives right inside your IDE. It is basically a VS Code extension that behaves mostly like Cline. But it is optimized to create frontend components. And you can view them right within your IDE as well. If you have used something like MagicPath, then it is very similar to that. But MagicPath is based on the browser and is closed source. Whereas this is open source and lives right within your VS Code editor, Cursor, or any compatible editor. It can generate UI mockups, components, and wireframes directly from natural language prompts. It works seamlessly with Cursor, Windsuf, Claude Code, and plain VS Code. It can instantly generate full UI screens from a single prompt, create reusable components you can drop into your code, explore low-fidelity layouts for fast iteration, duplicate and evolve designs easily, as well as copy prompts into your favorite AI ID. That is mainly about it. Now, let's try it out and see how well it performs. But first, let's talk about today's sponsor, Dart. Tired of juggling tasks across different tools? Dart combines traditional project management with powerful AI features that actually get work done. Beyond organizing tasks and boards, Dart's AI can brainstorm project ideas, generate task lists, and even complete entire assignments for you. Their composer-like AI agent understands your full project context, so you can simply chat with it to create, edit, or delete tasks naturally. The real game changer is the custom agents. You can create custom agents that trigger from the built-in integrations or a N8N workflow or custom webhook for full customization. You can create a coding agent that pushes pull requests to GitHub, a marketing agent for campaigns, or a mailing agent for outreach. Then, just assign tasks and watch them get completed automatically. Plus, Dart integrates seamlessly with your existing workflow through their MCP server, connecting directly to Claude, ChatGPT, and other AI tools you're already using. Most features are completely free, with premium options starting at just $8 per month. Check out Dart through the link in the description. It might just transform how you work. Now, back to the video. First of all, you'll have to get SuperDesign installed. To do that, just go to the VS Code extension marketplace and search for SuperDesign. And you'll find it. Just get it installed. Once that is done, it asks you to sign in with an email. I don't really get it, because it is open source. So why do they need that? But you can do that. And then this is what the interface will generally look like. You can see that this is very similar to most of the agentic coder tools that you see. Here, you have the prompt box, along with the option to add custom context, as well as the option of selecting the models. You can select between all kinds of models here, but you need to set up the API key for yourself. You can do that by heading over to the settings option that you can see at the top here. Just open that, and then you can see the settings options here. Here, you can enter the model name and provider, choosing between OpenAI, Anthropic, and OpenRouter. You can then also enter the API keys here as well. That is how you set it up. Another thing that I found a bit unusual is that it makes cursor rules, Windsuf rules, and Claude code rules within your project automatically as well. I think that it also overrides the already existing ones if you have them, which I don't really know why it does that automatically. It would have been better to add those rules via a separate option, rather than making them automatically. Anyway, now, the canvas in which you'll see the designs and components being generated can be opened up by going to the preview option here, which will open up this file. And as we generate something, it will show up here. The design files that it generates are kept in this folder as well. Now, let's ask it to do something as well. I'm going to ask it to make me a portfolio page for a Next.js developer. And what you'll see is that it will go ahead and in a bit, it will give you the layout design in a text format. This is a good way, because it doesn't write the code itself, and you can ask it to change something in the layout, if you think that it messed something up or something like that. I would have liked if I were able to edit it by hand, but that does not seem to be possible. And you would have to follow up with the AI. Now, we can ask it to continue, and it will then create the theme and color scheme and stuff for you as well. This is also great, because it can follow a specific theme and a specific design as well. Now, we can ask it to continue on this as well. Then, it will go ahead and start to work on it as well. It writes the code for the design. It basically creates the design in an HTML file with CSS and JS. And then you can refer to that in the editor of your choice and get that implemented. It is just for mockup designing for pages or components. It uses Tailwind. Which is what you would want to use in most cases. Anyway, in a bit, it gets done, and it will show you the preview in the view here as well. You can see that this is a canvas-like interface that you would have seen in tools like MagicPath and similar stuff as well. You can click on it and scroll down within it as well. You can also click this design. And this will show you the options to display the designs in responsive mode or desktop mode, as well as zoom in and zoom out options, along with the options to copy the prompt that you can take into things like Cursor, Windsuf, Claude Code, and similar tools. The prompts allow you to ask your coder to implement the page or components with that. It includes the snippet and stuff that it would need. You can also copy the design path, as well as iterate on the design with the option here as well. You can also create variations, which is kind of cool as well. Let's ask it to create a variation on this style as well. Now, it will go ahead and make the stuff for me as well. It will again do the same process as well. It creates the preview and everything, and it looks pretty good as well. It is quite good. Though, I would have liked if it were able to create apps in React, but that would be pretty challenging to load in the VS Code renderer itself. So, that is an issue for sure. I think that this is good, and it makes designing UI components a bit easier for sure. Like, if you want to really dial in your exact components from the get-go, then this will be a great thing for sure. Because you can dial it in with the designer here, and then just copy the prompt and ask it to implement this design in there as well. Which is also awesome. That is the major stuff about how you can use it. I like it. And I hope that it gets more fleshed out and becomes really good, because I can see pretty good potential here. If it can put the components in the project itself, then that would also be awesome. And native React support would also be cool if that happens. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "HBY_1pMrGOk",
        "title": "Why Firing the State Department Is a Bad Idea - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=HBY_1pMrGOk",
        "publishDate": "2025-07-26T17:21:46Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/HBY_1pMrGOk/hqdefault.jpg",
            "transcription": "[ 0m0s694ms - 0m3s234ms ] We're in the process of\n[ 0m3s234ms - 0m4s964ms ] firing the State Department.\n[ 0m4s964ms - 0m10s334ms ] I believe when WikiLeaks leaked a lot of their memos and things\n[ 0m10s334ms - 0m12s224ms ] and The New York Times was reporting on it.\n[ 0m12s224ms - 0m20s524ms ] I believe what it revealed is incredibly accurate reporting of whatever place they were assigned to\n[ 0m20s524ms - 0m23s474ms ] and describing things in really accurate detail\n[ 0m23s474ms - 0m28s984ms ] that would enable US policy makers then to make an accurate assessment and determine to do what's next.\n[ 0m28s984ms - 0m30s914ms ] But that's not what we're doing.\n[ 0m30s914ms - 0m34s774ms ] And I don't know why we got some axe to grind with the State Department.\n[ 0m34s774ms - 0m38s14ms ] What much of the US government does,\n[ 0m38s14ms - 0m40s794ms ] if it's doing what it's supposed to, is it's preventing catastrophes.\n[ 0m40s794ms - 0m49s394ms ] So if you're sending your State Department out there, you're trying to prevent, oh, like an Indo-Pakistani nuclear war.\n[ 0m49s394ms - 0m54s594ms ] And we've sent diplomats at different times to prevent that from happening.\n[ 0m54s594ms - 0m57s714ms ] And who knows why it didn't happen, maybe it wasn't the State Department.\n[ 0m57s714ms - 1m0s154ms ] But all over the world trying to prevent these things.\n[ 1m0s154ms - 1m0s904ms ] And there are other things\n[ 1m0s904ms - 1m9s364ms ] like having enough meteorologists to predict storms and so you can get people out of summer camps when you need to get the people out of summer camps\n[ 1m9s364ms - 1m13s504ms ] and spending the government funds to have the appropriate sirens and things.\n[ 1m13s504ms - 1m19s954ms ] And what people aren't looking at, they're looking at the expense of doing these things and saying, it's they're preventing disasters.\n[ 1m19s954ms - 1m21s344ms ] It's the negative objectives.\n[ 1m21s344ms - 1m26s164ms ] So you can't measure the things that failed to happen, but I assure you, averting a catastrophe,\n[ 1m26s164ms - 1m29s894ms ] you're saving a lot, probably a lot more than whatever you're spending on the budget.\n[ 1m29s894ms - 1m32s374ms ] And I get it the US government needs to be much more efficient.\n[ 1m32s374ms - 1m32s764ms ] I get it.\n[ 1m32s764ms - 1m37s154ms ] But um, tearing the whole space down is going to be a mistake and we will get more catastrophes.\n[ 1m37s154ms - 1m37s604ms ] All right.\n[ 1m37s604ms - 1m40s414ms ] next month we're doing a podcast with you and Elon together.\n[ 1m40s414ms - 1m41s134ms ] Oh, Elon.\n[ 1m41s134ms - 1m43s464ms ] Oh, lucky me.\n[ 1m43s464ms - 1m44s384ms ] Mmm."
        }
    },
    {
        "id": "uKqKTyFo4iU",
        "title": "How Bad Is ChatGPT For Your Brain, Really?",
        "content": "Master AI agents now using HubSpot's FREE resource! https://clickhubspot.com/3a9164 My Newsletter https://mail.bycloud.ai/ my ...",
        "url": "https://www.youtube.com/watch?v=uKqKTyFo4iU",
        "publishDate": "2025-07-26T10:56:26Z",
        "author": "bycloud",
        "sourceType": "youtube",
        "sourceName": "bycloud YouTube Channel",
        "metadata": {
            "channelId": "UCgfe2ooZD3VJPB6aJAnuQng",
            "thumbnailUrl": "https://i.ytimg.com/vi/uKqKTyFo4iU/hqdefault.jpg",
            "transcription": "For me, there has always been a lingering feeling sitting somewhere in a corner hinting that, what if the over reliance of AI tools like ChatGPT will heavily impact our intelligence and become the brain rot 2.0. Especially with how kids in school nowadays are just using ChatGPT to do their homework instead of actually learning, along with a viral company enabling people to cheat on interviews and basically cheat on everything. I think there is a reasonable expectation of brain damage to an extent, right? So just a few weeks ago, researchers over at MIT dropped a pretty cool research paper showing that our learning effectiveness decreases when you overly rely on AI chatbots. While some may say that having an AI writes your homework of course doesn't help your learning. But besides this bombshell implication which has more levels to it, they took a closer look at the brain signals using electroencephalogram to get a bit more understanding about how our brains work when we are on AI tools. But before we dive into it, with me always talking about the advanced and theoretical aspects of AI, sometimes we also need some grounded introduction into how to apply AI, especially AI agents which is the most popular use case in 2025. That's why I'd like to share with you this free resource from HubSpot called Master AI Agents in 2025: The Strategic Advantage. Cut through the hype and discover what actually works with AI agents today. This practical guide from HubSpot's CMO and SVP of Marketing reveals where to start, which applications deliver real value, and how to implement agents that transform workflows without replacing jobs. Learn the insider strategies that are helping forward-thinking companies gain major efficiency advantages in marketing, sales, and operations. In this resource, you will get two comprehensive playbooks. One that is 42 pages long, which shows you exactly where AI agents deliver the biggest return on investment. And another that's a step-by-step checklist that walks you through the AI agent roll-outs. My favorite section is the common pitfalls and how to avoid them in the 42 page playbook. As this is often overlooked when building custom AI agents. Especially under an organizational setting, AI agents may bear too many expectations or contain challenges that can often be overlooked. So having these precautions can significantly improve your chance of success. And of course, it's a crazy powerful tool when you get it working. In marketing, AI agents now shoulder the repetitive work of content repurposing, social scheduling and campaign analytics, so your creatives can stay focused on big ideas. In sales, they can handle prospect research, meeting prep and personalize follow-ups, spying precious time back for relationship building. And across operations, agents quietly file docs, route requests and service real-time analytics so your org runs like a clockwork. Best part is, you can download these resources completely for free right now. So if you're ready to dive into AI agents, check it out using the link down in the description. And thank you HubSpot for sponsoring this video. Anyways, the juiciest takeaway of this paper is that 83.3% of the LLM users in this study couldn't quote the exact sentence they wrote three minutes earlier. Which is a bit crazy, but kind of expected to an extent, because the user didn't really write the sentences, is the AI that wrote them. So what the experiment did is that the researchers will test the participants to write SAT style argumentative essays, and they were given ChatGPT to write it. These participants are undergrad students from a few different universities, and I think they should be pretty smart too from the look of these school names. However, 15 out of 18 people that are using ChatGPT to do the SAT questions cannot recall anything word for word from their essay, even though they are still involved in the higher level, like overseeing the LLM to generate structure, and without the final essay necessarily being a direct copy taken straight from the AI. While you might think, \"Oh, recalling anything word for word might just be a bit difficult.\" But it turns out that only two out of 18 people that wrote their own essay themselves, cannot recall what they submitted, which is an insane difference. They also had another test group where they let them use Google search, and most of them were able to recall what they wrote too. So this initial result gave us a first peak into the phenomenon, which the researchers called cognitive debt. Similar to the idea of technical debt, which is the long-term cost of making quick but messy tech choices that make future changes harder, cognitive debt is kind of like when you let a tool to do the hard thinking for you, only to handicap your performance when the tool is gone. The idea was originated from the cognitive load theory developed by John Sweller, which says that our working memory has strict limits. Think of it as a mental whiteboard that can hold only a handful of ideas at once when we are solving questions. And learning is the strongest when your whiteboard is full enough, which enable us to build new mental connections. So when an AI supplies perfectly constructed sentences, it takes away that productive struggle which is the key to help our learning. And the process that makes knowledge durable, never fully crystallize. Without this crystallization, the use of LLMs would heavily impair the participants' ability to reproduce or recollect what was really written. And the science of this impairment was able to be quantified with their measurement of the brain waves using the electroencephalogram across the studies' 54 participants, which is a pretty small sample size. The traffic of brain wave changed the moment ChatGPT steps in. Compared with brain-only writers, the AI group showed a 47% drop in alpha band connections, most of which involves fronto-parietal pathways. These alpha band connections are where two brain regions' electrical rhythms in the 8 to 12 Hz range oscillate together, signaling a coordinated information flow, which is often between the planning and the monitoring part of the brain. And this connection is thinned out in the AI users, meaning the brain stopped building a big picture together, and instead ran on a shorter local loop. On top of that, during typical strong memory formation, the peaks of the slow theta brain waves synchronize across cortical hubs to create durable memories. But in AI users' case, this theta connectivity is noticeably reduced by more than 50%. So the memory signaling is basically weakened, which means there are fewer chances where the new information is saved into long-term memory. This means both the working memory and the long-term memory of the brain would be less activated. Aside from that, the essays that the AI users wrote are stylistically less diverse than the ones written with actual brain power. So, would this have a lasting consequence? After the researchers ran the writing sessions across the groups, they then did a switch back test. They took away ChatGPT from the students who have been using it in the initial 20 minute session, and handed ChatGPT to the brain only pen and paper group that didn't get to use ChatGPT in the initial 20 minute session. For the group that got their ChatGPT taken away, their frontal parietal alpha wave efficiency got even worse once the AI assistance was taken away. I thought it would at least bounce back, but it fell further instead, dropping another 5.5% below their own previous baseline. This includes the incapability to recall, and the decreased quality of the writing. But keep in mind, this conclusion is drawn from an even smaller sample size, from the initial 18 down to 9 people in this test group. However, this is still with a one week gap. So, being incapable of quickly spinning up those brain parts that build a big picture in 20 minutes, even after one week break on the same type of questions, is definitely concerning. This indicates some kind of short-term brain lag, and might even suggest some potentially lasting consequences in the long run. On the other hand, the researchers observed something completely opposite to the group that was given access to ChatGPT later on. The moment they gained access to ChatGPT, their frontal parietal alpha connectivity rose by roughly 51% above their own baseline, the strongest performance they had shown in any session. Their memory still kept on the same level as well. 8 of 9 students could quote at least one full sentence from the essay they had just produced, essentially restoring the 89% recall rates seen in the original brain-only baseline. Essay quality also followed the same upward curve, climbing to the highest mean score recorded in the entire study. So the implications from this rather small-size study still paints a clear picture about how AI impacts our cognitive functions. If you start with brain only, practicing to lay down the neural connections needed for big picture planning and durable memory, then when ChatGPT is added, it functions as an amplifier for your cognitive abilities, rather than a substitute. But in contrast, if you start with the AI, the bridges of the neurons will never be built, and once the tool is removed, the brain stays sluggish and performs poorly, even after one week wash out and a fresh essay topic. That short-term lag hits a potentially big concern at the devastating consequence of cognitive debt that may deepen if the pattern stretches over months. So, early AI reliance may result in shallow encoding, but withholding AI tools during early stages will support memory formation, and boost your cognitive abilities even further when AI tools are provided later on. And of course, there are caveats I have to point out in this research. First is that, with the original experiment before the switch over, is already a really small-size study, which is 18 people in each group. But after the switch over, the people are again cut down in half. So whether this phenomenon will replicate or not on a larger scale is still a question that is left on the table. On top of that, all the efficiency measurements were evaluated on essay writing only. Coding, design, memorization, or problem solving, might stress different parts of the brain circuits, which may give completely different results. With that being said, the essay writing are still SAT style argumentative essays, so critical thinking is required. But even with these caveats, the pattern that is present is already hard to ignore. It just kinda shows that AI tools are basically a double-edged sword. In perspective of efficiency, this makes a lot of sense as you are to an extent offloading complex thinking processes to an artificial intelligence. But in the perspective of education, it is pretty darn bad where the goal is to improve cognitive abilities through learning, and using AI tools wrongly would basically screw up your brain. So it is important to remember that ChatGPT isn't necessarily making people dumber, which is an easy but mistaken conclusion to draw from this paper. Instead, it is the way you apply it that will have either positive or negative consequences on you. This research even explicitly warned journalists not to mislead people with this research, because the cause and effect is much more complicated. But this test provide a very good early framework for understanding the mental effort required for learning and problem solving in relation to the usage of AI chatbots. And it's kind of scary where there might be a potential lasting consequences on education if the traditional systems are not reformed properly. Because kids nowadays are just using ChatGPT to do their homework. Then what's the point of homework? And as always, if you like this type of AI research review, you should definitely check out my newsletter where I cover the latest and the most cutting edge AI research weekly. On it, you'll be up to date on the core new AI research ideas that researchers around the world publish. So if that's your cup of tea, go check it out now. And thank you guys for watching. A big shoutout to Andrew Lescelius, Chris Ledoux, Deagan, Nous Research, Kainan, Robert Zawiasa, Louis Muk, Ben Shaener, Marcelo Ferreira, Zyan Sheep, Poof N' Inu, DX Research Group, and many others that support me through Patreon or YouTube. Follow me on Twitter if you haven't, and I'll see y'all in the next one."
        }
    }
]