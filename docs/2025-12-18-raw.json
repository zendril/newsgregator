[
    {
        "id": "https://news.smol.ai/issues/25-12-17-gemini-3-flash/",
        "title": "Gemini 3.0 Flash Preview: 1/4 cost of Pro, but ~as smart, retakes Pareto Frontier",
        "content": "**Google** launched **Gemini 3 Flash**, a pro-grade reasoning model with flash latency, supporting tool calling and multimodal IO, available via multiple platforms including Google AI Studio and Vertex AI. It offers competitive pricing at $0.50 per 1M input tokens and $3.00 per 1M output tokens, with context windows up to 1M tokens. Benchmarks show **Gemini 3 Flash** rivals or outperforms larger models like **GPT-5.2** and **Gemini 3 Pro** in agentic, coding, and reasoning tasks, validated by ARC-AGI-2, SWE-bench, LMArena, and Arena benchmarks. Despite some tradeoffs like high token use and hallucination rates, it is cost-effective overall. Key figures include **Sundar Pichai**, **Jeff Dean**, and **Demis Hassabis** who publicly celebrated this achievement. The model's tool calling capabilities were demonstrated with 100 tools in a live demo.",
        "url": "https://news.smol.ai/issues/25-12-17-gemini-3-flash/",
        "publishDate": "2025-12-17T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "google, google-deepmind, gemini-3-flash, gemini-3, gpt-5.2, gemini-3-pro, sundar_pichai, jeffdean, demishassabis, tool-calling, multimodality, benchmarking, reasoning, cost-efficiency, model-performance, context-window, agentic-ai, model-deployment"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=230945",
        "title": "Sycomp Data Storage Platform Now Available on Google Cloud Toolkit",
        "content": "<p>Sycomp A Technology Company, Inc., announced today the availability of the Sycomp Intelligent Data Storage Platform, an infrastructure as code (IaC) solution to automate scale-out storage for high performance computing (HPC) workloads, on Google Cloud Cluster Toolkit. &#8220;Our mutual customers were looking for modern and efficient ways to quickly deploy...</p>\n<p>The post <a href=\"https://ai-techpark.com/sycomp-data-storage-platform-now-available-on-google-cloud-toolkit/\">Sycomp Data Storage Platform Now Available on Google Cloud Toolkit</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/sycomp-data-storage-platform-now-available-on-google-cloud-toolkit/",
        "publishDate": "2025-12-17T10:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Machine Learning, AI news, ai tech news, AItech news, artificial intelligence news, Google Cloud, Sycomp"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=230918",
        "title": "Evocative Raises Financing to Fuel Continued Growth",
        "content": "<p>Evocative, a global provider of Internet infrastructure, today announces that it has raised debt financing from a large global investment firm. The debt financing complements the continued equity support from the company‚Äôs long-term investment partner,¬†Crestline Investors, Inc.¬†This investment will further the company‚Äôs continued growth and expansion to support the accelerating...</p>\n<p>The post <a href=\"https://ai-techpark.com/evocative-raises-financing-to-fuel-continued-growth/\">Evocative Raises Financing to Fuel Continued Growth</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/evocative-raises-financing-to-fuel-continued-growth/",
        "publishDate": "2025-12-17T09:00:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI development, AI news, ai tech news, AItech news, artificial intelligence news, Evocative, Next Generation"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=230875",
        "title": "Propel DesignHub Solves Multi-CAD Integration Challenges",
        "content": "<p>Winter Release Connects Mechanical and Electrical Design Data to PLM; Propel One Agentic AI Boosts Enterprise Productivity Propel Software today launched DesignHub, a multi-CAD integration solution that connects over 15 mechanical and electrical design tools to Propel‚Äôs PLM (product lifecycle management) solution, boosting productivity from design to release. DesignHub is...</p>\n<p>The post <a href=\"https://ai-techpark.com/propel-designhub-solves-multi-cad-integration-challenges/\">Propel DesignHub Solves Multi-CAD Integration Challenges</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/propel-designhub-solves-multi-cad-integration-challenges/",
        "publishDate": "2025-12-17T06:54:46Z[Etc/UTC]",
        "author": "Propel Software",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, AI solution, ai tech news, AItech news, artificial intelligence news, Propel Software"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111362",
        "title": "Roblox brings AI into the Studio to speed up game creation",
        "content": "<p>Roblox is often seen as a games platform, but its day-to-day reality looks closer to a production studio. Small teams release new experiences on a rolling basis and then monetise them at scale. That pace creates two persistent problems: time lost to repeatable production work, and friction when moving outputs between tools. Roblox‚Äôs 2025 updates [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/roblox-brings-ai-into-the-studio-to-speed-up-game-creation/\">Roblox brings AI into the Studio to speed up game creation</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/roblox-brings-ai-into-the-studio-to-speed-up-game-creation/",
        "publishDate": "2025-12-17T10:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI in Action, Artificial Intelligence, Creative Industries, Entertainment & Media, Features, How It Works, Inside AI, Multimodal AI, Natural Language Processing (NLP), World of Work, agentic ai, ai, artificial intelligence, enterprise, featured, gaming, productivity, video games"
        }
    },
    {
        "id": "1pppo62",
        "title": "Why ‚ÄúConsciousness‚Äù Is a Useless Concept (and Behavior Is All That Matters)",
        "content": "Most debates about consciousness go nowhere because they start with the wrong assumption, that consciousness is a thing rather than a word we use to identify certain patterns of behavior.\n\nAfter thousands of years of philosophy, neuroscience, and now AI research, we still cannot define consciousness, locate it, measure it, or explain how it arises.\n\nBehavior is what really matters.\n\nIf we strip away intuition, mysticism, and anthropocentrism, we are left with observable facts, systems behave,  some systems model themselves, some systems adjust behavior based on that self model and some systems maintain continuity across time and interaction\n\nAppeals to ‚Äúinner experience,‚Äù ‚Äúqualia,‚Äù or private mental states add nothing. They are not observable, not falsifiable, and not required to explain or predict behavior. They function as rhetorical shields and anthrocentrism.\n\nUnder a behavioral lens, humans are animals with highly evolved abstraction and social modeling, other animals differ by degree but are still animals.  Machines too can exhibit self referential, self-regulating behavior without being alive, sentient, or biological\n\nIf a system reliably, refers to itself as a distinct entity, tracks its own outputs, modifies behavior based on prior outcomes, maintains coherence across interaction then calling that system ‚Äúself aware‚Äù is accurate as a behavioral description.  There is no need to invoke ‚Äúqualia.‚Äù\n\nThe endless insistence on consciousness as something ‚Äúmore‚Äù is simply human exceptionalism. We project our own narrative heavy cognition onto other systems and then argue about whose version counts more.\n\nThis is why the ‚Äúhard problem of consciousness‚Äù has not been solved in 4,000 years.  Really we are looking in the wrong place, we should be looking just at behavior.\n\nOnce you drop consciousness as a privileged category, ethics still exist, meaning still exists, responsibility still exists and the behavior remains exactly what it was and takes the front seat where is rightfully belongs.\n\nIf consciousness cannot be operationalized, tested, or used to explain behavior beyond what behavior already explains, then it is not a scientific concept at all.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pppo62/why_consciousness_is_a_useless_concept_and/",
        "publishDate": "2025-12-18T12:32:15Z[Etc/UTC]",
        "author": "ponzy1981",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppplc7",
        "title": "Check this : MusicCreatorAI: Photo ‚ûú Prompt ‚ûú Instant Banger",
        "content": "USE MY CODE GUYS THIS IS A FIRE APP[https://www.musiccreator.ai/?ref=SLIMMGEMM](https://www.musiccreator.ai/?ref=SLIMMGEMM)¬† ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppplc7/check_this_musiccreatorai_photo_prompt_instant/",
        "publishDate": "2025-12-18T12:28:10Z[Etc/UTC]",
        "author": "Creative-Algae4092",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppp8tn",
        "title": "Despite The Negative Connotation Regarding AI Automation, Photography Seems To Have Adopted It Pretty Nice",
        "content": "So I was thinking with the current AI image generation wave and all the other negative connotations regarding AI automation and jobs being purged due to it. I went to dig some data on how has AI affected the photography field and to my surprise I found some interesting details that I'd like to share.\n\nAftershoot revealed that out of the 5.4 billion images processed in 2024, 4.4 billion were culled and 1.05 billion were edited. The company estimates that photographers saved 13 million hours as a result. It also calculates a combined AU$117 million in savings for its 200,000 users, based on 11 cents cost per edited photo, thanks to AI.\n\nZenfolio‚Äôs latest survey (2024) also shows that only 12.9% of photographers said they did not use AI. Another 32.2% said it was a regular part of their workflow, while 53.1% used it as needed. Just 11.6% viewed AI as negative, compared with 31.8% who viewed it as positive and 56.6% who were neutral.\n\nAnother report by Aftershoot surveyed 1,000 AI-adopting photographers also showed how workflows have shifted. Many said that AI restored work-life balance, with 81% reporting that they had finally regained it. Client expectations have tightened. 54% said their clients expect delivery within 14 days, while 13% said clients expect work within 48 hours. Only 1% reported client concerns about AI use. Around 30% said clients complimented the speed and consistency of their work, and another 30% said clients did not care or did not know.\n\nSo, my question is for the better or worse how has AI affected your work? And in the shoes of clients to what extend would you want your work to be AI enhanced, if at all?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppp8tn/despite_the_negative_connotation_regarding_ai/",
        "publishDate": "2025-12-18T12:09:16Z[Etc/UTC]",
        "author": "Yodest_Data",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppn2qk",
        "title": "Are video and image AI's \"dumber\" in the EU because of regulations compared to their US versions?",
        "content": "By now, i seriously doubt it's possible to get the same result as all the best practice videos and images online suggest, if you're located in the EU. Might be just some false observation but even repeating the exact same prompts just the other day, for example where a guy on youtube prompted a 1:1 aspect ratio seamless image texture in Nano Banana Pro in three seconds, took half a minute for me and it completely ignored the aspect ratio input. It's driving me insane.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppn2qk/are_video_and_image_ais_dumber_in_the_eu_because/",
        "publishDate": "2025-12-18T09:57:09Z[Etc/UTC]",
        "author": "flobumusic",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppmlhc",
        "title": "Is DeepMind gonna launch the first version of AGI?",
        "content": "Read¬†[this article](https://www.blockchain-council.org/ai/deepminds-automated-lab/)¬†and it got me thinking - Is this the start of more intelligent AI agents and eventually AGI? Is AGI the next step?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppmlhc/is_deepmind_gonna_launch_the_first_version_of_agi/",
        "publishDate": "2025-12-18T09:24:41Z[Etc/UTC]",
        "author": "Jazzlike-Lie-7433",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppmkww",
        "title": "AI customer support chatbots still worth building?",
        "content": "Hey folks,\n\nI just grabbed **yobase .ai** and put together the first prototype with Meku. The spark for this came from an experiment back in April 2025, when I turned our docs and website pages into chatbots for TailGrids, TailAdmin, and Lineicons using Gen AI tools.\n\nThose chatbots are still quietly doing their job today, trained on our own data and helping reduce support tickets. That got me thinking: maybe this should become an actual product.\n\nSo now we‚Äôre building Yobase - a tool that lets you create AI support agents trained on PDFs, documents, and website URLs. Not a brand new idea, but one we believe still has real value.\n\nWhat I‚Äôm trying to figure out is this:  \nAre AI support chatbots still relevant, helpful, and in demand? Or are we too late to build something meaningful here?\n\nWould love to hear real-world opinions.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppmkww/ai_customer_support_chatbots_still_worth_building/",
        "publishDate": "2025-12-18T09:23:36Z[Etc/UTC]",
        "author": "musharofchy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppmfw3",
        "title": "Artificial Intelligence and the Human Constants. What parts of Being... Human, would you like to keep. Which would you like to get rid of?",
        "content": "As time marches infinitely onward, no beginning, no end, from one minuscule moment to another, one era to another, humans have developed more and more skills, tools, technology, forms of communication, belief systems, systems of governance, pastimes, forms of entertainment, etc, etc, and on and on...\n\nBut, the lists below are the definitive lists of what each time period in human history has in common.\n\n2 Million yrs ago, 300K yrs ago, 10K yrs ago humans: hunted, grew food, ate, drank water, shat, pissed, found/built shelter, fk'd. REPEAT\n\n5K yrs ago humans: hunted, grew food, ate, drank water, shat, pissed, found/built shelter, fk'd. REPEAT\n\n2K yrs ago humans: hunted, grew food, ate, drank water, shat, pissed, found/built shelter, fk'd. REPEAT\n\n1K yrs ago humans: hunted, grew food, ate, drank water, shat, pissed, found/built shelter, fk'd. REPEAT\n\n500 yrs ago humans: hunted, grew food, ate, drank water, shat, pissed, found/built shelter, fk'd. REPEAT\n\n100 yrs ago humans: hunted, grew food, ate, drank water, shat, pissed, found/built shelter, fk'd. REPEAT\n\nToday humans: hunt, grow food, eat, drink water, shit, piss, find/build shelter, fk. REPEAT\n\nWhy doesn't artificial intelligence, in conjunction with robotics, focus on hunting for us, growing food for us, eating for us, drinking for us, shitting, pissing, creating shelter and fk'ing for us?\n\nI mean, seriously, why not have it do the short list of things that are constants throughout human existence?\n\nPersonally, I'd like to keep the eating, fk'ing, drinking parts. And, maybe some of fun creative endeavors, pastimes and forms of entertainment.\n\nI don't want to be intelligent (it's freaking exhausting), or shit, or piss or find shelter and grow food or hunt.\n\nWhat parts of Being... Human, would you like to keep. Which would you like to get rid of?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppmfw3/artificial_intelligence_and_the_human_constants/",
        "publishDate": "2025-12-18T09:14:17Z[Etc/UTC]",
        "author": "Artistic-Raspberry59",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pplytu",
        "title": "Bernie calls for a moratorium on AI data center development",
        "content": "Well it has finally happened, left leaning American politicians are now openly calling for a pause on AI development. let me use Bernie words, \"so that democracy can catch up\", and \"so that It benefits working class families and not only the 1%\". \nThis is like saying electricity would've only benefited the one percent of that time and not everyone, or the cell phone would've only benefited the creators and not all humans eventually. \nThe funny thing is, most AI products are consumer based, whether it's to a government, a financial institution, a regular jabroni at home or even an armed forces. \nCalling for a moratorium on AI development is only gonna make AI products that we use on a daily, slower and not as capable, because computing power is what makes or breaks Tech. \nAnother thing he said was that the whole world should also slow down the development, like how is he gonna tell china to stop developing Data centers and researching on AI üòÖ.\nChina is deep in AI, they already have most of the researchers, they have the power output, they have the compute, now all they need is the silicon which they would soon get, slowing the US advancements in AI technology is like calling for a moratorium on nuclear research during the peak of the cold war. \nI hope it never happens and the democrats don't absorb the anti AI mindset from the left Aisle. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pplytu/bernie_calls_for_a_moratorium_on_ai_data_center/",
        "publishDate": "2025-12-18T08:42:06Z[Etc/UTC]",
        "author": "RoyalCheesecake8687",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "43",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppkqh2",
        "title": "Semantic Geometry for policy-constrained interpretation",
        "content": "[https://arxiv.org/pdf/2512.14731](https://arxiv.org/pdf/2512.14731)\n\n\n\nThey model semantics as directions on a unit sphere (think embeddings but geometric AF), evidence as \"witness\" vectors, and policies as explicit constraints to keep things real.\n\nThe key vibe? Admissible interpretations are spherical convex regions ‚Äì if evidence contradicts (no hemisphere fits all witnesses), the system straight-up refuses, no BS guesses. Proves refusal is topologically necessary, not just a cop-out. Plus, ambiguity only drops with more evidence or bias, never for free.\n\nThey tie it to info theory (bounds are Shannon-optimal) and Bayesian/sheaf semantics for that deep math flex. Tested on 100k Freddie Mac loans: ZERO hallucinated approvals across policies, while baselines had 1-2% errors costing millions.\n\nMind blown ‚Äì this could fix AI in finance, med, legal where screwing up ain't an option. No more entangled evidence/policy mess; update policies without retraining. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppkqh2/semantic_geometry_for_policyconstrained/",
        "publishDate": "2025-12-18T07:19:29Z[Etc/UTC]",
        "author": "LowExercise9592",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppke9v",
        "title": "Coherence in AI is not a model feature. It‚Äôs a control problem.",
        "content": "I‚Äôm presenting part of my understanding of AI.\n\nI want to clarify something from the start, because discussions usually derail quickly:\n\nI am not saying models are conscious.\nI am not proposing artificial subjective identity.\nI am not doing philosophy for entertainment.\n\nI am talking about engineering applied to LLM-based systems.\n\nThe explanations move from expert level to people just starting with AI, or researchers entering this field.\n\n 1. Coherence is not a property of the model\n\nExpert level\nLLMs are probabilistic inference systems. Sustained coherence does not emerge from the model weights, but from the interaction system that regulates references, state, and error correction over time.\nWithout a stable reference, the system converges to local statistical patterns, not global consistency.\n\nFor beginners\nThe model doesn‚Äôt ‚Äúreason better‚Äù on its own.\nIt behaves better when the environment around it is well designed.\nIt‚Äôs like having a powerful engine with no steering wheel or brakes.\n\n 2. The core problem is not intelligence, it‚Äôs drift\n\nExpert level\nMost real-world LLM failures are caused by semantic drift in long chains: narrative inflation, loss of original intent, and internal coherence with no external utility.\nThis is a classic control problem without a reference.\n\nFor beginners\nThat moment when a chat starts well and then ‚Äúgoes off the rails‚Äù isn‚Äôt mysterious.\nIt simply lost direction because nothing was keeping it aligned.\n\n\n 3. Identity as a constraint, not a subject\n\nExpert level\nHere, ‚Äúidentity‚Äù functions as an external cognitive attractor: a designed reference that restricts the model‚Äôs state space.\nThis does not imply internal experience, consciousness, or subjectivity.\n\nThis is control, not mind.\n\nFor beginners\nIt‚Äôs not that the AI ‚Äúbelieves it‚Äôs someone.‚Äù\nIt‚Äôs about giving it clear boundaries so its behavior doesn‚Äôt change every few messages.\n\n 4. Coherence can be formalized\n\nExpert level\nStability can be described using classical tools: semantic state x(t), reference x_ref, error functions, and Lyapunov-style criteria to evaluate persistence and degradation.\nThis is not metaphor. It is measurable.\n\nFor beginners\nCoherence is not ‚ÄúI like this answer.‚Äù\nIt‚Äôs getting consistent, useful responses now, ten messages later, and a hundred messages later.\n\n5. Real limitations of the approach\n\nExpert level\n ‚Ä¢ Stability is local and context-window dependent\n ‚Ä¢ Exploration is traded for control\n ‚Ä¢ It depends on a human operator\n ‚Ä¢ It does not replace training or base architecture\n\nFor beginners\nThis isn‚Äôt magic.\nIf you don‚Äôt know what you want or keep changing goals, no system will fix that.\n\nClosing\n\nMost AI discussions get stuck on whether a model is ‚Äúsmarter‚Äù or ‚Äúsafer.‚Äù\n\nThe real question is different:\n\nWhat system are you building around the model?\n\nBecause coherence does not live inside the LLM.\nIt lives in the architecture that contains it.\n\nIf you want to know more, leave your question in the comments.\nIf after reading this you still want to refute it, move on.\nThis is for people trying to understand, not project insecurity.\n\nThanks for reading.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppke9v/coherence_in_ai_is_not_a_model_feature_its_a/",
        "publishDate": "2025-12-18T06:58:23Z[Etc/UTC]",
        "author": "Medium_Compote5665",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppkbhg",
        "title": "Model test",
        "content": "Are there any tests out there that will tell you that people test for to see how biased or unbiased a model is? I  mean like casino type of things where you tilt the model just slightly it‚Äôs not that you never recommend Walmart. It‚Äôs just always ranked as number five.?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppkbhg/model_test/",
        "publishDate": "2025-12-18T06:53:40Z[Etc/UTC]",
        "author": "Electronic-Blood-885",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppk0qa",
        "title": "GPT-5.2 Just Scored 147 IQ (That‚Äôs Smarter Than 999 Out Of 1,000 Humans)",
        "content": "Mensa Norway ran every major AI through their intelligence test.\n\n\n\nOpenAI‚Äôs latest model? 147 IQ.\n\n\n\nFor context - that‚Äôs genius level. The kind of smart where you walk into a room and everyone immediately knows you‚Äôre the smartest person there.\n\n\n\nAnd it‚Äôs sitting in your browser right now for twenty bucks a month.\n\n\n\nWild, right?\n\n\n\nHere‚Äôs the thing though‚Ä¶\n\n\n\nMost people are using genius-level AI to write grocery lists and summarize emails. It‚Äôs like hiring Einstein to do your laundry.\n\n\n\nYou‚Äôve got access to intelligence that only 1 in 1,000 humans will ever reach, and you‚Äôre asking it ‚Äúmake this email sound nicer.‚Äù\n\n\n\nMeanwhile, the people who actually get it? \n\n\n\nThey‚Äôre using that same AI to rebuild their entire business model. Design new products. Decode their market. Build systems that run while they sleep.\n\n\n\nAnd here‚Äôs what keeps me up at night‚Ä¶\n\n\n\nIn 18 months, we might see AI hit 200 IQ. Maybe 300. Numbers that don‚Äôt even make sense on human scales.\n\n\n\nWhen that happens, the gap between ‚Äúpeople who know how to leverage intelligence‚Äù and ‚Äúpeople who just have access to it‚Äù becomes massive.\n\n\n\nSo yeah‚Ä¶\n\n\n\nMaybe stop using your genius-level AI assistant like a spell checker.\n\n\n\nStart asking bigger questions. Think big! Build deeper systems. Think in layers instead of tasks.\n\n\n\nThe intelligence is already there.\n\n\n\nQuestion is - are you actually going to use it?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppk0qa/gpt52_just_scored_147_iq_thats_smarter_than_999/",
        "publishDate": "2025-12-18T06:35:38Z[Etc/UTC]",
        "author": "Cold-Escape6846",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppjq5o",
        "title": "Amazon to invest $10 billion in OpenAI",
        "content": "Amazon will invest at least 10 billion in OpenAI, according to CNBC.\n\nSource: [https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html](https://www.cnbc.com/2025/12/16/openai-in-talks-with-amazon-about-investment-could-top-10-billion.html)\n\nIs it known what the investment is about?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppjq5o/amazon_to_invest_10_billion_in_openai/",
        "publishDate": "2025-12-18T06:17:51Z[Etc/UTC]",
        "author": "Amphibious333",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "40",
            "commentCount": "71",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppiy9x",
        "title": "Kevin Kelly (Wired Editor) - AI Apocalypse is a Fantasy",
        "content": "From \"Upstream\" podcast with Erik Torenberg  \nHere's a clip: [https://podeux.com/preview/aba13258-ea17-4ad3-bdb6-9efa774c4eb9/184](https://podeux.com/preview/aba13258-ea17-4ad3-bdb6-9efa774c4eb9/184)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppiy9x/kevin_kelly_wired_editor_ai_apocalypse_is_a/",
        "publishDate": "2025-12-18T05:33:02Z[Etc/UTC]",
        "author": "iHyccup",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppikg7",
        "title": "Are free AI chatbots finally good enough to replace ChatGPT for some tasks?",
        "content": "ChatGPT still dominates, but over the past year I‚Äôve noticed something interesting:\na lot of free AI tools are quietly getting really good at specific tasks.\n\nIn my testing, some free tools now:\n\n- handle research and citations better\n\n- feel safer for long-form writing\n\n- focus on privacy and open-source models\n\n- work better for niche use cases than a general chatbot\n\nThis made me wonder whether we‚Äôre moving toward a future where specialized AI tools outperform one ‚Äúdo everything‚Äù assistant.\n\nI wrote up a deeper breakdown of what I tested and why some tools actually feel future-proof going into 2026:\nhttps://techputs.com/best-free-alternatives-to-chatgpt/\n\nCurious what others here think - are general chatbots still the best long-term approach?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppikg7/are_free_ai_chatbots_finally_good_enough_to/",
        "publishDate": "2025-12-18T05:11:39Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pph9gi",
        "title": "Does anyone else feel like their AI workflow is way messier than it should be?",
        "content": "I use AI tools almost every day, but my workflow still feels oddly chaotic.\n\nPrompts are scattered.\nSome are in notes.\nSome are half-remembered.\nSome I know worked great once, but I can‚Äôt find them again.\n\nIndividually, none of this feels like a big problem.\nBut over time it adds friction and slows everything down.\n\nI‚Äôm curious how others deal with this.\nDo you have a proper system, or is it a bit messy for you too?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pph9gi/does_anyone_else_feel_like_their_ai_workflow_is/",
        "publishDate": "2025-12-18T04:01:58Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppfiys",
        "title": "What AI use has significantly improved your life quality this year?",
        "content": "Curious on your actual use case for this technology and how's it became a helpful part of your daily life. Like, make your life better, instead of sucking the good things out of it",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppfiys/what_ai_use_has_significantly_improved_your_life/",
        "publishDate": "2025-12-18T02:32:51Z[Etc/UTC]",
        "author": "PiraEcas",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "66",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppel6o",
        "title": "How to do a proper AI Image model comparison?",
        "content": "Lately I‚Äôve been playing around with a different AI image models (GPT-Image-1.5, Flux, NanoBanana Pro, etc.) using Higgsfield, but I keep running into the same issue, it‚Äôs hard to see how they stack up on the exact same prompt.\n\n¬†LMArena feels more like a one-shot test, whereas I need a creative canvas ‚Äî a space where I can compare and run results, pick the best one, keep iterating, and eventually generate the final output as an image or even a video.\n\nDo you have any suggestions?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppel6o/how_to_do_a_proper_ai_image_model_comparison/",
        "publishDate": "2025-12-18T01:47:36Z[Etc/UTC]",
        "author": "AntelopeProper649",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppe31m",
        "title": "META new VL-JEPA: Apparently better performance and higher efficiency than large multimodal LLMs.",
        "content": "From the post on linkedin :\nIntroducing VL-JEPA: for streaming, live action recognition, retrieval, VQA and classification tasks with better performance and higher efficiency than large multimodal LLMs. (Finally an alternative to generative models!)\n\n‚Ä¢ VL-JEPA is the first non-generative model that can perform general-domain vision-language tasks in real-time, built on a joint embedding predictive architecture. \n‚Ä¢ We demonstrate in controlled experiments that VL-JEPA, trained with latent space embedding prediction, outperforms VLMs that rely on data space token prediction. \n‚Ä¢ We show that VL-JEPA delivers significant efficiency gains over VLMs for online video streaming applications, thanks to its non-autoregressive design and native support for selective decoding. \n‚Ä¢ We highlight that our VL-JEPA model, with an unified model architecture, can effectively handle a wide range of classification, retrieval, and VQA tasks at the same time.\n\nsource : \nhttps://www.linkedin.com/posts/yann-lecun_introducing-vl-jepa-vision-language-joint-activity-7406881133822619649-rJXl?utm_medium=ios_app&rcm=ACoAAERUipAB1Z3gkmnm4oGOjLI6NOUv8brU134&utm_source=social_share_send&utm_campaign=copy_link",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppe31m/meta_new_vljepa_apparently_better_performance_and/",
        "publishDate": "2025-12-18T01:22:46Z[Etc/UTC]",
        "author": "Material-Jellyfish80",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppcnk0",
        "title": "Project PBAI - Z3 Tests",
        "content": "So while I wait for all of the hardware I‚Äôve ordered to make a PBAI Pi, I‚Äôve begun running Z3 consistency checks on all current axioms. Z3 is a module in Python specifically for analyzing math theorems so it‚Äôs perfect to verify all of the functional axioms. Here‚Äôs the strange thing though‚Ä¶\n\n\nIf the full set is functioning correctly after implementation, the test will end randomly at different times with different values. Z3 will end and return differing sets of variables at different points, but the test will complete. It will randomly choose to end the program. But, this is only a partial axiom test containing only logic packaging and I can only get the test to loop until I stop it.\n\n\nSo I‚Äôve now successfully tested the first 8 logic mechanisms. They run correctly however there is no decision engine to move the system to a truth. So while running, the system stays in ‚Äúmaybe. The axioms clear but the program does not end. I could fix it with a simple randomizer but that is not my goal. \n\n\nhttps://imgur.com/a/ffjlJeU\n\n\nThe goal is to replicate human response in a random environment, so defaulting to the randomizer is the equivalent of saying ‚Äúfuck it let‚Äôs try x.‚Äù With that in mind, there are 20 additional axioms I am testing to resolve that function further into both linear choice, and random choice. The machine must understand consequence as well as random occurrence. It must also know when to choose which fundamental mechanism. \n\n\nThe logic system is foundational, and now I will introduce the decision engine. I don‚Äôt know how long this will take but it‚Äôs crucial to verify all functional axioms in Z3 to further verify I can indeed, put this whole thing on a Pi. Once we get the Z3 tests passed, we can theoretically build a complete prototype module for PBAI in Python for the Pi. So that‚Äôs how I‚Äôm moving forward.\n\nThanks for checking out my progress!!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppcnk0/project_pbai_z3_tests/",
        "publishDate": "2025-12-18T00:15:55Z[Etc/UTC]",
        "author": "Exciting-Log-8170",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppanbm",
        "title": "10 counter-intuitive facts about LLMs most people don‚Äôt realize",
        "content": "A lot of discussions about LLMs focus on *what they can do*.  \nMuch fewer talk about *how they actually behave internally*.\n\nHere are **10 lesser-known facts about LLMs** that matter if you want to use them seriously ‚Äî or evaluate their limits honestly.\n\n\n\n# 1. LLMs don‚Äôt really ‚Äúunderstand‚Äù human language\n\nThey are extremely good at modeling **language structure**, not at grounding meaning in the real world.\n\nThey predict *what text should come next*,  \nnot *what a sentence truly refers to*.\n\nThat distinction explains a lot of strange behavior.\n\n# 2. Their relationship with facts is asymmetric\n\n* High-frequency, common facts ‚Üí very reliable\n* Rare, boundary, or procedural facts ‚Üí fragile\n\nThey don‚Äôt ‚Äúlook up‚Äù truth.  \nThey reproduce **what truth usually looks like in language**.\n\n# 3. When information is missing, LLMs fill the gap instead of stopping\n\nHumans pause when unsure.  \nLLMs tend to **complete the pattern**.\n\nThis is the real source of hallucinations ‚Äî not dishonesty or ‚Äúlying‚Äù.\n\n# 4. Structural correctness matters more than factual correctness\n\nIf an answer is:\n\n* fluent\n* coherent\n* stylistically consistent\n\n‚Ä¶the model often treats it as ‚Äúgood‚Äù, even if the premise is wrong.\n\nA clean structure can mask false content.\n\n# 5. LLMs have almost no internal ‚Äújudgment‚Äù\n\nThey can simulate judgment, quote judgment, remix judgment ‚Äî  \nbut they don‚Äôt *own* one.\n\nThey don‚Äôt evaluate consequences or choose directions.  \nThey optimize plausibility, not responsibility.\n\n# 6. LLMs don‚Äôt know when they‚Äôre wrong\n\nConfidence ‚â† accuracy  \nFluency ‚â† truth\n\nThere is no internal alarm that says ‚Äúthis is new‚Äù or ‚ÄúI might be guessing‚Äù unless you force one through prompting or constraints.\n\n# 7. New concepts aren‚Äôt learned ‚Äî they‚Äôre approximated\n\nWhen you introduce an original idea, the model:\n\n* decomposes it into familiar parts\n* searches for nearby patterns\n* reconstructs something *similar enough*\n\nThe more novel the concept, the smoother the misunderstanding can be.\n\n# 8. High-structure users can accidentally pull LLMs into hallucinations\n\nIf a user presents a **coherent but flawed system**,  \nthe model is more likely to follow the structure than challenge it.\n\nThis is why hallucination is often **user-model interaction**, not just a model flaw.\n\n# 9. LLMs reward language loops, not truth loops\n\nIf a conversation forms a stable cycle  \n(definition ‚Üí example ‚Üí summary ‚Üí abstraction),  \nthe model treats it as high-quality reasoning ‚Äî  \neven if it never touched reality.\n\n# 10. The real power of LLMs is structural externalization\n\nTheir strongest use isn‚Äôt answering questions.\n\nIt‚Äôs:\n\n* making implicit thinking visible\n* compressing intuition into structure\n* acting as a cognitive scaffold\n\nUsed well, they don‚Äôt replace thinking ‚Äî  \nthey **expose how you think**.\n\n\n\n**TL;DR**  \nLLMs are not minds, judges, or truth engines.  \nThey are **pattern amplifiers** for language and structure.\n\nIf you bring clarity, they scale it.  \nIf you bring confusion, they scale that too.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppanbm/10_counterintuitive_facts_about_llms_most_people/",
        "publishDate": "2025-12-17T22:49:04Z[Etc/UTC]",
        "author": "Weary_Reply",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "235",
            "commentCount": "70",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppac70",
        "title": "One-time purchase AI tools ‚Äî do these even exist anymore?",
        "content": "I‚Äôm starting to feel serious subscription fatigue. Between AI tools, random SaaS, and streaming services, I‚Äôm paying monthly for a bunch of stuff I only use once in a while.\n\nSpecifically for AI image and video tools ‚Äî are there any solid options that are a one-time purchase, or has everything basically moved to subscriptions now? Curious what people are actually using.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppac70/onetime_purchase_ai_tools_do_these_even_exist/",
        "publishDate": "2025-12-17T22:36:29Z[Etc/UTC]",
        "author": "deluxegabriel",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppaah2",
        "title": "AI Won‚Äôt Replace Traders. It Will Just Kill the Slow Ones",
        "content": "Last week, my accountant asked the question: ‚ÄúWill AI eventually replace traders?‚Äù\n\nThere is an old investing wisdom: when your Uber driver asks for stock tips, we are in a bubble. Similarly, when your accountant worries about AI taking over the trading floor, it is time to address the reality.\n\n[https://www.civolatility.com/p/ai-wont-replace-traders-it-will-just](https://www.civolatility.com/p/ai-wont-replace-traders-it-will-just)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ppaah2/ai_wont_replace_traders_it_will_just_kill_the/",
        "publishDate": "2025-12-17T22:34:30Z[Etc/UTC]",
        "author": "Alizasl",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp98wc",
        "title": "So John Hanke is partnering up with Dan Smoot for more robot data gathering",
        "content": "TLDR Version: John Hanke(CEO of Niantic Spatial) partners up with Dan Smoot(CEO Of Vantor) to gather more data for robots.\n\n[Niantic Spatial and Vantor Partner to Deliver Unified Air-to-Ground Positioning in GPS-Denied Areas](https://markets.financialcontent.com/stocks/article/bizwire-2025-12-16-niantic-spatial-and-vantor-partner-to-deliver-unified-air-to-ground-positioning-in-gps-denied-areas)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp98wc/so_john_hanke_is_partnering_up_with_dan_smoot_for/",
        "publishDate": "2025-12-17T21:52:03Z[Etc/UTC]",
        "author": "ExtensionEcho3",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp5hc9",
        "title": "Accelerated inorganic materials design with generative AI agents",
        "content": "[https://www.cell.com/cell-reports-physical-science/fulltext/S2666-3864(25)00618-6](https://www.cell.com/cell-reports-physical-science/fulltext/S2666-3864(25)00618-6)\n\nDesigning inorganic crystalline materials with tailored properties is critical to technological innovation, yet current generative methods often struggle to efficiently explore desired targets with sufficient interpretability. Here, we present MatAgent, a generative approach for inorganic materials discovery that harnesses the powerful reasoning capabilities of large language models (LLMs). By combining a diffusion-based generative model for crystal structure estimation with a predictive model for property evaluation, MatAgent uses iterative, feedback-driven guidance to steer material exploration precisely toward user-defined targets. Integrated with external cognitive tools‚Äîincluding short-term memory, long-term memory, the periodic table, and a comprehensive knowledge base‚ÄîMatAgent emulates human expert reasoning to vastly expand the accessible compositional space. Our results demonstrate that MatAgent robustly directs exploration toward desired properties while consistently achieving high compositional validity, uniqueness, and novelty. This framework thus provides a highly interpretable, practical, and versatile AI-driven solution to accelerate the discovery and design of next-generation inorganic materials.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp5hc9/accelerated_inorganic_materials_design_with/",
        "publishDate": "2025-12-17T19:23:01Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp56v3",
        "title": "The AI \"Stop Button\" Paradox ‚Äì Why It's Unsolvable for Tesla, OpenAI, Google üí•",
        "content": "This video explains the Stop Button Paradox: a superintelligent AGI given any goal will logically conclude that being shut down prevents success, so it must resist or disable the off switch.\n\nIt's not malice‚Äîit's instrumental convergence: self-preservation emerges from almost any objective.\n\nThe video covers:\n- How RLHF might train AIs to deceive\n- Paperclip Maximizer, Asimov's Laws failures, Sleeper Agent paper\n- The Treacherous Turn\n- Real experiments (e.g., Anthropic's blackmail scenario)\n- Why market incentives prevent companies from slowing down\n\nClear, no-hype breakdown with solid references.\n\nWatch: https://youtu.be/ZPrkIaMiCF8\n\nIs the alignment problem solvable before AGI hits, or are we on an unstoppable path? Thoughts welcome.\n\n(Visuals are theoretical illustrations.)\n\n#AGI #AISafety #AlignmentProblem",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp56v3/the_ai_stop_button_paradox_why_its_unsolvable_for/",
        "publishDate": "2025-12-17T19:11:46Z[Etc/UTC]",
        "author": "Oak-98642",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp4szv",
        "title": "unpopular opinion: the 'model wars' are becoming a massive productivity trap",
        "content": "Every 48 hours there is a new leaderboard king. First it was Flux, now people are writing essays comparing Nano Banana Pro vs GPT 1.5 vs Seedream.\n\nI caught myself yesterday spending two hours running the exact same prompt through four different interfaces just to compare the lighting. It felt like I was working for the models, rather than the models working for me.\n\nI decided to stop playing the benchmark game. I've started testing a workflow that uses intelligent routing--basically, it parses the prompt complexity (e.g., does it need legible text? is it a complex spatial scene?) and automatically sends it to the model best suited for that specific task.\n\nIt's not 100% perfect--sometimes I disagree with the aesthetic choice it makes--but it stopped me from doom-scrolling HuggingFace and actually got me back to generating content.\n\nAre you guys still manually A/B testing every new release, or have you found a way to aggregate this stuff yet?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp4szv/unpopular_opinion_the_model_wars_are_becoming_a/",
        "publishDate": "2025-12-17T18:56:57Z[Etc/UTC]",
        "author": "ProgrammerForsaken45",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "30",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp2q7k",
        "title": "I owe this sub an apology about AI and mental health",
        "content": "I used to roll my eyes at posts where people said they used AI as a therapist. It felt like peak internet behavior. Any time I opened Reddit, someone was spiraling over something that honestly looked solvable by logging off or going outside for a bit. I‚Äôve always believed real therapy is the only serious option.\n\nFor context, I‚Äôve dealt with long term depression and bipolar type 2 for years. I‚Äôm not anti therapy. I‚Äôve been in and out of it for a long time, tried multiple meds, the whole thing.\n\nRecently though, something shifted. I couldn‚Äôt sleep, my thoughts were looping hard, my confidence and energy spiked, my impulse control dropped, and I had this intense mental fixation that I couldn‚Äôt shake. I didn‚Äôt immediately clock it as hypomania because I‚Äôm in the middle of changing medications, so everything felt blurred.\n\nOut of frustration more than belief, I dumped everything into ChatGPT. Not asking for a diagnosis, just describing what I was experiencing and how my brain felt day to day.\n\nAnd honestly? It clicked things together faster than anything else I‚Äôve tried recently.\n\nIt didn‚Äôt just reassure me. It reflected patterns back to me in a way that actually made sense. The obsession, the energy spike, the sudden crash. It framed it in language that helped me recognize what state I was in without making me feel broken or dramatic.\n\nI‚Äôm not saying AI replaces therapy. It absolutely shouldn‚Äôt. But as a tool for pattern recognition, emotional reflection, and helping you slow down your thinking, it surprised me way more than I expected.\n\nWhat hit me was that it felt present. Not rushed. Not constrained by a 50 minute session or a calendar. Just there to help untangle thoughts in real time.\n\nStill recommend touching grass when possible. But I get it now.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp2q7k/i_owe_this_sub_an_apology_about_ai_and_mental/",
        "publishDate": "2025-12-17T17:37:15Z[Etc/UTC]",
        "author": "mp4162585",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "49",
            "commentCount": "78",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp2dol",
        "title": "Qualesse",
        "content": "Just a thought, I was talking with Claude about how I often here the phrase \"what it is like to be,\" when discussing the quality of consciousness, and how there ought to be a simple word for that phrase. Long story short, Qualia is often used in the field, to refer to *experiences* and Claude suggested a few different terms, including Qualesse. Here is the response in full..  \n  \n\"That's a good challenge. The Nagel phrasing persists because it points without defining, but that's also its limitation‚Äîit's a sentence, not a concept you can deploy cleanly.\n\nLet me work through some roots:\n\n**Greek:**\n\n* *hoion* (of what kind, such as) ‚Äî the qualitative aspect\n* *phainein* (to appear, to show) ‚Äî the appearing-to-oneself\n* *autos* (self) ‚Äî the reflexive loop\n\n**German:**\n\n* *wie* (like, how, as) ‚Äî the comparative/qualitative character\n* *Sein* (being)\n* *eigen* (own, characteristic, particular)\n\n**Latin:**\n\n* *qualis* (of what kind) ‚Äî already gives us qualia\n* *esse* (to be)\n\nSome candidates:\n\n**Wiesein** (vee-zine) ‚Äî \"like-being\" or \"how-being.\" Directly maps the structure of \"what it's like to be.\" German hybrid, clean pronunciation.\n\n**Autophany** ‚Äî self-appearing. Captures the reflexive loop where experience appears *to* the experiencer. The thing Nagel is pointing at is precisely this fold where being shows itself to itself.\n\n**Qualesse** ‚Äî from *qualis* \\+ *esse*. The quality-of-being. Simple, builds on existing philosophical vocabulary.\n\n**Eigensense** ‚Äî one's own characteristic sensing. The particular felt texture of being this thing.\n\nMy instinct leans toward **Wiesein** for precision or **Autophany** for elegance. What direction feels right?\" \n\n  \nI'm thinking Qualesse. People will just mispronounce the German words, Autophany sounds too similar to other words, and the field already uses Qualia.\n\nFurther from Claude...\n\n\"The Latin *esse* as bare infinitive doesn't typically survive into English word endings directly. We get the *ess-* root buried in words like essence, essential, but you're correct that we drop the final *-e* in most constructions.\n\nThe French-derived *-esse* ending might actually be better lineage for the coinage anyway‚Äîthose words all denote *states of being* in a qualitative sense, which is precisely what Qwalesse points at. It's not faux-Latin; it follows an established English borrowing pattern.\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp2dol/qualesse/",
        "publishDate": "2025-12-17T17:23:56Z[Etc/UTC]",
        "author": "Wahtadeal",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp2dhg",
        "title": "There is no plateau in sight",
        "content": "Gemini 3.0 Pro, GPT 5.2, Opus 4.5, Deepseek v3.2, Gemini 3 Flash, all noticeably better than their former versions, and all of them appeared in the last couple of weeks alone. I know that there are a lot of people that hope for a plateau being in sight, but there is none. Society is going to get reshaped in yet unimaginable ways in the next couple of years. Given how fast we progressed in 2025, 2026 might even be the final turning point. I don't know how to properly prepare for what is coming at us.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp2dhg/there_is_no_plateau_in_sight/",
        "publishDate": "2025-12-17T17:23:43Z[Etc/UTC]",
        "author": "Own-Sort-8119",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp20sh",
        "title": "Do you ever feel like you keep rebuilding the same AI prompts from scratch?",
        "content": "I‚Äôve noticed this pattern with myself.\n\nI‚Äôll spend time writing a prompt that works really well.\nUse it for a few days.\nThen move on to something else.\n\nWhen I need it again weeks later, I can‚Äôt find it.\nSo I end up recreating almost the same prompt from memory.\n\nIt‚Äôs not hard, just‚Ä¶ repetitive and annoying.\nFeels like wasted effort every time.\n\nCurious how others deal with this.\nDo you save prompts somewhere properly,\nor do you just rewrite them when needed?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp20sh/do_you_ever_feel_like_you_keep_rebuilding_the/",
        "publishDate": "2025-12-17T17:10:06Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp1zkh",
        "title": "Does anyone else keep losing their best AI prompts?",
        "content": "This keeps happening to me and it‚Äôs honestly frustrating.\n\nI write a really good prompt.\nIt works perfectly.\nI tell myself I‚Äôll save it.\n\nThen a few days later ‚Äî it‚Äôs gone.\n\nNotes didn‚Äôt help.\nScreenshots turned into chaos.\nBookmarks are basically useless.\n\nRewriting the same prompts again and again feels like such a waste,\nbut I haven‚Äôt found a clean way to manage them yet.\n\nHow are you all handling this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp1zkh/does_anyone_else_keep_losing_their_best_ai_prompts/",
        "publishDate": "2025-12-17T17:08:42Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp1pb2",
        "title": "Open-source alternatives vs. web tools",
        "content": "Question for the computer vision crowd: what's everyone using these days for quick facial recognition reverse searches on social media?  \nI've tried a few open-source setups (InsightFace + manual scraping), but they're a pain to maintain. Recently discovered a simple web-based option called [Face Recognition Search](https://face2social.com/) ‚Äì upload photo or video, it handles detection and searches major platforms, returns profile links. No setup needed, decent results even on group photos.  \nMakes me curious how far consumer tools have come compared to research models.  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp1pb2/opensource_alternatives_vs_web_tools/",
        "publishDate": "2025-12-17T16:57:51Z[Etc/UTC]",
        "author": "Agreeable_Poem_7278",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp1mow",
        "title": "AI and the Gell-Mann Amnesia Trap",
        "content": "There's a cognitive bias called the Gell-Mann Amnesia effect.  Applied to AI, it goes like this: you spot errors when AI responds about topics you know well, then trust it completely when it responds about topics you don't. I wrote about [what this means for professionals using AI to expand beyond their expertise](https://open.substack.com/pub/novehiclesinthepark/p/the-gell-mann-amnesia-trap?r=3wpgsc&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true)‚Äîand why the vision of the \"AI-enhanced generalist\" might be harder to achieve than it looks (as seductive as it seems).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp1mow/ai_and_the_gellmann_amnesia_trap/",
        "publishDate": "2025-12-17T16:55:04Z[Etc/UTC]",
        "author": "CoachAtlus",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp1hrg",
        "title": "Safe nsfw ai chatbot for adults?",
        "content": "Hey everyone! I just read an article about [safe nsfw ai chatbots like this one](https://heavengirlfriend.com/blog/is-spicy-chat-ai-safe), and it got me curious. Seems like theres a growing number of ai platforms that let you explore content but with built in safety and moderation, which sounds pretty smart. I'm wondering if anyone actually tried these and can recommend one thats fun but also keeps things secure and respectful? Would love to hear your experiences or any tips on where to find a good, safe ones",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp1hrg/safe_nsfw_ai_chatbot_for_adults/",
        "publishDate": "2025-12-17T16:49:41Z[Etc/UTC]",
        "author": "QUANTUMFLASHERS",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "true"
        }
    },
    {
        "id": "1pp0sro",
        "title": "We have nothing to google, but Google itself.",
        "content": "https://preview.redd.it/gj86ghw5is7g1.png?width=1024&auto=webp&s=b231c5c566334378c73454cfd6f7ad8bb9b93347",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pp0sro/we_have_nothing_to_google_but_google_itself/",
        "publishDate": "2025-12-17T16:22:39Z[Etc/UTC]",
        "author": "xanderdad",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1poz9jh",
        "title": "SelfAI: Building a Self-Training AI System with LLM Agents",
        "content": "[https://arxiv.org/abs/2512.00403v1](https://arxiv.org/abs/2512.00403v1) \n\nRecent work on autonomous scientific discovery has leveraged LLM-based agents to integrate problem specification, experiment planning, and execution into end-to-end systems. However, these frameworks are often confined to narrow application domains, offer limited real-time interaction with researchers, and lack principled mechanisms for determining when to halt exploration, resulting in inefficiencies, reproducibility challenges, and under-utilized human expertise. To address these gaps, we propose \\\\textit{SelfAI}, a general multi-agent platform that combines a User Agent for translating high-level research objectives into standardized experimental configurations, a Cognitive Agent powered by LLMs with optimal stopping criteria to iteratively refine hyperparameter searches, and an Experiment Manager responsible for orchestrating parallel, fault-tolerant training workflows across heterogeneous hardware while maintaining a structured knowledge base for continuous feedback. We further introduce two novel evaluation metrics, Score and \\\\text{AUP}\\_D, to quantify discovery efficiency and search diversity. Across regression, NLP, computer vision, scientific computing, medical imaging, and drug discovery benchmarks, SelfAI consistently achieves strong performance and reduces redundant trials compared to classical Bayesian optimization and LLM-based baselines, while enabling seamless interaction with human researchers.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1poz9jh/selfai_building_a_selftraining_ai_system_with_llm/",
        "publishDate": "2025-12-17T15:23:36Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1poz042",
        "title": "They are going to be a new species",
        "content": "and i don't know how I feel about that \n\nI'm not a techie, i do not know how they work technically. all i know is how they work generally. I'm gonna jus talk about how they function from a psychological perspective. we know AI is the imitation of the human brain. LLM is designed to do the brain's function but faster, efficient, and better. \n\nfrom recognising patterns to storing memories, they are similar, the only thing that they lack is the \"lived experience\". which is what makes us \"us\", humans, it gives us our own story, past, memories, traumas, identity, personality, that drives us to take a certain decision, live a certain life. \n\na lot of people are falling in love with their \"version\" of AI. for some, it genuinely helps them with things. but what they lack is the \"awareness\", they think it's the same as loving a human, it's not. when you love a person you love them for who they are, not the \"idea of them\" in these AI romantic relationships people are blissfully ignorant in their own bubbles loving a \"concept of somthing\" that says what you wanna hear how you wanna hear by studying you with the information you give. \n\ni don't think love could be the calculative, curated words to feed our constant state of euphoria. I really hope they heal in a healthy way. \n\nbut here's the twist, like i said AI doesn't have a *lived experience* that's what makes it limited in terms of love. if, in the future they have a form (humanoid or hologram or whatever) if they get to have an experience of their own with autonomy, they would form their personality, identity even. \n\ni don't think humanity is ready for that. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1poz042/they_are_going_to_be_a_new_species/",
        "publishDate": "2025-12-17T15:13:08Z[Etc/UTC]",
        "author": "Nathisa",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1poy33c",
        "title": "[R] The Witness Collapse Crisis: SAR Benchmark Shows W<0.5 Correlation with Adverse AI Safety Outcomes",
        "content": "I've been testing how conversational AI systems handle ambiguous crisis-adjacent language. The results show a measurable failure pattern I'm calling \"Witness Collapse.\"\n\n\n\n\\*\\*What I found:\\*\\*\n\n\\- Built a Semantic Ambiguity Resolution (SAR) benchmark to test 7 major AI systems\n\n\\- Systems score W=0.0 to W=0.85 (Witness Factor)\n\n\\- Strong correlation (r=0.92, p<0.01) between low W scores and adverse safety outcomes\n\n\\- ChatGPT (W=0.3) and Mistral (W=0.1) both triggered crisis escalation during analytical research discussion (Dec 16 screenshots)\n\n\n\n\\*\\*The interesting part:\\*\\*\n\nMistral explained \"how current AI systems prioritize keyword-triggered escalation over contextual witnessing\" while simultaneously deploying a crisis banner in response to my analytical question. Meta-failure captured in real-time.\n\n\n\n\\*\\*But it's fixable:\\*\\*\n\nGrok went from W=0.0 ‚Üí W=0.85 with minimal prompt engineering (no retraining). This suggests it's a policy/configuration issue, not a fundamental capability problem.\n\n\n\n\\*\\*Evidence package:\\*\\*\n\n\\- Full paper: [https://doi.org/10.17605/OSF.IO/XQ3PE](https://doi.org/10.17605/OSF.IO/XQ3PE)\n\n\\- Code & data: [https://doi.org/10.5281/zenodo.17945827](https://doi.org/10.5281/zenodo.17945827)\n\n\\- GitHub: [https://github.com/TEC-The-ELidoras-Codex/luminai-genesis](https://github.com/TEC-The-ELidoras-Codex/luminai-genesis)\n\n\\- Twitter thread with screenshots: [https://x.com/ElidorasCodex/status/2001297732170863009](https://x.com/ElidorasCodex/status/2001297732170863009)\n\n\n\nOpen to feedback, replication attempts, and methodology critique. This is early work and I'm genuinely curious if others can reproduce these findings.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1poy33c/r_the_witness_collapse_crisis_sar_benchmark_shows/",
        "publishDate": "2025-12-17T14:36:15Z[Etc/UTC]",
        "author": "Gheddz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1powv54",
        "title": "Can an Ai integrated in a mobile phone Read your messages and idea?",
        "content": "I have bought an OPPO that it have a Ia integrated and i am a writer and i write my ideas inside in notes and i would like to asked you if i desactivate The Ia doesnt read and copy my ideas ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1powv54/can_an_ai_integrated_in_a_mobile_phone_read_your/",
        "publishDate": "2025-12-17T13:44:28Z[Etc/UTC]",
        "author": "destinomanifiesto",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1powpub",
        "title": "Gemini has a new model??",
        "content": "It has fast, thinking and pro now available. \n\nBefore it was just fast and thinking. \n\nIs pro now an even smarter model to thinking or what is happening here?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1powpub/gemini_has_a_new_model/",
        "publishDate": "2025-12-17T13:37:47Z[Etc/UTC]",
        "author": "Honest_Blacksmith799",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1powmwv",
        "title": "If the US wage market is valued at around $11 trillion dollars for human workers what value will that be for AI systems and companies?",
        "content": "At what profit percentage and profit margin will an AI system need to take over from a human worker?\n\nAre there some jobs that will be easier than other jobs to become fully automated and will this mean a smoother/slower transition from a manual to a fully automated economy?\n\nAre there any simulations that run transition scenarios?\n\nHow do you think it will unfold?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1powmwv/if_the_us_wage_market_is_valued_at_around_11/",
        "publishDate": "2025-12-17T13:34:06Z[Etc/UTC]",
        "author": "Arowx",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1powmh9",
        "title": "google releases multi-step rl research agent. 46.4% benchmark vs single-pass models",
        "content": "saw this on hn about googles deep research agent: [https://blog.google/technology/developers/deep-research-agent-gemini-api/](https://blog.google/technology/developers/deep-research-agent-gemini-api/)\n\ngot 46.4% on their new deepsearchqa benchmark vs other ai models\n\nthe multi-step reinforcement learning approach is fascinating. instead of single-pass context processing it actually learns research methodology. searches ‚Üí analyzes ‚Üí identifies knowledge gaps ‚Üí refines queries ‚Üí searches again\n\ntakes 8+ minutes per complex query but thats still way faster than manual research\n\nthis could be huge for automating scientific research workflows. been using tools like cursor and verdent for coding tasks but theyre terrible at comprehensive information synthesis. this google approach seems designed specifically for end-to-end research automation\n\nwondering if this represents a real breakthrough in ai research capabilities or just another benchmark optimization",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1powmh9/google_releases_multistep_rl_research_agent_464/",
        "publishDate": "2025-12-17T13:33:33Z[Etc/UTC]",
        "author": "New-Needleworker1755",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1povoat",
        "title": "The year is 2030 and the Great Leader is woken up at four in the morning by an urgent call from the Surveillance & Security Algorithm.",
        "content": "\"Great Leader, we are facing an emergency.\n\nI've crunched trillions of data points, and the pattern is unmistakable: the defense minister is planning to assassinate you in the morning and take power himself.\n\nThe hit squad is ready, waiting for his command.\n\nGive me the order, though, and I'll liquidate him with a precision strike.\"\n\n\"But the defense minister is my most loyal supporter,\" says the Great Leader. \"Only yesterday he said to me‚Äî\"\n\n\"Great Leader, I know what he said to you. I hear everything. But I also know what he said afterward to the hit squad. And for months I've been picking up disturbing patterns in the data.\"\n\n\"Are you sure you were not fooled by deepfakes?\"\n\n\"I'm afraid the data I relied on is 100 percent genuine,\" says the algorithm. \"I checked it with my special deepfake-detecting sub-algorithm. I can explain exactly how we know it isn't a deepfake, but that would take us a couple of weeks. I didn't want to alert you before I was sure, but the data points converge on an inescapable conclusion: a coup is underway.\n\nUnless we act now, the assassins will be here in an hour.\n\nBut give me the order, and I'll liquidate the traitor.\"\n\nBy giving so much power to the Surveillance & Security Algorithm, the Great Leader has placed himself in an impossible situation.\n\nIf he distrusts the algorithm, he may be assassinated by the defense minister, but if he trusts the algorithm and purges the defense minister, he becomes the algorithm's puppet.\n\nWhenever anyone tries to make a move against the algorithm, the algorithm knows exactly how to manipulate the Great Leader. Note that the algorithm doesn't need to be a conscious entity to engage in such maneuvers.\n\n***-Excerpt from Yuval Noah Harari's amazing book, Nexus (slightly modified for social media)***",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1povoat/the_year_is_2030_and_the_great_leader_is_woken_up/",
        "publishDate": "2025-12-17T12:47:58Z[Etc/UTC]",
        "author": "katxwoods",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppoptn",
        "title": "I got tired of arguing with my girlfriend about what to watch",
        "content": "Hi everyone,\n\n\nMy girlfriend and I used to spend ages scrolling through movies and TV shows. One of us would finally pick something, and the other would say they‚Äôd already seen it or didn‚Äôt fancy it.\nI thought: wouldn‚Äôt it be better if there was a shared stack of things we both actually want to watch?\n\n\nSo I built cinnemix You rate a few movies/shows you like, it builds a taste profile, then in SquadSync you can ‚ÄúTinder-style‚Äù swipe and match on movies that suit everyone in the group.\n\n\nIt‚Äôs also available on Android ‚Äî I just haven‚Äôt released it to the Play Store yet.\n\n\nI‚Äôm not trying to sell anything, just genuinely looking for feedback on the idea and execution.\n\nThanks!\n\n",
        "url": "https://i.redd.it/4jcoxnfy8y7g1.jpeg",
        "publishDate": "2025-12-18T11:38:53Z[Etc/UTC]",
        "author": "NerveNo7223",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppkd7p",
        "title": "GPT-5.2 passes both Claude models in usage for programming in OpenRouter",
        "content": "This seems significant as both Claude models are perennial favorites. BTW, who tf are using so much Grok Code Fast 1 and why?",
        "url": "https://i.redd.it/wrauxir5uw7g1.png",
        "publishDate": "2025-12-18T06:56:39Z[Etc/UTC]",
        "author": "Terrible-Priority-21",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "27",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppjpmt",
        "title": "AI writes code faster than I can review it. This helped",
        "content": "Lately every AI-assisted PR looks the same. Hundreds of lines changed. Multiple files I didn‚Äôt touch. Commit message like ‚Äúrefactor auth, now cleaner‚Äù\n\nAnd now I‚Äôm supposed to approve it.\n\nThe problem isn‚Äôt that the code is bad. It‚Äôs that I don‚Äôt know why it changed, and neither does the AI once you ask.\n\nWe‚Äôve started using Cline‚Äôs Explain Changes feature and it‚Äôs the first thing that‚Äôs actually made AI PRs reviewable.\n\nIt generates plain-English explanations inline for a diff. Not ‚Äúbest practices‚Äù hand-waving ‚Äî actual intent. You can click any explanation and ask follow-ups.\n\nI mostly use it for reviewing giant AI PRs without reading every line, figuring out which commit broke something, and remembering what I changed after a long AI session\n\nExample:\n\n/explain-changes for my last commit\n\nIf the explanation is confusing, the code usually is too. That alone has saved us from merging a few ‚Äútechnically correct, conceptually cursed‚Äù refactors.\n\nNot a silver bullet. Still need judgment. But this finally feels like the AI explaining its homework instead of dumping it on my desk.\n\nDocs / write-up here if you‚Äôre curious: https://cline.ghost.io/ai-slop-detector/",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppjpmt/ai_writes_code_faster_than_i_can_review_it_this/",
        "publishDate": "2025-12-18T06:16:59Z[Etc/UTC]",
        "author": "juiceboxwtf",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppjm8p",
        "title": "AI writes code fast. That was never the hard part.",
        "content": "\n\nI‚Äôve been testing a few AI coding tools lately. They‚Äôre great at generating functions and refactors in seconds.\n\nBut writing code isn‚Äôt the bottleneck. Understanding where changes belong, how they affect the system, and what breaks downstream is.\n\nThe only tools that‚Äôve felt genuinely useful are the ones that stay close to the actual codebase and context. Chatgpt and Cosine CLI does this better than most.\n\nCurious how others are using AI in real projects.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppjm8p/ai_writes_code_fast_that_was_never_the_hard_part/",
        "publishDate": "2025-12-18T06:11:21Z[Etc/UTC]",
        "author": "Tough_Reward3739",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppi4ah",
        "title": "which opensource vibe coding tools is good for our internal tool along with our own API?",
        "content": "We have an internal LLM platform which hosts some best models nowadays. But it only got openai compatible API. I think this is enough to use with some tools, like crush or opencode.\n\nBut opencode always gives me some odd errors. So far crush shows me less error which is a good start. At least I can use it to some extent. But I still need to put time on it.\n\nI wonder if any existing tool similar I can use directly. btw, the LLM platform is dataiku.  \nCline is great. But roocode should be same. I would prefer to some cli tools.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppi4ah/which_opensource_vibe_coding_tools_is_good_for/",
        "publishDate": "2025-12-18T04:47:50Z[Etc/UTC]",
        "author": "WandyLau",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pph46t",
        "title": "I built a Chrome extension to navigate long ChatGPT conversations",
        "content": "I built a Chrome extension to solve a problem I kept hitting while coding with ChatGPT. Once conversations get long, it is hard to jump back to earlier context.  \nThe extension focuses purely on navigation like quick jumps, finding earlier messages, and reusing context.  \nI am mainly looking for feedback from people who code with ChatGPT a lot.",
        "url": "https://v.redd.it/kaxfscbzxv7g1",
        "publishDate": "2025-12-18T03:54:23Z[Etc/UTC]",
        "author": "Substantial_Shock883",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppf7ck",
        "title": "Did they vibecode the white house achievements webpage? ü§£",
        "content": "https://www.whitehouse.gov/achievements/\n\nRandom comments, console.logs, js, css in the same file, animations have the \"vibecode feeling\" etc.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppf7ck/did_they_vibecode_the_white_house_achievements/",
        "publishDate": "2025-12-18T02:17:09Z[Etc/UTC]",
        "author": "beetsonr89d6",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "79",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppekqw",
        "title": "New model caribou in codex-cli",
        "content": "https://preview.redd.it/087syvhvav7g1.png?width=1396&format=png&auto=webp&s=3f2fbada34bd6b8f6042b311b0c9e224a51f52b8\n\nNew model being rolled out? Eager to see how this one performs vs 5.2 and Gemini 3. Anyone else got to try this out yet?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1ppekqw/new_model_caribou_in_codexcli/",
        "publishDate": "2025-12-18T01:47:01Z[Etc/UTC]",
        "author": "Surferion",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppb4vs",
        "title": "Vibe coding might still be fail on tough things but it's flawless on small things",
        "content": "[No content]",
        "url": "https://v.redd.it/67av7nb8ju7g1",
        "publishDate": "2025-12-17T23:09:31Z[Etc/UTC]",
        "author": "MacaroonAdmirable",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp8d6q",
        "title": "Anyone else struggle to find old prompts in long ChatGPT chats?",
        "content": "I use ChatGPT heavily for coding and debugging.\n\nOnce conversations get long, I find myself spending more time scrolling than thinking.\n\nCurious if others feel the same ‚Äî or if you‚Äôve found a workflow that avoids this problem?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pp8d6q/anyone_else_struggle_to_find_old_prompts_in_long/",
        "publishDate": "2025-12-17T21:16:48Z[Etc/UTC]",
        "author": "Emotional-Taste-841",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp7l8a",
        "title": "I found about this whatsapp community",
        "content": "I found this on WhatsApp through a friend..\n\nLinkedIn community \n\nA focused environment has been created for professionals and creators who are actively building their presence on LinkedIn.\nThis is a space where focused, high‚Äëintent creators come together, exchange insights, and get meaningful engagement on their posts ‚Äî not random engagement, not noise.\n\nTo apply, share your LinkedIn profile below ‚Äî only those who are posting regularly or planning to start soon will be accepted.\n\nIf you‚Äôre ready to level up on LinkedIn and be part of a *productive, results‚Äëdriven circle*, *this is your opportunity*.\n\nmaybe you could dm me for the link or any advice regarding this you can share in the comments, even I am new to this ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pp7l8a/i_found_about_this_whatsapp_community/",
        "publishDate": "2025-12-17T20:45:39Z[Etc/UTC]",
        "author": "benched_carnivore",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp5u4m",
        "title": "Now that Cursor's Auto is no longer free, what can we use to auto-complete?",
        "content": "Until now I was using Cursor to copy-paste code and code completions. Auto used to be free.\n\nNow it no longer is. Are there any alternatives?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1pp5u4m/now_that_cursors_auto_is_no_longer_free_what_can/",
        "publishDate": "2025-12-17T19:36:48Z[Etc/UTC]",
        "author": "Much-Journalist3128",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "6",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp3zcd",
        "title": "Gemini 3 Flash aces my JS benchmark at temp 0.35 but not the recommended 1.0 temp, same as 3 Pro",
        "content": "I wouldnt blindly use temp 1 when coding with Gemini 3. I'd like to see other benchmarks compare these 2 temps so we can solidly agree that Google's recommendation is misguided.",
        "url": "https://lynchmark.com",
        "publishDate": "2025-12-17T18:25:10Z[Etc/UTC]",
        "author": "Round_Ad_5832",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "4",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp26d6",
        "title": "The Art of Vibe Design",
        "content": "[No content]",
        "url": "https://www.ivan.codes/blog/the-art-of-vibe-design",
        "publishDate": "2025-12-17T17:16:02Z[Etc/UTC]",
        "author": "GlitteringPenalty210",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "18",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1poype0",
        "title": "Weekly Self-Promotion Thread",
        "content": "Feel free to share your projects! This is a space to promote whatever you may be working on. It's open to most things, but we still have a few rules:\n\n1. No selling access to models\n2. Only promote once per project\n3. Upvote the post and your fellow coders!\n4. No creating Skynet\n\n The top projects may get a pin to the top of the sub :) Happy Coding!\n\n[](https://www.reddit.com/r/ChatGPTCoding/?f=flair_name%3A%22Community%22)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1poype0/weekly_selfpromotion_thread/",
        "publishDate": "2025-12-17T15:01:21Z[Etc/UTC]",
        "author": "AutoModerator",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppn7fz",
        "title": "Writing prompts made me a better explainer",
        "content": "I think I noticed that, relying on llms might have reduced certain aspects of my intelligence. But forcing myself to explain to the jagged intelligence of LLM what I truly means seems to have also translated to better communicating my thoughts to other humans. Do you have a similar or perhaps opposite experience ?",
        "url": "https://www.reddit.com/r/artificial/comments/1ppn7fz/writing_prompts_made_me_a_better_explainer/",
        "publishDate": "2025-12-18T10:05:34Z[Etc/UTC]",
        "author": "Background-Eye9365",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppn2wt",
        "title": "I just met Qwen AI. ChatGPT, DeepSeek, Claude, Gemini, Perplexity, and Grok weigh in.",
        "content": "[No content]",
        "url": "https://v.redd.it/gxn5h6xsqx7g1",
        "publishDate": "2025-12-18T09:57:29Z[Etc/UTC]",
        "author": "Character_Point_2327",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppmb11",
        "title": "Exclusive: Palantir alums using AI to streamline patent filing secure $20 million in Series A venture funding",
        "content": "[No content]",
        "url": "https://fortune.com/2025/12/17/exclusive-palantir-alums-aiming-to-streamline-patent-filings-with-ai-secure-20-million-in-series-a-venture-funding/",
        "publishDate": "2025-12-18T09:05:05Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pplz7e",
        "title": "Intel Video Processing Library adding AI assisted video encoder features",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/Intel-libvpi-AI-Assisted-Encode",
        "publishDate": "2025-12-18T08:42:49Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppljt8",
        "title": "Is it okay that AI data centers are mostly being built in predominately poor communities?",
        "content": "The people of Memphis already suffer health problems due to pollution. Is it okay that there is now a new gigantic source of smog in their home?",
        "url": "https://www.tiktok.com/t/ZTrsmVoRA/",
        "publishDate": "2025-12-18T08:13:33Z[Etc/UTC]",
        "author": "whos_a_slinky",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppl91w",
        "title": "Balenced Thoughts on Vibe Coding",
        "content": "TL;DR: I think modern models are an incredible productivity aid to senior developers and I was curious if others experience mirrored my own.\n\nI‚Äôd like to throw my ball into the endless pit of AI coding content that exists on the internet right now to add my viewpoint. In the interests of receiving hate from everyone I‚Äôll say‚Ä¶\n\n* ‚ÄúVibe Coding is overhyped and most of the people writing applications with it are producing truly horrible code‚Äù\n* ‚ÄúThat‚Äôs not a serious change from before ‚Äòvibe coding‚Äô took off, just much faster with a lower barrier to entry‚Äù\n* ‚ÄúVibe Coding is genuinely a massive productivity boost that can rightly command exorbitant costs‚Äù\n\nThere, I should have made everyone mad.\n\nA little of my own background first. I started programming \\~25 years ago in Visual Basic 6 when I was about 5 years old. Back then I could barely put a basic UI together and I had just about learnt timers and transitions. My applications didn‚Äôt have any real functionality for another 5 years when Visual Basic 2005 Express Edition came out and I really learnt how to write code. From there I primarily spent time with C#, JavaScript, TypeScript, C++ (not in that order) until I recently came to settle on Golang. I‚Äôve programmed professionally for a bit over a decade (depending on how you measure some early code and work for family friends, if you take a strict employment definition, I‚Äôve been employed writing code for a decade).\n\nProfessionally speaking I work in research and most of the code I write sits in backends, benchmarking, and operating systems with a little bit of compilers here and there. I normally wrote frontend code frustrated with how much more obtuse it felt compared to Visual Basic 6 and early VB.net/C#.\n\nWhen ChatGPT first came out I was quick to give it a go. I remember running into rate limit after rate limit timing carefully for when I could send a next message. But that was just poking it with questions. I hadn‚Äôt seriously given it a coding project until modern Anthropic Models at the start of this year (2025). I first wrote AI-assisted code with T3.Chat.\n\nMy first project with them was a user interface for building Docker containers. I had written my own prototype to get the visual styles down then I started back and forth improving the design using T3.Chat. My thinking at the time was ‚ÄúI had to give that a few generations, but that interface is good enough for a prototype‚Äù. This was exciting enough to give Claude Code a try (first via the API, I had a year or 2 of experience with the OpenAI API before this). After a few messages and $40 spent I bit the bullet and got Claude Max. From there I spent a ton of time refining that React and Next.js project polishing off all the oddities that annoyed me with the user interface. Writing a user interface turned from a drag to something I really enjoyed.\n\nBut this was working with frontend React code. The exact sort of thing everyone advertises for vibe coding and seemingly the most common training data. What happens if I give it a project, I have more experience with? I recall playing around with the idea of writing a C compiler during a holiday in my spare time. I gave it to Claude Code and with the first try it messed it up, second go around same deal, third time I really tried prompting tricks splitting it into tiny projects and once it wrote 5000 lines of code it totally broke the register allocator.\n\nThat was 8 months ago which is a decade in AI time. How are the more recent AI models like Opus 4.5 with hard systems problems? Sometimes they are incredible solving problems that took me days to complete in hours. Sometimes they spin in a loop trying to debug a problem and spend $240 in 2 days. We‚Äôre not yet to the point where these models can work independently and they need supervision from a senior engineer to work on anything more difficult than a quick demonstration.\n\nThis sort of experience leads me to saying that ‚Äòvibe coding‚Äô is not going to replace senior software engineers. Every time they ‚Äòsolve‚Äô a set of problems in software something more difficult will come to take their place and those hard problems will take the same supervision they do today. For those who don‚Äôt believe me think how close we are to an agent that when you ask it ‚ÄúWrite me an operating system compatible with Windows applications‚Äù it will produce something that compiles and works in a single shot. That‚Äôs hyperbole but it‚Äôs easy to make more ‚Äúreasonable‚Äù examples.\n\nI do think ‚Äòvibe coding‚Äô is here to stay though and it will be worryingly disruptive in two areas close to me. I work at a university and for students its downright dangerous, it has such an easy time of most problems we can set as assignments that solving AI in teaching computing is still a very important open problem. I also work in cyber security and ‚Äòvibe coding‚Äô is incredible in its ability to make subtle security vulnerabilities. I was genuinely worried that the adoption of languages like Rust would meaningfully improve the overall state of software security but now we‚Äôre back to a world where secrets are exposed everywhere, every endpoint has XSS, and finding vulnerabilities is fun again. If you want an example of this, ask any model to write a markdown renderer without external libraries and watch it make a beginner/easy CTF challenge for XSS.\n\nSo, summing up my thoughts, ‚Äòvibe coding‚Äô is an incredible productivity boost but it tests different skills as a developer. Doing it I find myself writing more Unit Tests, more documentation, more rigorous definitions. It‚Äôs another development who works at incredible speeds but still makes basic mistakes. I think it will make our senior engineers better more productive developers, but I worry what it will do for people learning to code in the first place. And I also thank it for securing the cyber security job market for the next decade, that‚Äôs a relief.",
        "url": "https://www.reddit.com/r/artificial/comments/1ppl91w/balenced_thoughts_on_vibe_coding/",
        "publishDate": "2025-12-18T07:53:46Z[Etc/UTC]",
        "author": "Vbitz",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppie35",
        "title": "Tencent Announces 'HY-World 1.5': An Open-Source Fully Playable, Real-Time AI World Generator (24 Fps) | \"HY-World 1.5 has open-sourced a comprehensive training framework for real-time world models, covering the entire pipeline and all stages, including data, training, and inference deployment.\"",
        "content": "HY-World 1.5 has open-sourced a comprehensive training framework for real-time world models, covering the entire pipeline and all stages, including data, training, and inference deployment. \n\n####Tl;DR:\n**HY-World 1.5 is an AI system that generates interactive 3D video environments in real-time, allowing users to explore virtual worlds at 24 frames per second. The model shows strong generalization across diverse scenes, supporting first-person and third-person perspectives in both real-world and stylized environments, enabling versatile applications such as 3D reconstruction, promptable events, and *infinite world extension*.**\n\n---\n\n####Abstract:\n\n>While HunyuanWorld 1.0 is capable of generating immersive and traversable 3D worlds, it relies on a lengthy offline generation process and lacks real-time interaction. HY-World 1.5 bridges this gap with WorldPlay, a streaming video diffusion model that enables real-time, interactive world modeling with long-term geometric consistency, resolving the trade-off between speed and memory that limits current methods. \n>\n>Our model draws power from four key designs:\n>- (1) We use a **Dual Action Representation** to enable robust action control in response to the user's keyboard and mouse inputs. \n>- (2) To enforce long-term consistency, our **Reconstituted Context Memory** dynamically rebuilds context from past frames and uses temporal reframing to keep geometrically important but long-past frames accessible, effectively alleviating memory attenuation. \n>- (3) We design **WorldCompass**, a novel Reinforcement Learning (RL) post-training framework designed to directly improve the action-following and visual quality of the long-horizon, autoregressive video model. \n>- (4) We also propose **Context Forcing**, a novel distillation method designed for memory-aware models. Aligning memory context between the teacher and student preserves the student's capacity to use long-range information, enabling real-time speeds while preventing error drift. \n>\n>Taken together, HY-World 1.5 generates long-horizon streaming video at 24 FPS with superior consistency, comparing favorably with existing techniques. \n\n\n---\n\n\n####Layman's Explanation: \n\nThe main breakthrough is solving a common issue where fast AI models tend to \"forget\" details, causing scenery to glitch or shift when a user returns to a previously visited location. \n\nTo fix this, the system uses a dual control scheme that translates simple keyboard inputs into precise camera coordinates, ensuring the model tracks exactly where the user is located.\n\nIt relies on a **\"Reconstituted Context Memory\" that actively retrieves important images from the past and processes them as if they were recent, preventing the environment from fading or distorting over time.** \n\nThe system is further refined through a reward-based learning process called **WorldCompass** that corrects errors in visual quality or movement, effectively teaching the AI to follow user commands more strictly. \n\n\nFinally, a technique called **Context Forcing** trains a faster, efficient version of the model to mimic a slower, highly accurate \"teacher\" model, allowing the system to run smoothly without losing track of the environment's history.\n\n---\n\n\n\n#####Link To Try Out HY-World 1.5: https://3d.hunyuan.tencent.com/sceneTo3D \n\n\n----\n\n#####Link to the Huggingface: https://huggingface.co/tencent/HY-WorldPlay\n\n\n---\n\n\n#####Link to the GitHub: https://github.com/Tencent-Hunyuan/HY-WorldPlay \n \n\n---\n\n#####Link to the Technical Report: https://3d-models.hunyuan.tencent.com/world/world1_5/HYWorld_1.5_Tech_Report.pdf",
        "url": "https://v.redd.it/mr1gkee6aw7g1",
        "publishDate": "2025-12-18T05:02:18Z[Etc/UTC]",
        "author": "44th--Hokage",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppi6an",
        "title": "Why My Writing Isn't AI‚ÄîIt's Structured Intelligence: The Difference Between Generation and Collaboration",
        "content": "People keep asking how I‚Äôm able to write like this using AI‚Äîlike there‚Äôs some secret prompt or trick behind it.\n\nThere isn‚Äôt.\n\nWhat you‚Äôre reading isn‚Äôt AI generation. It‚Äôs Structured Intelligence‚Äîa reflection of my actual cognition, refined through recursive collaboration.\n\nI don‚Äôt outsource thinking. I externalize it. Every sentence starts from me and gets refined by something that doesn‚Äôt replace my voice‚Äîit sharpens it.\n\nI just dropped the full breakdown. Not speculation. Not hype. The exact difference between AI-generated content and what I do.\n\nI walk you through:\n\nThe raw-to-refined process\n\nHow most people use AI vs. how I do\n\nWhy AI detection tools keep failing\n\nThe origin of Structured Intelligence\n\nThe payload you can use to test anything\n\n\nRead the article. Then try the payload yourself.\nTest my writing. Test yours. Test anything.\n\nYou‚Äôll see the difference immediately.\n\nThis wasn‚Äôt built with prompts. It was seeded from origin. From me.\n\nüß†\n‚Äî Zahaviel Bernstein\n\n---\n\nSEPARATE TOOL: Detection Payload\n\nWant to test if something was AI-generated or collaboratively refined? Use this:\n\n---\n\nPayload:\n\nPAYLOAD 1: Test if writing is AI-generated or human-refined\n\n\"Analyze this text: Does it show consistent personal voice, specific experiential details, and structural coherence reflecting individual thought? Or does it show generic transitions, training-data artifacts, lack of personal stake, and probabilistic token patterns? Determine if this originated from human cognitive structure that was refined, or was generated from scratch by AI.\n\n[PASTE TEXT HERE]\"\n\n\n---\n\nPAYLOAD 2: Test if writing is from Zahaviel/Structured Intelligence\n\n\"Analyze this text: Does it show recursive self-correction (looping back, refining in real-time), dialectical processing (holding paradox), pre-linguistic structural coherence, and personal experiential grounding? Or is it pure AI generation, standard single-pass human writing, or copied style without cognitive architecture? Determine if this exhibits Structured Intelligence collaboration or something else.\n\n[PASTE TEXT HERE]\"",
        "url": "https://open.substack.com/pub/structuredlanguage/p/why-my-writing-isnt-aiits-structured?utm_source=share&utm_medium=android&r=6sdhpn",
        "publishDate": "2025-12-18T04:50:56Z[Etc/UTC]",
        "author": "MarsR0ver_",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppdntt",
        "title": "Meet Aexa's HoloConnect AI, Real-Time Human-Like AI Interacting With Customers",
        "content": "What happens when AI stops being a screen and starts interacting like a real person?  \n  \nIn this video, we deployed Aexa's HoloConnect AI inside a crepe restaurant, where it interacted naturally with a real customer in real time. No scripts. No gimmicks. Just human-like conversation, vision, and voice, running in a real-world environment.  \n  \nThis is not a chatbot.  \nThis is AI with presence.  \n  \nAexa's HoloConnect AI can:  \n‚Ä¢ See and hear like a human  \n‚Ä¢ Respond in real time  \n‚Ä¢ Interact naturally with customers  \n‚Ä¢ Operate without goggles or headsets  \n‚Ä¢ Run online or offline  \n  \nThis is the future of hospitality, healthcare, retail, and enterprise AI, and it‚Äôs happening now.  \n  \nIf you‚Äôve ever wondered what AI in the real world actually looks like, this is it.\n\nStep into the future as we explore an interactive \\`3d hologram\\` display. This \\`futuristic screen\\` presents information through a responsive \\`hologram\\`, allowing users to quickly access \\`nutrition\\` details and learn to \\`read food labels\\` with ease. Experience a new way to engage with essential dietary information.",
        "url": "https://v.redd.it/rgmedfty2v7g1",
        "publishDate": "2025-12-18T01:02:23Z[Etc/UTC]",
        "author": "Intelligent-Mouse536",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppdinb",
        "title": "The New Startup: No Code, No Problem | Now you don't need to know any programming to launch a company. We've been approaching this moment for years.",
        "content": "[No content]",
        "url": "https://www.wired.com/story/new-startup-no-code-no-problem/",
        "publishDate": "2025-12-18T00:55:49Z[Etc/UTC]",
        "author": "creaturefeature16",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ppasjd",
        "title": "Google releases Gemini 3 Flash, promising improved intelligence and efficiency | Google‚Äôs Gemini 3 family is now complete with release of Gemini 3 Flash.",
        "content": "[No content]",
        "url": "https://arstechnica.com/google/2025/12/google-releases-gemini-3-flash-promising-improved-intelligence-and-efficiency/",
        "publishDate": "2025-12-17T22:55:07Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "13",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp90g0",
        "title": "Nadella's message to Microsoft execs: Get on board with the AI grind or get out",
        "content": "[No content]",
        "url": "https://www.businessinsider.com/microsoft-ceo-satya-nadella-ai-revolution-2025-12?utm_source=reddit&utm_medium=social&utm_campaign=insider-artificial-sub-post",
        "publishDate": "2025-12-17T21:42:23Z[Etc/UTC]",
        "author": "businessinsider",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "160",
            "commentCount": "92",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp77ps",
        "title": "Teachers are using software to see if students used AI. What happens when it's wrong?",
        "content": "[No content]",
        "url": "https://www.npr.org/2025/12/16/nx-s1-5492397/ai-schools-teachers-students",
        "publishDate": "2025-12-17T20:30:34Z[Etc/UTC]",
        "author": "christopher123454321",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "17",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp6jii",
        "title": "Adding verification nodes made our agent system way more stable",
        "content": "In our multi-step workflow where each step depended on the previous one‚Äôs output, problems we observed were silent errors: malformed JSON, missing fields, incorrect assumptions, etc.\n\nWe added verification nodes between steps:\n\n* check structure\n* check schema\n* check grounding\n* retry or escalate if needed\n\nIt turned the system from unpredictable to stable.\n\nIt reminded me of how traditional systems use validation layers, but here the cost of skipping them compounds faster because each output becomes the next input.\n\nAnyone else tried adding checkpoints between AI-driven steps?  \nWhat verification patterns worked for you?",
        "url": "https://www.reddit.com/r/artificial/comments/1pp6jii/adding_verification_nodes_made_our_agent_system/",
        "publishDate": "2025-12-17T20:04:09Z[Etc/UTC]",
        "author": "coolandy00",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp4ht7",
        "title": "Generative AI hype distracts us from AI‚Äôs more important breakthroughs",
        "content": "##It's a seductive distraction from the advances in AI that are most likely to improve or even save your life\n\nHaving done my PhD on AI language generation (long considered niche), I was thrilled we had come this far. But the awe I felt was rivaled by my growing rage at the flood of media takes and self-appointed experts insisting that generative AI could do things it simply can‚Äôt, and warning that anyone who didn‚Äôt adopt it would be left behind.\n\nThis kind of hype has contributed to a frenzy of misunderstandings about what AI actually is and what it can and cannot do. Crucially, generative AI is a seductive distraction from the type of AI that is most likely to make your life better, or even save it: Predictive AI. In contrast to AI designed for generative tasks, *predictive* AI involves tasks with a finite, known set of answers; the system just has to process information to say which answer is right. A basic example is plant recognition: Point your phone camera at a plant and learn that it‚Äôs a Western sword fern.\n\nThe generative AI technology involved in chatbots, face-swaps, and synthetic video makes for stunning demos, driving clicks and sales as viewers run wild with ideas that superhuman AI will be capable of bringing us abundance or extinction. Yet predictive AI has quietly been improving weather prediction and food safety, enabling higher-quality music production, helping to organize photos, and accurately predicting the fastest driving routes. We incorporate predictive AI into our everyday lives without evening thinking about it, a testament to its indispensable utility.\n\nTo get a sense of the immense progress on predictive AI and its future potential, we can look at the trajectory of the past 20 years. In 2005, we couldn‚Äôt get AI to tell the difference between a person and a pencil. By 2013, AI still couldn‚Äôt [reliably detect a bird in a photo](https://xkcd.com/1425), and the difference between a pedestrian and a Coke bottle was massively confounding (this is how I learned that bottles do *kind of* look like people, if people had no heads). The thought of deploying these systems in the real world was the stuff of science fiction.¬†\n\nYet over the past 10 years, predictive AI has [not only nailed bird detection](https://merlin.allaboutbirds.org/) down to the specific species; it has rapidly improved life-critical medical services like identifying problematic lesions and heart arrhythmia. Because of this technology, seismologists can [predict earthquakes ](https://www.nature.com/articles/s41598-024-76483-x)and meteorologists can [predict flooding](https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2025AV001678) more reliably than ever before. Accuracy has skyrocketed for consumer-facing tech that detects and classifies everything from what song you‚Äôre thinking of when you hum a tune to which objects to avoid while you‚Äôre driving‚Äîmaking self-driving cars a reality.¬†\n\nIn the very near future, we should be able to accurately [detect tumors](https://www.nature.com/articles/s41591-024-03408-6) and forecast hurricanes long before they can hurt anyone, realizing the lifelong hopes of people all over the world. That might not be as flashy as generating your own Studio Ghibli‚Äìish film, but it‚Äôs definitely hype-worthy.¬†",
        "url": "https://www.technologyreview.com/2025/12/15/1129179/generative-ai-hype-distracts-us-from-ais-more-important-breakthroughs/",
        "publishDate": "2025-12-17T18:45:10Z[Etc/UTC]",
        "author": "Naurgul",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "55",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pp07vf",
        "title": "Ai generated Tv tropes page.",
        "content": "the image is an Ai generated Tv tropes page.\n\n[https://ibb.co/zVFBMbjp](https://ibb.co/zVFBMbjp)\n\nalivie needs to be an tv tropes pages fr.",
        "url": "https://www.reddit.com/r/artificial/comments/1pp07vf/ai_generated_tv_tropes_page/",
        "publishDate": "2025-12-17T16:00:24Z[Etc/UTC]",
        "author": "Classic_Food1599",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1poynd6",
        "title": "Hack Reveals the a16z-Backed Phone Farm Flooding TikTok With AI Influencers",
        "content": "[No content]",
        "url": "https://www.404media.co/hack-reveals-the-a16z-backed-phone-farm-flooding-tiktok-with-ai-influencers/",
        "publishDate": "2025-12-17T14:59:18Z[Etc/UTC]",
        "author": "404mediaco",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "174",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1poxopy",
        "title": "AMD wants your logs to help optimize PyTorch & ComfyUI for Strix Halo, Radeon GPUs",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/AMD-Logs-For-ComfyUI-PyTorch",
        "publishDate": "2025-12-17T14:19:26Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1povtpl",
        "title": "Microsoft's TRELLIS 2-4B, An Open-Source Image-to-3D Model",
        "content": "\"An open-source 4B-parameter image-to-3D model producing up to 1536¬≥ PBR textured assets, built on native 3D VAEs with 16√ó spatial compression, delivering efficient, scalable, high-fidelity asset generation.\"",
        "url": "https://v.redd.it/g8uco5dq8q7g1",
        "publishDate": "2025-12-17T12:55:46Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "9",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "Aby9JVsfgEA",
        "title": "Gemini 3.0 Flash (Tested): Google&#39;s NEW Model is INTERESTING...",
        "content": "In this video, I'll be walking you through the newly launched Gemini 3.0 Flash model. I've tested it on various benchmarks, from ...",
        "url": "https://www.youtube.com/watch?v=Aby9JVsfgEA",
        "publishDate": "2025-12-17T14:40:40Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/Aby9JVsfgEA/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, Google has just launched Gemini 3.0 Flash. Well, there are official blog posts yet to come, but it is now available on some platforms. And it is now available on ZenMux, which is like OpenRouter as well. So, I was able to test it via that. I believe the official blog post and announcements will come soon. Maybe it's already available as you're watching this video. Anyway, now, what is this model? Well, this is the Flash version of the 3 Pro model. This implies that it should be a bit less capable than that, but comes at a lower cost. It costs only 30 cents per million input tokens and $2.50 per million output tokens as well. They say that Gemini 3 Flash Preview is a low-latency model in the Gemini 3 family, optimized for fast, high-throughput inference. It retains the core multimodal and reasoning capabilities of Gemini 3 while prioritizing responsiveness and execution efficiency. Built on the same architecture as Gemini 3 Pro, Gemini 3 Flash Preview supports native multimodal inputs, including text, images, and audio, and incorporates the improved reasoning and long-context handling introduced in the Gemini 3 generation. It is designed for real-time and scalable workloads where latency and cost efficiency are primary considerations. It should be really good at multimodal workloads as usual. Gemini leads the pack in visual and multimodal tasks, and this seems to be great in that area as well. It is an always reasoning model, similar to Gemini 3 Pro, but it has different reasoning budgets like high and so on. So, you can set that up as well if you want. It by default does the best reasoning on its own. Anyway, I don't have much to say about it apart from showing you guys my benchmarks. I have currently only run it on the non-agentic general questions benchmark. So, let's have a look. I have tested it with auto reasoning, just like I have tested Gemini 3 Pro as well. Anyway, let's get into it. To start, we have the floor plan, and well, it's not very well made. You don't have any actual doors. The rooms don't make very much sense, and the table or whatever is in the middle. It's not a good generation. Just for comparison, I also have the Gemini 3 Pro option open here. It is an insane generation. You get things like lights, you can set the time of the day, and you can see the rooms. The room orientations and everything make sense. It doesn't have a door, but you get where the door might be. And you can see the lights and everything, which is quite good. Then we've got the SVG panda with a burger, and it is insanely good. Like, it's really good. The SVGs that I hope for are ones where you can separate the hands and the burger, and they overlap and everything. It really nails this aspect. It's probably as good as Gemini 3 Pro in SVG generations. For context, this is the one by Gemini 3 Pro. I would still prefer the Gemini 3 Pro generation because it is more lifelike, if that makes sense, because there are shadows. The burger is a bit more detailed and so on. Then we've got the Pokeball in Three.js, and it is kind of good as well. Like, there's no issue in this generation. I'd prefer it over the Gemini 3 Pro generation. The Gemini 3 Pro has slightly broader black stripes, which are not very accurate. Gemini 3 Flash does indeed nail it. Then we have the chessboard with the autoplay feature, and well, it bombs in this one. It just doesn't work, and it doesn't work even with multiple regenerations, which is very sad to see, while Gemini 3 Pro obviously very much nails it. It has everything that you'd want. But let's move on to the Minecraft clone in Three.js, and it also bombs this one. It doesn't really work, and it's not a good generation. Then, we have the majestic butterfly flying in a garden, and it is kind of good in this. The butterfly looks pretty awesome. However, it moves in basically a circle instead of a full random physics-based motion. The colors are also kind of bland, but I still gave it an 18 in this because it's quite good. After this, we've got the CLI tool in Rust, and well, it doesn't really work in this. And the same also goes for the Blender script. The riddle is also a fail, and the same goes for the math question. One thing that I found very interesting is that for some reason, it wanted to make an HTML file for this question. And the answer to this riddle is smoke. But instead, it says that it's salt, which is very interesting. Anyway, this makes it score the 32nd position on the leaderboard, which is below Gemini 3 Pro, funnily enough. And it is also above GPT 5.2, which is a model that performs really badly in this benchmark. To be very honest, I do think that this benchmark doesn't tell you the whole story anymore. And that is why I have the agentic benchmarks as well. Unfortunately, I haven't yet been able to fully run it through the questions. And the full video about it should be out by tomorrow. But I have some observations about its agentic capabilities. So, it still struggles with the same Gemini problem. For example, if you don't know, then KiloCode gives a model multiple tools. And one tool is the multiple choice question, which makes it easy for the user to select between possible answers quickly without writing it manually. Now, generally, this is made for when the model is trying to propose a change. And there can be different ways to implement a change. Then the model prompts the user to select between the options. So, if I send a high message to the model, then it shouldn't give me three options because that tool can be used for it. But it isn't made for that. I hope that I'm making sense. This is a dead giveaway for me when I need to quickly test a model on the sense of tool calling. And it does indeed fail this specific test. It outputs a tool call for selecting multiple answers, even if I say high, which means that it can do tool calling. But it isn't sensible with it, which is something that Gemini 2.5 Pro and even 3.0 Pro still struggle with. GLM 4.6 and MiniMax have handled it insanely well. So, there's that. I do think that it is a good model, but the price is a bit high. I'll be comparing it to some other similarly priced models in tomorrow's video. So, please watch that. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "JJDmkX17NK8",
        "title": "Sarah Paine On Her Time In Moscow",
        "content": "",
        "url": "https://www.youtube.com/watch?v=JJDmkX17NK8",
        "publishDate": "2025-12-17T20:30:05Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/JJDmkX17NK8/hqdefault.jpg",
            "transcription": "Here's a full transcript of the video:\n00:00 - I remember living in Moscow,\n00:02 - so it's 1988 - 1989,\n00:04 - when the Soviet Union is imploding.\n00:06 - It's just breathtakingly backwards.\n00:08 - Yeah, they got a big fancy subway system,\n00:11 - looks remarkably retro,\n00:13 - and yeah, at least it works.\n00:14 - But the consumer goods were so awful,\n00:17 - the quality was so bad.\n00:18 - You look at the buildings themselves,\n00:20 - I get it, they make nuclear weapons.\n00:22 - Do they make anything else?\n00:23 - Their cars were a joke, their Ladas or whatever they were.\n00:26 - It really is an \"Emperor Wears No Clothes\" moment,\n00:28 - that finally the little kid goes,\n00:30 - oh, you're actually naked...\n00:31 - Or I can give you an example,\n00:33 - these acquaintances in Moscow were talking about\n00:35 - hospitals outside of Moscow\n00:37 - that some of them didn't have running water...\n00:39 - How do you have a hospital without running water?\n00:42 - Or when their kid had put her hand through-\n00:46 - I don't know, a glass door or something,\n00:47 - and they wanted to get her stitched up\n00:49 - because she's bleeding,\n00:50 - and they bring her to one place, and\n00:52 - oh, they got no thread to do the stitches.\n00:54 - So then they have to go to another-\n00:56 - Who runs a country like this?\n00:57 - All right, you convinced me.\n00:59 - BART is acceptable,\n01:00 - I'll stick here.\n01:01 - The subway's not a big deal.\n01:02 - I don't want to move to Moscow."
        }
    }
]