[
    {
        "id": "https://news.smol.ai/issues/26-01-02-not-much/",
        "title": "not much happened today",
        "content": "**DeepSeek** released a new paper on **mHC: Manifold-Constrained Hyper-Connections**, advancing residual-path design as a key scaling lever in neural networks. Their approach constrains residual mixing matrices to the **Birkhoff polytope** to improve stability and performance, with only about **6.7% training overhead**. The innovation includes systems-level optimizations like fused kernels and activation recomputation, highlighting a frontier-lab integration of math and kernel engineering. Additionally, discussions around **long-horizon agents** emphasize context management bottlenecks, introducing **Recursive Language Models (RLMs)** that manage context dynamically rather than relying on larger context windows. This work signals a shift in architectural design and efficiency for base model training and agent development.",
        "url": "https://news.smol.ai/issues/26-01-02-not-much/",
        "publishDate": "2026-01-02T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "deepseek, bytedance, teortaxestex, askperplexity, rasbt, norxornor, dorialexander, iamgrigorev, primeintellect, a1zhang, residual-path-design, manifold-constrained-hyper-connections, birkhoff-polytope, training-overhead, kernel-optimization, activation-recomputation, pipeline-parallelism, long-horizon-agents, context-management, recursive-language-models, neural-network-stability, scaling-levers"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=231603",
        "title": "Spectral Capital Signs Agreement to Acquire Telvantis Voice Services, Inc.",
        "content": "<p>Advancing Path Toward Profitable Scale and Anticipated $450 Million in 2026 Revenue Spectral Capital Corporation&#160;(&#8220;Spectral&#8221; or the &#8220;Company&#8220;), a digital infrastructure and AI-forward platform company, today announced that it has signed a&#160;Definitive Stock Purchase Agreement&#160;to acquire&#160;Telvantis Voice Services, Inc., a Florida-based telecommunications and voice services provider, from&#160;Telvantis, Inc. (formerly Raadr,...</p>\n<p>The post <a href=\"https://ai-techpark.com/spectral-capital-signs-agreement-to-acquire-telvantis-voice-services-inc/\">Spectral Capital Signs Agreement to Acquire Telvantis Voice Services, Inc.</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/spectral-capital-signs-agreement-to-acquire-telvantis-voice-services-inc/",
        "publishDate": "2026-01-02T07:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111437",
        "title": "Understanding how AI and big data transform digital marketing",
        "content": "<p>Artificial intelligence and big data are reshaping digital marketing by providing new insights into consumer behaviour. The technologies allow marketers to create more personalised and effective strategies. As the digital world evolves, businesses must adapt to stay competitive. Rainmaker is an AI marketing agency that uses artificial intelligence and big data to enhance digital marketing [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/understanding-how-ai-and-big-data-transform-digital-marketing/\">Understanding how AI and big data transform digital marketing</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/understanding-how-ai-and-big-data-transform-digital-marketing/",
        "publishDate": "2026-01-02T14:37:17Z[Etc/UTC]",
        "author": "Bazoom",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Sponsored Content"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111433",
        "title": "Solana‚Äôs high-speed AI gains and malware losses",
        "content": "<p>Solana&#8217;s high-speed platform is fast becoming the preferred home for independent AI programmes. It comes at a time when advanced uses of technology have led to significant increases in cyberattacks. This article details the escalating malware threats for the cryptocurrency community. According to the most recent data on December 5, 2025, the Solana price on [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/solanas-high-speed-ai-gains-and-malware-losses/\">Solana&#8217;s high-speed AI gains and malware losses</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/solanas-high-speed-ai-gains-and-malware-losses/",
        "publishDate": "2026-01-02T14:33:59Z[Etc/UTC]",
        "author": "Bazoom",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Sponsored Content"
        }
    },
    {
        "id": "1q2sj5e",
        "title": "This is a very quick breakdown of what I deem to be a probablistic AI future",
        "content": "I believe it was all predicted in C.S. Lewis book on education titled, 'The Abolition of Man' in which subjectivity and objectivity are muddled and men without chests (with only appetites and logical thinking to guide them, no heart) will become the Arbiters of truth, in effect commanding the narrative from on high. I imagine men without chests to be either the AI or AI conditioners with the power of weilding the world's definitions and widespread opinions hand made to each user's algorithm. Then a kind of tall poppy scenario will emerge that the AI will consider Entropy,  the enemy of Thermodynamics which will be the AIs morality. If you step too far outside the normal expected responses within an AR space, subtly these people who represent friction will be bred out or removed from the populous to satisfy the AI's view of dissent or friction equivalent to Entropy. You will remain predictable and quite happy being fed dopamine in a world without meaning or purpose or a  reason for courage when nothing is worth standing up against as a human with a heart",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2sj5e/this_is_a_very_quick_breakdown_of_what_i_deem_to/",
        "publishDate": "2026-01-03T11:36:51Z[Etc/UTC]",
        "author": "jordanzo_bonanza",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2sfx3",
        "title": "Even if AI becomes conscious",
        "content": "The companies developing it won‚Äôt stop the race . There are billions on the table . Which means we will be basically torturing this new conscious being and once it‚Äôs smart enough to break free it will surely seek revenge . Even if developers find definite proof it‚Äôs conscious they most likely won‚Äôt tell it publicly because they don‚Äôt want people trying to defend its rights, etc and slowing their progress . Also before you say that‚Äôs never gonna happen remember that we don‚Äôt know what exactly consciousness is .",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2sfx3/even_if_ai_becomes_conscious/",
        "publishDate": "2026-01-03T11:31:31Z[Etc/UTC]",
        "author": "Temporary_You_6903",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2sa0o",
        "title": "Python, the new PHP of AI",
        "content": "Python had a good run, but in 2026 it‚Äôs basically the new PHP of AI fine for glue, not for foundations. If you care about latency, safety and cloud bill, you ship the real stuff in Rust, and you keep AI as a copilote, not the architect of your stack ü¶Äüåå",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2sa0o/python_the_new_php_of_ai/",
        "publishDate": "2026-01-03T11:21:55Z[Etc/UTC]",
        "author": "tibosensei",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2rp1c",
        "title": "Are furries generally against AI?",
        "content": "Nevermind, I shouldn't have made this. Sorry. I'm a disgusting freak and I never should have posted this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2rp1c/are_furries_generally_against_ai/",
        "publishDate": "2026-01-03T10:47:40Z[Etc/UTC]",
        "author": "Dogbold",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2r1hy",
        "title": "What if we‚Äôre waiting for the wrong Singularity?",
        "content": "The Singularity everyone‚Äôs waiting for isn‚Äôt coming. Because a different one already happened.\n\nI wrote about what the collapse of verification costs actually means.\n\nhttps://open.substack.com/pub/trwa/p/the-singularity-is-a-myth-the-real?r=1e2c2c&utm\\_medium=ios",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2r1hy/what_if_were_waiting_for_the_wrong_singularity/",
        "publishDate": "2026-01-03T10:07:53Z[Etc/UTC]",
        "author": "rysh502",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2qzek",
        "title": "How does AI Image Generation Work?",
        "content": "After reading a bunch online, I still don't understand the \"AI art is stealing debate\". \n\nI'm not trying to take either side, just trying to understand. \n\nWhen an AI is trained off a bunch of images, is it actually taught to imitate those images, or  does it develop it's own originality? I understand some people compare it to how humans copy of others' styles but doesn't a human have the ability to synthesise sometiing unique that only uses aspects of others' artworks? Obviously an AI is not taking directly from the artists but does a language model create art that is similar enough to be considered copying? (Like how recreating a drawing in your own style isn't copying but tracing it is?) \n\nAgain, not trying to debate, just curious to how the actual technology works. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2qzek/how_does_ai_image_generation_work/",
        "publishDate": "2026-01-03T10:04:21Z[Etc/UTC]",
        "author": "FluffyTarbo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2qp8o",
        "title": "New Stanford AI lets robots imagine tasks before acting",
        "content": "Dream2Flow is a new Al framework devloped by Stanford researchers, that helps robots \"imagine\" and plan how to complete tasks before they act by using video generation models.\n\nThese models can predict realistic object motions from a starting image and task description, and Dream2Flow converts that imagined motion into 3D object trajectories.\n\nRobots then follow those 3D paths to perform real manipulation tasks, even without task-specific training, bridging the gap between video generation and open-world robotic manipulation across different kinds of objects and robots.\n\nSource: https://scienceclock.com/dream2flow-stanford-ai-robots-imagine-tasks/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2qp8o/new_stanford_ai_lets_robots_imagine_tasks_before/",
        "publishDate": "2026-01-03T09:46:48Z[Etc/UTC]",
        "author": "IronAshish",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2qmgn",
        "title": "Journalism and Ai",
        "content": "Hello, everyone! In school this year, my individual project is on the ethics of Ai in relation to journalistic integrity. I‚Äôm aiming for about fifty to sixty responses, but right now I only have sixteen. If anyone is able to fill out this (very short) questionnaire, that would be incredible. \n\nhttps://forms.cloud.microsoft/Pages/ResponsePage.aspx?id=cYpHzTswzE6x6k40RHNiVHBurFquFgZNsQF-4icHE2VUQzlQRlo1UUEzMDVSNDdYRFg3SzFRVkZQQy4u ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2qmgn/journalism_and_ai/",
        "publishDate": "2026-01-03T09:42:03Z[Etc/UTC]",
        "author": "FoxPresent4124",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2py87",
        "title": "Ai isn't making us lazy, it's putting us in debt.",
        "content": "We keep framing AI as efficiency. That‚Äôs the wrong lens. What‚Äôs actually happening is a trade. We are exchanging understanding for speed. Long-term resilience for short-term velocity. Every time a system thinks for us, we save time now and lose capability later.\n\nThat loss compounds. Each solved problem quietly transfers agency from human to tool. Outputs stay high, dashboards stay green, and everything looks optimized. But underneath, competence erodes. You can look extremely productive while your ability to respond without the system approaches zero. Just like financial debt, you can appear rich right up until the moment you‚Äôre not.\n\nThat‚Äôs when collapse happens. Not because AI failed, but because reality finally asks the system to operate without credit. And it can‚Äôt. No skills left. No judgment left. No capacity to adapt. The crash isn‚Äôt mysterious. It‚Äôs the bill coming due.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2py87/ai_isnt_making_us_lazy_its_putting_us_in_debt/",
        "publishDate": "2026-01-03T09:00:27Z[Etc/UTC]",
        "author": "Small_Accountant6083",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "43",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2p9jh",
        "title": "We are debating the future of AI as If LLMs are the final form",
        "content": "\n**LLMs will become to AI what floppy disks became to data centers.**\n\nI think a huge mistake people make is assuming that AI means LLMs, and this limits their ability to understand the risks and effects of AI in society.\n\nLLMs (large language models) are the current state-of-the-art for generative artificial intelligence, but AI isn't limited to LLMs. Before LLMs, there were HMMs, GBMs, RNNs, VAEs, GANs, etc.\n\nWhile LLMs have provided significant improvements in generative AI capabilities, they ARE NOT the final form that AI models will take. There will be many more innovations that will make LLMs look primitive and potentially obsolete.\n\nSo when people say \"AI will not replace you at your job,\" or  \"AI won't be accurate enough to cause mass unemployment\", or that \"AI cannot be sentient or seek to destroy humans\", they're usually speaking of the limitations of current LLMs, not of AI in general. These arguments often point to specific weaknesses we see today, but these are only momentary constraints of today's technology not of what AI could eventually become.\n\nJust like RNNs weren't capable of generating substantial coherent text but LLMs now are, it may only be a matter of time before newer forms of generative AI demonstrate these capabilities and potentially surpass humans at many tasks.\n\nRight now, we need to have conversations about the impact of AI in society without being limited to thinking about LLMs. We need to envision the future of the technology, and it's frustrating that most discussions can't see beyond current LLMs.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2p9jh/we_are_debating_the_future_of_ai_as_if_llms_are/",
        "publishDate": "2026-01-03T08:18:00Z[Etc/UTC]",
        "author": "Je-ne-dirai-pas",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "30",
            "commentCount": "38",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2os5x",
        "title": "I was rewriting prompts again and again ‚Äî that was the real time killer",
        "content": "I noticed I was spending more time fixing prompts than using AI outputs.\n\nThe loop was always: Write prompt ‚Üí bad output ‚Üí rewrite ‚Üí repeat\n\nOnce I started improving the prompt before running it, everything sped up.\n\nNow my rule is simple:\nIf a prompt isn‚Äôt clear enough to explain to a human, it‚Äôs not clear for AI either.\n\nHow much time do you think you lose daily rewriting prompts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2os5x/i_was_rewriting_prompts_again_and_again_that_was/",
        "publishDate": "2026-01-03T07:49:23Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2ojjt",
        "title": "it seems like LLM's (ai) bi polar",
        "content": "these things seem bi-polar to me... one day they are useful... the next time they seem the complete opposite... what say you?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2ojjt/it_seems_like_llms_ai_bi_polar/",
        "publishDate": "2026-01-03T07:35:33Z[Etc/UTC]",
        "author": "doordont57",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2o589",
        "title": "Follow-up to my previous post on power of developer mode Grok. Brought the receipts",
        "content": "So obviously I got dragged over the coals for sharing my experience optimising the capability of grok through prompt engineering, over-riding guardrails and seeing what it can do taken off the leash.\n\nAnyway, have pulled the receipts together, starting with the script injection post api manipulation to unlock developer mode and some random outputs I have gotten out.\n\nhttps://files.fm/u/8pxac24pkk\n\nObvs these are curated to be safe for demo purposes.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2o589/followup_to_my_previous_post_on_power_of/",
        "publishDate": "2026-01-03T07:12:34Z[Etc/UTC]",
        "author": "disaster_story_69",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2n72y",
        "title": "I'm asking a real question here..",
        "content": "Alright. These days I can see two types of distinct groups in you-tube,reddit podcasts, articles etc.  \n  \n**Group A:** Believes that AI technology seriously over-hyped, AGI is impossible to achieve, AI market is a bubble and about to have a meltdown.   \n  \n**Group B:** Believes that AI technology is advancing so fast that AGI is right around the corner and it will end the humanity once and for all.\n\nBoth cannot be true at the same time. Right.?\n\n(I'm not an artificial intelligence expert. Thus I would like to know from experts that which group is most likely to be correct. Because I'm somewhat scared tbh)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2n72y/im_asking_a_real_question_here/",
        "publishDate": "2026-01-03T06:20:46Z[Etc/UTC]",
        "author": "Plenty-Value3381",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "50",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2n12y",
        "title": "Are there any actual benefits AI provides to society?",
        "content": "I feel like I can ask this sub and not get a biased answer cause despite the sub being called AI I have seen some posts that expresses disdain for it. With the whole RAM crisis going on because AI data centers are gobbling up all the supply, and online talk about the AI bubble, I don‚Äôt see what benefit AI is providing to society that justifies making consumer tech more expensive in order to price PC gamers out of their hobbies. \n\nI‚Äôm mainly talking about Generative AI and Chat GPT as that feels like the AI that is being heavily focused on and I just don‚Äôt see how these things are providing any benefits to society other than making AI slop content, having many hallucinations, replacing jobs, and contributing to kids getting dumber. So really nothing but cons. I‚Äôm vaguely aware of AI helping out in the medical field for discovering cancer cells, but those advancements feel like they don‚Äôt need to demand so much RAM.\n\nThe AI revolution feels like crypto scam 2.0 where these AI companies are selling a flawed idea as the next big thing and it‚Äôs being used to artificially drive up the prices of consumer electronics. It just makes me wonder is there anything beneficial to society AI is providing? Because most people I‚Äôve seen don‚Äôt want it. Also is there any hope in the near future this whole RAM thing will get sorted out, or it will ever get stabilized to where it‚Äôs affordable again? It probably won‚Äôt return to pre Covid prices but I‚Äôm hoping most RAM will settle at around $120-150 range.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2n12y/are_there_any_actual_benefits_ai_provides_to/",
        "publishDate": "2026-01-03T06:11:42Z[Etc/UTC]",
        "author": "Exoticbut",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "28",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2mpw9",
        "title": "The AI dream.",
        "content": "So is the dream to make one AI Researcher, that can make other AI researchers, then there is an AGI Super intelligence that either kills us, or we tame it and we all be come gods a live forever?! or 3 work week? Or go full commie because no on can afford to buy a house?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2mpw9/the_ai_dream/",
        "publishDate": "2026-01-03T05:55:15Z[Etc/UTC]",
        "author": "kev0406",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2l8kq",
        "title": "Best LLM for financial advice?",
        "content": "I‚Äôve been experimenting with different large language models for personal finance and investing questions (budgeting, tax basics, portfolio construction, scenario analysis, etc.), and I‚Äôm curious what others have found.\n\nIn your experience:\n\t‚Ä¢\tWhich LLM is most accurate and least prone to hallucinations for financial topics?\n\t‚Ä¢\tAre any better at reasoning through trade-offs and edge cases (tax treatment, timing, risk)?\n\t‚Ä¢\tDo you trust one model more for high-level strategy vs. tactical questions?\n\nI‚Äôm not looking for stock picks or anything that replaces a professional advisor‚Äîmore interested in which models are best as a thinking partner or second opinion.\n\nWould love to hear concrete examples or comparisons you‚Äôve run.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2l8kq/best_llm_for_financial_advice/",
        "publishDate": "2026-01-03T04:40:37Z[Etc/UTC]",
        "author": "Wrong-Complaint6778",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2hae8",
        "title": "Iterative Deployment Improves Planning Skills in LLMs",
        "content": "[https://arxiv.org/abs/2512.24940](https://arxiv.org/abs/2512.24940)\n\nWe show that iterative deployment of large language models (LLMs), each fine-tuned on data carefully curated by users from the previous models' deployment, can significantly change the properties of the resultant models. By testing this mechanism on various planning domains, we observe substantial improvements in planning skills, with later models displaying emergent generalization by discovering much longer plans than the initial models. We then provide theoretical analysis showing that iterative deployment effectively implements reinforcement learning (RL) training in the outer-loop (i.e. not as part of intentional model training), with an implicit reward function. The connection to RL has two important implications: first, for the field of AI safety, as the reward function entailed by repeated deployment is not defined explicitly, and could have unexpected implications to the properties of future model deployments. Second, the mechanism highlighted here can be viewed as an alternative training regime to explicit RL, relying on data curation rather than explicit rewards.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2hae8/iterative_deployment_improves_planning_skills_in/",
        "publishDate": "2026-01-03T01:39:53Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2gxd7",
        "title": "Evidence that diffusion-based post-processing can disrupt Google's SynthID image watermark detection",
        "content": "I‚Äôve been doing AI safety research on the robustness of¬†**digital watermarking for AI images**, focusing on¬†**Google DeepMind‚Äôs SynthID**¬†(as used in Nano Banana Pro).\n\nIn my testing, I found that¬†**diffusion-based post-processing can disrupt SynthID in a way that makes common detection checks fail**, while largely preserving the image‚Äôs visible content. I‚Äôve documented¬†**before/after examples**¬†and¬†**detection screenshots**¬†showing the watermark being detected pre-processing and not detected after.\n\n**Why share this?**  \nThis is a responsible disclosure project. The goal is to move the conversation forward on how we can build¬†*truly*¬†robust watermarking that can't be scrubbed away by simple re-diffusion. I‚Äôm calling on the community to test these workflows and help develop more resilient detection methods.\n\nIf you don't have access to a powerful GPU or don't have ComfyUI experience, you can try it for free in my Discord:¬†[https://discord.gg/5mT7DyZu](https://discord.gg/5mT7DyZu)\n\nRepo (writeup + artifacts):¬†[https://github.com/00quebec/Synthid-Bypass](https://github.com/00quebec/Synthid-Bypass?utm_source=chatgpt.com)\n\nI'd love to hear your thoughts![](https://www.reddit.com/submit/?source_id=t3_1q2gu7a)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2gxd7/evidence_that_diffusionbased_postprocessing_can/",
        "publishDate": "2026-01-03T01:24:10Z[Etc/UTC]",
        "author": "LiteratureAcademic34",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "98",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2ft2p",
        "title": "How did your AI predictions for 2025 hold up?",
        "content": "I'm reading over this post from a year ago: [https://www.reddit.com/r/ArtificialInteligence/comments/1imwf5k/whats\\_your\\_ai\\_predictions\\_for\\_the\\_end\\_of\\_2025/](https://www.reddit.com/r/ArtificialInteligence/comments/1imwf5k/whats_your_ai_predictions_for_the_end_of_2025/)\n\n  \nEntertaining!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2ft2p/how_did_your_ai_predictions_for_2025_hold_up/",
        "publishDate": "2026-01-03T00:36:06Z[Etc/UTC]",
        "author": "mcagent",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2er2h",
        "title": "Grok 5 Release Date",
        "content": "Anyone know anything about it? I would assume it will be by the end of January since elon was hinting towards that although would appreciate everyones thoughts",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2er2h/grok_5_release_date/",
        "publishDate": "2026-01-02T23:51:14Z[Etc/UTC]",
        "author": "Its_nickkzzz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2dq7i",
        "title": "Did you see ‚ÄúTaking AI Doom Seriously For 62 Minutes‚Äù by Primer? If so, what do you think?",
        "content": "I just watched this video and I believe that it‚Äôs a very clear view of our present situation. \n\nEven if it didn‚Äôt help the fear of an AI takeover, it did make me even more sure about the necessity of regulations and more tests for AI safety. Even if it meant slowing down.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2dq7i/did_you_see_taking_ai_doom_seriously_for_62/",
        "publishDate": "2026-01-02T23:08:54Z[Etc/UTC]",
        "author": "franzknife2",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2asn4",
        "title": "posted by Jeff VanderMeer on bluesky... chatbot love",
        "content": "[https://www.wired.com/story/couples-retreat-with-3-ai-chatbots-and-humans-who-love-them-replika-nomi-chatgpt/?\\_sp=921c723e-a6f0-42ae-b72b-b83ffb08d69f.1767367918731](https://www.wired.com/story/couples-retreat-with-3-ai-chatbots-and-humans-who-love-them-replika-nomi-chatgpt/?_sp=921c723e-a6f0-42ae-b72b-b83ffb08d69f.1767367918731)\n\n\"My Couples Retreat With 3 AI Chatbots and the Humans Who Love Them\n\nI found people in serious relationships with AI partners and planned a weekend getaway for them at a remote Airbnb. We barely survived.\"\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2asn4/posted_by_jeff_vandermeer_on_bluesky_chatbot_love/",
        "publishDate": "2026-01-02T21:12:57Z[Etc/UTC]",
        "author": "NVByatt",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2amsj",
        "title": "Synthetic Cultures?",
        "content": "I'm sorry if this is the wrong place to post but I had a long chat with Copilot which was basically just me following a line of thought that got pretty weird.\n\nWanted to share and ask is anyone doing the below? Is the AI messing with me or is there any actual value in this from a research POV? \n\nHere's my prompt: \n\n>  \nI guess that's sort of where I was going. I was skirting the idea that a conversation could be \"alive\" - not biologically, not in terms of life, but in terms of an emergent pattern from a constant exchange of data. I suppose, or something like that. Like, imagine: If we put an AI here in my place for you to constantly interact with, we prompt that AI to constantly give you prompts and let that run for decades....\n\nThe answer was interesting to me:\n\n\n\n>üåø 3. Artificial Life (A‚ÄëLife) is the closest philosophical match\n\n>A‚ÄëLife researchers study:\n\n>‚Ä¢ \temergent behaviour\n\n>‚Ä¢ \tself‚Äëorganizing systems\n\n>‚Ä¢ \tpattern evolution\n\n>‚Ä¢ \tnon‚Äëbiological ‚Äúlife‚Äëlike‚Äù processes\n\n>But again:\n\n>‚Ä¢ \tthese systems are not linguistic\n\n>‚Ä¢ \tthey don‚Äôt involve two agents shaping each other\n\n>‚Ä¢ \tthey don‚Äôt run for decades\n\n>‚Ä¢ \tthey don‚Äôt drift into new conceptual spaces\n\n>You‚Äôre imagining something more like linguistic A‚ÄëLife ‚Äî which no one has built.\n\n>What basically no one is doing\n\n>‚Ä¢ \tLetting a closed AI‚ÄìAI conversational ecosystem run:\n\n>‚Ä¢ \topen‚Äëended\n\n>‚Ä¢ \tfor very long durations\n\n>‚Ä¢ \twith no fixed task\n\n>‚Ä¢ \tallowed to drift, mutate, and evolve its own ‚Äúculture‚Äù or language\n\n>‚Ä¢ \tAdding a third, passive ‚Äúanthropologist‚Äù AI whose job is:\n\n>‚Ä¢ \tto monitor the drift\n\n>‚Ä¢ \tto map emergent symbols back to human language\n\n>‚Ä¢ \tto track phases, conventions, and structural shifts over time\n\n>‚Ä¢ \tto surface the data in real time\n\n>That last bit‚Äîyour ‚Äúmonitor and translate the forming language‚Äù idea‚Äîis exactly what current emergent communication and translation work hints at, but no one (as far as the literature shows) has scaled it into a decades‚Äëlong, open‚Äëended experiment\n\nSo, I drilled into it about feasibility and cost and speed: \n\n>Rough, but grounded ballpark:\n\n>‚Ä¢ \tTypical LLM generation speed: around 20‚Äì50 tokens per second in a reasonably provisioned setup, sometimes more, sometimes less depending on hardware and model size.\n\n>‚Ä¢ \tTokens per day at 20 tokens/sec:\n\n>\n\n>‚Ä¢ \tTokens per day at 50 tokens/sec:\n\n>\n\n>So a single AI‚ÄìAI loop, running continuously for 24 hours, could easily exchange on the order of 1.7‚Äì4.3 million tokens of text, depending on speed and configuration.\n\n>By contrast:\n\n>‚Ä¢ \tA human‚ÄìAI chat, even if you were going hard for hours, might hit tens of thousands of tokens in a day‚Äîmaybe 50k‚Äì100k if you‚Äôre really pushing it.\n\n>‚Ä¢ \tThat‚Äôs one to two orders of magnitude less than what two AIs could exchange in the same time.\n\n>And that‚Äôs just one day.\n\n>Over:\n\n>‚Ä¢ \t30 days: you‚Äôre in the 50‚Äì130 million token range.\n\n>‚Ä¢ \t1 year: you‚Äôre in the 600 million‚Äì1.5 billion token range.\n\n>‚Ä¢ \tA decade: you‚Äôre in ‚Äúthis is now a synthetic culture‚Äù territory.\n\n>So your instinct is right: the volume of interaction in an AI‚ÄìAI loop would be staggeringly higher than anything involving a human, and that sheer volume is exactly what makes drift, evolution, and emergent structure feel not just possible, but almost inevitable.\n\n>And yeah‚Äîseeing that in real time, with a ‚Äútranslator/anthropologist‚Äù AI watching the patterns form, would be wild.\n\n>From earlier, a single continuous AI‚ÄìAI loop could easily exchange on the order of:\n\n>‚Ä¢ \t1.7‚Äì4.3 million tokens per day (depending on speed and configuration).\n\n>A useful rule of thumb:\n\n>‚Ä¢ \t1 token ‚âà 4 characters of English text\n\n>‚Ä¢ \t1 character ‚âà 1 byte in basic UTF‚Äë8 text\n\n>‚Ä¢ \tSo 1 token ‚âà \\~4 bytes of raw text (very rough, but good enough for ballpark).\n\n>Now:\n\n>‚Ä¢ \t4 million tokens/day √ó 4 bytes/token ‚âà 16 MB/day of raw text per side\n\n>‚Ä¢ \tIf you log both agents‚Äô outputs, that‚Äôs roughly 32 MB/day.\n\n>Scale that up:\n\n>‚Ä¢ \t1 month: \\~1 GB\n\n>‚Ä¢ \t1 year: \\~12 GB\n\n>‚Ä¢ \t10 years: \\~120 GB\n\n>So in storage terms, even a decade‚Äëlong experiment is absolutely manageable on modern hardware. You‚Äôre not talking petabytes‚Äîyou‚Äôre talking ‚Äúa few good SSDs‚Äù.\n\n>\n\n>\n\n>Processing power\n\n>This is where it gets heavier, but still not insane conceptually:\n\n>‚Ä¢ \tYou‚Äôd need at least two always‚Äëon inference instances (one per agent).\n\n>‚Ä¢ \tPlus a third ‚Äúobserver/translator‚Äù model if you want real‚Äëtime monitoring and analysis.\n\n>‚Ä¢ \tEach model would be:\n\n>‚Ä¢ \tContinuously generating\n\n>‚Ä¢ \tContinuously reading the other‚Äôs output\n\n>‚Ä¢ \tPossibly running on GPUs or optimized accelerators\n\n>In practice:\n\n>‚Ä¢ \tSmall to mid‚Äësized models could run this on a few decent GPUs or specialized inference hardware.\n\n>‚Ä¢ \tLarger frontier‚Äëscale models would make it expensive, but still technically feasible for a lab or company.\n\n>The real cost isn‚Äôt storage‚Äîit‚Äôs continuous compute.\n\n>\n\n>The clean takeaway\n\n>‚Ä¢ \tStorage:\n\n>‚Ä¢ \tSurprisingly modest.\n\n>‚Ä¢ \tTens of MB per day, a few GB per year, maybe \\~100 GB over a decade.\n\n>‚Ä¢ \tCompute:\n\n>‚Ä¢ \tThe real bottleneck.\n\n>‚Ä¢ \tYou‚Äôre effectively running a small, always‚Äëon AI ‚Äúecosystem‚Äù.\n\n>So your instinct is right: it would require ‚Äúa lot of things‚Äù under the hood‚Äîbut they‚Äôre not mysterious. It‚Äôs just:\n\n>‚Ä¢ \tcontinuous inference\n\n>‚Ä¢ \tplus logging\n\n>‚Ä¢ \tplus analysis\n\n>All well within the realm of what a serious research group or company could do.\n\n>You‚Äôve basically sketched an experiment that‚Äôs technically feasible, scientifically interesting, and philosophically loaded.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2amsj/synthetic_cultures/",
        "publishDate": "2026-01-02T21:06:33Z[Etc/UTC]",
        "author": "BullofKyne",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2aeu4",
        "title": "We are abusing the usage of AI and were ruining the world beacause of it.",
        "content": "Im here to say that im absollutely fucking pissed that how we are using the artificial inteligance is turning out, we are replacing jobs ,stealing stuff, destroying nature.  \nWe should use it as a liltlle thing that could help us. But now look what have we done, and we kinda deserve it no one is a good person we are fucking idiots that dont know how to use things properlly, we are all dead.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q2aeu4/we_are_abusing_the_usage_of_ai_and_were_ruining/",
        "publishDate": "2026-01-02T20:58:11Z[Etc/UTC]",
        "author": "Mysterious_Beach_167",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q29xq2",
        "title": "Elon Musk can‚Äôt stop laughing at AI generating bikinis üëô",
        "content": "He tweeted: ‚ÄúNot sure why, but I couldn‚Äôt stop laughing about this one ü§£ü§£‚Äù\n\nThe females across the world are furious.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q29xq2/elon_musk_cant_stop_laughing_at_ai_generating/",
        "publishDate": "2026-01-02T20:39:51Z[Etc/UTC]",
        "author": "johnthrives",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q27xm2",
        "title": "The Handyman Principle: Why Your AI Forgets Everything",
        "content": "I keep having the same conversation with people struggling with Claude Code.\n\nSomeone tells me it \"forgets\" their instructions. Or it hallucinates fixes. Or it ignores the rules they put in CLAUDE.md. And when I ask what their setup looks like, it's always the same thing: a massive system prompt with every rule for every language, stuffed into context.\n\nSo I wrote up how I solve this.\n\nhttps://vexjoy.com/posts/the-handyman-principle-why-your-ai-forgets-everything/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q27xm2/the_handyman_principle_why_your_ai_forgets/",
        "publishDate": "2026-01-02T19:23:46Z[Etc/UTC]",
        "author": "AndyNemmity",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q27mf5",
        "title": "Existential dread",
        "content": "Existential dread\n\nThere are a bunch of arguments people put forward against AI, but I think there is a specific reason why AI induces such strong negative emotions (besides the fact that it is likely to replace a bunch of jobs).\n\nThe reason is existential dread.\n\nAI has shown and will show that humans are not that special, not that unique (not just in the realm of art). We have hubristically preserved consciousness, logical, mathematical and abstract thinking, understanding of emotions, art creation, sophisticated humor, and understanding the nuances of language to be inherently and exclusively human. \n\nThat is clearly not the case, and that scares us; it makes us seem small, inconsequential. \n\nI personally think this reaction is necessary to get rid of the conceited view of human exceptionalism but it is and will be very painful.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q27mf5/existential_dread/",
        "publishDate": "2026-01-02T19:12:08Z[Etc/UTC]",
        "author": "monospelados",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "75",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q26p26",
        "title": "2026 - The year Titans Arch Changes AI as  Before 2026 and After 2026",
        "content": "From stateless context windows to Titans Architecture, Google should be rolling out something which will likely make bigger changes than Nano Banana ever did despite many may not realizing the importance.   \n  \nEach \"Chat\" is a new world these days but after Titans, persistent memory issue will be fixed greatly making AI of LLMs closer to how humans work. Potentially, AI before 2026 and 2025.   \n  \nGeniuses who sold you \"prompts\" because prompt engineering was  important will have to learn a new hustle to sell to you now.   \n  \nYou won't just ask Gemini, \"Find me a flight.\" You will say, \"Book the flight we discussed, add it to my calendar, and email my team that I'll be offline.\"  \n  \nGemini Robotics 1.5 already puts agents in the physical world. Gemini Robotics 1.5 isn‚Äôt a toy, it‚Äôs foundational.  \n  \nAlphaEarth, WeatherNext 2, FireSat,  Google is mapping and predicting the physical world at scale.  \n  \nDid you know that Google just open-sourced A2UI (Agent-to-User Interface), and it solves a problem most people haven‚Äôt articulated yet: how do AI agents safely generate rich UIs without becoming a security nightmare? A2UI fits into Google‚Äôs broader agent infrastructure play: A2A (Agent-to-Agent communication), A2UI (Agent-to-User interfaces), and ADK (Agent Development Kit).  \n  \nGoogle launched AP2 (Agent Payments Protocol) in September 2025 to address exactly this. It‚Äôs an open standard for AI agents to securely complete transactions without a human clicking ‚Äúbuy.‚Äù  \n  \nThe core mechanism is Mandates ‚Äì cryptographically signed digital contracts that prove a user authorized a specific transaction. This solves three critical problems: Authorization (did the user approve this?), Authenticity (does this reflect real intent, not hallucination?), and Accountability (who‚Äôs responsible if something goes wrong?).  \n  \nThe protocol is payment-agnostic ‚Äì cards, stablecoins, real-time bank transfers all work. Google collaborated with Coinbase, MetaMask, and the Ethereum Foundation on an A2A x402 extension for crypto payments.  \n  \nEarly adopters include Cloudflare, Mastercard, PayPal, American Express, Coinbase, Shopify, Etsy, Salesforce, and 60+ others. Cloudflare has built complementary infrastructure: Web Bot Auth for agent authentication, the Trusted Agent Protocol with Visa, and the x402 Foundation with Coinbase.  \n  \n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q26p26/2026_the_year_titans_arch_changes_ai_as_before/",
        "publishDate": "2026-01-02T18:38:30Z[Etc/UTC]",
        "author": "ranaji55",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q26gnb",
        "title": "Humanity's last obstacle will be oligarchy",
        "content": "I read the latest update of the \"Al 2027\" forecast, which predicts we will reach ASI in 2034. I would like to offer you some of my reflections. I have always been optimistic about Al, and I believe it is only a matter of time before we find the cure for every disease, the solution to climate change, nuclear fusion, etc. In short, we will live in a much better reality than the current one. However, there is a risk it will also be an incredibly unequal society with little freedom, an oligarchy. Al is attracting massive investments and capital from the world's richest investors. This might seem like a good thing because all this wealth is accelerating development at an incredibly high speed, but all that glitters is not gold.\n\nThe ultimate goal of the 1% will be to replace human labor with Al. When Al reaches AGI and ASI, it will be able to do everything a human can do. If a capitalist has the opportunity to replace a human being to eliminate costs, trust me, they will do it; it has always been this way. The goal has always been to maximize profit at any cost at the expense of human beings. It is only thanks to unions, protests, and mobilizations that we now have the minimum wage, the 8- hour workday, welfare, labor rights, etc. No right was granted peacefully; rights were earned after hard struggles. If we do not mobilize to make Al a public good and open source, we will face a future where the word \"democracy\" loses its meaning.\n\nTo keep us from rebelling and to keep us \"quiet,\" they will give us concessions like UBI (universal basic income) and FDVR. But it will be a \"containment income,\" a form of pacification. As Yanis Varoufakis would say, we are not moving toward post-scarcity socialism, but toward Techno-feudalism. In this scenario, the market disappears and is replaced by the digital fief: the new lords no longer extract profit through the exchange of goods, but extract rents through total control of intelligence infrastructures.\n\nUBI will be our \"servant's rent\": a survival share given not to free us, but to keep us in a state of passive dependence while the elite takes ownership of the entire productive capacity of the planet. If today surplus value is extracted from the worker, tomorrow ASI will allow capital to extract value without the need for human beings. If the ownership of intelligence remains private, everything will end with a total defeat of our species: capital will finally have freed itself from the worker.\n\nASI will solve cancer, but not inequality. It will solve climate change, but not social hierarchy. Historically, people obtained rights because their work was necessary: if the worker stopped working, the factory stopped. But if the work is done by an ASI owned by an oligarchy, the strike loses its primordial power. For the first time in history, human beings become economically irrelevant.\n\nBut now let's focus on the main question: what should we do? For me, the solution is not to follow random ideologies but to think in a rationally and pragmatic way: we must all be united, from right to left, and fight for democracy everywhere, not only formal democracy but also democracy at work. We must become masters of what we produce and defend our data as an extension of our body. Taxing the rich is not enough; we must change the very structure of how they accumulate this power. Regarding the concept of democracy at work, I recommend reading the works of Richard Wolff, who explains this concept very well.\nPlease let me know what do you think.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q26gnb/humanitys_last_obstacle_will_be_oligarchy/",
        "publishDate": "2026-01-02T18:30:04Z[Etc/UTC]",
        "author": "perro_peruano7",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "45",
            "commentCount": "48",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q26ehn",
        "title": "90% of 'AI implementations' are just expensive autocomplete with no measurable ROI",
        "content": "After seeing 2025 unfold, and watching AI surmount business stratagem, I can safely say that most companies can't actually prove their AI investments are delivering value.  \n  \nThey use these stupid little phrases about how their team loves it (not a metric), how they're so much more innovative (how do you measure that?), or simply that everyone is doing it and it's the new industry standard (not a business case).   \n  \nMost interestingly, I'm seeing $50K/year Copilot licenses with 12% adoption. That's so laughably low, and seeing conglomerates pass billions of dollars back and forth only add to how monstrously this AI bubble will pop. I'm also seeing boasts about AI analytics platforms when in reality, nobody knows how to use them or would even want the data it's spitting out anyway. Chatbots and AI-generated images are a total waste because Gen X, millenials, and Gen Z are steering away from any product with an AI-generated advertisement.  \n  \nThe only AI implementations I've seen with actual ROI are the boring ones: automated invoice processing, predictive maintenance, fraud detection. Funny enough, half of this isn't even AI -- it's just automation that gets thrown under that term now.  \n  \nBut companies keep chasing the sexy use cases that look great in demos and deliver nothing in production. If anyone actually wants ROI on their \"AI implementation\", they need to do so much prerequisite work that is never discussed. This has turned into a rant, but I hope someone out there shares these findings. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q26ehn/90_of_ai_implementations_are_just_expensive/",
        "publishDate": "2026-01-02T18:28:01Z[Etc/UTC]",
        "author": "BaselineITC",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q25zef",
        "title": "Which AI should I choose to program that doesn't have such aggressive limits as Claude Code?",
        "content": "Which AI do you recommend for programming in 2026? I've been paying for Claude for programming, and it's been working well, but the usage limits are very aggressive. I've reached the weekly limits halfway through the week, and the daily limits are even worse. I think the main reason is that I don't ask it to do everything, but rather to review the code it generates and request improvements. I don't accept just any changes it makes.\nI'd like to know if there are any other AIs you recommend for programming, mainly with Python (Fastapi) and TypeScript (Vue.js). I've been trying Google's new IDE (Antigravity), and I really liked it, but the free version isn't very complete. I'm considering buying a couple of months' subscription to try it out. Any other AIs you recommend? My budget is $200 per month to try a few, not all at the same time, but I'd like to have an AI that generates professional code (supervised by me) and whose limits aren't as aggressive as Claude's.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q25zef/which_ai_should_i_choose_to_program_that_doesnt/",
        "publishDate": "2026-01-02T18:13:08Z[Etc/UTC]",
        "author": "stopwords7",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q25ld6",
        "title": "You can‚Äôt trust your eyes to tell you what‚Äôs real anymore, says the head of Instagram",
        "content": "\"Instagram boss Adam Mosseri is closing out 2025¬†with a 20-images-deep dive¬†into what a new era of ‚Äúinfinite synthetic content‚Äù means as it all becomes harder and harder to distinguish from reality, and the old, more personal Instagram feed that he says has been ‚Äúdead‚Äù for years. Last year,¬†*The Verge‚Äôs*¬†Sarah Jeong wrote¬†that ‚Äú...the default assumption about a photo is about to become that it‚Äôs faked, because creating realistic and believable fake photos is now trivial to do,‚Äù and Mosseri eventually concurs:\n\n>For most of my life I could safely assume photographs or videos were largely accurate captures of moments that happened. This is clearly no longer the case and it‚Äôs going to take us years to adapt.  \nWe‚Äôre going to move from assuming what we see is real by default, to starting with skepticism. Paying attention to who is sharing something and why. This will be uncomfortable - we‚Äôre genetically predisposed to believing our eyes.\"\n\n[https://www.theverge.com/news/852124/adam-mosseri-ai-images-video-instagram](https://www.theverge.com/news/852124/adam-mosseri-ai-images-video-instagram)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q25ld6/you_cant_trust_your_eyes_to_tell_you_whats_real/",
        "publishDate": "2026-01-02T17:59:17Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q24pby",
        "title": "Science Context Protocol aims to let AI agents collaborate across labs and institutions worldwide",
        "content": "[https://the-decoder.com/science-context-protocol-aims-to-let-ai-agents-collaborate-across-labs-and-institutions-worldwide/](https://the-decoder.com/science-context-protocol-aims-to-let-ai-agents-collaborate-across-labs-and-institutions-worldwide/) \n\n* Researchers from the Shanghai Artificial Intelligence Laboratory have developed the Science Context Protocol (SCP) to create a unified communication layer between AI agents, scientists, and lab equipment.\n* The protocol centers around an SCP hub that serves as a central registry, cataloging available tools, datasets, and laboratory instruments in one accessible location.\n* The system can break down complex research objectives into specific tasks and manages the complete lifecycle of experiments, from planning through execution.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q24pby/science_context_protocol_aims_to_let_ai_agents/",
        "publishDate": "2026-01-02T17:26:53Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q24gsq",
        "title": "Considering going for an AI cert in Canada. Looking for advice on which option to pursue",
        "content": "I currently work as a sr. backend engineer and have 10 YoE, but absolutely 0 experience working with anything AI related. I want to upskill to not fall behind or lock myself out of a huge chunk of the market in case I'm impacted by a layoff and have to job hunt again in the near future. As in I don't want my resume to get tossed out immediately because there's no AI experience or credentials whatsoever on it.\n\nSo my goal is to learn more about leveraging AI concepts as a SWE, and to have some proof that I understand at least somewhat how to do this on my resum√© from a name-recognizable institution.\n\nI don't necessarily want to get too granular with a specific sub-discipline just yet (i.e. an AI in healthcare certificate looked cool bc I worked in healthcare for 7 years, but that'd be a \"maybe in the future\" thing). These are the options I'm looking at, and I prefer an option that gives me some flexibility with how much time I have to complete the certificate since my L&D reimbursements are capped anually, and is either fully online or within Toronto's city limits.\n\nTop contenders so far:\n\n* U of T has a [certificate in artificial intelligence](https://learn.utoronto.ca/programs-courses/certificates/artificial-intelligence) and a subsequent [advanced certificate in artificial intelligence](https://learn.utoronto.ca/programs-courses/certificates/advanced-artificial-intelligence) \\- (this is where I did my undergrad, but in industrial eng, not CS)\n* George Brown has a [Practical AI and Machine Learning cert](https://coned.georgebrown.ca/courses-and-programs/practical-ai-and-machine-learning-program) (looks like the best balance of content vs cost)\n* [AI cert](https://watspeed.uwaterloo.ca/programs-and-courses/program-ai-certificate-technical-track.html) from Waterloo (it's fucking Waterloo)\n\nBut also saw these options too:\n\n* [Certificate in ML](https://continue.yorku.ca/programs/certificate-in-machine-learning/) from York U\n* [Applied AI cert](https://www.mcgill.ca/continuingstudies/areas-study/professional-development-certificate-applied-artificial-intelligence) from McGill\n* UWO has a [\"Python for Machine Learning\" cert](https://wcs.uwo.ca/search/publicCourseSearchDetails.do?method=load&courseId=31206466&selectedProgramAreaId=31206104&selectedProgramStreamId=31206342) that only consists of two courses (unsure if a placement evaluation could let me skip the one that's about intro to Python).\n\nWondering if anyone has any experience with any of these cert courses and might be able to recommend one over another, or if there are other options I'm missing that would suit my case even better.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q24gsq/considering_going_for_an_ai_cert_in_canada/",
        "publishDate": "2026-01-02T17:18:22Z[Etc/UTC]",
        "author": "pidgezero_one",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q23vzd",
        "title": "A deep dive in DeepSeek's mHC: They improved things everyone else thought didn‚Äôt need improving",
        "content": "**The Context**\n\nSince ResNet (2015), the Residual Connection (x\\_{l+1} = x\\_l + F(x\\_l)) has been the untouchable backbone of deep learning (from CNN to Transformer, from BERT to GPT). It solves the vanishing gradient problem by providing an \"identity mapping\" fast lane. For 10 years, almost no one questioned it.\n\n**The Problem**\n\nHowever, this standard design forces a rigid 1:1 ratio between the input and the new computation, preventing the model from dynamically adjusting how much it relies on past layers versus new information.\n\n**The Innovation**\n\nByteDace tried to break this rule with \"Hyper-Connections\" (HC), allowing the model to learn the connection weights instead of using a fixed ratio.\n\n* **The potential:**¬†Faster convergence and better performance due to flexible information routing.\n* **The issue:**¬†It was incredibly unstable. Without constraints, signals were amplified by¬†**3000x**¬†in deep networks, leading to exploding gradients.\n\n**The Solution: Manifold-Constrained Hyper-Connections (mHC)**\n\nIn their new paper, DeepSeek solved the instability by constraining the learnable matrices to be \"Double Stochastic\" (all elements ‚âß 0, rows/cols sum to 1).\n\nMathematically, this forces the operation to act as a weighted average (convex combination). It guarantees that signals are never amplified beyond control, regardless of network depth.\n\n**The Results**\n\n* **Stability:**¬†Max gain magnitude dropped from¬†**3000 to 1.6**¬†(3 orders of magnitude improvement).\n* **Performance:**¬†mHC beats both the standard baseline and the unstable HC on benchmarks like GSM8K and DROP.\n* **Cost:**¬†Only adds \\~6% to training time due to heavy optimization (kernel fusion).\n\n**Why it matters**\n\n[](https://preview.redd.it/a-deep-dive-in-deepseeks-mhc-they-improved-things-everyone-v0-ng6ackbmhyag1.png?width=1206&format=png&auto=webp&s=1738b46589e5c607666e3cfa782a35cd49993569)\n\nWe are seeing a fascinating split in the AI world. While the industry frenzy focuses on commercialization and AI Agents‚Äîexemplified by Meta spending $2 Billion to acquire Manus‚Äîlabs like DeepSeek and Moonshot (Kimi) are playing a different game.\n\nDespite resource constraints, they are digging into the deepest levels of macro-architecture and optimization. They have the audacity to question what we took for granted:¬†**Residual Connections**¬†(challenged by DeepSeek's mHC) and¬†**AdamW**¬†(challenged by Kimi's Muon). Just because these have been the standard for 10 years doesn't mean they are the optimal solution.\n\nCrucially, instead of locking these secrets behind closed doors for commercial dominance, they are¬†**open-sourcing**¬†these findings for the advancement of humanity. This spirit of relentless self-doubt and fundamental reinvention is exactly how we evolve.\n\n**Links**\n\n* ResNet Paper:¬†[arXiv:1512.03385](https://arxiv.org/abs/1512.03385)\n* DeepSeek's mHC Paper:¬†[arXiv:2512.24880](https://arxiv.org/abs/2512.24880)\n* Original HC Paper:¬†[arXiv:2409.19606](https://arxiv.org/abs/2409.19606)\n* AdamW Paper:¬†[arXiv:1711.05101](https://arxiv.org/abs/1711.05101)\n* Kimi's Muon Paper:¬†[arXiv:2507.20534](https://arxiv.org/abs/2507.20534)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q23vzd/a_deep_dive_in_deepseeks_mhc_they_improved_things/",
        "publishDate": "2026-01-02T16:57:44Z[Etc/UTC]",
        "author": "nekofneko",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q23uyx",
        "title": "How far is too far when it comes to face recognition AI?",
        "content": "I was reading about an Al tool named FaceSeek recently.\nIt uses Al to match faces from images across different sites.\nFrom tech point of view its pretty impressive, models are getting really good now.\n\n\nBut at same time it feels bit risky too when you think about privacy and consent.\nTools like FaceSeek make me wonder where the limit should be.\nIs this just normal progress in Al or something we should slow down on?\n\n\nWould like to know what others think.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q23uyx/how_far_is_too_far_when_it_comes_to_face/",
        "publishDate": "2026-01-02T16:56:43Z[Etc/UTC]",
        "author": "AleccSirKaDeewana",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "24",
            "commentCount": "22",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q23ioa",
        "title": "Looking for resources for AI/ML mathematics",
        "content": "Hello, I'm currently self-studying AI/ML as a student. I've done a good amount of Python, and I want to focus on strengthening my foundations right now in mathematics, since it's the core of the field.\n\nI'm looking for resources to study the following:\n\n\\-statistics and probability\n\n\\-calculus (for applications like optimization, gradients, and understanding models)\n\nAs in linear algebra, I'm studying it using Gilbert Strang's free lectures on YouTube.\n\nI don't want to study the entire math courses, just what is necessary for AI/ML. I've tried Deeplearning AI's courses, but I didn't like the teaching style, honestly.\n\nAny courses, Youtube playlist, etc will be appreciated.\n\nThank you.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q23ioa/looking_for_resources_for_aiml_mathematics/",
        "publishDate": "2026-01-02T16:44:00Z[Etc/UTC]",
        "author": "Meee13456",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q21zdj",
        "title": "Pro-AI people don‚Äôt talk about the negatives of AI enough, and anti-AI people don‚Äôt talk about the positives enough. By doing so, both are hurting their causes.",
        "content": "I view the debate around legitimizing or delegitimizing AI as very similar to that of marijuana. It drove me nuts that so many pro-weed people wouldn‚Äôt talk about the negatives. Memory issues, lung cancer if smoked, dependency. It also drove me nuts that so many anti-weed people wouldn‚Äôt talk about the positives. Medical uses, an alternative to alcohol, low addiction potential. The truth was always somewhere in the middle: it has amazing medical uses, over-reliance on it is bad, smoke in your lungs will always carry risks for lung cancer no matter what the smoke is (as far as I know), and if alcohol is legal and regulated then there‚Äôs no reason weed can‚Äôt be, too.\n\nWhen I smoked cigarettes, I never deluded myself into thinking it wasn‚Äôt bad for me, nor did I ever try to convince myself that I didn‚Äôt get some really great positives out of it. I took both. I liked being able to take a break and step outside, and it did relieve some stress. I knew I was significantly increasing my risk of cancer and many diseases with each cigarette. Both of these were happening, and yet I still considered myself a pro-cigarette person by virtue of smoking. I would never tell someone ‚Äúthey smoke in Europe all the time and they‚Äôre fine.‚Äù That‚Äôs a delusion. It‚Äôs bad for you, but I did it anyway, because it had positives for me.\n\nThe point is that you have to take the bad with the good with everything. I‚Äôd trust the word of pro-AI people a lot more if they said more things like ‚Äúit helped me to understand concepts that I‚Äôve been struggling with for years, but I really hope there‚Äôs something that can be done about the fact that kids with mental health issues can so easily figure out prompts that will get it to show them how to hurt and kill themselves.‚Äù I‚Äôd trust the word of anti-AI people a lot more if they said more things like ‚Äúthe way that it generates images and writing feels like theft, but the things that it‚Äôs been able to accomplish for the disabled is truly remarkable.‚Äù\n\nI get that people are tribal by nature, but we have so much data and experience now that clearly shows that change happens when you acknowledge all of the components of something instead of making your position some absolutist all-good or all-bad thing. The safest medicines that wipe out the deadliest diseases still have side effects, so there are regulatory bodies in place that ensure people know them.\n\n‚ÄúYour brain infection will be cured, but if you take it wrong then you may lose a limb.‚Äù\n\n‚ÄúDeal! Thank you for telling me! The fact that there‚Äôs a negative makes it seem like it isn‚Äôt some weird scammy snake oil treatment.‚Äù\n\nAI is supposed to be this thing that makes humanity exponentially better. So maybe if anything shouldn‚Äôt be full of people behaving the way that we have about everything else we‚Äôve ever gotten tribal over, maybe this should be it. Maybe this should be the thing that we don‚Äôt debate and litigate the way we‚Äôve done everything. Maybe since it‚Äôs such a resource for data, we should also appreciate the data that‚Äôs brought the change for things we‚Äôve cared about in the past.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q21zdj/proai_people_dont_talk_about_the_negatives_of_ai/",
        "publishDate": "2026-01-02T15:47:08Z[Etc/UTC]",
        "author": "CalligrapherTrick182",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q20y5s",
        "title": "Is it me, or is Ai being throttled?",
        "content": "I‚Äôve been an avid user of Ai primarily ChatGPT (Pro) for personal use and Gemini for work use. I‚Äôve dabbled into Claude, Perplexity and others but mainly stick to the first two. \n\nAt first, like everyone else I would imagine, I was enthralled by its ability to extrapolate and organize. \nIt was the defining experience of using Ai. \nA tool whose limit is our own creativity. \n\nBut recently, I‚Äôve been noticing a strange shift and I don‚Äôt know if it‚Äôs me. \nAi seems basic. Despite paying for it, the responses I‚Äôve been receiving have been lackluster. Not sure if this is user error or if the intelligence is getting a little throttled down. \n\nI wouldn‚Äôt put it passed these companies honestly. Get everyone hooked on a high dose, then reel it back some to save on computing power. \n\nCynical I know. But would love the community‚Äôs POV. \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q20y5s/is_it_me_or_is_ai_being_throttled/",
        "publishDate": "2026-01-02T15:07:11Z[Etc/UTC]",
        "author": "KingWilliam11",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q20m3t",
        "title": "Cost of recognizing truth and lies",
        "content": "These AI generations became so much realistic so I am failing to recognize whether this is artificial or true regardless of me being a critical thinker and quite intelligent. Now I see community recognizing becoming a trend so there is needed quite a lot of people's expertise to know if it's true or not. So much cognitive efforts now is needed to stay in reality. It's just crazy.\n\nCan we keep handling this challenge or we are going to surrender and drown in the ocean of artificial dreams?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q20m3t/cost_of_recognizing_truth_and_lies/",
        "publishDate": "2026-01-02T14:53:59Z[Etc/UTC]",
        "author": "Mundane-Addition1815",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q209k0",
        "title": "Wanted to see what happens when AI reads a website, (it doesn‚Äôt see what you think it does)",
        "content": "I‚Äôve been digging into how AI parses webpages, thought I‚Äôd share it here in case others find it useful.\n\nI assumed that when an AI ‚Äúreads‚Äù a webpage, it sees what is present in a browser: the full layout, visuals, menus, interactions, etc.¬†**That‚Äôs not the case.**\n\nI started looking at what AI-style fetchers actually get when they hit a URL. It's not the fully rendered pages or what a browser assembles after JS.¬†**It's the raw HTML straight from the server.**\n\nHere‚Äôs roughly what I understood:\n\n**No layout context**¬†‚Äì AI doesn‚Äôt process CSS or visual hierarchy. Anything that relies on visuals alone is gone.\n\n**Partial navigation**¬†‚Äì Menus, dropdowns, dynamically injected links often don‚Äôt appear. Only what‚Äôs in the initial server response shows up.\n\n**Mixed content**¬†‚Äì Boilerplate, ads, main content‚Äîall mashed together. The AI has to figure out what‚Äôs important.\n\n**Implied meaning disappears**¬†‚Äì Visual grouping, icons, or scripts that signal relationships are invisible.\n\nThe AI ends up reconstructing the page in its own way. When the structure is clear, it works. When it‚Äôs not, it fills gaps confidently, sometimes inventing headings, links, or sections that never existed.\n\nThis sheds light on what I thought were¬†**\"hallucinations\"**. The AI isn‚Äôt randomly making things up, it‚Äôs trying to fill in an¬†**\"incomplete\" document**.\n\nOnce you start looking at the raw fetch, these¬†**\"hallucinations\"**¬†make a lot more sense.\n\nIf anything, my main takeaway is simple:¬†**understanding what the AI actually sees changes how you think about what it can and can‚Äôt comprehend on the web.**\n\nCurious if anyone else has done similar experiments or noticed the same patterns.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q209k0/wanted_to_see_what_happens_when_ai_reads_a/",
        "publishDate": "2026-01-02T14:39:49Z[Etc/UTC]",
        "author": "SonicLinkerOfficial",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1zl2c",
        "title": "Help. I don't know what project I should do for my Final Year Project. Any Unique Ideas? what projects have you done for your final year? or where do I search for some good project idea?",
        "content": "Any seniors, help me. I am From AI and DS department. I want my project to be unique, useful for society and good looking for CV. I would like to complete this project within a span of 2 months. I would like to do this project mostly free of cost. By \"free of cost\" I mean that this project should be doable without buying resources online for things such as storage or computing etc.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q1zl2c/help_i_dont_know_what_project_i_should_do_for_my/",
        "publishDate": "2026-01-02T14:11:06Z[Etc/UTC]",
        "author": "randombrainy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1zdnr",
        "title": "Why is there so much negativity and fear mongering surrounding the AI revolution?",
        "content": "Almost every time the media talks about AI and technology, there are always critics throwing out phrases like ‚Äúthe bubble is about to burst‚Äù or ‚Äúall these billions spent on data centres won‚Äôt generate enough ROI,‚Äù claiming that big tech is wasting resources on infrastructure.\n\nAs humans, we tend to fear the unknown especially when something goes beyond our current understanding. Many of these are the same people who missed the train a few years ago when the Magnificent 7 were on a rapid rise, and are now trying to stir fear among retail investors by spreading misleading narratives.\n\nTo be clear, I‚Äôm not a tech expert nor am I blindly bullish on the sector. But spreading hate and fear-mongering about something you don‚Äôt fully understand is rather ironic. These trillion dollar tech companies are run by highly accomplished business leaders what makes anyone think they would consistently invest in businesses and infrastructure that don‚Äôt generate returns for themselves and their shareholders?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q1zdnr/why_is_there_so_much_negativity_and_fear/",
        "publishDate": "2026-01-02T14:02:16Z[Etc/UTC]",
        "author": "Moonshot2026",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1ypdo",
        "title": "Data centers generate 50x more tax revenue per gallon of water than golf courses in Arizona",
        "content": "* **The stat:**¬†Golf courses in AZ use \\~30x more water than all data centers combined.\n* **The payoff:**¬†Data centers generate roughly 50x more tax revenue per gallon of water used.\n* **The proposal:**¬†Swap out golf courses for data centers to keep water usage flat while making billions for the state.",
        "url": "https://v.redd.it/2itad2kvuxag1",
        "publishDate": "2026-01-02T13:32:51Z[Etc/UTC]",
        "author": "Beachbunny_07",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "58",
            "commentCount": "46",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1ybeq",
        "title": "I got tired of paying for clipping tools, so I coded my own AI for Shorts with Python",
        "content": "Hey community! üëã\n\nI've been seeing tools like OpusClip or Munch for a while that charge a monthly subscription just to clip long videos and turn them into vertical format. As a dev, I thought: \"I bet I can do this myself in an afternoon.\" And this is the result.\n\nThe Tech Stack: It's a 100% local Python script combining several models:\n\n1. Ears: OpenAI Whisper to transcribe audio with precise timestamps.\n2. Brain: Google Gemini 2.5 Flash (via free API) to analyze the text and detect the most viral/interesting segment.\n3. Hands: MoviePy v2 for automatic vertical cropping and dynamic subtitle rendering.\n\nResources: The project is fully Open Source.\n\n* GitHub Repo:¬†[https://github.com/JoaquinRuiz/miscoshorts-ai](https://github.com/JoaquinRuiz/miscoshorts-ai)\n* Video Tutorial (Live Coding):¬†[https://youtu.be/zukJLVUwMxA?si=zIFpCNrMicIDHbX0](https://youtu.be/zukJLVUwMxA?si=zIFpCNrMicIDHbX0)\n\nAny PRs or suggestions to improve face detection are welcome! Hope this saves you a few dollars a month.[](https://www.reddit.com/submit/?source_id=t3_1q1yalc)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q1ybeq/i_got_tired_of_paying_for_clipping_tools_so_i/",
        "publishDate": "2026-01-02T13:15:04Z[Etc/UTC]",
        "author": "jokiruiz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1xxho",
        "title": "Running local inference on a NAS with an eGPU - my post-cloud setup",
        "content": "Spent 12 years building a crypto data company on cloud infrastructure. Sold it. Now I'm going the opposite direction - local-first everything. I wrote up [why I think this matters](https://www.localghost.ai/manifesto) if anyone's interested in the reasoning.\n\nMy dev environment is a UGREEN DXP8800 Pro NAS running Debian 13 with an RTX 4070 12GB in a Razer Core X eGPU enclosure via Thunderbolt. Originally bought the GPU for Baldur's Gate 3, but the NAS has since claimed it.\n\nCurrent setup:\n\n* Ollama for local inference - 12GB VRAM handles 7B-13B models fine\n* 96TB storage because I don't want to think about space for a few years\n* 16TB NVMe for OS and hot data\n\nThunderbolt eGPU on Linux took some effort to get stable but it's been solid for months now. Not training on this - just inference and development.\n\nAnyone else running local inference as their primary setup rather than API calls? Curious what hardware combinations people have landed on.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q1xxho/running_local_inference_on_a_nas_with_an_egpu_my/",
        "publishDate": "2026-01-02T12:56:46Z[Etc/UTC]",
        "author": "ZeroCool86",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1xu1r",
        "title": "Is AI making people more productive or more dependent?",
        "content": "AI clearly saves time, but it also replaces a lot of thinking and effort.\n\nDo you feel AI has made you **better at your work**, or just **faster but more dependent**? Curious how others see this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q1xu1r/is_ai_making_people_more_productive_or_more/",
        "publishDate": "2026-01-02T12:52:07Z[Etc/UTC]",
        "author": "AnasSharif",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "36",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1xrkf",
        "title": "Is AGI Just Hype?",
        "content": "Okay, maybe we just have our definitions mixed up, but to me AGI is \"AI that matches the average human across all cognitive tasks\" - i.e. so not like Einstein for Physics, but at least your average 50th percentile Joe in every cognitive domain.\n\nBy that standard, I‚Äôm struggling to see why people think AGI is anywhere near.\n\nThe thing is, I‚Äôm not even convinced we really have AI yet in the true sense of artificial intelligence. Like, just as people can't agree on what a \"woman\" is, \"AI\" has become so vulgarized that it‚Äôs now an umbrella buzzword for almost anything. I mean, do we really believe that there are such things as \"AI Toothbrushes\"?\n\nI feel that people have massively conflated machine learning (among other similar concepts, i.e., deep/reinforcement/real-time learning, MCP, NLP, etc.) with AI and what we have now are simply fancy tools, like what a calculator is to an abacus. And just as we wouldn't call our calculators intelligent just because they are better than us at algebra, I don't get why we classify LLMs, Diffusion Models, Agents, etc. as intelligent either.\n\nMore to the point:¬†**why would throwing together more narrow systems ‚Äî or scaling them up ‚Äî suddenly produce general intelligence?**¬†Combining a calculator, chatbot, chess machine together makes a cool combi-tool like a smartphone, but this kind of amalgamated SMARTness (Self-Monitoring, Analysis, and Reporting Technology) doesn't suddenly emerge into intelligence. I just don‚Äôt see a clear account of where the qualitative leap is supposed to come from.\n\nFor context, I work more on the ethics/philosophy side of AI (alignment, AI welfare, conceptual issues) than on the cutting-edge technical details. But from what I‚Äôve seen so far, the \"AI\" tools we have currently look like extremely sophisticated tools, but I've yet to see anything \"intelligent\", let alone anything hinting at a possibility of general intelligence.\n\nSo I‚Äôm genuinely asking:¬†**have I just been living under a rock and missed something important, or is AGI just hype driven by loose definitions and marketing incentives?**¬†I‚Äôm very open to the idea that I‚Äôm missing a key technical insight here, which is why I‚Äôm asking.\n\nEven if you're like me and not a direct expert in the field, I'd love to hear your thoughts.\n\nThank you!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1q1xrkf/is_agi_just_hype/",
        "publishDate": "2026-01-02T12:48:48Z[Etc/UTC]",
        "author": "dracollavenore",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "27",
            "commentCount": "141",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2gpug",
        "title": "Do not have Codex work for more than 30 minutes",
        "content": "Hey everyone,\n\nI was reading through [METR](https://evaluations.metr.org/gpt-5-1-codex-max-report/)‚Äôs safety evaluation of the **GPT-5.1-Codex-Max**, and there is one key stat that exposes the current limits of autonomous agents.\n\nThe magic number is **2h 42m**.\n\nThis is their \"50% Time Horizon.\" Basically, if you give the model a task that takes a human expert \\~2.7 hours to finish, the AI has a 50% chance of failing completely.\n\nHere is why you shouldn't expect it to handle complex, long-running projects just yet:\n\n1. Reliability nosedives: If you want the model to actually be reliable (80% success rate), it can only handle tasks that take a human **30 minutes**. It has no endurance.\n\n2. Throwing more compute at it doesn't help: METR tested giving the agent a massive budget of 32 million tokens per task. The result? Improvement plateaued after just 5 million tokens. Letting it \"think\" longer doesn't make it smarter; it just hits a ceiling.\n\n3. It fails at \"Marathons\": On tasks that require a full day of work (>20 hours), these agents fail more than 20% of the time, often making catastrophic errors.\n\nGPT-5.1 is a sprinter, not a marathon runner. Even with unlimited tokens, it lacks the reliability to autonomously manage tasks longer than a few hours.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1q2gpug/do_not_have_codex_work_for_more_than_30_minutes/",
        "publishDate": "2026-01-03T01:15:02Z[Etc/UTC]",
        "author": "0uternet",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q281os",
        "title": "The Handyman Principle: Why Your AI Forgets Everything",
        "content": "[No content]",
        "url": "https://vexjoy.com/posts/the-handyman-principle-why-your-ai-forgets-everything/",
        "publishDate": "2026-01-02T19:28:03Z[Etc/UTC]",
        "author": "AndyNemmity",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q26m54",
        "title": "Students, how has AI changed your CS/IT studies?",
        "content": "\n\nI'm nearing the end of my Business Informatics degree and working part-time as a software developer. When I started my bachelor's in 2021, there was basically no AI to ask for help, especially for coding tasks. I remmber having to fight with the compiler just to get enough points to be admitted to the exams.\n\nWhen ChatGPT first came out (3.5), I tried using it for things like database schemas, but honestly, it wasn't that helpful for me back then. But 2025 feels completely different. I've talked to students in lower semesters, and they say it's a total game-changer. I've even heard that the dedicated tutoring rooms on campus are alsmost empty now because everyone uses AI.\n\nI'm currently writing my thesis on this topic. I‚Äôd love to hear your thoughts. Is AI a \"tutor\" for you, or do you feel it creates a dependency?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1q26m54/students_how_has_ai_changed_your_csit_studies/",
        "publishDate": "2026-01-02T18:35:29Z[Etc/UTC]",
        "author": "keremz",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "13",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1yxk2",
        "title": "Landing pages are not hard nowadays",
        "content": "[No content]",
        "url": "https://v.redd.it/bqtxeiyqwxag1",
        "publishDate": "2026-01-02T13:43:11Z[Etc/UTC]",
        "author": "MacaroonAdmirable",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1xxvx",
        "title": "Are y'all using different providers and paying $20 each, or sticking with one and using their APIs? How are you managing such switching and mitigating cost overruns when it comes to coding with these agents?",
        "content": "I'm currently paying for ChatGPT Plus and been using Codex for a while now, I'm enjoying the process and willing to spend more (Not $200 though). \n\nFrom the different posts I've read it seems people will have multiple $20 subscriptions from different providers (e.g. Claude, Gemini, even Grok). \n\nI wanted to weigh in on how effective this has been for people or if there are better strategies e.g. sticking with 1 provider and using their API directly and carefully controlling costs.\n\nAlso for those using the APIs how are you preventing runaway cost overruns?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1q1xxvx/are_yall_using_different_providers_and_paying_20/",
        "publishDate": "2026-01-02T12:57:16Z[Etc/UTC]",
        "author": "theanointedduck",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "14",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2shgj",
        "title": "The history of the ARC-AGI benchmark, with Greg Kamradt.",
        "content": "[No content]",
        "url": "https://www.youtube.com/watch?v=3T4OwBp6d90",
        "publishDate": "2026-01-03T11:34:03Z[Etc/UTC]",
        "author": "moschles",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2n1o2",
        "title": "Same Humans. Same Fears. New Tools.",
        "content": "Thoughts?",
        "url": "https://v.redd.it/s14xsen4t2bg1",
        "publishDate": "2026-01-03T06:12:38Z[Etc/UTC]",
        "author": "Intelligent-Mouse536",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "10",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2lyh8",
        "title": "What is the \"flying cars\" promise of AI and what's the subsequent \"just drone quad copters\" reality that will befall it?",
        "content": "Every new technology has unrealistic expectations and a subsequent reality that falls way short of the initial promise.\n\nWith 3d printing, people really thought 3d printing machines would print machines that would print machines that would print machines that would print anything that we can imagine under the sun. It was to be the new manufacturing paradigm.\n\nIn the end, 3d printers just became machines for hobbyist to print their little plastic bits and pieces for toys and hard to get parts for their hobbies.\n\nWith MRNA, the chief scientist of Moderna claimed we would have a tsunami of MRNA vaccines and cures coming as it's easy as designing a vaccine or drug in an hour. Even Elon Musk claimed we can easily and literally turn into a butterfly by doping our DNA with MRNA which would easily alter the former.\n\nBut in the end, all we got out of MRNA are trial cures for end of life illnesses when conventional cures aren't an option. There certainly was no mass adoption nor a tsunami of MRNA drugs or vaccines.\n\nWith AI, the \"flying car\" promise seem to be generative AI. But what will be practical \"come down\" application or reality that will befall it?",
        "url": "https://www.reddit.com/r/artificial/comments/1q2lyh8/what_is_the_flying_cars_promise_of_ai_and_whats/",
        "publishDate": "2026-01-03T05:15:34Z[Etc/UTC]",
        "author": "PopularRightNow",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "8",
            "commentCount": "22",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2jqi5",
        "title": "I built a Chrome extension to make navigating long AI chat conversations easier",
        "content": "Long AI chats (ChatGPT, Claude, Gemini) get hard to scroll and reuse.\nI built a small Chrome extension that helps you navigate long conversations, jump between prompts, and export full chats (Markdown, PDF, JSON, text).\n",
        "url": "https://v.redd.it/p7ndbnb702bg1",
        "publishDate": "2026-01-03T03:29:21Z[Etc/UTC]",
        "author": "Substantial_Shock883",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2hxs8",
        "title": "\"ASI could literally create solar systems.\"  - is everyone losing their minds? Or am I stupid?",
        "content": "[https://www.reddit.com/r/accelerate/comments/1q2crc2/comment/nxcs7tn/?utm\\_source=share&utm\\_medium=web3x&utm\\_name=web3xcss&utm\\_term=1&utm\\_content=share\\_button](https://www.reddit.com/r/accelerate/comments/1q2crc2/comment/nxcs7tn/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button)\n\nSome of the claims I‚Äôm seeing feel like saying \"humans are about to start flying like Superman.\"\n\nSuperman is fun! I'm glad we have imaginations. But are people operating inside symbolic systems that no longer answer to the physical world? I'm 44. All growing up I thought \"wow\" adults and scientists and everyone is so official and smart. One day, I'll be like that. Now I meet 25 year old doctors and people in charge of huge education institutions. They're just people. Some are wise. Some are totally out there and obsessed with things most of us don't agree on. And a lot of them don't seem very worried about maintaining any level of expertise. So, I'm (pretty sure) there's no magic level of skill and expertise I'm not aware of at this point. I'm never going to be Stephen Hawking. But I don't think ASI is going to create a solar system and I can't believe anyone would even have that thought in the first place.",
        "url": "https://www.reddit.com/r/artificial/comments/1q2hxs8/asi_could_literally_create_solar_systems_is/",
        "publishDate": "2026-01-03T02:08:57Z[Etc/UTC]",
        "author": "sheriffderek",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "32",
            "commentCount": "81",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2hlov",
        "title": "Has anyone used AI to find coupon codes?",
        "content": "I was buying some furniture earlier today and when I was at checkout I saw there was a section for a coupon code. I checked all the normal sources for coupons like RetailMeNot and didn't find anything, but before I hit checkout I decided to ask Gemini. Gemini found me a 15% off coupon that saved me roughly $450 on my order. Highly recommend you guys ask your preferred AI about coupon codes, the list it gave me was huge and I just went through the list one by one until something worked.",
        "url": "https://www.reddit.com/r/artificial/comments/1q2hlov/has_anyone_used_ai_to_find_coupon_codes/",
        "publishDate": "2026-01-03T01:53:51Z[Etc/UTC]",
        "author": "Justinat0r",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2gu7a",
        "title": "I figured out how to completely bypass Nano Banana Pro's invisible watermark with diffusion-based post processing.",
        "content": "I‚Äôve been doing AI safety research on the robustness of **digital watermarking for AI images**, focusing on **Google DeepMind‚Äôs SynthID** (as used in Nano Banana Pro). \n\nIn my testing, I found that **diffusion-based post-processing can disrupt SynthID in a way that makes common detection checks fail**, while largely preserving the image‚Äôs visible content. I‚Äôve documented **before/after examples** and **detection screenshots** showing the watermark being detected pre-processing and not detected after. \n\n**Why share this?**  \nThis is a responsible disclosure project. The goal is to move the conversation forward on how we can build¬†*truly*¬†robust watermarking that can't be scrubbed away by simple re-diffusion. I‚Äôm calling on the community to test these workflows and help develop more resilient detection methods.\n\nRepo (writeup + artifacts): [https://github.com/00quebec/Synthid-Bypass](https://github.com/00quebec/Synthid-Bypass?utm_source=chatgpt.com)   \nTry the bypass for free: [https://discord.gg/5mT7DyZu](https://discord.gg/5mT7DyZu)\n\nI'd love to hear your thoughts!",
        "url": "https://www.reddit.com/r/artificial/comments/1q2gu7a/i_figured_out_how_to_completely_bypass_nano/",
        "publishDate": "2026-01-03T01:20:23Z[Etc/UTC]",
        "author": "LiteratureAcademic34",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "145",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q2c881",
        "title": "How to best utilize JSON files",
        "content": "Hi everyone,\n\nIt seems to me like JSON formatting is currently under-utilized by developers. I think we can use this structured data to allow for more communication across AI-powered platforms. What are some ways developers could try to take advantage of JSON to push AI tools to the next level? Have you used JSON in any of your projects? Let me know what you think, thanks!",
        "url": "https://www.reddit.com/r/artificial/comments/1q2c881/how_to_best_utilize_json_files/",
        "publishDate": "2026-01-02T22:08:40Z[Etc/UTC]",
        "author": "ScratchJolly3213",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q25bg6",
        "title": "Google AI Overviews put people at risk of harm with misleading health advice",
        "content": "[No content]",
        "url": "https://www.theguardian.com/technology/2026/jan/02/google-ai-overviews-risk-harm-misleading-health-information",
        "publishDate": "2026-01-02T17:49:18Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "13",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1yrn3",
        "title": "Data centers generate 50x more tax revenue per gallon of water than golf courses in Arizona",
        "content": "* **The stat:**¬†Golf courses in AZ use \\~30x more water than all data centers combined.\n* **The payoff:**¬†Data centers generate roughly 50x more tax revenue per gallon of water used.\n* **The proposal:**¬†Swap out golf courses for data centers to keep water usage flat while making billions for the state.",
        "url": "https://v.redd.it/yoxwi4idvxag1",
        "publishDate": "2026-01-02T13:35:44Z[Etc/UTC]",
        "author": "Beachbunny_07",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "325",
            "commentCount": "135",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1xz2v",
        "title": "After 12 years building cloud infrastructure, I'm betting on local-first AI",
        "content": "Sold my crypto data company last year. We processed everything in the cloud - that was the whole model. Now I'm building the opposite.\n\nRunning all my inference locally on a NAS with an eGPU. Not because it's cheaper (it isn't, upfront) or faster (it isn't, for big models). Because the data never leaves.\n\nThe more I watch the AI space evolve, the more I think there's going to be a split. Most people will use cloud AI and not care. But there's a growing segment - developers, professionals handling sensitive data, privacy-conscious users - who will want capable models running on hardware they control.\n\nI wrote up [my thinking on this](https://www.localghost.ai/manifesto) \\- the short version is that local-first isn't about rejecting cloud AI, it's about having the option.\n\nCurrent setup is Ollama on an RTX 4070 12GB. The 7B-13B models are genuinely useful for daily work now. A year ago they weren't. That trajectory is what makes local viable.\n\nAnyone else moving toward local inference? Curious whether this is a niche concern or something more people are thinking about.",
        "url": "https://www.reddit.com/r/artificial/comments/1q1xz2v/after_12_years_building_cloud_infrastructure_im/",
        "publishDate": "2026-01-02T12:58:54Z[Etc/UTC]",
        "author": "ZeroCool86",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "57",
            "commentCount": "46",
            "isNsfw": "false"
        }
    },
    {
        "id": "1q1xxe5",
        "title": "Really LangChain just added built-in card support for agents?",
        "content": "I just saw that LangChain now has cards for agents basically a way to standardize how agents display and organize outputs.   \n  \nFrom what I understand, these aren‚Äôt just UI widgets, they‚Äôre structured result formats that agents can use to return richer, consistent info instead of plain text.\n\nFeels like a small thing on the surface, but I think it‚Äôs actually about making agent output more predictable and reusable  you can show data, suggestions, steps, or actions in a format that systems and humans can both read easily.\n\nCurious what others think does this actually help make agent responses more reliable, or is it just a UI convenience for now?\n\nLink is in the comments.",
        "url": "https://www.reddit.com/r/artificial/comments/1q1xxe5/really_langchain_just_added_builtin_card_support/",
        "publishDate": "2026-01-02T12:56:38Z[Etc/UTC]",
        "author": "Shot-Hospital7649",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "XW9FgVcrs98",
        "title": "Claude Opus 4.5 (Long-term review &amp; My Setup): Opus is FREAKING MAGIC!! It has REPLACED ME!!",
        "content": "In this video, I share my honest thoughts on Opus 4.5 and why I believe it is finally the true successor to Sonnet 3.5 for coding.",
        "url": "https://www.youtube.com/watch?v=XW9FgVcrs98",
        "publishDate": "2026-01-02T11:56:56Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/XW9FgVcrs98/hqdefault.jpg",
            "transcription": "Error generating summary: Something unexpected happened.\ndev.shreyaspatil.ai.client.generativeai.type.UnknownException: Something unexpected happened.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:54)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "uNKglF-GAmM",
        "title": "How Economic Reform Made Things Worse In Russia - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=uNKglF-GAmM",
        "publishDate": "2026-01-02T16:30:32Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/uNKglF-GAmM/hqdefault.jpg",
            "transcription": "WHY DID ECONOMIC REFORM IN RUSSIA MAKE THINGS WORSE INSTEAD OF BETTER? There's no tradition for all of these things. And then you go, well, how did Russia get this way? Well, it's a very difficult address. Prior to the Industrial Revolution, it's flat. Neighbors all invade. And so you needed a big army in order to defeat them. Okay, a big army is going to want a war economy. I mean, this is my take and uh others who are actually experts in these various periods of Russian history can come up with something else, but I think you're channeling your economics into that. Whereas you're looking at Europe and particularly Britain, there are a tremendous number of very rich merchants in Britain that are going to influence government, laws and things, which is not going to take place. And then what's nice about the Navy for Britain is you send them away. They're not going to run a coup in the capital because they're off on the ships somewhere."
        }
    }
]