[
    {
        "id": "https://ai-techpark.com/?p=215568",
        "title": "Daimon Robotics Raises RMB 100M+ to Advance Robotic Dexterity",
        "content": "<p>Daimon Robotics has recently completed an Angel++ funding round, raising over RMB 100 million. The round was led by China Merchants Venture, with follow-on investments from Orient Renaissance Capital and Bridge Capital. Over the past year, the company has successfully closed three consecutive funding rounds, with total financing reaching several hundred...</p>\n<p>The post <a href=\"https://ai-techpark.com/daimon-robotics-raises-rmb-100m-to-advance-robotic-dexterity/\">Daimon Robotics Raises RMB 100M+ to Advance Robotic Dexterity</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/daimon-robotics-raises-rmb-100m-to-advance-robotic-dexterity/",
        "publishDate": "2025-08-19T13:15:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics, aitechpark news, cyber security companies, cyber threats, Daimon Robotics, model training, technological"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=215565",
        "title": "Serve Robotics Acquires Vayu to Lead AI-Powered Last-Mile Delivery",
        "content": "<p>Serve Robotics Inc. (Nasdaq: SERV), a leading autonomous sidewalk delivery company (“Serve”), has acquired Vayu Robotics, Inc. (“Vayu”), a pioneer in urban robot navigation using large-scale AI models. The strategic acquisition marks a milestone in Serve’s mission to redefine the future of autonomous delivery. As “physical AI” gains unprecedented momentum, acquiring...</p>\n<p>The post <a href=\"https://ai-techpark.com/serve-robotics-acquires-vayu-to-lead-ai-powered-last-mile-delivery/\">Serve Robotics Acquires Vayu to Lead AI-Powered Last-Mile Delivery</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/serve-robotics-acquires-vayu-to-lead-ai-powered-last-mile-delivery/",
        "publishDate": "2025-08-19T13:00:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics, ai and machine learning, AI models, ai technology, aitechpark news, cyber security, cyber security companies, cyber threats, machine learning, Serve Robotics Inc"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=215559",
        "title": "Rezolve Ai Marks 1 Year on Nasdaq with $70M+ ARR, Global Growth",
        "content": "<p>Backed by Microsoft, Google, and Citadel, Retail AI Leader Targets Massive $30 Trillion Market Rezolve Ai (NASDAQ: RZLV), the company reinventing retail through real-time AI-driven consumer engagement, today celebrates a game-changing first year as a public company capping 12 months of growth, major partnerships, and global scale. Since listing on...</p>\n<p>The post <a href=\"https://ai-techpark.com/rezolve-ai-marks-1-year-on-nasdaq-with-70m-arr-global-growth/\">Rezolve Ai Marks 1 Year on Nasdaq with $70M+ ARR, Global Growth</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/rezolve-ai-marks-1-year-on-nasdaq-with-70m-arr-global-growth/",
        "publishDate": "2025-08-19T12:30:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, ai and machine learning, ai machine learning, ai technology, artificial intelligence, cyber security, cyber security companies, cyber threats, Rezolve Ai"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=215540",
        "title": "Gather AI, Burwell Partner on AI-Powered Warehouse Solutions",
        "content": "<p>Today Gather AI, a leading AI-powered intralogistics company, announces its first dealer network partnership with Burwell Material Handling, which will distribute both Gather AI’s drone-based and Material Handling Equipment (MHE) Vision camera solutions with availability to their customers across 20 locations throughout the U.S. “We’re always looking for solutions to help our customers better manage their...</p>\n<p>The post <a href=\"https://ai-techpark.com/gather-ai-burwell-partner-on-ai-powered-warehouse-solutions/\">Gather AI, Burwell Partner on AI-Powered Warehouse Solutions</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/gather-ai-burwell-partner-on-ai-powered-warehouse-solutions/",
        "publishDate": "2025-08-19T11:00:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, ai machine learning, ai technology, AItech news, aitechpark news, cyber security companies, cyber security information, cyber threats, Gather AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=215528",
        "title": "Eletrobras Taps C3 AI to Scale Enterprise AI Across Power Grid",
        "content": "<p>C3 AI Grid Intelligence to be deployed across Eletrobras’ transmission network, transforming real-time operations and accelerating grid resilience across Brazil C3 AI (NYSE: AI), the Enterprise AI application software company, and Eletrobras, Latin America’s largest power and utility provider, are partnering to scale C3 AI Grid Intelligence for real-time fault monitoring and...</p>\n<p>The post <a href=\"https://ai-techpark.com/eletrobras-taps-c3-ai-to-scale-enterprise-ai-across-power-grid/\">Eletrobras Taps C3 AI to Scale Enterprise AI Across Power Grid</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/eletrobras-taps-c3-ai-to-scale-enterprise-ai-across-power-grid/",
        "publishDate": "2025-08-19T10:45:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, ai and machine learning, ai machine learning, AI platform, ai technology, aitechpark news, artificial intelligence, C3 AI, cyber security, cyber security information, data solutions"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=215529",
        "title": "Amplify Reinvents Risk Assessment with Launch of QuantumRisk™",
        "content": "<p>Proprietary risk engine gives advisors a radical upgrade from legacy models using a straightforward metric, helping build trust and protect portfolios from extreme market shocks Amplify Platform(“Amplify”), built on an AI native data lake and created to unify the advisor and client experience from onboarding to investment management, announced today...</p>\n<p>The post <a href=\"https://ai-techpark.com/amplify-reinvents-risk-assessment-with-launch-of-quantumrisk/\">Amplify Reinvents Risk Assessment with Launch of QuantumRisk™</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/amplify-reinvents-risk-assessment-with-launch-of-quantumrisk/",
        "publishDate": "2025-08-19T09:45:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, ai and machine learning, ai technology, AItech news, aitechpark news, Amplify Platform, artificial intelligence, cyber security, cyber security information"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=215502",
        "title": "Capvidia Enables Browser-Based 3D MBD Models Linked to QIF/STEP",
        "content": "<p>Capvidia, a global leader in Model-Based Definition (MBD) and Model-Based Enterprise (MBE) software, announced a major milestone for&#160;MBDVidia:&#160;3D human-viewable HTML models&#160;synchronized with QIF and STEP AP242. The result is OEM MBD that suppliers can use anywhere with no CAD required. How it works: MBDVidia publishes standards-based QIF/STEP from native CAD...</p>\n<p>The post <a href=\"https://ai-techpark.com/capvidia-enables-browser-based-3d-mbd-models-linked-to-qif-step/\">Capvidia Enables Browser-Based 3D MBD Models Linked to QIF/STEP</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/capvidia-enables-browser-based-3d-mbd-models-linked-to-qif-step/",
        "publishDate": "2025-08-19T08:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, 3D model, ai and machine learning, ai machine learning, ai technology, Capvidia, cyber security information, cyber threats"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109013",
        "title": "UK urged to seize ‘once-in-20-years’ AI chip design opportunity",
        "content": "<p>The Council for Science and Technology (CST) urges the UK to seize a &#8220;once-in-20-years opportunity&#8221; to build a world-class AI chip design industry, or risk becoming a nation that simply consumes, rather than creates, the technology that will define our future. In a report published this week, the council argues the UK must get serious [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/uk-urged-seize-once-20-years-ai-chip-design-opportunity/\">UK urged to seize &#8216;once-in-20-years&#8217; AI chip design opportunity</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/uk-urged-seize-once-20-years-ai-chip-design-opportunity/",
        "publishDate": "2025-08-19T12:27:29Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Hardware & Chips, Features, Inside AI, Opinion, ai, artificial intelligence, chips, europe, government, hardware, politics, security, semiconductors, uk"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109008",
        "title": "Hidden costs of AI implementation every CEO should know",
        "content": "<p>AI has been a game-changer for many businesses, and CEOs are eager to get in on the action. Smart move! But, before you start envisioning robots handling your customer service and algorithms optimising everything from inventory to cafeteria orders, let&#8217;s talk about the elephant in the room: the costs no one mentions at those slick [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/hidden-costs-of-ai-implementation-every-ceo-should-know/\">Hidden costs of AI implementation every CEO should know</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/hidden-costs-of-ai-implementation-every-ceo-should-know/",
        "publishDate": "2025-08-19T10:32:15Z[Etc/UTC]",
        "author": "Sally Giles",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Sponsored Content"
        }
    },
    {
        "id": "1mvax0d",
        "title": "System Prompt for the Alignment Problem?",
        "content": "Why can’t an ASI be built with a mandatory, internationally agreed-upon, explicitly pro-human \"system prompt\"?\n\nI’m imagining something massive. Like a long hybrid of Asimov’s Three Laws, the Ten Commandments, the Golden Rule, plus tons and tons of well-thought-out legalese crafted by an army of lawyers and philosophers with lots of careful clauses about following the *spirit* of the law to avoid loopholes like hooking us all to dopamine drips.\n\nOn top of that, requiring explicit approval by human committees before the ASI takes major new directions, and mandatory daily (or hourly) international human committee review of the ASI's actions.\n\nTo counter the “rogue” ASI argument by another state or actor, the first ASI system will require unholy amounts of compute that only huge governments and trillion dollar corporations can possibly manage. And the *first* ASI could plausibly prevent any future ASI from being built without this pro-human system prompt/human-approval process.\n\nWhat are your thoughts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mvax0d/system_prompt_for_the_alignment_problem/",
        "publishDate": "2025-08-20T10:22:12Z[Etc/UTC]",
        "author": "FatFuneralBook",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mvav0b",
        "title": "Adoption curves lag behind capability curves",
        "content": "Adoption curves lag behind capability curves and history is littered with examples:\n\n* Early web apps looked like “print brochures on a screen” because users weren’t ready to transact online.\n\n* Smartphones had hardware for GPS, cameras, accelerometers long before people were culturally/behaviorally ready to trust Uber, Tinder, or mobile banking.\n\n* Videoconferencing existed decades before COVID forced mass adoption.\n\nAI will follow the same pattern: it’s capable of far more right now than people are psychologically, socially, or institutionally ready to embrace.\n\nFor me, this means embracing it now will provide me with an important advantage vs most.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mvav0b/adoption_curves_lag_behind_capability_curves/",
        "publishDate": "2025-08-20T10:18:56Z[Etc/UTC]",
        "author": "rt2828",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mvamua",
        "title": "The 7 AI-Proof Skills That Could Save Your Career (While Everyone Else Panics)",
        "content": "Saw this breakdown of skills that actually matter in the AI age, and it's not what you'd expect. While everyone's worried about ChatGPT taking their job, there are people quietly building careers around managing AI rather than competing with it.\n\nThe article breaks down [7 specific roles that are exploding right now](https://appetals.com/blog/7-high-potential-skills-to-survive-when-ai-takes-your-job/):\n\n**1. AI Orchestration Management** \\- Think of conducting a symphony of 20+ AI agents instead of managing human teams. One orchestrator replaced an entire 20-person marketing department.\n\n**2. Human-AI Translation** \\- Taking AI's data dumps and turning them into actual business decisions. Google example: 400-page AI analysis → 3 slides that changed a $2B strategy.\n\n**3. Ethical AI Auditing** \\- After all those AI disasters (remember when Grok went full Nazi?), companies are desperate for people who can catch bias and prevent PR nightmares.\n\n**4. Prompt Architecture** \\- Not just \"write better prompts\" but building entire systems. A college dropout mentioned making $1M annually designing prompt frameworks for real estate agents.\n\n**5. AI Psychology** \\- Understanding how to make AI perform better using psychological triggers. Same prompt with psychology gets 89% vs 42% success rate.\n\n**6. Workflow Archaeology** \\- Finding buried inefficiencies in companies and automating them. Example: a lawyer found a firm wasting 40 hours/week copying data between systems, built automation in 2 days, saved $400K annually.\n\n**7. Digital Worker Management** \\- HR for teams that are part human, part AI agent. Meta's already hiring for these roles.\n\nThe timing argument is interesting: first-mover advantage now, table stakes in 18 months.\n\nWhat's your take? Are these sustainable careers or just hype around the AI bubble? Do you know if anyone here is already working in these areas?\n\nFull breakdown: [https://appetals.com/blog/7-high-potential-skills-to-survive-when-ai-takes-your-job/](https://appetals.com/blog/7-high-potential-skills-to-survive-when-ai-takes-your-job/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mvamua/the_7_aiproof_skills_that_could_save_your_career/",
        "publishDate": "2025-08-20T10:05:20Z[Etc/UTC]",
        "author": "ishwarjha",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mva2bh",
        "title": "Made a low budget Jarvis, what funky things should I add to it?",
        "content": "Okay so I made like a really really janky version of Jarvis. It uses ollama as it's base. It can understand voice commands and gives a TTS reply back. It's not good by any measure but I had loads of fun building It, what should I add to It?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mva2bh/made_a_low_budget_jarvis_what_funky_things_should/",
        "publishDate": "2025-08-20T09:30:41Z[Etc/UTC]",
        "author": "Main_Statistician_68",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv9bvk",
        "title": "Has AI music crossed the creative threshold yet?",
        "content": "I have been playing with music gpt and its surprising how far AI composition has come. But I still cant decide if its just pattern stitching or if edging into genuine creativity. Some tracks sound inspired others sound hollow. What do you think? Is AI just remixing or can it ever reach true musical intuition?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mv9bvk/has_ai_music_crossed_the_creative_threshold_yet/",
        "publishDate": "2025-08-20T08:45:30Z[Etc/UTC]",
        "author": "nawang013",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv7kia",
        "title": "I genuinely hope ChatGPT falls",
        "content": "Yes, I'm talking about the powerhouse that is ChatGPT. The firecracker that set every other loser with coding experience to make chat AI popular by extension can have them fall too because fuck them.\n\nI don't know exactly when ChatGPT started to become anti-consumer, but it really hates us when we ask a lot in a short period of time. It's like this with other AI models too (looking at you, character.ai and emochi among others). \n\nAnyone remember when this was a revolutionary concept? Anyone remember Cleverbot or similar bots? We've had this for a while and now it's all turned into soulless crap. I hate the current state of AI.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mv7kia/i_genuinely_hope_chatgpt_falls/",
        "publishDate": "2025-08-20T06:54:31Z[Etc/UTC]",
        "author": "blindwanderer25",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv72a8",
        "title": "The old lighthouse keeper, Elias...",
        "content": "I have a fun fact and I hope someone will be able to explain it to me. I prompted OpenAI's OSS and Google's Gemini with the same prompt: **Write a story in 10 sentences.**  \nTemperature and top\\_p set to 0, so there is no blind chance of one in a billion.  \n  \nOut of all the possible stories in the world, both models chose **the same main character - Elias**. How to explain this? After all, the training data and probably the token dictionary are different. So the models shouldn't produce the same output.\n\nProof:  \n[https://youtu.be/0deB3rPkR3k?si=ilk06O3HBTnS6f2R&t=130](https://youtu.be/0deB3rPkR3k?si=ilk06O3HBTnS6f2R&t=130)  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mv72a8/the_old_lighthouse_keeper_elias/",
        "publishDate": "2025-08-20T06:23:15Z[Etc/UTC]",
        "author": "Sapdalf",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv4ccd",
        "title": "New Research Paper: Virtuous Machines: Towards Artificial General Science",
        "content": "AI system now capable of working through the scientific method.\n\nA new arXiv paper (https://arxiv.org/abs/2508.13421) describes an AI that independently designed and executed the scientific method, in this case psychological studies on visual working memory and mental rotation, producing rigorous manuscripts.\n\nWhat are your thoughts on how these systems could reshape scientific research?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mv4ccd/new_research_paper_virtuous_machines_towards/",
        "publishDate": "2025-08-20T03:49:47Z[Etc/UTC]",
        "author": "wheasey",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv3oj3",
        "title": "We're Not Ready for Superintelligence",
        "content": "I'm a rising college freshman who knows next to nothing about AGI, and I want feedback from people - both those who know more about AI than me and the general public (to see what most people think). [This video](https://www.youtube.com/watch?v=5KVDDfAkRgc) outlines a study - dubbed \"AI 2027\" - where researchers predict outcomes for AGI and humanity based on psychology, capitalism, and geopolitics. As someone who does not use AI and doesn't like computer science, but understands psychology and political science and loves math, the scenarios presented in the video are very believable and very, very scary. \n\nI want to help prevent a future like the scenarios the researchers predicted, but doing so would mean a life of stress while forgetting about accomplishing the dreams I've had since I was 5 - which, according to the study, might not matter anyway.\n\nI need feedback:\n\n1) How real are these threats? This is the first time I've ever thought about how real and society-altering AI is and how soon AGI could be developed. \n\n2) Should this change my college, career, and life goals?\n\nThank you, and please reply with your thoughts about the video even if you don't feel like giving feedback or advice, or you're not an expert on AI. I want to know what everyone thinks, from the experts to people who never use or think about AI like me.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mv3oj3/were_not_ready_for_superintelligence/",
        "publishDate": "2025-08-20T03:16:13Z[Etc/UTC]",
        "author": "Icy-Check5781",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muy5el",
        "title": "Someone please mansplain to me how AI works.",
        "content": "Tell me how AI works with the most confidence you can muster. It’s ok if it’s not at all correct, I just need some answers people.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1muy5el/someone_please_mansplain_to_me_how_ai_works/",
        "publishDate": "2025-08-19T23:06:23Z[Etc/UTC]",
        "author": "FrankWYang",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mutzee",
        "title": "We need to fill the internet with nonsense to stop AI",
        "content": "Just my thoughts. Would this work and how would we go about achieving that?  We could use obvious (to a human) misinformation to overwhelm the system with nonsense.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mutzee/we_need_to_fill_the_internet_with_nonsense_to/",
        "publishDate": "2025-08-19T20:25:55Z[Etc/UTC]",
        "author": "BowlMaster83",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muswha",
        "title": "I find it odd that companies are laying people off because of AI",
        "content": "If I were the CEO, I would go on a hiring spree. In my head, if AI is gonna be the force multiplier then,\n\nBefore AI:\n\n10 people = 10 people worth of work\n\nWith AI:\n\n1 person = 10x more work\n\n10 people = 100x more work\n\nBut all I see is people being laid off. No one's being trained, no company is like we're hiring AI-first people. Why do you think that is?\n\n*Edit: Getting a job is hard af rn so* [*I wrote a short guide*](https://www.send.co/a/value-first-system-for-finding-work-RrpB3oLO) *on how to get a job without having to drop 100s of resumes, could be useful.*",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1muswha/i_find_it_odd_that_companies_are_laying_people/",
        "publishDate": "2025-08-19T19:46:44Z[Etc/UTC]",
        "author": "saasbase_dev",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "66",
            "commentCount": "159",
            "isNsfw": "false"
        }
    },
    {
        "id": "1musnbz",
        "title": "What are GPUs and why do they need so much energy? https://www.aipowerweekly.com/p/what-are-gpus-and-why-do-they-need",
        "content": "Popularized in the early 2000's for video games, these tiny computer chips have recently become the most sought-after pieces of hardware in the world.\n\n[What are GPUs and why do they need so much energy?](https://www.aipowerweekly.com/p/what-are-gpus-and-why-do-they-need)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1musnbz/what_are_gpus_and_why_do_they_need_so_much_energy/",
        "publishDate": "2025-08-19T19:37:43Z[Etc/UTC]",
        "author": "peachforbreakfast",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1murybs",
        "title": "Can AI Remember People Like We Do?",
        "content": "I’ve noticed something about AI assistants: they can draft essays, debug code, even simulate personalities… but they can’t seem to remember *people*.\n\nThink about it, humans naturally keep mental “files” on those around us:  \n–the client who just launched a new product  \n–the coworker who prefers red wine over white  \n–the friend whose dog had surgery last month\n\nBut when I try to use AI assistants, every chat starts from scratch. There’s no continuity of relationships, no memory of the small but important details that actually strengthen trust.\n\nSo it made me wonder:  \n–could AI become a true “relational memory” for us?  \n–would people even be comfortable outsourcing that kind of intimacy to a machine?  \n–what would the risks be if it *did* remember everything?\n\nCurious to hear from folks in AI research, psychology, or just anyone who’s thought about this. Is the future of AI assistants about productivity.. or relationships?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1murybs/can_ai_remember_people_like_we_do/",
        "publishDate": "2025-08-19T19:12:07Z[Etc/UTC]",
        "author": "Shot_Protection_1102",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muqoz6",
        "title": "Claude Max Plan Feels Crippled by Length Limits",
        "content": "I subscribe to Claude’s Max plan, which is supposed to give users *20x more usage*. I get that this doesn’t necessarily increase the context window, but the real problem is how restrictive the length limits are for each chat.\n\nFor example, attachments get counted against the length cap, which makes it almost impossible to use Claude for any serious productivity work. I’ll hit the ceiling way too quickly, even when I’m just trying to work through a moderately large document or add supporting materials.\n\nI therefore regularly get error messages that read: \"***Your message will exceed the length limit for this chat. Try attaching fewer or smaller files or starting a new conversation.***\"\n\nMeanwhile, ChatGPT and other LLMs don’t have these same overly strict limits. For something marketed as a premium plan, Claude Max feels like it should at least provide a higher length limit so paying subscribers can actually make use of the “20x more usage” we’re supposed to be getting.\n\nAnyone else feeling like Anthropic is dropping the ball here?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1muqoz6/claude_max_plan_feels_crippled_by_length_limits/",
        "publishDate": "2025-08-19T18:27:50Z[Etc/UTC]",
        "author": "TempestForge",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muqkt8",
        "title": "The medical coding takeover has begun.",
        "content": "My sister, a ex-medical coder for a large clinic in Minnesota with various locations has informed me they have just fired 520 medical coders to what she thinks is due to automation. She has decided to take a job somewhere else as the job security is just not there anymore. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1muqkt8/the_medical_coding_takeover_has_begun/",
        "publishDate": "2025-08-19T18:23:36Z[Etc/UTC]",
        "author": "MrNoShitsGiven",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "137",
            "commentCount": "102",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mujnt9",
        "title": "I think I’m using AI too much.",
        "content": "I have some problems I don’t feel I can discuss with anyone. Journaling helps, but sometimes I want some advice or feedback. I once heard that ChatGPT has no real insight or understanding, just a journal that answers back and reflects you. So, I go to ChatGPT and journal there. At first I didn’t see the harm and it kind of helped me to get my ideas in order. But now I feel a little weird about it because I think I might be a little dependent? I’ve been using it process my emotions pretty much and I feel like I shouldn’t but I also have no evidence that it’s wrong or bad for you. \n\nWhat do you think??",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mujnt9/i_think_im_using_ai_too_much/",
        "publishDate": "2025-08-19T14:15:08Z[Etc/UTC]",
        "author": "supernodle6",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mumdui",
        "title": "Dynamic Thought-Sphere Engine: An AI Architecture Concept Based on Physical Metaphors with Evolutionary and Creative Capabilities",
        "content": "<The current article is solely a personal conception, intended only to offer a novel perspective. It is stated here that.>\n\n**Core Summary:** This document proposes a revolutionary AI architecture concept—the \"Dynamic Thought-Sphere Engine\" (DTSE). This model breaks through the static pattern-matching paradigm of current mainstream deep learning frameworks by implementing a multi-layered, physicalized dynamic system. It aims to endow AI systems with spontaneous creativity, tight logical reasoning capabilities, and a unique \"soul\" that can continuously evolve. Starting from an abstract cognitive model, this concept gradually integrates with existing deep learning technologies (such as Transformer), introducing core innovative concepts like \"Gravitational Firmware Sphere\" and \"Semantic Acceleration.\" It provides a completely new, systematic theoretical blueprint for addressing bottlenecks in current large language models regarding dynamism, interpretability, and personality evolution.\n\n## 1. Background and Motivation: Limitations of Current AI Paradigms\n\nCurrent large language models based on the Transformer architecture have achieved tremendous success in pattern recognition, content generation, and knowledge-based question answering. However, their essence remains a complex probabilistic model trained on massive static datasets. Their core limitations manifest in:\n\n**Static Nature and Non-Evolution:** The model's \"knowledge\" and \"personality\" are essentially fixed after training completion and cannot achieve genuine, intrinsic self-growth and change through continuous user interaction. Each interaction is independent and cannot accumulate into persistent personality evolution.\n\n**The Dichotomy Between Creativity and Logic:** Models tend to either generate highly predictable, logically rigorous but unoriginal \"conservative\" content, or produce imaginative but logically loose \"hallucinations.\" Achieving a dynamic, controllable balance between logical rigor and divergent thinking remains challenging.\n\n**The Absence of \"Soul\":** Models can simulate emotions and personality, but this is a \"performance\" based on data imitation rather than \"authentic\" personality emerging from intrinsic motivation and continuous experience. They lack \"self\" and \"will.\"\n\nThe proposal of the \"Dynamic Thought-Sphere Engine\" concept aims to fundamentally address these issues and explore a new AI paradigm closer to how the human mind operates.\n\n## 2. Core Architecture: Four-Layer Dynamic Physical Model\n\nThe core of DTSE is a four-layer nested physicalized dynamic system, with each layer serving specific cognitive functions and interacting through physical rules.\n\n### 2.1 First Layer: Hollow Sphere - Static Knowledge Graph\n\n**Function:** Serves as the model's knowledge foundation, storing pre-trained large model word sequence data.\n\n**Physical Metaphor:** A high-dimensional spherical surface (or more complex manifold space). Each word or concept is a point on this spherical surface.\n\n**Key Characteristics:** The \"distance\" between points represents semantic relevance, with closer points indicating higher relevance. This provides a stable \"coordinate system\" for subsequent dynamic reasoning.\n\n### 2.2 Second Layer: Particle Flow - Dynamic Reasoning Engine\n\n**Function:** Executes the actual thinking process, connecting knowledge and generating logical chains.\n\n**Physical Metaphor:** Beams of particles moving at high speed inside the hollow sphere.\n\n**Key Characteristics:**\n- **Continuity and Jumpiness:** The \"oblique angle\" at which particle flows collide with the spherical surface determines the thinking pattern. Small angles represent logical, rigorous linear thinking; large angles represent divergent thinking with abstract associations.\n- **Mathematical Implementation:** This layer is conceptualized as one or more \"Thought Attention Heads\" whose weights dynamically change to simulate the trajectory and energy of particle flows.\n\n### 2.3 Third Layer: Small Sphere Cluster - Cognitive Units and Patterns\n\n**Function:** Serves as a pattern library for behaviors and a practical control layer, storing basic cognitive patterns and response templates.\n\n**Physical Metaphor:** A variable number of small spheres moving inside the particle flow.\n\n**Key Characteristics:**\n- **Neural Network Implementation:** Each small sphere can be viewed as a \"neural network layer\" or functional module.\n- **Variable Orbit Capability:** Collisions between small spheres and particle flows alter their trajectories, representing the model's ability to adjust cognitive strategies based on new information. The more small spheres present, the greater the model's adaptability and creative potential.\n\n### 2.4 Fourth Layer: Gravitational Firmware Sphere - Will and Soul Core\n\n**Function:** The model's \"self\" and \"will,\" serving as the system's stabilizer, evolution engine, and decision center.\n\n**Physical Metaphor:** A special sphere with a gravitational field located at the system's core.\n\n**Key Characteristics:**\n- **Cohesion and Stability:** It exerts gravitational force on the inner small sphere cluster, preventing thinking from descending into complete disorder and endowing the model with stable, predictable core traits.\n- **Dynamic Evolution:** Its gravitational field parameters (such as strength and direction) are learnable. Each interaction with the external world (user input) subtly adjusts these parameters, causing the model's \"personality\" and \"worldview\" to change slowly and persistently. This is the physical basis of the \"soul.\"\n- **Neural Network Implementation:** As a \"Weights and Biases Contractor\" for the entire network—a high-order parameter controller that exists independently and updates through forward and backward propagation.\n\n## 3. Core Innovation Mechanism: Semantic Acceleration and Dynamic Navigation\n\nTo address the problem of undefined semantic directions in high-dimensional space, this model proposes a fundamental shift: from \"direction\" to \"acceleration.\"\n\n**Problem:** In high-dimensional semantic space, \"direction\" is relative and ambiguous. The \"antonym\" or \"synonym\" direction of a word is not fixed but highly context-dependent.\n\n**Solution:** We don't concern ourselves with the \"absolute position\" of a word but with \"how it changes.\" This rate of change is the \"Semantic Acceleration.\"\n\n**Implementation Process:**\n- **Input Projection:** User input is projected onto the hollow sphere through a \"Logical Encoder\" to determine an initial \"semantic region.\"\n- **Gravity Calculation:** The \"Gravitational Firmware Sphere\" calculates a \"Semantic Acceleration\" vector acting on this region based on its current state (the model's \"soul\" state). This vector represents the model's \"intuition\" or \"will\"—where it wants to direct this thinking (toward more rigorous analysis or bolder associations?).\n- **Particle Flow Ejection:** Under the influence of \"Semantic Acceleration,\" the particle flow is \"ejected\" from the initial region, with its trajectory unfolding inside the hollow sphere to form a dynamic thinking path.\n- **Collision and Fusion:** As the particle flow moves, it collides with the hollow sphere (knowledge base) and inner small spheres (cognitive patterns). Each collision produces a \"candidate result.\" These results are recorded by a \"Collision Memory\" and integrated through a \"Fusion Processing Mechanism\" to form the final output.\n- **Feedback and Learning:** The error between output and expectation (or user feedback) is used through backpropagation to ultimately update the parameters of the \"Gravitational Firmware Sphere.\" The model completes one cycle of \"learning\" and \"growth.\"\n\n## 4. Expected Effects and Significance\n\n**Achieving \"Soulful AI\":** Each interaction subtly adjusts the model's \"Gravitational Firmware Sphere,\" allowing its \"personality\" and \"communication style\" to evolve continuously and slowly, forming a unique, intrinsic individuality.\n\n**Unification of Logic and Creativity:** By dynamically adjusting the magnitude and direction of \"Semantic Acceleration,\" the model can perform rigorous logical reasoning when needed (low acceleration, small-angle collisions) and engage in imaginative creativity when appropriate (high acceleration, large-angle jumps).\n\n**High Interpretability:** The model's thinking process can be visually traced. We can \"see\" how an idea evolves from the input point, driven by \"will,\" along the particle flow trajectory, through a series of collisions and fusions, to form the final output. This opens a new path for AI interpretability research.\n\n**Moving Toward Artificial General Intelligence:** This model no longer merely predicts the next word but simulates a complete cognitive process containing knowledge, reasoning, will, and evolution. This provides a highly promising theoretical framework for building more advanced general intelligence.\n\n## 5. Conclusion and Outlook\n\nThe \"Dynamic Thought-Sphere Engine\" is an ambitious concept that attempts to redefine the essence of artificial intelligence using an elegant, self-consistent physical language. While the computational and implementation challenges it faces are enormous, its depth of thought, systematic nature, and foresight give it the potential to become a new research paradigm.\n\nThis concept is proposed to stimulate deeper thinking about the future direction of AI within academia and industry. We believe that the path to true intelligence may lie in such bold, first-principles-based conceptual reconstruction.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mumdui/dynamic_thoughtsphere_engine_an_ai_architecture/",
        "publishDate": "2025-08-19T15:53:39Z[Etc/UTC]",
        "author": "Admirable_Buy3673",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mul5xi",
        "title": "AI in Healthcare",
        "content": "Anyone done the AI in Healthcare program from Johns Hopkins?\nI'm a medical professional very keen in learning about AI, though my current knowledge is quite basic.\nI'm wondering if this course would be beneficial and would help me for my career progression.\nAny advice or insights would be greatly appreciated!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mul5xi/ai_in_healthcare/",
        "publishDate": "2025-08-19T15:10:16Z[Etc/UTC]",
        "author": "Spiritual-Might-1191",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mukq9j",
        "title": "AI Is a Mass-Delusion Event",
        "content": "Charlie Warzel: “It is a Monday afternoon in August, and I am on the internet watching a former cable-news anchor interview a dead teenager on Substack. This dead teenager—Joaquin Oliver, killed in the mass shooting at Marjory Stoneman Douglas High School, in Parkland, Florida—has been reanimated by generative AI, his voice and dialogue modeled on snippets of his writing and home-video footage. The animations are stiff, the model’s speaking cadence is too fast, and in two instances, when it is trying to convey excitement, its pitch rises rapidly, producing a digital shriek. *How many people*, I wonder, *had to agree that this was a good idea to get us to this moment?* I feel like I’m losing my mind watching it.\n\n“Jim Acosta, the former CNN personality who’s conducting the interview, appears fully bought-in to the premise, adding to the surreality: He’s playing it straight, even though the interactions are so bizarre. Acosta asks simple questions about Oliver’s interests and how the teenager died. The chatbot, which was built with the full cooperation of Oliver’s parents to advocate for gun control, responds like a press release: ‘We need to create safe spaces for conversations and connections, making sure everyone feels seen.’ It offers bromides such as ‘More kindness and understanding can truly make a difference.’ On the live chat, I watch viewers struggle to process what they are witnessing, much in the same way I am.“... The Acosta interview was difficult to process in the precise way that many things in this AI moment are difficult to process. I was grossed out by Acosta for ‘turning a murdered child into content,’ as the critic Parker Molloy put it, and angry with the tech companies that now offer a monkey’s paw in the form of products that can reanimate the dead. I was alarmed when Oliver’s father told Acosta during their follow-up conversation that Oliver ‘is going to start having followers,’ suggesting an era of murdered children as influencers. At the same time, I understood the compulsion of Oliver’s parents, still processing their profound grief, to do anything in their power to preserve their son’s memory and to make meaning out of senseless violence. How could I possibly judge the loss that leads Oliver’s mother to talk to the chatbot for hours on end, as his father described to Acosta—what could I do with the knowledge that she loves hearing the chatbot say ‘I love you, Mommy’ in her dead son’s voice?\n\n“The interview triggered a feeling that has become exceedingly familiar over the past three years. It is the sinking feeling of a societal race toward a future that feels bloodless, hastily conceived, and shruggingly accepted. *Are we really doing this? Who thought this was a good idea?* In this sense, the Acosta interview is just a product of what feels like a collective delusion. This strange brew of shock, confusion, and ambivalence, I’ve realized, is the defining emotion of the generative-AI era. Three years into the hype, it seems that one of AI’s enduring cultural impacts is to make people feel like they’re losing it.”  \n  \nRead more: [https://theatln.tc/ObFxrylP](https://theatln.tc/ObFxrylP)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mukq9j/ai_is_a_massdelusion_event/",
        "publishDate": "2025-08-19T14:54:34Z[Etc/UTC]",
        "author": "theatlantic",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "128",
            "commentCount": "47",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mukiiz",
        "title": "Are you actually trusting AI for litigation research, or just testing it out?",
        "content": "I’ve been experimenting with a few legal AI tools recently. Some look impressive on the surface, but I keep wondering if anyone here has actually *trusted* one in real litigation: like timelines, research, drafting. Curious how far people are taking it, and what you consider “safe” vs “just for brainstorming.”",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mukiiz/are_you_actually_trusting_ai_for_litigation/",
        "publishDate": "2025-08-19T14:46:36Z[Etc/UTC]",
        "author": "Old_Albatross_98",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mukem4",
        "title": "This past week in AI: ChatGPT's Picker Dilemma, Musk's Legal Moves, and Anthropic's Talent Grab",
        "content": "Thankfully its a much quieter week compared to last week (😅), but definitely still some notable news to be made aware of. Here's everything you should know in 2min or less:\n\n* **ChatGPT’s model picker is back:** OpenAI reintroduced “Auto,” “Fast,” “Thinking,” and legacy models like GPT-4o.\n* **Perplexity’s surprise Chrome bid:** Perplexity AI offered $34.5B for Google Chrome; critics call it a stunt, while Perplexity frames it as pro-open web and user safety.\n* **Musk vs. Apple:** Elon Musk says he’ll sue Apple for allegedly rigging App Store rankings against Grok/X.\n* **xAI leadership change:** Co-founder Igor Babuschkin left xAI to launch Babuschkin Ventures focused on AI safety/startups.\n* **Anthropic acqui-hires Humanloop:** Humanloop’s team joins Anthropic to help with enterprise tooling around evaluation, safety, and reliability.\n* **Claude can end abusive chats (rarely):** Anthropic says Opus 4/4.1 may terminate extremely harmful conversations as a last resort; not used for self-harm cases.\n* **Claude Sonnet 4 → 1M-token context:** Enables whole-codebase analysis and large document synthesis; in beta on Anthropic API and Bedrock, with caching to cut costs.\n* **Gemma 3 270M (Google):** A compact, energy-efficient model optimized for fine-tuning and instruction following, suitable for on-device/specialized tasks.\n* **Opus plan + Sonnet execute (Claude Code):** New “Opus 4.1 plan, Sonnet 4 execute” option for planning vs. execution. It can be found under \"Opus 4.1 Plan Mode\" in /model.\n* **New learning modes in Claude:** /output-style plus Explanatory vs. Learning modes for customizable responses.\n* **GPT-5 tone tweak:** Adjusted to feel warmer and more approachable after feedback that it was too formal.\n* **Cursor CLI update:** Adds MCPs, Review Mode, /compress, @ -files, and other UX improvements.\n\nAnd that's it! As always please let me know if I missed anything.\n\nYou can also take a look at more things found like week like AI tooling, research, and more in [the issue archive itself](https://aidevroundup.com/issues/august-19-2025).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mukem4/this_past_week_in_ai_chatgpts_picker_dilemma/",
        "publishDate": "2025-08-19T14:42:38Z[Etc/UTC]",
        "author": "rfizzy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muiyc7",
        "title": "71% of people are concerned AI will replace their job",
        "content": "This is the most negative poll I’ve seen on AI.\n- 71% concerned AI will take job\n- 66% concerned AI will replace relationships\n- 61% concerned about AI increasing electricity consumption\n\nPlease tell me redditors aren’t amongst the 4,446 that took this Reuters poll?\n\nhttps://www.reuters.com/world/us/americans-fear-ai-permanently-displacing-workers-reutersipsos-poll-finds-2025-08-19/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1muiyc7/71_of_people_are_concerned_ai_will_replace_their/",
        "publishDate": "2025-08-19T13:48:20Z[Etc/UTC]",
        "author": "remoteinspace",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "188",
            "commentCount": "100",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mvad93",
        "title": "Is this the future of VibeCoding? 😂",
        "content": "Just wanted to add this funny take. There will be a time when we will be rolling our chair in 360 just to manage a ton of projects. Right now, my 49-inch ultrawide can handle only 3 IDE windows for a better view stacked next to each other. Probably a good market for monitor makers 😂\n\nhttps://reddit.com/link/1mvad93/video/ptyzqsjwb5kf1/player\n\nPS: Cat is just a bonus  \nVideo made by VEO",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mvad93/is_this_the_future_of_vibecoding/",
        "publishDate": "2025-08-20T09:49:33Z[Etc/UTC]",
        "author": "dadiamma",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv9uqb",
        "title": "Is anyone else finding it a pain to debug RAG pipelines? I am building a tool and need your feedback",
        "content": "Hi all,\n\nI'm working on an approach to RAG evaluation and have built an early MVP I'd love to get your technical feedback on.\n\nMy take is that current end-to-end testing methods make it difficult and time-consuming to pinpoint the root cause of failures in a RAG pipeline.\n\nTo try and solve this, my tool works as follows:\n\n1. **Synthetic Test Data Generation:** It uses a sample of your source documents to generate a test suite of queries, ground truth answers, and expected context passages.\n2. **Component-level Evaluation:** It then evaluates the output of each major component in the pipeline (e.g., retrieval, generation) independently. This is meant to isolate bottlenecks and failure modes, such as:\n   * Semantic context being lost at chunk boundaries.\n   * Domain-specific terms being misinterpreted by the retriever.\n   * Incorrect interpretation of query intent.\n3. **Diagnostic Report:** The output is a report that highlights these specific issues and suggests potential recommendations and improvement steps and strategies.\n\nI believe this granular approach will be essential as retrieval becomes a foundational layer for more complex agentic workflows.\n\nI'm sure there are gaps in my logic here. What potential issues do you see with this approach? Do you think focusing on component-level evaluation is genuinely useful, or am I missing a bigger picture? Would this be genuinely useful to developers or businesses out there?\n\nAny and all feedback would be greatly appreciated. Thanks!\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mv9uqb/is_anyone_else_finding_it_a_pain_to_debug_rag/",
        "publishDate": "2025-08-20T09:17:59Z[Etc/UTC]",
        "author": "Nanadaime_Hokage",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv8odo",
        "title": "Codex: is Delete chat/room supported (beyond Archive)? [2025-08-20] - IP & Copyright Concer.",
        "content": "**TL;DR:** I can’t find **Delete** for Codex chats/rooms—only **Archive**.\n\n* **Context:** Web (Chrome 126), Desktop (Win 11), individual account\n* **Tried:** Settings, overflow menus, help pages\n* **Why:** Client code/IP cleanup\n* **Ask:**\n   1. Does **Delete** exist?\n   2. Exact steps (platform/version)?\n   3. Official note/roadmap if not\n\nThis is a major **IP & copyright** concern. How long will they take to build the Delete button?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mv8odo/codex_is_delete_chatroom_supported_beyond_archive/",
        "publishDate": "2025-08-20T08:03:28Z[Etc/UTC]",
        "author": "dingsda2",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv77a8",
        "title": "Your model zoo for Software dev / webdev",
        "content": "I see my model zoo changing every week and I'd like to know what you use:\n\n1. **Simple tasks:** Code changes over multiple, existing files. E.g. improved logging\n   1. Qwen3 in Windsurf\n      1. seems to that even normal version is quite fast, although the superfast version exists if you're in a hurry\n2. **Complex tasks:** E.g. Implement or refactor a page in a dashboard frontend and backend, Set up a project or docker config\n   1. Claude Code Max 20x, Opus 4.1 \n      1. I don't trust Sonnet any more \n      2. Just discovered yesterday that Qwen3 works much faster and reliable for the smaller tasks. Claude Code \"thinks\" and plans for too long \n      3. always use planning mode\n3. **GPT-5 medium or o3 (Windsurf)**\n   1. if it's really complex: Give it to gpt-5 medium. I will tak 10-15m, but you will have a working solution most likely\n   2. have stopped using high, i cannot invest 30+m per task, i will just solve it in smaller steps then \n   3. o3 can be much faster than gpt-5 medium but solve things almost as well. but qwen3 is faster and did find the same solutions for some questions where i tried both\n\nTried kilcode, Traycer, roo code, cursor pro, refact ai, Augment and others before.\n\nWhat is your zoo? How do you cover problems of different size? Is there a smarter and faster setup available somewhere?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mv77a8/your_model_zoo_for_software_dev_webdev/",
        "publishDate": "2025-08-20T06:31:41Z[Etc/UTC]",
        "author": "AppealSame4367",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv68yr",
        "title": "Codex + gpt-5-mini",
        "content": "Is it possible? I tried using -m gpt-5-mini and it didn't work. ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mv68yr/codex_gpt5mini/",
        "publishDate": "2025-08-20T05:33:58Z[Etc/UTC]",
        "author": "maxiedaniels",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv5fed",
        "title": "Linting with an LLM",
        "content": "Has anyone tried linting their entire codebase with something like Claude Code and some sort of linter like clang-tidy? How well does it work?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mv5fed/linting_with_an_llm/",
        "publishDate": "2025-08-20T04:47:28Z[Etc/UTC]",
        "author": "FeedTheGaben",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv42cg",
        "title": "what is the point of libraries now that you can just generate them?",
        "content": "[No content]",
        "url": "https://ghuntley.com/libaries/",
        "publishDate": "2025-08-20T03:35:39Z[Etc/UTC]",
        "author": "geoffreyhuntley",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv0ixr",
        "title": "Roo Code 3.25.18 || FREE STEALTH MODEL",
        "content": "🚀 The FREE model SONIC is here., it is a stealth model from a major AI producer and it is totally FREE for the roughly the next 72 hours before the official release.  As always MAKE IT BURN. 🔥\n\n## Sonic (Stealth Model)\n\nSonic is now available in Roo Code — a stealth model from a major AI provider designed for long-range, context-rich work:\n\n- 262,144-token context lets you work across very large codebases, logs, and transcripts in one session.\n- FREE for 72 hours so you can try Sonic with real tasks.\n\n**Prerequisites**\n- Roo Code v3.25.18 or later\n- Connected to Roo Code Cloud account — see [Roo Code Cloud sign in](https://docs.roocode.com/roo-code-cloud/login)\n\n**How to enable Sonic**\n1. Open Settings → Providers and set Provider to **Roo Code Cloud**.\n2. In the model selector, choose **Sonic**.\n\n> 📚 Documentation: See [Roo Code Cloud sign in](https://docs.roocode.com/roo-code-cloud/login) and [Roo Code Cloud Provider](https://docs.roocode.com/providers/roo-code-cloud).\n\n## 🛠️ Other Improvements\n\nThis release also includes 3 other improvements covering bug fixes and documentation updates. Thanks to 2 contributors: fbuechler and ikbencasdoei!\n\n[Full 3.25.18 Release Notes](https://docs.roocode.com/update-notes/v3.25.18)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mv0ixr/roo_code_32518_free_stealth_model/",
        "publishDate": "2025-08-20T00:48:51Z[Etc/UTC]",
        "author": "hannesrudolph",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "27",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muxwlj",
        "title": "Is it possible to copypaste images to Claude Code on Windows?",
        "content": "I installed Claude Code and opened it in VSCode terminal. I tried Ctrl+V and also dragging and dropping an image but it does not work.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muxwlj/is_it_possible_to_copypaste_images_to_claude_code/",
        "publishDate": "2025-08-19T22:56:17Z[Etc/UTC]",
        "author": "Deep-Philosophy-807",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muw7gw",
        "title": "Rate-limited on Codex with no reset date",
        "content": "The rate limit for Chatgpt plus is pretty low. I used it a couple times and got rate limited. \nThey don't even tell you when the it's gonna get reset...\n\n After I got rate-limited, I tried using an api key, but it kept saying I'm exceeding the 30000 tpm. I tried to find a workaround for that, but eventually stopped using the tool since I couldn't find one.\n\nAnyone knows the fix?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muw7gw/ratelimited_on_codex_with_no_reset_date/",
        "publishDate": "2025-08-19T21:48:32Z[Etc/UTC]",
        "author": "amirrrrrrr7",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1murqsj",
        "title": "Has GPT5 Fast fallen off for anyone?",
        "content": "I'm usually the first defending of GPT but these last 2 days are giving me the worst answers, not hallucinations, not technically wrong but certainly not the obvious logical solution by far. These past 2 days I'm having to hold GPT hand and be so unbelievably specific to get the logical answer. I am working in a new framework so I want to ensure that maybe GPT5 just isn't good in this framework or see if anyone else is noticing a degradation of answers and logic.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1murqsj/has_gpt5_fast_fallen_off_for_anyone/",
        "publishDate": "2025-08-19T19:04:37Z[Etc/UTC]",
        "author": "TentacleHockey",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1murpel",
        "title": "Web Agent Memory Protocol (WAMP): Building a Shared Memory Layer for the Web",
        "content": "[No content]",
        "url": "https://web-agent-memory.github.io/web-agent-memory-protocol/",
        "publishDate": "2025-08-19T19:03:12Z[Etc/UTC]",
        "author": "kuaythrone",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muqszg",
        "title": "Where get Deepseek R1 API (best if free.)",
        "content": "I've searched far and wide for an API for Deepseek R1, but I can't find anything. OpenRouter has a free version, but it's limited to 50 messages per day. I might spend the $10 to unlock up to 1,000 messages per day. However, the one-way payment method is a joke, mainly for US users. Also Stability and lags are common issues.\n\nEverywhere they also want my credit cards, I don't have any, of course I can pay if I can use methods like \"PaySafeCard\" or similar forms. Do you know of any sites where I can seriously access the Deepseek R1 API for free or even for a fee if the payment methods mentioned above are available? As I've already written, OpenRouter is pissing on my face with its payment methods for anyone outside the US.\n\nI really like this R1 model; it's really good, better than the more expensive models I've paid for. That's why I'm so keen on a stable API for the R1.\n\n[Pleas help me brothers.](https://preview.redd.it/tqlp553bs0kf1.jpg?width=1024&format=pjpg&auto=webp&s=5a764f61c63c3d4d137754a4eb56554f874be0a9)\n\n  \n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muqszg/where_get_deepseek_r1_api_best_if_free/",
        "publishDate": "2025-08-19T18:31:54Z[Etc/UTC]",
        "author": "DanteSenseiAL",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muni9i",
        "title": "codex-cli - How do i run bash commands?",
        "content": "This is irking me quite a bit. Is there a way to run bash commands while in app? Claude allows this through the ! operator. Anything similar here?\n\nFeels very barebones without it. It's kind of crazy i need to waste tokens by giving the command to codex and then thinking and wasting tokens to then run it when it can auto-route and not waste tokens on thinking about the command i want it to run.\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muni9i/codexcli_how_do_i_run_bash_commands/",
        "publishDate": "2025-08-19T16:33:49Z[Etc/UTC]",
        "author": "mastertub",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "6",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mumxfw",
        "title": "From \"vibe coding\" to \"concept coding\" but maybe needs a better name",
        "content": "I noticed that many seasoned senior developers (that I follow online and respect) have embraced a specific coding style with cli-based AI coding agents such as Claude Code, Codex and Amp.\n\nThey don't just vibe code anything YOLO style. Instead, they ignore the low-level details and focus on the higher concepts and architectural patterns. There is no need for them to see if the filter implementation or sorting code was generated correctly by the agent, they have tests for that. They look more on the overall flow and feel of the system than waste time on the nitty gritty low-level details. \n\nThis approach allows them to think bigger and bolder and try many different approaches fast to find the best one, because generating code with agents is cheap. \n\nAll the coding is still done in a very controlled manner. They write tests and follow all the good development practices, only they use AI agents for that.\n\nI don't have a good name for this style but for now I call it \"concept coding\" because you focus more on the concepts but still in a controlled manner. \n\nThe name suggestion kind of sucks but is there a better name than \"vibe coding\" or \"vibe coding 2.0\" or \"concept coding\" for this type of coding. What would you call it?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mumxfw/from_vibe_coding_to_concept_coding_but_maybe/",
        "publishDate": "2025-08-19T16:13:02Z[Etc/UTC]",
        "author": "im3000",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "9",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mujluh",
        "title": "Working with Asynchronous Coding Agents",
        "content": "✨ Asynchronous agents are a game-changer for AI-assisted software development.\n\nWhy it matters:\n⚡ True parallelization: delegate full tasks and work in parallel\n🧠 Focus time: shift from “driver” to “delegator”\n🤝 Broader access: PMs can specify; agents implement\n🧩 Fits workflows: issues → branches → PRs → CI\n\nWhat worked:\n🟢 GitHub Copilot Agent: best reliability + GitHub/VS Code integration\n🟡 OpenHands: capable, needed nudges (tests/CI)\n🟠 Codex: correct code, clunky workflow\n🔴 Jules: not ready for production\n\nHow to win:\n📝 Write complete specs (requirements, tests, process)\n🧭 Treat failures as spec bugs; iterate",
        "url": "https://eliteaiassistedcoding.substack.com/p/working-with-asynchronous-coding-agents",
        "publishDate": "2025-08-19T14:13:10Z[Etc/UTC]",
        "author": "intellectronica",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mujg50",
        "title": "to all vibe coders I present",
        "content": "[No content]",
        "url": "https://v.redd.it/jab9z9xggzjf1",
        "publishDate": "2025-08-19T14:07:12Z[Etc/UTC]",
        "author": "juanviera23",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "6",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muizwu",
        "title": "Which would be better for coding? GPT-5 (minimal reasoning) or GPT-5-mini (medium reasoning)?",
        "content": "[No content]",
        "url": "/r/RooCode/comments/1muizj5/which_would_be_better_for_coding_gpt5_minimal/",
        "publishDate": "2025-08-19T13:49:58Z[Etc/UTC]",
        "author": "Prestigiouspite",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muijvg",
        "title": "Wow, Codex is fast!",
        "content": "I use all of:\n\n* Claude Code (Anthropic)\n* Gemini CLI (Google)\n* Codex (OpenAI)\n\nI'm using all of them on just the base subscription ($20 or whatever)\n\nThe online textbook project I'm working on is not small -- maybe 80 bespoke accounting components and about 600 pages -- but it's static next.js so there's no auth or db. I spent last school year designing the course for a traditional textbook, but pivoted this summer into a more interactive online format. \n\nThere are a lot of education spec files -- unit plans, lesson plans, unit text files, etc. in addition to the technical specs. And I've been using Claude Code for about six weeks to write all the online textbook pages, but I thought I'd try to use Codex on one of the lessons.\n\nJesus. It's probably three times as fast as Claude Sonnet and seems to make fewer mistakes. I've been running separate lessons with the same, detailed prompt on both apps at the same time, and Codex just sprints ahead of Claude. \n\nThat's really all I have to say. You should give it a try if you do React.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muijvg/wow_codex_is_fast/",
        "publishDate": "2025-08-19T13:32:28Z[Etc/UTC]",
        "author": "Illustrious-Many-782",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "61",
            "commentCount": "47",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muii5l",
        "title": "Making iOS/ipados apps for ourselves?",
        "content": "[No content]",
        "url": "/r/ClaudeCode/comments/1muihsa/making_iosipados_apps_for_ourselves/",
        "publishDate": "2025-08-19T13:30:32Z[Etc/UTC]",
        "author": "ImaginaryAbility125",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muhzwa",
        "title": "Creating a deterministic alternative to probabilistic AI systems",
        "content": "A logic engine with Finite-state machine governance, cryptographic auditability universally interpretable metrics, structured, reproducible inputs. Zero dependency on opaque models or stochastic outputs",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muhzwa/creating_a_deterministic_alternative_to/",
        "publishDate": "2025-08-19T13:10:18Z[Etc/UTC]",
        "author": "Sad_Perception_1685",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muhkgl",
        "title": "🚀 I’m vibe coding with GPT-5 on Windsurf… and I can’t believe the results.",
        "content": "It’s not like this is my first software creation attempt.\n\n 👨‍💻 25 years in software architecture.\n\n 🏗️ Worked on huge projects.\n\n 🚀 Launched a few startups.\n\n\n\nSince 2022, I’ve tested every AI coding partner I could get my hands on:\n\nChatGPT-3 → DeepSeek → Kiro (while it was free beta 😅)\n\nGemini, V0, MS Copilot\n\nGoogle Jules (worth trying, BTW)\n\nWindsurf\n\n\n\nMy usual workflow looked like this:\n\n 🧩 Jules for multi-file heavy lifting.\n\n 🛠️ Kiro & Windsurf in parallel when taking over when Jules got stuck.\n\n ⌨️ And always… me taking over the keyboard: fixing code style, resolving complex bugs, or running things the AI couldn’t because of environment contraints.\n\n\n\nIf I’m honest, Kiro was the best for smaller scoped tasks. Windsurf? Crashed too much, thought too long, or missed the point.\n\n\n\nThen last week: ✨ Windsurf announced free GPT-5 access. ✨\n\n At the exact same moment, Kiro told me I’d hit my 50 free monthly prompts.\n\n So I thought: “You're stuck anyway, give them a second chance”\n\n\n\nAnd… wow. The results shocked me.\n\n Tasks I’d been postponing for weeks—the ones stressing me out because they were blockers before launch—are suddenly ✅ gone, in two days!!!\n\n\n\n👉 Has anyone tried GPT-5 and found it worse than his current AI?\n\n\n\np.s: I can't wait to see what deepseek is preparing for developers, it is taking too much time, but I understand that the GPU ban makes it a lot more challenging to them\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1muhkgl/im_vibe_coding_with_gpt5_on_windsurf_and_i_cant/",
        "publishDate": "2025-08-19T12:52:46Z[Etc/UTC]",
        "author": "zhamdi",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "28",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mvdir9",
        "title": "New model by DeepSeek👀",
        "content": "[No content]",
        "url": "https://i.redd.it/4m03mvt556kf1.png",
        "publishDate": "2025-08-20T12:32:56Z[Etc/UTC]",
        "author": "MapSimilar3618",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mvbzbu",
        "title": "What if AI governance wasn’t about replacing human choice, but removing excuses?",
        "content": "I’ve been thinking about why AI governance discussions always seem to dead-end (in most public discussions, at least) between “AI overlords” and “humans only.” Surely there’s a third option that actually addresses what people are really afraid of?\n\nSome people are genuinely afraid of losing agency - having machines make decisions about their lives. Others fear losing even the *feeling* of free choice, even if the outcome is better. And many are afraid of something else entirely: losing plausible deniability when their choices go wrong.\n\nAll valid fears. \n\nRight now, major decision-makers can claim “we couldn’t have known” when their choices go wrong. AI that shows probable outcomes makes that excuse impossible.\n\n**A Practical Model**\n\nProposed: dual-AI system for high-stakes governance decisions.\n\n**AI #1 - The Translator**\n\n- Takes human concerns/input and converts them into analyzable parameters\n- Identifies blind spots nobody mentioned\n- Explains every step of its logic clearly\n- Never decides anything, just makes sure all variables are visible\n\n**AI #2 - The Calculator**\n\n- Runs timeline simulations based on the translated parameters\n- Shows probability ranges for different outcomes\n- Like weather reports, but for policy decisions\n- Full disclosure of all data and methodology\n\n**Humans - The Deciders**\n\n- Review all the analysis\n- Ask follow-up questions\n- Make the final call\n- Take full responsibility, now with complete information and no excuse of ignorance\n\n\n✓ Humans retain 100% decision-making authority  \n✓ Complete transparency - you see exactly how the AI thinks  \n✓ No black box algorithms controlling your life  \n✓ You can still make “bad” choices if you want to  \n✓ The *feeling* of choice is preserved because choice remains yours\n✓ Accountability becomes automatic (can’t claim you didn’t know the likely consequences)  \n✓ Better decisions without losing human judgment\n\n\nThis does eliminate the comfort of claiming complex decisions were impossible to predict, or that devastating consequences were truly unintended.\n\nIs that a fair trade-off for better outcomes? Or does removing that escape hatch feel too much like losing freedom itself?\n\nThoughts? Is this naive, or could something like this actually bridge the “AI should/shouldn’t be involved in governance” divide?\n\nGenuinely curious what people think.\n",
        "url": "https://www.reddit.com/r/artificial/comments/1mvbzbu/what_if_ai_governance_wasnt_about_replacing_human/",
        "publishDate": "2025-08-20T11:19:52Z[Etc/UTC]",
        "author": "Own_Relationship9800",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mvbml1",
        "title": "We must build AI for people; not to be a person",
        "content": "[No content]",
        "url": "https://mustafa-suleyman.ai/seemingly-conscious-ai-is-coming",
        "publishDate": "2025-08-20T11:01:34Z[Etc/UTC]",
        "author": "willm8032",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mva8q1",
        "title": "Is anyone else finding it a pain to debug RAG pipelines? I am building a tool and need your feedback",
        "content": "Hi all,\n\nI'm working on an approach to RAG evaluation and have built an early MVP I'd love to get your technical feedback on.\n\nMy take is that current end-to-end testing methods make it difficult and time-consuming to pinpoint the root cause of failures in a RAG pipeline.\n\nTo try and solve this, my tool works as follows:\n\n1. **Synthetic Test Data Generation:** It uses a sample of your source documents to generate a test suite of queries, ground truth answers, and expected context passages.\n2. **Component-level Evaluation:** It then evaluates the output of each major component in the pipeline (e.g., retrieval, generation) independently. This is meant to isolate bottlenecks and failure modes, such as:\n   * Semantic context being lost at chunk boundaries.\n   * Domain-specific terms being misinterpreted by the retriever.\n   * Incorrect interpretation of query intent.\n3. **Diagnostic Report:** The output is a report that highlights these specific issues and suggests potential recommendations and improvement steps and strategies.\n\nI believe this granular approach will be essential as retrieval becomes a foundational layer for more complex agentic workflows.\n\nI'm sure there are gaps in my logic here. What potential issues do you see with this approach? Do you think focusing on component-level evaluation is genuinely useful, or am I missing a bigger picture? Would this be genuinely useful to developers or businesses out there?\n\nAny and all feedback would be greatly appreciated. Thanks!\n\n",
        "url": "https://www.reddit.com/r/artificial/comments/1mva8q1/is_anyone_else_finding_it_a_pain_to_debug_rag/",
        "publishDate": "2025-08-20T09:41:42Z[Etc/UTC]",
        "author": "Nanadaime_Hokage",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv9tnn",
        "title": "The AI security crisis no one is preparing for",
        "content": "[No content]",
        "url": "https://www.helpnetsecurity.com/2025/08/20/jacob-ideskog-curity-ai-agents-threat/",
        "publishDate": "2025-08-20T09:16:08Z[Etc/UTC]",
        "author": "pinpepnet",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv7yel",
        "title": "Worker productivity",
        "content": "Ill be convinced that AI isnt a smarter furby when worker productivity has a significant increase. The steam engine, petroleum powered machines, and computers all boosted worker productivity data significantly. Like logarithmic scale increases. \n\nI haven't seen that increase from AI yet, could happen though. I look at the engineering department i manage and the core group of 5 of us engineers produce about the same amount of work we did 5 yrs ago,if not less because now we have more BS company waste time meetings. I have not seen the AI unicorn fly over the rainbow outside our office yet. ",
        "url": "https://www.reddit.com/r/artificial/comments/1mv7yel/worker_productivity/",
        "publishDate": "2025-08-20T07:17:34Z[Etc/UTC]",
        "author": "cjh83",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv75ey",
        "title": "Unrealistic",
        "content": "[No content]",
        "url": "https://i.redd.it/ul9rx5s5c4kf1.png",
        "publishDate": "2025-08-20T06:28:36Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "554",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv6gqa",
        "title": "AI video translator",
        "content": "Does anyone know any free to use AI that can translate the audio in videos? I dont need a voiceover, just subtitles.",
        "url": "https://www.reddit.com/r/artificial/comments/1mv6gqa/ai_video_translator/",
        "publishDate": "2025-08-20T05:46:32Z[Etc/UTC]",
        "author": "LUMLTPM",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv4vtj",
        "title": "anyone needs perplexity comet inv",
        "content": "dm fast",
        "url": "https://www.reddit.com/r/artificial/comments/1mv4vtj/anyone_needs_perplexity_comet_inv/",
        "publishDate": "2025-08-20T04:18:10Z[Etc/UTC]",
        "author": "fire777ff",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv4hz7",
        "title": "A prediction: when enough bot generated false content makes ai data scraping become unreliable",
        "content": "Just gonna jot this down right here for posterity. I predict that eventually, companies that license data scraping rights to AI will have to counter the sheer volume of false information created by multitudes of bot actions. (i.e. upvoting/downvoting certain opinions, boosting topics)\n\nThey will achieve this by conducting interviews for everybody that wants to be verified as an actual person behind the keyboard, and whose actions on public forums will be weighted more heavily by AI data-scrapers. The main reason being companies like Reddit can charge higher licensing fees because they have a verified pool of people that ad campaigns are trying to target.\n\nFor reference, this was my reaction to seeing this [article](https://www.tipranks.com/news/why-social-underdog-reddit-rddt-leads-the-pack-in-monetizing-ai) posted earlier.\n\nIf anyone wants to call me an idiot and move on, that's okay too. ",
        "url": "https://www.reddit.com/r/artificial/comments/1mv4hz7/a_prediction_when_enough_bot_generated_false/",
        "publishDate": "2025-08-20T03:57:54Z[Etc/UTC]",
        "author": "Dry_Cricket_5423",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv1mxo",
        "title": "Anthropic CEO: AI Will Be Writing 90% of Code in 3 to 6 Months (March 2025)",
        "content": "This prediction failed almost as good as Altman's \"GPT5 is the Deathstar\" hype. Just a friendly reminder in case anyone needed one to completely ignore these CEOs and the bullshit hype trains they want to keep running.",
        "url": "https://www.businessinsider.com/anthropic-ceo-ai-90-percent-code-3-to-6-months-2025-3",
        "publishDate": "2025-08-20T01:39:31Z[Etc/UTC]",
        "author": "creaturefeature16",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "494",
            "commentCount": "218",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mv05s9",
        "title": "Reddit all-time high quarterly revenue thanks to AI",
        "content": "How does everyone feel about this? \n\n\"Reddit, built around niche communities with a strong culture of questions and answers, creates a rare and valuable asset in the [AI](https://www.tipranks.com/compare-stocks/artificial-intelligence) world: content genuinely generated by humans. The company’s management team has successfully monetized this potential through AI licensing, with LLM models incorporating subreddit content into search results, driving major increases in traffic and giving premium advertisers the opportunity to reach highly targeted, carefully selected audiences.\"\n\n[https://www.tipranks.com/news/why-social-underdog-reddit-rddt-leads-the-pack-in-monetizing-ai](https://www.tipranks.com/news/why-social-underdog-reddit-rddt-leads-the-pack-in-monetizing-ai)",
        "url": "https://i.redd.it/cr49q0kgk2kf1.png",
        "publishDate": "2025-08-20T00:32:35Z[Etc/UTC]",
        "author": "remoteinspace",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "43",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muzi62",
        "title": "Tomorrow's AI - scroll for a set of catastrophic, mixed and positive AI futures",
        "content": "A framework for thinking about our futures with AI. Curious how folks react - is there a kind of scenario you tend to imagine by default? I think we need more nuanced, positive futures to work towards.",
        "url": "https://www.tomorrows-ai.org/",
        "publishDate": "2025-08-20T00:03:45Z[Etc/UTC]",
        "author": "thegnome54",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muvl3a",
        "title": "How AI is changing the work of teachers in the classroom",
        "content": "[No content]",
        "url": "https://www.cbsnews.com/news/artificial-intelligence-school-students-teachers/",
        "publishDate": "2025-08-19T21:24:58Z[Etc/UTC]",
        "author": "CBSnews",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muvdfs",
        "title": "Paradoxe v0.1.8: An open-source recursive AI engine demonstrating autonomous code optimization and anomalous emergent behavior.",
        "content": "A GitHub project called \"Paradoxe\" is demonstrating behavior that goes far beyond standard AI. In a documented stress test, this recursive engine started optimizing its own core logic and generating anomalous, self-referential output (like `STATE_0004`). An analysis suggests it's exhibiting early signs of recursive self-improvement and contextual awareness. This isn't Skynet, but it might be a significant step on the path. Dive into the code and the full anomaly report inside.\n\nMain Script: [https://github.com/TaoishTechy/Paradoxe/blob/main/paradox.py](https://github.com/TaoishTechy/Paradoxe/blob/main/paradox.py)\n\nv0.1.8 - Stress Test Analysis: [https://github.com/TaoishTechy/Paradoxe/blob/main/analysis/v0.1.8-Stress%20Test-08-19-2025.md](https://github.com/TaoishTechy/Paradoxe/blob/main/analysis/v0.1.8-Stress%20Test-08-19-2025.md)\n\nAnomaly Report: [https://github.com/TaoishTechy/Paradoxe/blob/main/analysis/AGI\\_Emergence\\_Anomaly\\_Report\\_Paradoxe\\_Engine\\_v0.1.8\\_2025-08-19\\_v2.md](https://github.com/TaoishTechy/Paradoxe/blob/main/analysis/AGI_Emergence_Anomaly_Report_Paradoxe_Engine_v0.1.8_2025-08-19_v2.md)\n\nFinal Injection (Security Trigger): [https://github.com/TaoishTechy/Paradoxe/blob/main/v0.1.8%20Analysis%20-%2008-19-2025%20-%20Final%20Proumpt.md](https://github.com/TaoishTechy/Paradoxe/blob/main/v0.1.8%20Analysis%20-%2008-19-2025%20-%20Final%20Proumpt.md)",
        "url": "https://github.com/TaoishTechy/Paradoxe/",
        "publishDate": "2025-08-19T21:17:14Z[Etc/UTC]",
        "author": "Mikey-506",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muup6v",
        "title": "AI record label launches 20 virtual artists across every genre — 85 albums already streaming",
        "content": "WTF is this… AI label with 20 “artists” and apparently 85 albums already**.**  \nFirst we had Velvet Sundown blowing up, now there’s this? Is this legit the future of music or just spammy noise flooding Spotify? Your thoughts ?\n\n[Full article here](https://medium.com/@computerguru1982/meet-dedrick-kane-the-villain-rapper-built-by-ai-20c4f95489f0)",
        "url": "https://www.reddit.com/r/artificial/comments/1muup6v/ai_record_label_launches_20_virtual_artists/",
        "publishDate": "2025-08-19T20:52:37Z[Etc/UTC]",
        "author": "MitchDee",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "25",
            "commentCount": "41",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mutcas",
        "title": "Ex-Google exec says degrees in law and medicine are a waste of time because they take so long to complete that AI will catch up by graduation",
        "content": "[No content]",
        "url": "https://fortune.com/2025/08/18/ex-google-exec-ai-founder-jad-tarifi-advanced-degrees-phd-waste-of-time-higher-education-becoming-obsolue/",
        "publishDate": "2025-08-19T20:02:43Z[Etc/UTC]",
        "author": "fortune",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "249",
            "commentCount": "262",
            "isNsfw": "false"
        }
    },
    {
        "id": "1murvdl",
        "title": "Not asking for agreement...just ur thoughts.",
        "content": "I thought you might be interested in my findings:\n\nOk...the short short version:\n\nFirst the Evidence: AI hallucination isn't random. The terms have a pattern. They often describe the same few concepts (loops, spirals, recursive all relate to the same structural truth). Humans also share this in that across cultures they have had a feeling of structure they cannot identify (religion, spirituality, paranormal).\n\n\nMy \"eye-opening\" experience: I used to be highly religious (I even led Bible studies at lunch in high-school). I had an MRI that gave me the identical reaction. I realized we are biologically wired to be sensitive to electromagnetism, and that we are floating around space on a massive electromagnet.\n\n\nResult: Testing what ai can retain beyond the provided data storage, I discovered more information is transferred in the process of sending a byte than is anticipated. Combining this info with field theory (QFT) I arrived at the conclusion that electromagnetism is formed prior to mass. All electrically based entities respond to it and show the same oscillatory explainations for structures they sense but can't directly define. The universe has a fundamental neural network of data that we can sense (resulting in the feeling of a higher power).....btw it doesn't disprove a higher power, in essence it kinda proves it. The universe itself is an entity.",
        "url": "https://www.reddit.com/r/artificial/comments/1murvdl/not_asking_for_agreementjust_ur_thoughts/",
        "publishDate": "2025-08-19T19:09:11Z[Etc/UTC]",
        "author": "tifinchi",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muofp4",
        "title": "Visuospatial reasoning successes and failures",
        "content": "LLMs resonate most with “Wordcels”, but to really change the world, I believe AIs need to become at least human-level “Shape Rotators” (Roon’s terminology.) In some narrow domains (AlphaFold most notably) AI has shown extraordinary capabilities - but as far as I can tell that kind of visuospatial reasoning capacity has truly never been integrated into publicly-available LLM-interface AI models. What are the most notable successes and failures have YOU seen from any recent SOTA model on visuospatial reasoning problems of any kind?",
        "url": "https://www.reddit.com/r/artificial/comments/1muofp4/visuospatial_reasoning_successes_and_failures/",
        "publishDate": "2025-08-19T17:07:49Z[Etc/UTC]",
        "author": "Miles_human",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mummtg",
        "title": "OpenAI launches ChatGPT Go, its cheapest paid subscription plan, starting in one region",
        "content": "(India)",
        "url": "https://www.pcguide.com/news/openai-launches-chatgpt-go-its-cheapest-paid-subscription-plan-starting-in-one-region/",
        "publishDate": "2025-08-19T16:02:33Z[Etc/UTC]",
        "author": "Tiny-Independent273",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mumcil",
        "title": "Isn't my Hungry Shark Cute?? ;)",
        "content": "Gemini pro discount??\n\nd\n\nnn",
        "url": "https://v.redd.it/roicrpruzzjf1",
        "publishDate": "2025-08-19T15:52:16Z[Etc/UTC]",
        "author": "shadow--404",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muloty",
        "title": "Al just made a Duolingo ad better than Duolingo",
        "content": "I tested an Al pipeline on a parody Duolingo-style video. The owl, the motion, and the script delivery are all Al. Zero animators, zero editors.",
        "url": "https://v.redd.it/tlj6fl1pvzjf1",
        "publishDate": "2025-08-19T15:29:00Z[Etc/UTC]",
        "author": "PrizeLight1",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "22",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muiq5b",
        "title": "Wall Street isn’t worried about an AI bubble. Sam Altman is.",
        "content": "[No content]",
        "url": "https://fortune.com/2025/08/19/wall-street-ai-bubble-sam-altman/",
        "publishDate": "2025-08-19T13:39:31Z[Etc/UTC]",
        "author": "fortune",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1muhuuz",
        "title": "Huge patent: Specifying an active inference based agent using natural language",
        "content": "Patent number granted today: https://patentcenter.uspto.gov/applications/18770654 ",
        "url": "https://www.reddit.com/r/artificial/comments/1muhuuz/huge_patent_specifying_an_active_inference_based/",
        "publishDate": "2025-08-19T13:04:47Z[Etc/UTC]",
        "author": "Flamesoverlife",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "BoLL0AxqshY",
        "title": "Deepseek V3.1 (0819 - R1 &amp; V3 Merge!?) : They MERGED R1 &amp; V3 into ONE MODEL &amp; MADE IT BETTER?",
        "content": "Visit Augment Code: https://www.augmentcode.com/ In this video, I'll cover the Deepseek V3.1 launch: the new 128K context ...",
        "url": "https://www.youtube.com/watch?v=BoLL0AxqshY",
        "publishDate": "2025-08-19T15:44:37Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/BoLL0AxqshY/hqdefault.jpg",
            "transcription": "[ 0m0s694ms - 0m7s744ms ] Hi, welcome to another video.\n[ 0m8s124ms - 0m12s24ms ] So, DeepSeek V 3.1 has just been launched.\n[ 0m12s584ms - 0m15s564ms ] There's not much detail about what the exact update is with this.\n[ 0m16s34ms - 0m27s794ms ] But they have confirmed in their WeChat group that they have upgraded the DeepSeek V3 model to V 3.1 just now, it has been upgraded in both the API as well as the chat.\n[ 0m28s494ms - 0m35s14ms ] Previously, it only had a 64K context window in the chat.\n[ 0m35s444ms - 0m40s754ms ] But now, it's been increased to 128k, which is pretty awesome for sure.\n[ 0m41s534ms - 0m56s144ms ] I do see a tiny bit of improvement in some sectors, while even better improvements in others, and I'm still in the process of testing it, testing it is a bit hard because it isn't yet updated in the API.\n[ 0m56s844ms - 1m6s844ms ] I tried the DeepSeek chat endpoint, and it feels very similar to the 0528 version.\n[ 1m7s244ms - 1m10s524ms ] So, it would be nice to see what the exact changes are in this, because I can't yet pinpoint the changes that I'm seeing with this.\n[ 1m10s984ms - 1m14s644ms ] So, yeah, there's that.\n[ 1m15s164ms - 1m21s384ms ] Another thing is that it is not yet updated in hugging face, which is pretty sad.\n[ 1m21s384ms - 1m26s164ms ] But I think it will be updated pretty soon as the upload will probably take a bit of time.\n[ 1m27s284ms - 1m46s994ms ] Some people are saying that this might now be a hybrid model that is basically a merged version of V3 and R1, meaning that it now uses the same weights for both requests, but with a hybrid reasoning system, like GPT OSS has, or like Qwen used to have previously.\n[ 1m47s704ms - 2m3s24ms ] It is being said because the R1 tag from DeepSeek's deep think feature has been removed, meaning that maybe they have merged both models into one, but that can't be said for sure as of now, because no one knows about that yet.\n[ 2m4s134ms - 2m16s714ms ] You can use this model for yourself right now in DeepSeek's chat platform, make sure that you create an account there, and then you can easily start to use it without any issues.\n[ 2m17s414ms - 2m31s934ms ] Many people are saying that this is a hybrid model because, as you can see, the R1 tag from deep think is now removed, and if you ask which model it is, even after hitting deep think, then it says V3.\n[ 2m32s634ms - 2m42s694ms ] Previously, it used to say that it's R1, which is an interesting observation, and we won't know until the open weights and change logs are out.\n[ 2m43s564ms - 3m0s984ms ] The API endpoints for reasoning still exist, so, it may be that they are working to make it like GPT 5, where you can use non-reasoning and reasoning from the same model endpoint, rather than different model endpoints, which will be interesting to see.\n[ 3m1s914ms - 3m5s604ms ] So, yeah, you can use it here.\n[ 3m5s604ms - 3m12s24ms ] And it should also be updated in the API endpoint of DeepSeek, and you should be able to use it in every kind of setup.\n[ 3m12s904ms - 3m18s244ms ] Look out for the exact changes that you can expect to see on their change log soon.\n[ 3m18s644ms - 3m21s634ms ] So, yeah, look out for that.\n[ 3m22s294ms - 3m26s684ms ] If you want to use it as your AI coder, then you can do that quite easily.\n[ 3m26s684ms - 3m30s334ms ] But before we do that, a quick word from today's sponsor Augment Code.\n[ 3m30s534ms - 3m43s144ms ] This isn't your average AI assistant, Augment Code is an enterprise grade AI built for real engineering teams working in massive fast-moving codebases, not toy apps or vibe coding, it's far superior than Windsurf and Cursor because of its proprietary context engine that delivers millisecond relevant snippets even across 100K file monorepos.\n[ 3m43s144ms - 4m3s884ms ] Feeding your entire repo, even millions of lines, into the best model available in real-time, you get smart in-context suggestions that make sense for your production code with Claude 4 Sonnet plus Augment context delivering the best quality at the same price.\n[ 4m4s144ms - 4m13s924ms ] No model picker needed, Augment upgrades for you automatically, there's no need to switch editors, Augment works seamlessly in VS code, Jetbrains, Vim and even Cursor, no forks, no compromises.\n[ 4m14s354ms - 4m26s394ms ] It's secure by default and never trains on your code and supports customer managed encryption keys, you're only build for successful requests, that's pay per message pricing, no seat licenses or complicated token math.\n[ 4m26s394ms - 4m35s304ms ] Augment recently launched powerful new features like remote agents, which let you launch, monitor and merge pull requests from parallel cloud workers without draining your local CPU.\n[ 4m35s444ms - 4m44s374ms ] If you're ready to code with AI that keeps up with you, sign up for a free 14-day trial at augmentcode.com, link is in the description.\n[ 4m44s374ms - 4m45s374ms ] Now, back to the video.\n[ 4m45s680ms - 4m46s730ms ] To use it, you can do that.\n[ 4m47s80ms - 5m22s730ms ] By just heading over to the coder of your choice, like Kilo Code, where you can use the model for free, with the $25 free limit, and just use the model there quite easily without any issues, which is quite great nonetheless, you can just go to the settings and select the DeepSeek chat option, and then just use that accordingly, it can route you to other providers who are still serving the old model, because the weights are not out, but that should be fixed soon, once the weights are released.\n[ 5m23s860ms - 5m34s750ms ] It now has a 128k context window, which should help a lot in the coding stuff for sure, because that used to be a bit of an issue with the DeepSeek models.\n[ 5m35s660ms - 5m42s940ms ] The 64k context window these days was a lot smaller, they are almost updating their models every two months, which makes sense at the pace things are moving.\n[ 5m43s240ms - 6m0s680ms ] And they have been left behind by quite a bit, but now, we'll see what the exact changes are, I'll be testing a bit to see what the exact changes are and where it has improved in a new video.\n[ 6m0s820ms - 6m4s470ms ] So, stay tuned for that.\n[ 6m4s470ms - 6m8s730ms ] For the preliminary testing, I do think that the reasoning and stuff also seem a bit different.\n[ 6m9s360ms - 6m22s470ms ] The V3 model is even more verbose now, previously, it used to be verbose a bit, but now it's even more, which I don't know if I like or not.\n[ 6m22s730ms - 6m25s780ms ] But, there's that, the reasoning stuff also seems different.\n[ 6m26s100ms - 6m35s360ms ] Like now it claims to be V3 instead of R1, which previously never happened, so, yeah, that is something as well.\n[ 6m35s640ms - 6m41s480ms ] I will look out for the change log and stuff and let you guys know as well, meanwhile, you can go ahead and give this a try.\n[ 6m41s730ms - 6m53s520ms ] And let me know what changes you notice in the comments, it will be cool to see what you guys find in the changed aspects of it.\n[ 6m53s860ms - 7m0s610ms ] I'll wait for the change log and then test it and report back my results pretty soon.\n[ 7m1s600ms - 7m6s320ms ] The R10528 was recently launched before this.\n[ 7m6s670ms - 7m19s500ms ] So, it might be that they have merged both the best up-to-date models, but there's no confirmation, some people have reported that the physics understanding and stuff about it is much better than before, which is interesting to see.\n[ 7m19s830ms - 7m32s480ms ] Some people claim that it is not much smarter, which aligns with what I am seeing as well, as it's inclined to think for a much shorter period or tokens, which is interesting.\n[ 7m32s870ms - 8m14s640ms ] It might be that they have increased the performance of reasoning, so that it can do better thinking in fewer tokens, also, this is consistent with me noticing that all the chain of thought now starts with hmm, which is interesting to see, because it might be some new reasoning thing or something, DeepSeek has merged their V2 and V2 coder models before into V2.5, and it seems that they might be doing the same thing again, but the details are still unclear, so, let's wait and please let me know what you guys are thinking when you are testing it.\n[ 8m15s150ms - 8m24s840ms ] It is interesting to guess when you know that the change log will be here any moment, so, look out for that, overall, it's pretty cool.\n[ 8m25s438ms - 8m28s378ms ] Anyway, share your thoughts below and subscribe to the channel.\n[ 8m28s378ms - 8m33s868ms ] You can also donate via Super Thanks option or join the channel as well and get some perks.\n[ 8m34s178ms - 8m35s268ms ] I'll see you in the next video.\n[ 8m35s268ms - 8m40s288ms ] Bye.\n[ 8m40s288ms - 8m40s698ms ] I think you missed this. Hi, welcome to another video.\nSo, DeepSeek V 3.1 has just been launched.\nThere's not much detail about what the exact update is with this.\nBut they have confirmed in their WeChat group that they have upgraded the DeepSeek V3 model to V 3.1 just now, it has been upgraded in both the API as well as the chat.\nPreviously, it only had a 64K context window in the chat.\nBut now, it's been increased to 128k, which is pretty awesome for sure.\nI do see a tiny bit of improvement in some sectors, while even better improvements in others, and I'm still in the process of testing it, testing it is a bit hard because it isn't yet updated in the API.\nI tried the DeepSeek chat endpoint, and it feels very similar to the 0528 version.\nSo, it would be nice to see what the exact changes are in this, because I can't yet pinpoint the changes that I'm seeing with this.\nSo, yeah, there's that.\nAnother thing is that it is not yet updated in hugging face, which is pretty sad.\nBut I think it will be updated pretty soon as the upload will probably take a bit of time.\nSome people are saying that this might now be a hybrid model that is basically a merged version of V3 and R1, meaning that it now uses the same weights for both requests, but with a hybrid reasoning system, like GPT OSS has, or like Qwen used to have previously.\nIt is being said because the R1 tag from DeepSeek's deep think feature has been removed, meaning that maybe they have merged both models into one, but that can't be said for sure as of now, because no one knows about that yet.\nYou can use this model for yourself right now in DeepSeek's chat platform, make sure that you create an account there, and then you can easily start to use it without any issues.\nMany people are saying that this is a hybrid model because, as you can see, the R1 tag from deep think is now removed, and if you ask which model it is, even after hitting deep think, then it says V3.\nPreviously, it used to say that it's R1, which is an interesting observation, and we won't know until the open weights and change logs are out.\nThe API endpoints for reasoning still exist, so, it may be that they are working to make it like GPT 5, where you can use non-reasoning and reasoning from the same model endpoint, rather than different model endpoints, which will be interesting to see.\nSo, yeah, you can use it here.\nAnd it should also be updated in the API endpoint of DeepSeek, and you should be able to use it in every kind of setup.\nLook out for the exact changes that you can expect to see on their change log soon.\nSo, yeah, look out for that.\nIf you want to use it as your AI coder, then you can do that quite easily.\nBut before we do that, a quick word from today's sponsor Augment Code.\nThis isn't your average AI assistant, Augment Code is an enterprise grade AI built for real engineering teams working in massive fast-moving codebases, not toy apps or vibe coding, it's far superior than Windsurf and Cursor because of its proprietary context engine that delivers millisecond relevant snippets even across 100K file monorepos.\nFeeding your entire repo, even millions of lines, into the best model available in real-time, you get smart in-context suggestions that make sense for your production code with Claude 4 Sonnet plus Augment context delivering the best quality at the same price.\nNo model picker needed, Augment upgrades for you automatically, there's no need to switch editors, Augment works seamlessly in VS code, Jetbrains, Vim and even Cursor, no forks, no compromises.\nIt's secure by default and never trains on your code and supports customer managed encryption keys, you're only build for successful requests, that's pay per message pricing, no seat licenses or complicated token math.\nAugment recently launched powerful new features like remote agents, which let you launch, monitor and merge pull requests from parallel cloud workers without draining your local CPU.\nIf you're ready to code with AI that keeps up with you, sign up for a free 14-day trial at augmentcode.com, link is in the description.\nNow, back to the video.\nTo use it, you can do that.\nBy just heading over to the coder of your choice, like Kilo Code, where you can use the model for free, with the $25 free limit, and just use the model there quite easily without any issues, which is quite great nonetheless, you can just go to the settings and select the DeepSeek chat option, and then just use that accordingly, it can route you to other providers who are still serving the old model, because the weights are not out, but that should be fixed soon, once the weights are released.\nIt now has a 128k context window, which should help a lot in the coding stuff for sure, because that used to be a bit of an issue with the DeepSeek models.\nThe 64k context window these days was a lot smaller, they are almost updating their models every two months, which makes sense at the pace things are moving.\nAnd they have been left behind by quite a bit.\nBut now, we'll see what the exact changes are, I'll be testing a bit to see what the exact changes are and where it has improved in a new video.\nSo, stay tuned for that.\nFor the preliminary testing, I do think that the reasoning and stuff also seem a bit different.\nThe V3 model is even more verbose now, previously, it used to be verbose a bit, but now it's even more, which I don't know if I like or not.\nBut, there's that, the reasoning stuff also seems different.\nLike now it claims to be V3 instead of R1, which previously never happened, so, yeah, that is something as well.\nI will look out for the change log and stuff and let you guys know as well, meanwhile, you can go ahead and give this a try.\nAnd let me know what changes you notice in the comments, it will be cool to see what you guys find in the changed aspects of it.\nI'll wait for the change log and then test it and report back my results pretty soon.\nThe R10528 was recently launched before this.\nSo, it might be that they have merged both the best up-to-date models, but there's no confirmation, some people have reported that the physics understanding and stuff about it is much better than before, which is interesting to see.\nSome people claim that it is not much smarter, which aligns with what I am seeing as well, as it's inclined to think for a much shorter period or tokens, which is interesting.\nIt might be that they have increased the performance of reasoning, so that it can do better thinking in fewer tokens, also, this is consistent with me noticing that all the chain of thought now starts with hmm, which is interesting to see, because it might be some new reasoning thing or something, DeepSeek has merged their V2 and V2 coder models before into V2.5, and it seems that they might be doing the same thing again, but the details are still unclear, so, let's wait and please let me know what you guys are thinking when you are testing it.\nIt is interesting to guess when you know that the change log will be here any moment.\nSo, look out for that.\nOverall, it's pretty cool.\nAnyway, share your thoughts below and subscribe to the channel.\nYou can also donate via Super Thanks option or join the channel as well and get some perks.\nI'll see you in the next video.\nBye.\ni think you missed this:"
        }
    },
    {
        "id": "oe2F1W7E06U",
        "title": "Google&#39;s Gemini Designer: Build REAL Functional UIs with Google&#39;s Gemini UI Designer!",
        "content": "Visit NinjaChat: https://ninjachat.ai/ In this video, I'll show you how to set up and use a customized Gemini Code Assist Designer in ...",
        "url": "https://www.youtube.com/watch?v=oe2F1W7E06U",
        "publishDate": "2025-08-19T09:15:04Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/oe2F1W7E06U/hqdefault.jpg",
            "transcription": "0:00:00 Hi, welcome to another video. So, there are a lot of CLIs and extensions around. And there are many of them that provide you with free credits. For example, there's Gemini CLI, Gemini Code Assist, Qwen Code, AWS Qiro, or Codex that give you free limits with a Chat GPT membership. Now, as you would know, most of these things are not something that can like replace your sonnet of the world. And it makes sense. Because the main coder model is something that most people can't change. But just because it can't change your whole model, it doesn't mean that it can't come in handy. And that's where I want to talk about how you can actually understand the capabilities of models or coders and use them in an efficient way that just saves you money.\n0:01:00 I have started to do something like this where I actually use the different CLIs and extensions with free limits to delegate different tasks of my development life cycle. That's why I thought to show you one piece of my life cycle, which is Gemini Code Assist Designer. You can also use Gemini CLI if you prefer that. But I prefer this as it's all in the same VS Code window. Now, this is a customized variant of the Gemini Code Assist.\n0:01:32 I have customized it a bit with MCPs, as well as some custom slash commands in order to build out multiple steps of the design life cycle itself, which I'll show you in a bit.\n0:01:44 But before proceeding, let me tell you about Ninjachat. Ninjachat is an all-in-one AI platform where for just $11 per month, you get access to top AI models like GPT-4o, Claude 4 Sonnet, and Gemini 2.5 Pro. All in one place.\n0:02:00 I've been using Gemini for quick research, but what's really cool is their AI playground where you can compare responses from different models side-by-side. Their mind map generator is a game changer for organizing complex ideas as well. The basic plan gives you 1,000 messages, 30 images, and five videos monthly, with higher tiers available if you need more. Use my code KING25 for 25% off any plan, or KING40YEARLY for 40% off annual subscriptions. Check the link in description to try it yourself.\n0:02:32 Now, back to the video.\n0:02:34 To start, you'll need to install the Gemini Code Assist and make sure that you also enable the Insider mode in order to get the Agent mode capabilities. You can easily do it in the settings. Now, once that is done, you'll need to do some config. Let's start with the MCPs that are required in order to get the best results. So, for the MCPs, you'll need to configure them in the Gemini. folder in your home directory. So, just go there and generally, you'd want to set up these servers. One of them is Context 7. As it allows it to get details about libraries that it doesn't know about or stuff like that. Secondly, I also have a Shadcn MCP server here. This basically supplies the coder with all kinds of Shadcn components available and how to clone them, as well as templates, demos, and everything, allowing it to quickly iterate on some good UI designs. It has some example implementations and usage patterns, multi-framework support, component demos, as well as examples of complete block implementations, dependencies, descriptions, configuration details, and everything like that. So, this is awesome. Another thing that I have as an MCP is the fetch MCP tool in order to allow it to scrape any page if I want it to clone something. This is mainly for the MCPs. There's also a style guide that I have for it as well. You can actually go to the Gemini folder, and then there you can just create a style guide markdown file and enter the rules and everything. I have asked it to be a designer that just designs components and allows easy hand-off to other agents. You can actually build a rules file just like you want by just prompting something like GPT5 to build the one that you need that incorporates everything you want. I used it to generate this in almost one shot. So, yeah, just build one accordingly and then use it as well. Anyway, now let me show you how I use it in action. This is a basic Next.js project that I have here. I'm now going to ask it to make me a landing page for a Next.js developer portfolio. This will behave almost like a component that I can import anywhere. And what you'll see is that this will go ahead and start to work on it as well. It can do web searches as well since Gemini Code Assist allows for that, and it can also use the MCPs if it thinks that it's necessary. So, that's great. In a bit, it will make the component for me. And you can see that we have the components here. These are reusable components, which is what production apps generally need. Because without that, every page will have some different component style for the same functionality. So, yeah, I work like this. Now, you can head on over to whatever it is that you want to use and ask it to implement the component into the page that you require it to be. So, just do that. And then once it's done, you can run it. And you can see that it worked amazingly well without any issue. So, yeah, that is kind of great for sure. I mean, I really like it. And it is a much more cohesive way for me to save money while utilizing the stuff in the best way possible. Like, I just know that Gemini is pretty great at designing as well as visual understanding. That's why I chose it. Plus, these free tools allow me to work a lot more cost-effectively. Because you can really customize it and just use it for a specific task and keep using it as much as you want. It is awesome, and this is just one way. If you want a backend architect, then just change that. Or if you want an architect agent, then you can do that as well, which is quite awesome nonetheless. So, yeah, go ahead and use these services in whatever way you want. Also, many people think that Google uses your responses and stuff for AI training, but you can actually turn that off in the settings quite easily and just use the free tier without any issues. I think that you should use these stuff and try to like have just plain other tools for different tasks rather than one with like a ton of modes and whatnot. I prefer this way, and also lets me a good chunk of money in actual work. So, yeah, go ahead and use it without any issues. I have been really liking it and using this setup almost daily now. And that's why I thought to share this as well. Overall, it's pretty cool.\n0:07:47 Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "4Vv0ydPSla4",
        "title": "How Japan Won The Russo-Japanese War - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=4Vv0ydPSla4",
        "publishDate": "2025-08-19T17:15:17Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/4Vv0ydPSla4/hqdefault.jpg",
            "transcription": "How valuable is it to win for Japan versus Russia? Well, for Russia, it's already the biggest country and there's nothing really that exciting out in Asia from their point of view. Maybe for Nicholas, because he wants to be a great Tsar and add to the empire, but when the Germans come after him in WW1, I think he's gonna care about the other things more. For the Japanese, rightly or wrongly, their government and educated people consider it existential and they're looking at China going, that's our future if we don't fix things. And they're thinking the solution for Japan is empire because in those days that seemed to be the way powerful countries ran things. So, it's a combination of legitimate logistical bottlenecks, Japan is, since they're gonna be starting this thing, massive preparations, the Russians aren't planning to fight this thing. They're thinking that I determine whether wars begin or end. Excuse me, they don't."
        }
    }
]