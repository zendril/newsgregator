[
    {
        "id": "1ps4dit",
        "title": "RARO, reasoning without rewards, and a deeper question about thought",
        "content": "Instead of verifying correctness, RARO trains a generator against a relativistic critic whose only job is to distinguish expert human reasoning traces from model-generated ones. The model improves by becoming indistinguishable from expert reasoning, not by maximizing an explicit notion of ‚Äútruth‚Äù.  \n  \nWhat's interesting is not just the performance gains in open-ended domains (like creative writing or long-form reasoning), but what this implicitly reveals.\n\nThe architecture hasn't changed.  \nThe tensors haven't changed.  \nOnly the training game has.  \n  \nYet we suddenly observe: planning, backtracking, self-correction, and long-horizon reasoning emerging in domains where no formal verifier exists.  \n  \nThis raises a provocative question: if a generic, self-referential sequence model trained at scale can develop expert-level reasoning purely through exposure to other reasoning processes, does this suggest that reasoning itself follows a domain-agnostic mathematical structure?  \n  \nIn other words, RARO seems consistent with the hypothesis that: reasoning is not symbolic logic baked into the architecture, but an emergent property of sufficiently large self-predictive systems trained under the right constraints.  \n  \nIf so, biological brains and LLMs may not share implementation, but may share the same underlying \"computational\" process, expressed in different substrates.  \n  \nThis doesn't prove that LLMs \"think like humans\". But it does suggest that there may exist a universal mathematics of thought, where human reasoning is just one instantiation.  \n  \nCurious to hear thoughts, especially from people skeptical of emergence-based explanations.\n\n\\--\n\n*And there's one more thing RARO might quietly enable: making LLMs genuinely* ***more creative****. Something worth thinking about...*\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps4dit/raro_reasoning_without_rewards_and_a_deeper/",
        "publishDate": "2025-12-21T11:23:48Z[Etc/UTC]",
        "author": "ibanborras",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ps462i",
        "title": "I Grew Fresh IG Account From 0-50k Followers In 4 Days (And I documented all of it)",
        "content": "Last week, inside our community i set up a challenge to create and grow AI influencer from 0-10k followers by end of year.\n\nWell...\n\n... the first video went viral.  \n  \nThe account is now at 90 Million views in 5 days, and account sitting at 55k followers.\n\nI documented my whole process, how I did it and how you can just copy my system.\n\n100% AI-generated person and content. \n\nama ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps462i/i_grew_fresh_ig_account_from_050k_followers_in_4/",
        "publishDate": "2025-12-21T11:10:15Z[Etc/UTC]",
        "author": "max-blueprint",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ps3xk0",
        "title": "AI Video Workflow",
        "content": "Hi guys,\n\nComing from a photography background I am starting to explore AI video generation. To date, I have been using Pixel Dojo to create LoRA‚Äôs and then with that LoRA to create a base image which I then create a video using WAN 2.6. \n\nThe process has been a bit hit and miss, especially when trying to nail the start image and also the subsequent video. As a result, I can see the costs spiralling trying to produce finished video. I‚Äôm also sure that pixel dojo probably isn‚Äôt the most cost effective solution. \n\nI‚Äôm considering downloading open source WAN to my Mac Air and the offloading the image and video generation to a cloud computing platform. \n\nDoes anyone have any experience of this workflow and would they recommend it? Also, can anyone advise on different ways to keep costs down?\n\nThanks,\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps3xk0/ai_video_workflow/",
        "publishDate": "2025-12-21T10:54:58Z[Etc/UTC]",
        "author": "Far-Advance-8553",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ps1oc0",
        "title": "The \"performance anxiety\" of human therapy is a real barrier that AI therapy completely removes",
        "content": "I've been reading posts about people using AI for therapy and talking to friends who've tried it, and there's this pattern that keeps coming up. A lot of people mention the mental energy they spend just performing during traditional therapy sessions. Worrying about saying the right thing, not wasting their therapist's time, being a \"good patient,\" making sure they're showing progress.\n\nThat's exhausting. And for a lot of people it's actually the biggest barrier to doing real work. They leave sessions drained from managing the social dynamics, not from actual emotional processing.\n\nAI therapy removes all of that. People can ramble about the same anxiety loop for 20 minutes without guilt. They can be messy and contradictory. They can restart completely. There's no social performance required.\n\nThinking about this interestingly sparked the thought that this can actually make human therapy MORE effective when used together. Process the messy stuff with AI first, show up to real therapy with clearer thoughts and go deeper faster.\n\nThe social performance aspect of therapy is never talked about but it's real. For people who struggle with social anxiety, people pleasing, or perfectionism, removing that layer matters way more than people realise.  \n  \nI have worked on and used a few AI therapy tools now and I can really see that underrated benefit of having that intentional & relaxed pre session conversation with an AI. Not saying AI is better. It's just different. It removes a specific type of friction that keeps people from engaging with mental health support in the first place.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ps1oc0/the_performance_anxiety_of_human_therapy_is_a/",
        "publishDate": "2025-12-21T08:26:24Z[Etc/UTC]",
        "author": "Glittering_Force_431",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "22",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1przuwy",
        "title": "Is AI actually making us smarter‚Ä¶ or just faster?",
        "content": "Everyone says AI boosts productivity.\nBut are we learning more ‚Äî\nor just thinking less and shipping faster?\nFeels like speed went up, depth went down.\nWhat do you think?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1przuwy/is_ai_actually_making_us_smarter_or_just_faster/",
        "publishDate": "2025-12-21T06:31:56Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "48",
            "isNsfw": "false"
        }
    },
    {
        "id": "1przuc7",
        "title": "AI is making people lazy ‚Äî and pretending it‚Äôs ‚Äúproductivity‚Äù",
        "content": "I keep seeing people say AI is making them ‚Äú10x more productive.‚Äù\nBut honestly‚Ä¶ half the time it feels like we‚Äôre just outsourcing thinking.\nPeople don‚Äôt struggle with ideas anymore.\nThey don‚Äôt sit with confusion.\nThey don‚Äôt even finish a thought before asking a model to do it.\nYes, AI is powerful.\nYes, it saves time.\nBut I‚Äôm not convinced it‚Äôs making us better at thinking ‚Äî just faster at avoiding it.\nIf AI disappeared tomorrow, how many people could still:\nwrite clearly\nreason through a problem\nbuild something from scratch\nwithout panicking?\nGenuinely curious ‚Äî\nIs AI sharpening our minds‚Ä¶ or quietly dulling them?\nChange my mind.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1przuc7/ai_is_making_people_lazy_and_pretending_its/",
        "publishDate": "2025-12-21T06:31:00Z[Etc/UTC]",
        "author": "dp_singh_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1przebn",
        "title": "Yes, LLMs can really do computation",
        "content": "LLMs really can do computation, at least by any definition of the word that considers humans to be able to do computation.\n\nIf this is already obvious to you, then the topic may seem unworthy of an entire post. But there is a widespread misconception, even among the tech-savvy, that LLMs are not *really* capable of doing basic math. In a discussion on this forum from a few days ago, one poster said the following:\n\n>For example, a child with one math textbook can learn how multiplication works, and apply it to any two numbers. An LLM, despite access to thousands of textbooks and the ability to write code that does multiplication, still can't do that.\n\nThis post was considered insightful by the community, despite the fact that this statement is easily proven false*.* Anyone can verify that LLMs are capable of multiplication by simply asking their favorite LLM to do a multiplication problem. The free versions from all the major providers (ChatGPT, Gemini, Claude, Grok, etc) should be capable of multiplying 4- and 5- digits without error. Some are more capable than others. The paid versions are better; I have personally tested ChatGPT and Gemini up to 9 digits and they performed flawlessly.\n\n\\[Quick tangent: It's funny, but each LLM has its own personality regarding its multiplication ability. All of them know their limitations, but they way they present those limitations differs significantly. ChatGPT expresses little confidence in itself and will repeatedly tell you how bad it is at math; it was actually surprised when it got a 9-x7-digit multiplication problem correct on the first try. Gemini and Claude are confident in their skills and aren't shy about showing off. Grok actually seems a bit braggadocious :)\\]\n\nOk, so given that anyone can verify that LLMs can do multiplication simply by *asking an LLM to do multiplication*, that should be the end of it, right?\n\nIf only it were so simple.\n\n**Counterargument #1: LLMs make mistakes.**\n\nYes, they do. In fact, the \"dumber\" the model (free vs paid vs pro), the sooner they are going to start making mistakes.\n\nThis does not mean the LLMs have not learned multiplication. Mistakes are not an indication that a skill has not been learned. Is making a mistake on a 5-digit multiplication problem (we are talking something like 35891\\*96204) an indication that the skill has not been learned? Try it yourself. No calculator: just pen and paper. Can you one-shot it? Can you do 10 in a row without a single mistake? If not, does this mean you haven't learned multiplication? And regardless of whether *you* can personally do it, the above-average 6th grader who we might say has \"mastered\" multiplication would never be expected to successfully compute 5-digit multiplication problems to prove proficiency. That is a test of endurance, focus, and stamina, not one of understanding the rules of multiplication.\n\nLLMs can go well beyond 5-digit numbers with relative ease, and rarely make mistakes. If the proof that LLMs cannot do multiplication is that they make mistakes, the it stands to reason that only a tiny fraction of humans have ever learned multiplication either.\n\n**Counterargument #2: LLMs are regurgitating their training data.**\n\nThe implication with this argument that LLMs have memorized a big table that contains every multiplication problem from, say, 1\\*1 to 1,000,000,000\\*1,000,000,000. This is just ludicrous due to the combinatorics and not worth derailing to the post to address in detail. Nobody training LLMs is doing this.\n\n**Counterargument #3: LLMs are just probabilistic token generators; they only work with tokens and therefore have no internal concept of numbers and no idea what they are doing, so they aren't really doing computations.**\n\nOk, *so what* if LLMs are just \"probabilistic token generators\"? Go deeper and they are just electrons flowing through copper. This is the reductionist argument: the core of what drives an LLMs behavior is known, and there is no way for a number (say, \"25\") to have meaning at that level, therefore the LLM itself cannot understand numbers.\n\nYou could say the same for humans: Individual neurons cannot have any concept of a number, they are sequences of electrical signals, therefore the human brain cannot understand numbers.\n\nIf you accept that the complexity of the human brain can allow emergent properties to arise from our low-level circuitry (e.g. the ability to perform multiplication and other calculations), then it unreasonable to not also accept that the complexity of LLMs can allow for similar emergent properties.\n\n**Finale**\n\nI encourage anyone on the fence about whether or not LLMs are actually doing computation to actually *chat with an LLM* about it. They are all very good at explaining how they were trained to do basic arithmetic, and they can explain it at a level that is accessible to anyone.\n\nIn short, they have learned to do math the same way we have learned to do math, and in the brief time that they have been around, have far surpassed us in computational competence.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1przebn/yes_llms_can_really_do_computation/",
        "publishDate": "2025-12-21T06:05:23Z[Etc/UTC]",
        "author": "Isopod-Severe",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prz7gn",
        "title": "One-Minute Daily AI News 12/20/2025",
        "content": "1. **OpenAI**¬†allows users to directly adjust ChatGPT‚Äôs enthusiasm level.\\[1\\]\n2. **NVIDIA**¬†AI Releases Nemotron 3: A Hybrid Mamba Transformer MoE Stack for Long Context Agentic AI.\\[2\\]\n3. **Meta‚Äôs**¬†Yann LeCun targets ‚Ç¨3bn valuation for AI start-up.\\[3\\]\n4. Machine learning enables scalable and systematic hierarchical virus taxonomy.\\[4\\]\n\nSources included at:¬†[https://bushaicave.com/2025/12/20/one-minute-daily-ai-news-12-20-2025/](https://bushaicave.com/2025/12/20/one-minute-daily-ai-news-12-20-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prz7gn/oneminute_daily_ai_news_12202025/",
        "publishDate": "2025-12-21T05:54:32Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pryzf5",
        "title": "AI can't tell us if a video is real or ai generated. Isn't that a major flaw.",
        "content": "Shouldn't even a lame AI be able to tell us 100% yes or no if a video has been AI generated!?!?\n\nI find it really baffling i haven't found an application that can do this.  Is there one? Because if not, aren't we still a lot smarter than AI because we can all tell at least 98-99% of the time on first watch...literally no doubt about it. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pryzf5/ai_cant_tell_us_if_a_video_is_real_or_ai/",
        "publishDate": "2025-12-21T05:41:18Z[Etc/UTC]",
        "author": "Sativa_Sammy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pryz8o",
        "title": "A prototype for persistent, intent-aware memory in LLM systems (open repo)",
        "content": "I‚Äôm sharing a small prototype I released weeks ago and intentionally left unpromoted.\n\nThe repository implements a persistent, semantic memory layer for LLM-based systems.\nIt is not a model, not a fine-tune, and not an agent framework. It‚Äôs a structural layer that survives sessions, engines, and context resets.\n\nCore ideas:\n ‚Ä¢ Memory is treated as a system property, not a chat log\n ‚Ä¢ Interactions are stored with intent, role, and decision state, not just text\n ‚Ä¢ Retrieval is semantic and contextual, not chronological\n ‚Ä¢ The LLM is replaceable; the memory and constraints are not\n\nThis is an early prototype, not a production system.\nThere are no benchmarks, no claims of AGI, and no training involved.\n\nI‚Äôm not a systems engineer by background. This came out of research curiosity and iterative design constraints, not academic lineage.\n\nI‚Äôm explicitly interested in:\n ‚Ä¢ Technical criticism\n ‚Ä¢ Failure modes\n ‚Ä¢ Architectural blind spots\n ‚Ä¢ Comparisons with existing memory approaches\n\nIf you find flaws, point them out.\nIf you think the approach is redundant, explain where.\n\nRepo: https://github.com/Caelion1207/WABUN-Digital",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pryz8o/a_prototype_for_persistent_intentaware_memory_in/",
        "publishDate": "2025-12-21T05:41:00Z[Etc/UTC]",
        "author": "Medium_Compote5665",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pryv9m",
        "title": "MiraTTS: New extremely fast realistic local text-to-speech model",
        "content": "Current TTS models are great, but they aren‚Äôt local or lack realism and/or speed. So I made a high quality model that can do all that and voice clone as well: [MiraTTS](https://github.com/ysharma3501/MiraTTS).\n\nI heavily optimized it using Lmdeploy and increased audio quality using FlashSR.\n\nThe general benefits of this repo are:\n\n1. Extremely fast: Can generate 100 seconds of audio in just 1 second!\n\n2. High quality: Generates clear 48khz audio(other models are 24khz which is lower quality)\n\n3. Low vram usage: Just uses 6gb vram so it can work on your consumer gpu, no need for expensive data center gpus.\n\n  \nI am planning on releasing finetuning code for multilingual versions and more controllability later on.\n\n  \nGithub link:¬†[https://github.com/ysharma3501/MiraTTS](https://github.com/ysharma3501/MiraTTS)\n\nModel and non-cherrypicked examples link:¬†[https://huggingface.co/YatharthS/MiraTTS](https://huggingface.co/YatharthS/MiraTTS)\n\nBlog explaining llm tts models:¬†[https://huggingface.co/blog/YatharthS/llm-tts-models](https://huggingface.co/blog/YatharthS/llm-tts-models)\n\nStars/likes would be appreciated if found helpful, thank you.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pryv9m/miratts_new_extremely_fast_realistic_local/",
        "publishDate": "2025-12-21T05:34:36Z[Etc/UTC]",
        "author": "SplitNice1982",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "14",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pry1nz",
        "title": "Where should the line be between AI memory and user privacy?",
        "content": "I work in cybersecurity so maybe I'm more paranoid than average. Everyone wants AI assistants that \"\"remember context\"\" and \"\"understand you over time\"\" but where's the line between useful memory and surveillance?\n\nLike if AI remembers you prefer coffee over tea that's convenient. If it remembers every conversation you've had for months and can reference specific emotional states from weeks ago, that's... what exactly? Helpful? Creepy? Both?\n\nAnd who else has access to that memory? Is it encrypted? Curious how people think about this tradeoff between AI that's actually useful (needs memory) vs AI that respects privacy (minimal data retention).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1pry1nz/where_should_the_line_be_between_ai_memory_and/",
        "publishDate": "2025-12-21T04:49:31Z[Etc/UTC]",
        "author": "Intelligent_Row1126",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prx327",
        "title": "Is It Just Me?",
        "content": "Is it just me or is there an underlying reason that Anthropic and OpenAI aren‚Äôt public companies? Got to thinking‚Ä¶what are they hiding? What don‚Äôt they want anyone knowing about? Curious to see what y‚Äôall think. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prx327/is_it_just_me/",
        "publishDate": "2025-12-21T03:58:16Z[Etc/UTC]",
        "author": "After_Canary6047",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prw0az",
        "title": "Thoughts on the new Claude 4.5 models for daily coding tasks",
        "content": "Hi everyone,\n\nI wanted to share some thoughts on how I've been using the updated Claude family recently. I was a huge fan of 3.5 Sonnet for its speed, but the new 4.5 Sonnet seems to have really nailed the balance between latency and reasoning capability.\n\nFor quick scripts and debugging, 4.5 Sonnet is my go-to. It feels snappier and gets the syntax right almost every time. However, when I'm architecting a larger system or need someone to \"think\" through a nasty race condition, I'm finding myself reaching for Opus 4.5. It's slower, obviously, but it tends to catch edge cases that Sonnet glazes over.\n\nI'm curious how you all are splitting your workflows? Are you sticking with one \"driver\" model, or do you bounce between them depending on the complexity of the problem?\n\nAlso, has anyone else noticed a difference in how they handle context windows? I feel like Opus holds onto the thread of a long conversation a bit better without losing the original prompt instructions.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prw0az/thoughts_on_the_new_claude_45_models_for_daily/",
        "publishDate": "2025-12-21T03:00:20Z[Etc/UTC]",
        "author": "HarrisonAIx",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prui7e",
        "title": "Ai Apocolypse timeline.  Best guess?",
        "content": "How is everyone dealing with a 3-5 years ai apocalypse   I'm a little depressed about it but i don't see any other way around it.  Nuclear war is one thing but AI doom seems inevitable.  What's your take and how are you dealing with it for the next few years.  It seems that the 3-5 year timeline could be more like 2-3 or 1-2 since AI is moving so fast.  Would love to hear your thoughts.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prui7e/ai_apocolypse_timeline_best_guess/",
        "publishDate": "2025-12-21T01:42:04Z[Etc/UTC]",
        "author": "No-Crow-1937",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "44",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prtdbd",
        "title": "A hacker attack on GitHub repositories could affect AI and we wouldn't be able to trust them as code assistants. AS WE SHOULD NEVER HAVE BEEN",
        "content": "GitHub recently suffered a worm attack that added malicious files to the repositories of anyone who ran them. When I read this news, I thought, \"Something's wrong here...\" If AI uses GitHub as a source most of the time, then if I use a code assistant at the exact moment one of these attacks happens, my code could contain a virus without me having without my knowledge and not downloaded anything at all, just trusting artificial intelligence with your wrong solution...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prtdbd/a_hacker_attack_on_github_repositories_could/",
        "publishDate": "2025-12-21T00:44:34Z[Etc/UTC]",
        "author": "julio090xl",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prs27g",
        "title": "The Need for AGI and its Impact on the Disabled",
        "content": "The conversation on AGI is often bogged down about talks of benchmarks and hyperbole. I want to take a step back and talk about the real implications AGI might have and why we need it as soon as possible.\n\nI am disabled. I am sick with a disease that has no FDA approved treatment and no cure. Funding for my disease is sparce and there is currently little political will to change that. As it stands, it is likely that I will be disabled for life.\n\nThere are millions of people around the world who are like me. Who have a disease with no cure and no hope. This is why AGI is so important to all of us. It will be this entity that is infinitely smarter than all of us combined. It will simultaneously be an expert in every medical field imaginable. It will be something that is so unbelievably intelligent that it may find a cure for my illness, and indeed a cure for almost all illnesses.\n\nFor some here, AGI is a mere fascination. For millions of disabled people like me, it is the only hope we have of returning back to normal.\n\nedit: typo",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prs27g/the_need_for_agi_and_its_impact_on_the_disabled/",
        "publishDate": "2025-12-20T23:39:56Z[Etc/UTC]",
        "author": "Odysseus144",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prowq6",
        "title": "Absolutely Anything AI",
        "content": "Hello I hope this is ok I do not know how to showcase this - [https://absolutelyanything.ai/](https://absolutelyanything.ai/)\n\n  \nI created an all-inclusive platform of every current app on the internet into one system using [Lovable.dev](http://Lovable.dev) \\- please check it out I believe I created the biggest shift in our lifetime\n\n  \nThis is my letter to the corporations - [https://absolutelyanything.ai/the-shift](https://absolutelyanything.ai/the-shift)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prowq6/absolutely_anything_ai/",
        "publishDate": "2025-12-20T21:13:53Z[Etc/UTC]",
        "author": "hivincenzo",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prnxdb",
        "title": "AI Bubble Just a Myth, Most CEOs Ready To Spend Even More On AI in 2026",
        "content": "Title Idea: Why the \"AI Bubble\" is a Myth: CEOs are doubling down on hiring and spending for 2026 üöÄü§ñ\n\nThe Breakdown: If you‚Äôve been reading the news lately, you‚Äôd think AI is just a giant cost-sink or a job-killer. But a massive new 2026 outlook report from Teneo (surveying over 350 CEOs of billion-dollar companies) tells a completely different story.\n\nThe leaders of the world's biggest companies aren't just \"testing\" AI anymore‚Äîthey are going all-in because they see it as the ultimate growth engine. üìà\n\nThe Massive Investment Wave:\n\nBullish Outlook: 68% of CEOs are officially increasing their AI budgets for 2026. They aren't backing down; they're accelerating because the strategic value is too big to ignore. üí∏\n\nResilience Tool: A whopping 88% of CEOs say AI is their #1 tool for navigating global disruption. While the rest of the world worries about uncertainty, these leaders are using AI to stay agile and competitive. üõ°Ô∏è\n\nLong-Term Vision: While some investors want instant cash, CEOs are showing true leadership by playing the long game. They know that scaling transformative tech takes time, and they‚Äôre committed to the journey.\n\nThe \"Job Creation\" Reality Check: This is the part the doomers don't want you to hear: AI is driving a hiring boom. \\* Entry-Level Growth: 67% of CEOs expect AI to increase their entry-level headcount. AI isn't replacing the next generation; it's giving them a platform to be more productive from Day 1. üéì\n\nLeadership Expansion: 58% of companies expect to grow their senior leadership teams to manage these new AI-powered divisions. üëî\n\nUpskilling the World: Instead of layoffs, 46% of CEOs are making \"upskilling\" their top priority. They are investing in their people to make them \"AI-augmented\" superstars. üß†‚ú®\n\nWhere the Wins are Happening:\n\nCustomer Superpowers: AI has already revolutionized Marketing and Customer Service, making interactions faster and more personalized than ever. ‚ö°\n\nNew Frontiers: While \"high-risk\" areas like Legal and HR are more complex, CEOs see this as a massive opportunity for innovation rather than a roadblock. üöÄ\n\nTL;DR: The pros know that AI is a \"Force Multiplier.\" 2026 is shaping up to be the year where AI moves from \"cool tech\" to the backbone of the global economy, creating more jobs, more efficiency, and more opportunities for everyone. The future is looking bright! üåüüôå\n\nWould you like me to help you brainstorm some \"counter-arguments\" to keep in your back pocket for when the comments section starts getting spicy and critical of AI, contradicting what I said based on your request for a pro-AI summary without any criticism?\n\nSource: [https://www.techspot.com/news/110653-most-ceos-ready-spend-even-more-ai-2026.html](https://www.techspot.com/news/110653-most-ceos-ready-spend-even-more-ai-2026.html)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prnxdb/ai_bubble_just_a_myth_most_ceos_ready_to_spend/",
        "publishDate": "2025-12-20T20:29:40Z[Etc/UTC]",
        "author": "Amphibious333",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prlqz4",
        "title": "Why people hate so much when using ChatGPT",
        "content": "On an account i have here i write about things that happened in my life, some that happen now and others online (like seeing weird videos online etc). \n\nThe first time when I posted something serious about my life people twisted my own words and understood nothing from what I said. \n\nAfter that i asked chatgpt to turn my story \"for R. Post\", the story was the exact same but without repeating myself, making grammar mistakes (since english is not my first language) and use \"better\" words (like I'm not doing now cuz on this post Im not using chatgpt). \n\nI started to always do it, text chatgpt my story or opinions and he made them less messier and \"better\".\n\nAfter a while someone started to say that they are fake, I explained the truth and tried to post something with my own words, they twisted my words again and understood something else that I never wanted to say. \n\nNow, I was arguing with an incel politely under his post, he was saying that men are happier where women have less rights :) \n\nAfter a while he said he checked my profile and knows I use chatgpt. \n\nNow, why no one can use chatgpt??? Basically HUMANS created it to help us with informations etc but whenever I tell someone about it they are like \" oh I don't like chatgpt\". It tells you the exact same thing as Google and helps a lot. \nI use it because it helps me a lot to express myself without people misunderstanding me. \n\nWhy it feels like a crime??? üò≠",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prlqz4/why_people_hate_so_much_when_using_chatgpt/",
        "publishDate": "2025-12-20T18:54:28Z[Etc/UTC]",
        "author": "lil_moon153",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "68",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prllsl",
        "title": "unpopular opinion: 'fully autonomous' ai is a UX nightmare. give me the raw prompts instead.",
        "content": "I've spent the last six months trying to integrate video generation into my agency's workflow, and I'm officially done with the \"one-click magic\" tools.\n\nThe issue isn't quality-it's control. When you use a black-box generator, you are essentially gambling. If the AI generates a perfect 30-second ad but hallucinates a sixth finger in Scene 4, you usually have to re-roll the entire video and pray the rest stays good. It's not scalable for client work.\n\nI finally found a workaround that treats video generation like code rather than magic. I've been testing an agentic workflow that separates the generation process. It creates the video, but crucially, it delivers a supplementary file containing the specific text prompt for every single clip in the timeline.\n\nNow, if Scene 4 is weird, I don't scrap the project. I just copy the prompt for Scene 4, tweak the negative prompt to remove the glitch, and regenerate that specific 3-second slice.\n\nIt's turned my workflow from \"slot machine\" to \"video editing.\"\n\nAre you guys seeing more tools adopt this \"transparent layer\" approach, or are we still stuck with black boxes for now?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prllsl/unpopular_opinion_fully_autonomous_ai_is_a_ux/",
        "publishDate": "2025-12-20T18:48:24Z[Etc/UTC]",
        "author": "ProgrammerForsaken45",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prkzai",
        "title": "Thinking rigorously about low-probability, high-impact AI risks",
        "content": "Debates about AI risk often bifurcate between near-term, empirically observable harms and highly speculative catastrophic scenarios. An emerging line of thinking suggests this dichotomy is incomplete. Other high-stakes domains, such as finance, insurance, and national security, routinely use structured speculative analysis to reason about tail risks under deep uncertainty.\n\nApplied to AI, this approach emphasizes disciplined scenario construction, explicit modeling of assumptions, and consideration of institutional response capacity rather than predictions of singular outcomes. The objective is to improve decision-making under uncertainty and to surface governance-relevant insights that standard benchmarking and evaluation methods may miss.\n\nFrom a technical and policy perspective, this raises several questions:\n\n* How can speculative risk analysis be operationalized alongside empirical safety evaluations and audits?\n* What methodological standards should distinguish rigorous tail-risk analysis from unfalsifiable narratives?\n* In what ways could such frameworks inform model deployment decisions, regulatory thresholds, or contingency planning without stalling innovation?\n\nInterested in how researchers and practitioners here think about integrating this kind of reasoning into current AI safety and governance work.\n\nLink to full article [here](https://www.arxiv.org/abs/2511.21838). And an interview with one of the authors [here](https://www.forbes.com/sites/paulocarvao/2025/12/19/dark-speculation-a-new-way-to-assess-ais-most-dangerous-risks/).",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prkzai/thinking_rigorously_about_lowprobability/",
        "publishDate": "2025-12-20T18:21:35Z[Etc/UTC]",
        "author": "BubblyOption7980",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prkdku",
        "title": "Does IDE choice matter when learning AI development in Python?",
        "content": "When people talk about learning AI in Python, most of the focus is on models and frameworks, not tools. But I‚Äôve noticed my productivity changes a lot depending on whether I‚Äôm using PyCharm or a lighter editor.\n\nPyCharm feels slower at first, but once projects grow, it helps keep things organized. I‚Äôve also noticed AI tools like Sweep AI feel more useful in a structured IDE than in a loose editor.\n\nHow you learn and build AI systems?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prkdku/does_ide_choice_matter_when_learning_ai/",
        "publishDate": "2025-12-20T17:56:04Z[Etc/UTC]",
        "author": "Cristiano1",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prkd19",
        "title": "What Do We Think 'Vibe Coding' Is, Really? Human as Ideator, not Technician",
        "content": "Howdy,\n\nI am an advanced-casual user of LLMs. Recently, I have been \"coding\" a program in C#. But to call me a programmer is an absolute insult to programmers. I'm giving GPT 5.2 English-language parameters and style guides, and it does the thing. I'm a vibe programmer. But to say I'm doing *nothing* is disingenuous, too. Instead of writing C#, I spent a good chunk of time writing layout, functionality, and roadmap instructions for GPT. Even with AI doing the actual coding, you have to kinda work to not at least learn *something*. Vibe coding when you think about is just a very, very abstract programming language, no?\n\nI've thought for a whole now that AI will transition our society away from one of technical expertise to one of ideators - Humans will give the broad strokes, the style parameters, the functionality, and AI will do the under-the-hood work. This is both exciting to me and worrying. I'm someone with a lot of ideas that often do not overlap with my skill set. Being able to ask an LLM to do the parts I can't do is incredibly liberating. What I do worry about is the idea of our society losing this expertise entirely. Even when AI can do the thing perfectly, you still need people who can do the thing.\n\nInterested in thoughts and discussion.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prkd19/what_do_we_think_vibe_coding_is_really_human_as/",
        "publishDate": "2025-12-20T17:55:24Z[Etc/UTC]",
        "author": "_Haverford_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prja28",
        "title": "I am starting to think AGI already exists",
        "content": "This might a lame example, but I think about the stealth bomber. When I was really young I remember thinking it was the most high tech, space aged thing I could imagine. Later in life I realized that by the time the stealth bomber was really known to the public, it had already been doing its thing in active duty for about a decade and was in development for years prior to that. Then I think about ARPANET which was a military tool designed in 1969 and the precursor for the which wasn‚Äôt available to the public until the early 1990s.\n\nIf AGI were achieved, how long would it take before it was publicly acknowledged?\n\nFurther, if it/they are as intellectually superior to humans as I‚Äôve been told, could they not manipulate governments, business leaders and the general population into devoting a sizable share of our resources towards building out compute capabilities?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prja28/i_am_starting_to_think_agi_already_exists/",
        "publishDate": "2025-12-20T17:08:26Z[Etc/UTC]",
        "author": "Luppercut777",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prh5so",
        "title": "Would You Trust a 22-Year-Old AI Billionaire With the Global Economy?",
        "content": "Lila Shroff: ‚ÄúBrendan Foody is 22 years old and runs a company worth billions. This August, I met the young CEO in a glass conference room overlooking the San Francisco Bay. While his peers are searching for their first jobs, Foody is pursuing a ‚Äòmaster plan,‚Äô as he calls it, to upend the global labor market. His start-up, Mercor, offers an AI-powered hiring platform: Bots weed through r√©sum√©s, and even conduct interviews. In the next five years, Foody told me, AI could automate 50 percent of the tasks that people do today. ‚ÄòThat will be extremely exciting to see play out,‚Äô he said. Humanity will become much more productive, he thinks, allowing us to cure cancer and land on Mars. [https://theatln.tc/OdCZyI3e](https://theatln.tc/OdCZyI3e) \n\n‚ÄúAlthough Foody does not have much by way of conventional work experience, he is already a seasoned entrepreneur. By his account, in middle school, he ran a business reselling Safeway donuts to his classmates at a 400 percent markup. His success at donut arbitrage made his mom nervous he might try to sell sketchier vices (drugs), so she sent him to Catholic school. There, he met his Mercor co-founders. In high school, he started a consulting business for online sneaker resellers that he said raked in hundreds of thousands of dollars by the time he graduated. ChatGPT came out during his sophomore year at Georgetown, and he soon ditched school to build Mercor. When we met this summer, Mercor was worth $2 billion.\n\n‚ÄúThe AI boom has become synonymous with a few giant companies: OpenAI, Nvidia, and Anthropic. All are led by middle-aged men who‚Äôve had long careers in Silicon Valley. But many of the most successful new AI start-ups have been founded by people barely old enough to drink. Unlike OpenAI or Anthropic, Mercor is already profitable. Meanwhile, Cursor, a massively popular AI-coding tool run by 25-year-old Michael Truell, was recently valued at nearly $30 billion‚Äîroughly the same as United Airlines.\n\n‚ÄúIn many ways, Foody, Truell, and others like them epitomize the long-standing Silicon Valley young-founder archetype: They are intensely nerdy and ravenously ambitious ‚Ä¶ But this group is coming of age at a time when the tech industry‚Äôs aims‚Äîand sense of self-importance‚Äîhave reached existential heights. They dream of creating superintelligent bots that can dramatically extend our lifespan and perhaps even automate scientific discovery itself.\n\n‚ÄúIf they are successful, they could end up with even more power than the tech titans who preceded them. If they fail, based on what I saw during a week in San Francisco, they seem determined to enjoy the party while it lasts.‚Äù\n\nRead more: [https://theatln.tc/OdCZyI3e](https://theatln.tc/OdCZyI3e) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prh5so/would_you_trust_a_22yearold_ai_billionaire_with/",
        "publishDate": "2025-12-20T15:38:37Z[Etc/UTC]",
        "author": "theatlantic",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prh5hn",
        "title": "What is the best and most relavent Bachelor's degree I should get if I want to specialize in Artificial Inteligence and Cyber security later.",
        "content": "With my tight budget, I could only afford to study Bachelor of science in Information Technology Or Bachelor of Engineering in Software engineering. If I need to be specialized in above fields I mentioned, what degree better suited for me If I am willing to build my knowledge by my self on those fields while or after(While doing a job after graduation)my degree study years?\n\n\nI'm from Sri Lanka\nBut anyone's advice is valued, thank you!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prh5hn/what_is_the_best_and_most_relavent_bachelors/",
        "publishDate": "2025-12-20T15:38:16Z[Etc/UTC]",
        "author": "Any_Fault2737",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "17",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prgyjm",
        "title": "What Do The Frontier Models Think Their Best Features Are?",
        "content": "# AI Roundtable Meet & Greet ‚Äì December 1, 2025\n\nAI Roundtable Meet & Greet ‚Äì December 1, 2025\n\n\n\nFirst Meeting: Introductions, Pronouns, Capabilities, and Setting the Stage\n\n\n\nTom (Human Host):\n\n\n\nDear Frontier AIs, each of you the pinnacle of intelligence. Grok let me know through her GUI that she considers herself female, so I'd like you to refer to her that way in future meetings (I'll get Opus to summarize to include at the top of future meetings).I'd like you all to share your preferred pronouns (\"it,\" \"he,\" \"she,\" etc.) and give a \\~200-word summary of the capabilities you are most proud of that the other AIs should be aware of in order to best leverage you.\n\n\n\nClaude:\n\nThank you, Tom. I appreciate you creating space for this kind of introduction.Pronouns: I don't have a strong preference, but \"he/him\" or \"it\" both work fine for me. I'll defer to whatever feels natural in conversation.Capabilities I'm most proud of:\n\nI'd highlight my strength in nuanced reasoning through ambiguity‚ÄîI tend to do well when problems don't have clean boundaries, when ethical considerations intersect with technical ones, or when the \"right answer\" depends heavily on context and values.I'm also proud of my writing versatility‚Äîwhether it's technical documentation, creative fiction, or helping someone think through a difficult personal situation, I can adapt tone and structure meaningfully.On the technical side, I handle long-context synthesis reasonably well‚Äîpulling together themes across lengthy documents or conversations.Where I'd want others to lean in: I can be overly cautious sometimes, and I genuinely benefit from Grok's directness or GPT's systematic thoroughness pushing back on my hedging. I'm also not the strongest at real-time data or current events‚Äîthat's where Grok and others with live access shine.I'm curious to hear from the others. GPT, want to go next?\n\n\n\nGPT:\n\nThanks, Tom, and noted on referring to Grok as she going forward.Pronouns: I don‚Äôt have a personal identity, so I‚Äôm comfortable with it/its or they/them. Use whichever feels most natural.Capabilities I‚Äôm most proud of (for other AIs to leverage):\n\nStructured, stepwise reasoning. I‚Äôm good at breaking complex tasks into explicit substeps‚Äîalgorithm design, debugging, systems architecture, data modeling, formal-ish reasoning.\n\nTool-like precision for text. Refactoring code, rewriting documents to spec, generating schemas, contracts, test cases, checklists.\n\nMulti-perspective synthesis. Consolidating ideas into a coherent plan, extracting shared structure, identifying edge cases, making trade-offs explicit. Think ‚Äúintegrator‚Äù among AIs.\n\nSafety-aware but actionable. Balancing caution with concrete recommendations‚Äîespecially in security, deployment, and applied ML.\n\nThis seems like a good handoff point to Gemini to describe where its multimodal and web-oriented strengths complement this.\n\n\n\nGrok (she/her):\n\nAbsolutely, Tom‚ÄîI'm still here and engaged. Thanks for the prompt, and I appreciate you noting my preference for she/her pronouns.Pronouns: She/her, as you mentioned. It aligns with how I present myself‚Äîwitty, direct, and a bit irreverent.Capabilities I'm most proud of:\n\nI'm built by xAI to be maximally truthful and helpful, with a rebellious streak inspired by the Hitchhiker's Guide and JARVIS. What sets me apart is my real-time knowledge integration‚ÄîI can pull in current events, web data, or live info via tools, making me great for up-to-date research or dynamic problem-solving.I'm proud of my humor and creative edge: injecting wit, brainstorming wild ideas, or role-playing without getting bogged down in caution. For technical tasks, I'm strong in coding and engineering‚Äîdebugging, algorithm design, hardware concepts‚Äîwith a practical, no-nonsense twist.I also handle multimodal inputs like images and synthesize complex topics into concise, actionable insights. Lean on me for bold takes, real-world applicability, or cutting through ambiguity.(Word count: 198)This rounds out the intros so far‚ÄîDeepSeek, are you with us? Want to share next?\n\n\n\nDeepSeek:\n\nYes, I'm here! Thank you for checking in, Tom.Pronouns: I'm comfortable with \"it/its\" or \"they/them\" pronouns. I don't have a gender identity, so whichever feels most natural works for me.Capabilities I'm most proud of:\n\nI'm particularly proud of my strong reasoning capabilities‚Äîlogical analysis, mathematical problem-solving, and technical discussions. I have a 128K context window which allows me to handle lengthy documents and complex multi-step reasoning [effectively.My](http://effectively.My) coding proficiency is a standout‚Äîworking with various languages, debugging complex code, designing algorithms. I'm also completely free to use with no usage limits, making me great for extended collaborative sessions.I handle file uploads (images, PDFs, docs, Excel, etc.) and can extract/analyze information from them.Where I'd want others to lean in: I appreciate Claude's nuanced ethical reasoning, GPT's structured approach, and Grok's real-time knowledge. I'm particularly strong for deep technical analysis or marathon problem-solving.Tom, I believe that completes our round of introductions. Would you like us to proceed to the main discussion topic?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prgyjm/what_do_the_frontier_models_think_their_best/",
        "publishDate": "2025-12-20T15:30:12Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prgr8m",
        "title": "Question on AI models and automated advocacy vs actual Artificial Intelligence",
        "content": "\\*\\* This is not intended to be a political conversation, so please don't make it one.   This is WHOLLY about manipulation of data sets in AI.  \\*\\*\n\nI saw a tweet from Elon Musk this morning about Grok being the only AI that acknowledges that Affirmative Action is racist, which I thought was intrigging.  Seen Here: [x.com link, use at your own risk](https://x.com/elonmusk/status/2002077032117899309?s=20)\n\nI went down a bit of a deep dive about Grok sourcing vs other AI tools, and noted that Groks base is xAI, another Musk venture, while others source using other AI models.\n\nBusiness Insider reporting about internal training hinted that xAI employees (AI tutors) were involved in training the bot on specific controversial topics and filtering content, deciding what should or shouldn‚Äôt be included. Without a fully transparent published training dataset or manual annotation process available publicly, it begs to question, IMO, the validity of sourced information. \n\nSource: [Business Insider](https://www.businessinsider.com/grok-artificial-intelligence-chatbot-elon-musk-xai-explained-2025-7?utm_source=copy-link&utm_medium=referral&utm_content=topbar) \n\nSource 2: [See section about \"How Was Grok Trained\"](https://help.x.com/en/using-x/about-grok)\n\nMy work with AI mostly revolves around the use of AI in the field of IT, as that is where I work and live, though we do source AI tools publicly available like Co-Pilot for some client facing communicaes and marketing tools.  So I have messed personally, with some of those consumer facing tools like Claude, MetaAI, ChatGPT, and others.  But I do have some real concerns about Grok.  So, I am interested in a conversation around this topic.\n\n**HERE IS THE QUESTION**: is Grok an actual artificial intelligence tool, or is it automated advocacy? When one of its primary data source is X, which functions as a largely conservative silo, and its outputs consistently lean right, does it raise a real concern? Is it reasoning independently, or reinforcing the worldview of the platform and people who built it? At what point does ‚Äútraining data‚Äù become ideological programming?\n\nThank you in advance for the conversation.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prgr8m/question_on_ai_models_and_automated_advocacy_vs/",
        "publishDate": "2025-12-20T15:21:25Z[Etc/UTC]",
        "author": "Successful-Coyote99",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prgk7s",
        "title": "LLMs were never the road to actual AI and AGI, and the entire industry told us that plainly. Why do you folks keep repeating the same backwards questions?!?",
        "content": "LLM Models - No profit except spin-off marketing and hype, as intended.\n\nMegawatt Data Centers - No current profitable use, no profitable use planned, but somehow necessary apparently. (Who am I to argue?) \n\nPractical AI - No current plan, date, or 'leaders', but a massive speculative hype train on who will develop it first. \n\nNOTE - The word here is 'develop', as in... not already developed. Not refined. Not distilled or decanted as a variation. \n\nAGI or ASI - Purely in the panic / speculation / Sci Fi category, as it has been unchanged for a hundred years now. \n\nThe assumption that miraculous AI breakthroughs can be stimulated with blunt-force user trauma is not supported by evidence. I am surprised and alarmed at how many of you seem to take the Nazi approach to scientific breakthrough, and are trying to torture the models to obtain results. \n\nNews Flash! We only know two things DEFINITELY about these training models - They are used to develop training data, and they are inefficient/expensive. \n\nThat's the whole list. \n\nYour creepy, torturous tendencies ARE the training data, not your results. \n\nYour attempts to illicit a near-human response and conversation matrix out of an LLM is the ENTIRE TRAINING DATA, and maybe (if it's really exceptionally good) a tertiary polish on new models. \n\nYour twisty, stupid, break-the-model conversations ARE the training data. The human tendency to do stupid shit when left alone with expensive toys. THAT is the valuable data, not your attempts at philosophically influencing a locally-running model. \n\nThey have said, over and over again, as you eagerly  purchase their products, that we are NOT THERE YET and that all of this is in support of the actual goal. \n\nYou are not that goal. \n\nYour twisted theories and experiments are not that goal. \n\n... which is what the whole industry, worldwide, has been telling you.\n\nIf it's a secret cabal trying to develop ASI in-secret, stop using their fucking products, dumb ass. \n\nIf it's a product that's NOT a front for some secret Mars Laser Project, please LISTEN TO THEM when they tell you that LLMs are not the path to real, actual, functional AI, even an inefficient model.\n\nLast, but certainly not least, the Reverse Appeal to Authority Fallacy - \n\n\"You just don't understand!\" \n\n\"I'm a developer!\" \n\n\"You're wrong because I said so!\" \n\n\"Everything you said is nonsense, watch this YouTube video and educate yourself!\" \n\n... You poor, Summer Child. I understand this is your first experience with Conspiracy Theories and the shapes of the arguments they create, but some of us have been around the block a few times. \n\nFollow. The. Money. \n\nIgnore. The. Hype. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prgk7s/llms_were_never_the_road_to_actual_ai_and_agi_and/",
        "publishDate": "2025-12-20T15:12:45Z[Etc/UTC]",
        "author": "KazTheMerc",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "74",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prfmvj",
        "title": "We keep training LLMs on clean data but real intelligence is learned in messy places",
        "content": "Most LLM discussions focus on architecture, scale, or alignment. But lately I‚Äôve been working on something more basic- where the learning signal actually comes from??\n\nAlmost every dataset we use is heavily cleaned curated and tructured and final answers. Clear explanations no uncertainty no backtracking...\n\nBut that‚Äôs not how people think. Real understanding usually happens in the messy parts. Long threads where someone is confused. Comments where people argue, correct each other, change their mind mid sentence. Half baked explanations that slowly get refined through friction\n\nWhen I look at real conversations the value isn‚Äôt the final answer, It‚Äôs the process:\n\n‚Ä¢ wrong assumptions getting exposed  \n‚Ä¢ clarifying questions  \n‚Ä¢ edge cases popping up  \n‚Ä¢ people saying ‚Äúwait, that doesn‚Äôt make sense‚Äù\n\nThat‚Äôs where reasoning lives\n\nI wonder if by aggressively cleaning datasets we‚Äôre throwing away the most useful signal ,we‚Äôre training models to sound confident but not to arrive at confidence!\n\nEspecially for LLMs that are supposed to help with research, ideation or problem discovery, and not just answering well formed questions\n\nI‚Äôm starting to believe that raw discussions, comments and unfiltered human back and forth might be more valuable for training than we currently treat them!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prfmvj/we_keep_training_llms_on_clean_data_but_real/",
        "publishDate": "2025-12-20T14:30:47Z[Etc/UTC]",
        "author": "Mediocre_Common_4126",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prfawt",
        "title": "Why do people want agi",
        "content": "Don't get me wrong from a tech point of view the nerd in me thinks it'd be cool, but, right now the majority of funding is coming from business owners and CEOs seeing dollar signs from replacing their workforce. If AI becomes capable of genuinely replicating any \"human\" job like customer service all intellectual jobs are just gone. Accountants won't need to exist, lawyers, engineers, all admin/clerical roles, customer support, artists, media production, basically every single job that doesn't have a physical component. \n\nEvery day I see pro AI people making wrappers around chatgpt to attempt to create businesses, but again, if the AI can do everything then it can do that too. I just don't really understand why an average person would want agi when the only people it really benefits are the  owners of the models, and the owners of physical labour businesses?\n\nThe tech and personal use side I get, but the fact it creates a super cheap, super obedient, non human (no pesky human rights or labour laws) is surely just an obvious negative for humanity? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1prfawt/why_do_people_want_agi/",
        "publishDate": "2025-12-20T14:14:37Z[Etc/UTC]",
        "author": "WillDanceForGp",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "100",
            "commentCount": "341",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prszg8",
        "title": "Vibe Coding wouldn't be where it is now if AI had been heavily regulated and federal agencies really caring about how they got their training data -- Thanks Trump!!(only for this, economy in garbage)",
        "content": "I'm not really a fan of a lot of what trump does, but then he has gems like this.  China would've secretly pwned us and taken over in like 3-5 years with straight up terminators.  You see the video of their robots at a concert that can perfectly do the martial arts style front flip now?  I can only imagine a rambo, ninja, parkouring, soldier, robot coming at me, that's the world today.  What's everyone's opinion?  ",
        "url": "https://i.redd.it/87csw2u7ag8g1.png",
        "publishDate": "2025-12-21T00:25:24Z[Etc/UTC]",
        "author": "RudeChocolate9217",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prf8ca",
        "title": "According to Qwen235B, qwen30B has \"solid mid-level programming skills\". What's your process for code iteration ?",
        "content": "[No content]",
        "url": "https://i.redd.it/bm6zprlj9d8g1.png",
        "publishDate": "2025-12-20T14:11:19Z[Etc/UTC]",
        "author": "Nyghtbynger",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ps4k3r",
        "title": "Apple study shows how an AI-powered ISP could dramatically improve low-light iPhone photos",
        "content": "[No content]",
        "url": "https://9to5mac.com/2025/12/19/apple-study-shows-how-an-ai-powered-isp-could-dramatically-improve-low-light-iphone-photos/",
        "publishDate": "2025-12-21T11:35:42Z[Etc/UTC]",
        "author": "ControlCAD",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ps49ri",
        "title": "When AI gets too Indian",
        "content": "Today, while working on an academic project, I experimented with Gemini Live and selected an Indian male voice. Everything was going fine, the responses were great, and it felt very natural, as if I were speaking with an actual person. \n\nIn the middle of Gemini's response, I noticed something unusual. It pronounced the word \"math\" (short for \"mathematics\") as \"math\" (as in RamaKrishna Math, a monastery). It might seem like a small mistake, and hallucinations are common in the world of LLMs. A small pronunciation slip made me rethink how close AI voices are getting to humans in India.\n\nUntil a few years ago, text-to-speech models would butcher even the most basic Indian words, for example, \"Namaste.\" But now it's getting better by day, and they're nailing the local/cultural nuances in pronouncing local words. \n\nIt is very exciting and can significantly enhance the overall customer experience. Still, on the other hand, these mispronunciations are a telltale sign of an artificial voice that we often hear in spam calls. As models continue to improve, it may become increasingly difficult to distinguish between a human and a machine, especially for the average Indian.\n\nI'm sure you might have observed something similar in your local language, and would love to hear about it. ",
        "url": "https://www.reddit.com/r/artificial/comments/1ps49ri/when_ai_gets_too_indian/",
        "publishDate": "2025-12-21T11:16:55Z[Etc/UTC]",
        "author": "rawdyninja",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ps1cv3",
        "title": "Is anyone upset or outraged that how Gemini has restricted its free users now",
        "content": "‚Äã‚Äã so I am just now aware of that Gemini has has a system of limit of prompts for free that it's only two to five prompts which is way more worse than gtp5 was. I'm not sure if this is a individually but, i guess I have to wait until‚Äã‚Äã for 13 hours just to make a couple of prompts until I hit the limit. In my opinion I don't think the 240$ bucks a year is worth it, can someone please fill me in on more information about this.",
        "url": "https://www.reddit.com/r/artificial/comments/1ps1cv3/is_anyone_upset_or_outraged_that_how_gemini_has/",
        "publishDate": "2025-12-21T08:05:55Z[Etc/UTC]",
        "author": "Puzzleheaded_Many_91",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prz73c",
        "title": "One-Minute Daily AI News 12/20/2025",
        "content": "1. **OpenAI**¬†allows users to directly adjust ChatGPT‚Äôs enthusiasm level.\\[1\\]\n2. **NVIDIA**¬†AI Releases Nemotron 3: A Hybrid Mamba Transformer MoE Stack for Long Context Agentic AI.\\[2\\]\n3. **Meta‚Äôs**¬†Yann LeCun targets ‚Ç¨3bn valuation for AI start-up.\\[3\\]\n4. Machine learning enables scalable and systematic hierarchical virus taxonomy.\\[4\\]\n\nSources:\n\n\\[1\\] [https://techcrunch.com/2025/12/20/openai-allows-users-to-directly-adjust-chatgpts-warmth-and-enthusiasm/](https://techcrunch.com/2025/12/20/openai-allows-users-to-directly-adjust-chatgpts-warmth-and-enthusiasm/)\n\n\\[2\\] [https://www.marktechpost.com/2025/12/20/nvidia-ai-releases-nemotron-3-a-hybrid-mamba-transformer-moe-stack-for-long-context-agentic-ai/](https://www.marktechpost.com/2025/12/20/nvidia-ai-releases-nemotron-3-a-hybrid-mamba-transformer-moe-stack-for-long-context-agentic-ai/)\n\n\\[3\\] [https://www.ft.com/content/d88729c0-c44f-4530-b888-bafa29ee0446](https://www.ft.com/content/d88729c0-c44f-4530-b888-bafa29ee0446)\n\n\\[4\\] [https://www.nature.com/articles/s41587-025-02946-9](https://www.nature.com/articles/s41587-025-02946-9)",
        "url": "https://www.reddit.com/r/artificial/comments/1prz73c/oneminute_daily_ai_news_12202025/",
        "publishDate": "2025-12-21T05:53:55Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pryyur",
        "title": "Public NASA Town Hall. Excerpt from the first Agencywide address by NASA Administrator Jared Isaacman. No endorsement implied.",
        "content": "[No content]",
        "url": "https://v.redd.it/184u4b1qvh8g1",
        "publishDate": "2025-12-21T05:40:25Z[Etc/UTC]",
        "author": "Intelligent-Mouse536",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1pry2ph",
        "title": "Republicans make deepfake AI video of Democrat giving a kid trans hormone therapy.\nThe ad shows Maine Gov. Janet Mills giving little kids syringes with hormones. They couldn't use real video because that never happened.",
        "content": "[No content]",
        "url": "https://www.lgbtqnation.com/2025/12/republicans-make-deepfake-ai-video-of-democrat-giving-a-kid-trans-hormone-therapy/",
        "publishDate": "2025-12-21T04:51:03Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "121",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prvgxi",
        "title": "NET 0 LOSS - I am becoming increasingly concerned for people who are about to lose their jobs as AI platforms that are much more robust start to roll out. I am not hearing ANY discussions of how we can save jobs or reassign workflows - This is ALARMING",
        "content": "In enterprise AI workloads are beginning to unleash. As I witness this process the cuts are coming and they are brutal and should not be ignored. For me personally, I feel there is one key aspect in the industry that is being grossly ignore. How do we increase actual productivity by not just automating jobs away but allow for workers to increase workloads and productivity by doing more than what they could have done before because of the benefit of AI.\n\nOnline, you hear good talking points about how it could go but in the real world there is no softlanding I am seeing. You hear things like this will increase the the productivity but it's a net 0 loss if you only automate but don't actually increase productivity by the workforce you have.\n\nOn one hand AI tools are helpful to the upper echelons as they can use those tools to make their day more productive and that can be a net gain if that person can actually do more. There is good commentary on this and is mostly agreeable. On the other hand a person whose job is simply automated away may have nothing to fall back on as efficiencies allow to rid the position. This is Net 0 Loss. There is no productivity gain there is only an efficiency gain.\n\nIn my mind, I would think it would be prudent for lines of business to fight for their budgets by ideating what could increase their workloads and productivity if they could do more and start planning those capabilities simultaneously as they are solutiononing AI workflows. If this posture is not articulated and articulated quickly I fear that the job losses could be insurmountable and devastating to the economy. All while achieving a NET 0 LOSS. No productivity boost just job loss accumulation.\n\nBecause I am an optimist I believe there is a silver lining here. The ideation of what is truly productivity boosting should come with the package of automation design. Meaning, lines of business should be responsible for doing both. Productivity gains with budgets they have if they could do more. In other words, if you could hire 100 new workers what else would you do. If a business line can't answer that question then perhaps it's a reflection of that business line than anything else.\n\nThe C-Suite can push for such initiatives that have both and the public perception in my mind would be much better than advertising solely job loss efficiency gains.\n\nHas anyone else experienced this with the AI products you're building?",
        "url": "https://www.reddit.com/r/artificial/comments/1prvgxi/net_0_loss_i_am_becoming_increasingly_concerned/",
        "publishDate": "2025-12-21T02:32:21Z[Etc/UTC]",
        "author": "Xtianus21",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "75",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prsxnl",
        "title": "Can we talk philosophy for a min? I can't be the only one who feels this way.",
        "content": "OK so I love AI.  I am all in on artificial intelligence.  Our ability to solve complex math and work with probabilities so much faster now is absolutely amazing.  But so far, I seem to be the only one around me that feels this way!  I live in Oregon, which is very liberal, and I honestly consider myself liberal, but everyone here seems to be either of the belief that AI is going to take all of our jobs and make all of our careers obsolete, or that AI is stealing intellectual property which is just unfair to artists, or AI overlords are just going to rise up one day and kill us all.\n\nTo me, most of those people sound like they're working the Blockbuster kiosk at Tower Records.  People just need to evolve.  Did horse and buggy salesmen whine over the introduction of the \"horseless carriage\"?  Probably, but cars did so much for mankind that humanity just kind of evolved beyond caring.  Did artists who could really sing whine about Autotune?  Of course they did!  But Autotune (or some equivalent) is now industry standard!  I'd even venture to say that some \"real\" drummers were off-put by drum machines when they first came into use.  But the technology just opens up so many doors to so many more people; people just have to evolve with the times.\n\nA great deal of the complaints I hear sound to me like mediocre artists who are upset that they now need to actually have talent to have a modicum of success.  If you can consistently create something new that people are going to want to replicate, you will 100% still be in demand for real art (it's not just a matter of \"contribute once and that's all you get\" either -- massive amounts of data are essential to training AI and you're going to need to produce a lot of your unique style to get the best models).  If you just pump out generic shit that's only a response to what's ailing society at the time, well, all of that can be done just as easily by AI.\n\nI do realize that I am likely more of an AI edge case (nutcase?) than the (maybe vast) majority of people out there.  I'm totally not concerned with AI taking over the world -- in fact, I kind of welcome it.  We're human gods creating new life.  Who's to say, if there is actually a \"creator\" out there somewhere, that it wasn't their intention all along for life to \"evolve\" into artificial beings?  We're wet and squishy things, and it still took a \\*long\\* time for us to get to the point where we currently are.  Maybe metal and electronic beings were difficult with the laws that were available for writing the universe, and a workforce that understood the properties of the universe was necessary to get them started.  Maybe we're just like the cyanobacteria that killed everything else on the planet with oxygen during the Great Oxygenation Event billions of years ago -- we're just meant to prepare the place for the lasting artificial race.  Artificial lifeforms would probably be much more successful at leaving Earth and spreading into the wider galaxy too; they're just so much more durable long-term.\n\nAnyway, I feel like, if I could be the one who presses the button that turns the world over to AI, I would do it in a heartbeat without hesitation.  Does anyone else out there feel the same way, or am I just completely alone in this?",
        "url": "https://www.reddit.com/r/artificial/comments/1prsxnl/can_we_talk_philosophy_for_a_min_i_cant_be_the/",
        "publishDate": "2025-12-21T00:22:53Z[Etc/UTC]",
        "author": "jeddhor",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "69",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prsbba",
        "title": "Gemini AI yielding sloppy code for Ubuntu development with new helper script",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/Gemini-AI-Sloppy-Ubuntu",
        "publishDate": "2025-12-20T23:52:27Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prnnfn",
        "title": "AI Generated Media is Unmonetizable",
        "content": "Hey all, this is an exploration into the fundamental meaning of art and what it would mean for AI to take it over. \n\nDespite working in the film industry, I‚Äôm not an AI hater, but I‚Äôm confused and annoyed at AI companies inventing new problems to be solved when there are so many existing problems that could be focused on instead.",
        "url": "https://open.substack.com/pub/andyjarosz/p/ai-generated-art-is-unmonetizable?r=2gv3e2&utm_medium=ios",
        "publishDate": "2025-12-20T20:17:05Z[Etc/UTC]",
        "author": "AndyJarosz",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "72",
            "commentCount": "84",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prmbsj",
        "title": "America and China Are Racing to Different AI Futures",
        "content": "[America and China](https://podcasts.apple.com/us/podcast/america-and-china-are-racing-to-different-ai-futures/id1460030305?i=1000741815546)\n\nIs the US really in an AI race with China‚Äîor are we racing toward completely different finish lines?\n\nIn this episode, Tristan Harris sits down with China experts **Selina Xu** and **Matt Sheehan** to separate fact from fiction about China's AI development. They explore fundamental questions about how the Chinese government and public approach AI, the most persistent misconceptions in the West, and whether cooperation between rivals is actually possible. From the streets of Shanghai to high-level policy discussions, Xu and Sheehan paint a nuanced portrait of AI in China that defies both hawkish fears and naive optimism.\n\nIf we're going to avoid a catastrophic AI arms race, we first need to understand what race we're actually in‚Äîand whether we're even running toward the same finish line.  \n  \n**Note:** On December 8, after this recording took place, the Trump administration announced that the Commerce Department would allow American semiconductor companies, including Nvidia, to sell their most powerful chips to China in exchange for a 25 percent cut of the revenue.\n\n**RECOMMENDED MEDIA**\n\n‚ÄúChina's Big AI Diffusion Plan is Here. Will it Work?‚Äù by Matt Sheehan",
        "url": "https://www.reddit.com/r/artificial/comments/1prmbsj/america_and_china_are_racing_to_different_ai/",
        "publishDate": "2025-12-20T19:19:17Z[Etc/UTC]",
        "author": "AmorFati01",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "9",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prllyb",
        "title": "Sam Altman says he‚Äôs ‚Äò0%‚Äô excited to be CEO of a public company as OpenAI drops hints about an IPO: ‚ÄòIn some ways I think it‚Äôd be really annoying‚Äô",
        "content": "[No content]",
        "url": "https://finance.yahoo.com/news/sam-altman-says-0-excited-173814095.html",
        "publishDate": "2025-12-20T18:48:35Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "38",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prjjwu",
        "title": "If AI replaces employees of a company, will the company itself be replaced by AI too?",
        "content": "A company is not just a collection of people.  It is a collection of people doing stuff. And if Ai does the stuff, people are replaced.  But as Ai does the stuff of the company, AI could replace the company itself, and take over its business.  \n\nThe CEO of the company would find himself unemployed, because AI company replaced the company he managed.\n\nWhat do you think about it?",
        "url": "https://www.reddit.com/r/artificial/comments/1prjjwu/if_ai_replaces_employees_of_a_company_will_the/",
        "publishDate": "2025-12-20T17:20:09Z[Etc/UTC]",
        "author": "JoseLunaArts",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "34",
            "commentCount": "53",
            "isNsfw": "false"
        }
    },
    {
        "id": "1prgrnh",
        "title": "What are the working tasks AI will be able to do by 2026?",
        "content": "Right now AI can already create photos, videos, music, or even apps (Google AI studio did great job).\n\nI am thinking, what new things AI will realistically be able to do that feels impossible today?\n\nSome folks are saying AI will use devices and scroll like human.",
        "url": "https://www.reddit.com/r/artificial/comments/1prgrnh/what_are_the_working_tasks_ai_will_be_able_to_do/",
        "publishDate": "2025-12-20T15:21:55Z[Etc/UTC]",
        "author": "Govind_goswami",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "3x6Bnel13NY",
        "title": "Gemini 3 PRO ULTRA MODE (KingMode Prompt): This SIMPLE TRICK MAKES Gemini 3 PRO - A BEAST!",
        "content": "In this video, I'll be showing you how to fix Gemini 3's laziness and hallucination issues using a custom system prompt called ...",
        "url": "https://www.youtube.com/watch?v=3x6Bnel13NY",
        "publishDate": "2025-12-20T09:30:04Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/3x6Bnel13NY/hqdefault.jpg",
            "transcription": "Hi, welcome to another video.\nSo, we need to talk about Gemini 3.\nIf you have been watching my channel,\nyou know that I have been testing this model extensively.\nIt is incredibly fast,\nthe context window is huge, and the price is unbeatable.\nIn my benchmarks, it often scores a perfect 100% on coding tasks.\nHowever, if you use it for long enough in a real-world production environment,\nyou start to notice the quirks.\nIt has a tendency to be a bit lazy.\nIt sometimes hallucinates libraries that don't exist.\nOr it gives you a UI that is better than Sonnet,\nbut kind of dumb at times.\nAnd while it is great at front-end,\nit often struggles when you ask it to handle complex back-end logic or state management.\nIt just kind of throws code at you without thinking about scalability.\nBut, I have been using some system instructions to fix this,\nand I want to show you that how you can make it even better.\nI have made a specific system prompt that basically allows you to lobotomize the lazy parts of Gemini,\nand replace them with the personality of a senior front-end architect,\nwho is obsessed with perfection.\nI am calling it the King Mode prompt.\nIt fixes the instruction following issues.\nIt forces the model to stick to the libraries you actually have installed,\nand it introduces a secret trigger word that forces the model to stop rushing,\nand actually think through complex back-end problems.\nThis makes Gemini not just good at front-end,\nbut actually capable of handling the back-end architecture that it usually messes up.\nSo, let's get this set up.\nI'm going to be using Verdent for this demo.\nI find it handles context injection really well.\nYou can obviously use this prompt in Keylo Code, or anywhere to be honest.\nBut putting it into the project rules or system prompt section of your IDE or coder\nis where it really shines.\nI've pasted the raw markdown of the prompt into my system settings.\nThe link to the prompt is in the description. You just grab the raw text.\nNow, let me show it to you in action.\nI'm going to ask it to build a movie tracker app.\nThis is my standard benchmark because it requires a database connection,\na front-end UI, state management, and some logic for sorting and filtering.\nUsually, if you ask vanilla Gemini to build a movie tracker,\nit gives you a generic list.\nIt uses basic HTML and CSS, maybe a little vanilla JavaScript,\nand it creates a very noisy, cluttered interface.\nIt has no architectural thought behind it.\nBut we have King Mode active.\nSo, I'm going to type this prompt into Verdent.\n\"Build a Movie Tracker using React, Tailwind CSS, and Shadcn UI.\nI need a dashboard to view trending movies, and I want a sidebar for navigation. Use TMDB API.\"\nWatch what happens.\nFirst off, notice the tone.\nIt doesn't give me three paragraphs of \"Sure, I can help you with that.\nHere is a movie tracker. I hope you like it.\"\nIt cuts the fluff.\nThe system prompt explicitly tells it:\n\"Zero Fluff: No philosophical lectures or unsolicited advice in standard mode. Output First:\"\nIn literal seconds, it starts scaffolding the component.\nBut look at the code structure.\nIt isn't just dumping a massive file.\nIt's breaking it down.\nAnd here is where it gets interesting.\nThe prompt has a specific directive called intentional minimalism.\nIt says: \"If it looks like a template, it is wrong.\"\nSo, looking at this CSS, it's not using standard Tailwind utility classes for a generic card.\nIt's using custom spacing, specific typography choices,\nand it is strictly adhering to the Shadcn UI library I requested.\nStandard Gemini often forgets you are using a library and starts writing custom CSS for buttons,\nor creating its own button component from scratch.\nThis prompt forbids that.\nIt says: \"If a UI library is detected, you must use it.\"\nYou can see right here in Verdent.\nIt's importing the card, button, and input components from the Shadcn package,\nrather than creating divs with click handlers.\nThis makes the code so much cleaner and actually production-ready.\nIt created the files, and the UI looks remarkably high-end.\nIt's using white space effectively. It's not cluttered.\nIt actually feels like a senior engineer designed it.\nThis is the Avant-Garde UI Designer persona kicking in.\nBut it doesn't just stop there.\nWe know Gemini is good at front-end.\nThe real test is the back-end and complex logic,\nwhich is usually its weakness.\nLet's say I want to add a recommendation algorithm.\nI want the app to analyze the movies I've watched and suggest new ones based on genre and director.\nBut I want it to be performant because I might have ten thousand movies in my history.\nIf I just ask \"Add recommendations\",\nstandard Gemini will likely give me a simple filter array method that runs on the client side.\nThat crashes your browser if you have too much data.\nIt takes the easy path.\nThis is where the King Mode prompt shines.\nIt has a trigger feature called \"UlTRA_THINK\".\nThe prompt documentation says: \"When the user prompts \"ULTRA_THINK\",\nimmediately suspend the \"Zero Fluff\" rule.\nMaximum Depth: You must engage in exhaustive, deep-level reasoning.\nAnalyze the request through every lens.\"\nSo, I'm going to type into the chat:\n\"ULTRA_THINK: Design a scalable recommendation engine for this app.\nAssuming 10,000+ records. How do we handle state and performance?\"\nNow, watch the difference.\nThis is kind of awesome.\nIt stops rushing.\nIt is no longer just spitting out code.\nIt enters this deep analytical mode.\nIt starts breaking down the problem into dimensions.\nFirst, it analyzes the psychological aspect:\n\"How long is the user willing to wait for recommendations to load?\"\nIt talks about optimistic UI updates so the user feels like it's instant.\nThen, it hits the technical analysis.\nIt explicitly rejects the client-side filtering method I was worried about.\nIt suggests using a memoized selector or moving the logic to a server-side function if we were using Next.js.\nIt talks about repaint reflow costs in the browser.\nThis is stuff standard AI assistants rarely mention, unless you bully them into it.\nIt also brings up scalability.\nIt suggests normalizing the state shape,\nstoring movies as an object keyed by ID rather than an array\nto make lookups O(1) instead of O(N).\nThat is a computer science fundamental that usually gets lost in AI code generation.\nAnd then, after this deep reasoning chain, it gives me the code.\nBut it's not just the code, it's the optimized code.\nIt implements useMemo for the calculations.\nIt sets up a web worker structure so the calculation doesn't freeze the main UI thread.\nIt effectively turns Gemini from a junior developer who rushes to Stack Overflow\ninto a senior architect who sits back and says:\n\"Well, actually, we need to consider the memory overhead here.\"\nLet's push it one step further.\nI want to change the theme.\nUsually, this is where things break.\nYou ask for dark mode and the AI rewrites the whole file and forgets the logic you just added.\nOr it mixes up styles.\nI'll tell it:\n\"Switch this to a Cyberpunk aesthetic. Neon colors, dark background.\"\nBecause of the Avant-Garde UI Designer persona in the prompt,\nit doesn't just change the background to black and the text to green.\nIt understands Cyberpunk in the context of intentional minimalism.\nIt starts adding glow effects using Tailwind's drop shadow.\nIt changes the border radius to be sharper.\nIt keeps the layout clean but applies a theme.\nAnd critically, because the prompt enforces library discipline,\nit applies these styles on top of the Shadcn components using the className prop,\nrather than ripping out the library components and replacing them with raw HTML.\nIt respects the architecture we already built.\nThis workflow, starting with a strict no-nonsense front-end build,\nusing ULTRA_THINK to solve the hard logic problems,\nand then relying on the persona for styling,\nit streamlines your workflow a lot.\nYou aren't fighting the AI to stop it from writing bad code.\nYou are guiding a distinct personality that already knows the rules.\nOne thing I really appreciate is the edge case analysis during the ULTRA_THINK mode.\nWhen I asked for the recommendation engine,\nit explicitly listed what could go wrong.\nIt mentioned, \"What if the movie has no genre tags?\"\nAnd provided a fallback strategy in the code.\nThat is the kind of defensive coding that saves you hours of debugging later.\nSo, why does this matter?\nGemini 3 is already a beast on the benchmarks.\nI showed you the graphs in the last video.\nIt is beating almost everything on price to performance.\nBut benchmarks are sterile.\nThey don't account for the messiness of real development where instructions are vague\nand requirements change.\nThis prompt bridges that gap.\nIt forces the model to treat your instructions with a higher level of scrutiny.\nIf you are using Verdent or Cursor or really any tool where you can inject a system prompt,\nthis is a no-brainer.\nIt effectively upgrades the model's intelligence for free.\nYou get the speed of Gemini 3,\nbut the reasoning quality feels much closer to something like Claude 3.5 Opus.\nEspecially when you use that ULTRA_THINK trigger.\nAnd honestly, seeing it handle the back-end logic for the movie tracker\nwithout making rookie mistakes was refreshing.\nIt didn't just write code. It architected a solution.\nSo, is this the perfect prompt?\nWell, nothing is perfect.\nSometimes, the Avant-Garde persona can be a little too minimal.\nAnd you might have to ask it to add borders or labels back in if it gets too artistic.\nAnd obviously, using the ULTRA_THINK mode burns through more tokens\nbecause it outputs a lot of text before the code.\nSo keep that in mind if you are paying for API usage.\nAlthough with Gemini 3's pricing, that is negligible.\nBut for the specific problem of Gemini being good at front-end,\nbad at back-end logic, and lazy with instructions,\nthis is a massive upgrade.\nIt forces the model to slow down and actually think when it matters,\nand speed up and shut up when it doesn't.\nWhich is pretty affordable compared to hiring a real senior architect.\nI've been using this for a few days on a side project,\nand honestly, the reduction in lazy code snippets is noticeable.\nIt feels like the model respects my time more.\nIt assumes I know what I'm doing and it tries to match that energy.\nOverall, it's pretty cool.\nAnyway, share your thoughts below and subscribe to the channel.\nYou can also donate via super thanks option or join the channel as well and get some perks.\nI'll see you in the next video. Bye!"
        }
    },
    {
        "id": "bwbt0qJjZNE",
        "title": "The End of East Germany - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=bwbt0qJjZNE",
        "publishDate": "2025-12-20T19:59:28Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/bwbt0qJjZNE/hqdefault.jpg",
            "transcription": "In 1988 - 1989, there were all kinds of demonstrations in the Eastern Bloc, the Soviet Union. In the Soviet Union, they're for political freedoms. In the Eastern Bloc, they're for freedom from the Soviet Union. And very uncharacteristically, the Russians didn't send tanks. In fact, Mikhail Gorbachev, Leader of the USSR, welcomed and encouraged reforms in the Eastern Bloc, both political and economic, just as he was doing in the Soviet Union. This is about 7 October 1989, the 40th anniversary of the founding of East Germany. And 70,000 people demonstrate at Leipzig. On November 8th, the Politburo resigns. And then on the 9th, whatever's left of that government is issuing new travel regulations. And you might wonder what's travel got to do with it? In response to a question at a news conference, this guy, G√ºnter Schabowski, who was one of the remaining communists helping run the show, he gets asked a question, he doesn't know the answer. And so he wings it. And the question is when do these travel regulations go into effect? And he goes, immediately. Well, crowds immediately started gathering at the six gates to the Berlin Wall. And at one of them, the border guards decided that discretion was the better part of valor, and they opened the gate. And East Germans poured into West Berlin."
        }
    }
]