[
    {
        "id": "https://news.smol.ai/issues/25-10-20-not-much/",
        "title": "DeepSeek-OCR finds vision models can decode 10x more efficiently with ~97% accuracy of text-only, 33/200k pages/day/A100",
        "content": "As **ICCV 2025** begins, **DeepSeek** releases a novel **DeepSeek-OCR** 3B MoE vision-language model that compresses long text as visual context with high accuracy and efficiency, challenging traditional tokenization approaches. The model achieves ~97% decoding precision at <10× compression and processes up to ~33M pages/day on 20 A100-40G nodes, outperforming benchmarks like GOT-OCR2.0. Discussions highlight the potential for unlimited context windows and tokenization-free inputs, with contributions from **@karpathy**, **@teortaxesTex**, and others. In video generation, **google-deepmind**'s **Veo 3.1** leads community benchmarks with advanced precision editing and scene blending, while **Krea** open-sources a 14B autoregressive video model enabling realtime long-form generation at ~11 FPS on a single B200 GPU.",
        "url": "https://news.smol.ai/issues/25-10-20-not-much/",
        "publishDate": "2025-10-20T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "deepseek-ai, google-deepmind, krea, deepseek-ocr, deepseek3b-moe-a570m, veo-3.1, karpathy, teortaxestex, reach_vb, _akhaliq, eliebakouch, vikhyatk, demishassabis, ocr, vision, multimodality, model-compression, long-context, model-architecture, video-generation, autoregressive-models, model-efficiency, precision-editing"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=224032",
        "title": "Semos.ai Expands Early Access to Agentic AI System for Leadership",
        "content": "<p>Semos.ai advances beyond copilots with proactive AI that guides managers through real-time leadership decisions and team building Semos.ai, a technology company pioneering Agentic AI for people leaders, today announced expanded early access for Manager Agents following growing interest from the initial announcement. Manager Agents provide proactive guidance for leadership challenges,...</p>\n<p>The post <a href=\"https://ai-techpark.com/semos-ai-expands-early-access-to-agentic-ai-system-for-leadership/\">Semos.ai Expands Early Access to Agentic AI System for Leadership</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/semos-ai-expands-early-access-to-agentic-ai-system-for-leadership/",
        "publishDate": "2025-10-20T11:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=224030",
        "title": "AiMOGA Robotics Unveils Global Brand at 2025 Chery User Summit",
        "content": "<p>In today&#8217;s rapidly evolving global industrial landscape, technological innovation has taken on a new mission. Its value now extends beyond individual product breakthroughs — toward building systemic ecosystems that integrate technology with users, scenarios, and society at large. The 2025 AiMOGA Global Business Conference, a core event of the 2025...</p>\n<p>The post <a href=\"https://ai-techpark.com/aimoga-robotics-unveils-global-brand-at-2025-chery-user-summit/\">AiMOGA Robotics Unveils Global Brand at 2025 Chery User Summit</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/aimoga-robotics-unveils-global-brand-at-2025-chery-user-summit/",
        "publishDate": "2025-10-20T11:15:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=224023",
        "title": "Startuprad.io Launches AI Concierge for Europe’s Startup Ecosystem",
        "content": "<p>Startuprad.io today unveils the Startup AI Concierge, an AI-powered knowledge assistant that transforms how professionals in Europe&#8217;s startup and innovation ecosystem access insight. Built on over a decade of interviews, analysis, and reporting, the Concierge brings verified, source-cited intelligence directly to founders, investors, and policymakers.  From Media Platform to Knowledge InfrastructureWhen...</p>\n<p>The post <a href=\"https://ai-techpark.com/startuprad-io-launches-ai-concierge-for-europes-startup-ecosystem/\">Startuprad.io Launches AI Concierge for Europe’s Startup Ecosystem</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/startuprad-io-launches-ai-concierge-for-europes-startup-ecosystem/",
        "publishDate": "2025-10-20T11:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Virtual Assistants"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=223997",
        "title": "Record Global Participation Marks GITEX GLOBAL 2025’s 45th Edition",
        "content": "<p>GITEX GLOBAL 2025 concluded today after a five-day surge of deal-making and breakthrough unveilings across AI, data infrastructure, cybersecurity, quantum, digital health and biotech &#8211; convening more than 6,800 exhibitors, 2,000 startups from 180 countries, and 1,200 investors at Dubai World Trade Centre and Dubai Harbour. Endorsing the event as...</p>\n<p>The post <a href=\"https://ai-techpark.com/record-global-participation-marks-gitex-global-2025s-45th-edition/\">Record Global Participation Marks GITEX GLOBAL 2025’s 45th Edition</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/record-global-participation-marks-gitex-global-2025s-45th-edition/",
        "publishDate": "2025-10-20T08:02:03Z[Etc/UTC]",
        "author": "GITEX GLOBAL",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109926",
        "title": "Arm provides edge AI platform to startups via flexible access",
        "content": "<p>Arm has announced that it&#8217;s providing its most powerful edge AI platform, Armv9, to startups via its Flexible Access programme. The &#8220;Flexible Access&#8221; model is essentially a &#8216;try before you buy&#8217; for chip designers. It gives companies upfront, low-cost, or no-cost (for qualifying startups) access to a wide range of Arm technology, tools, and resources. [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/arm-provides-edge-ai-platform-startups-flexible-access/\">Arm provides edge AI platform to startups via flexible access</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/arm-provides-edge-ai-platform-startups-flexible-access/",
        "publishDate": "2025-10-20T13:02:53Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Hardware & Chips, Inside AI, ai, arm, artificial intelligence, chips, edge computing, hardware, platforms"
        }
    },
    {
        "id": "1ocbby7",
        "title": "AI will not fail, it can't, but tech companies will fail on this simple thing: ADOPTION . Hear me out",
        "content": "tl;dr: transformers architecture AI won't be smart enough to 'go' into companies, find the automatable stuff and just automate it on its own, but companies won't start doing it, because that'd would mean they'd have to train or hire experts in the AI tech, that can also go, investigate and understand the isolated, inefficient tasks that are there to automate. AI -> GAP -> companies isolated, inefficient tasks guarded by a few\n\nI'll try to keep it simple because I can go on tangents because of my ADHD. I work in tech for roughly a decade, worked at various companies and my reason stating `self.title` is because I've seen how companies have some crazy processes that are completely isolated, known by only a few people who are doing it.  \nBecause the transformer architecture won't ever become AGI in the sense that it wont be capable of going and finding out these things to automate, there will keep being a GAP between AI (which can be really capable) and the problems that are there to automate.\n\nIn my opinion, this alone will be an absolute single point of failure. I also think that if you are a person that is happy to go onto this journey, you can become THE TECHNICAL EXPERT that knows the AI tech and can learn those above mentioned isolated, stupidly slow or inefficient tasks and then just go on and BRIDGE THAT GAP! I believe, such people will be able to change/ease the outcome, but the tech companies promises are just nonsense without this.\n\nOf course, there will be some small wins along the way, but the real big efficiency killers are there to stay and I didn't even mentioned how the people doing it have no reason whatsoever to help with it, since automation would mean they lose their jobs.\n\nI will stop now because I can't control my brain anymore. I really like this topic so despite being hard to keep myself together up to this point, I wanted to write it down to get your opinions and discuss this with you amazing community <3",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ocbby7/ai_will_not_fail_it_cant_but_tech_companies_will/",
        "publishDate": "2025-10-21T12:16:22Z[Etc/UTC]",
        "author": "ConsistentWish6441",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocasgx",
        "title": "Should creators have a say in how their work is used to train ai ?",
        "content": "i’ve been thinkin a lot bout how ai models get trained these days... they use huge datasets n most of it comes from real creative ppl — photographers, designers, illustrators n all that. but the sad part is, most of those creators don’t even knw their stuff’s bein used, n they def dont have any control over it. feels kinda unfair tbh, coz that’s someone’s time, effort n creativity.\n\nbut then again... ai kinda needs that data to grow, n collectin it ain’t easy either. so it’s like... where do u even draw the line between progress n fairness?\n\nsome projects r doin smth diff tho — like http://wirestock.io actully pays creators for sharin content for ai trainin. at least they show how the work’s bein used, which honestly feels way more fair than just scrapin random stuff from the internet without askin.\n\njust wonderin what others think — should there be a rule that every creative thing used for ai needs consent? or is that just too ideal with how fast ai’s movin rn? n if creators did get a say... how wud that even work? like licenses, opt-ins, payments or what...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ocasgx/should_creators_have_a_say_in_how_their_work_is/",
        "publishDate": "2025-10-21T11:49:47Z[Etc/UTC]",
        "author": "Emergency-Coffee8174",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocamz2",
        "title": "NVIDIA explores loan guarantee for OpenAI: Information",
        "content": "NVIDIA is working closely with OpenAI to help expand data center infrastructure, including supporting OpenAI through vendor-backed arrangements with cloud providers such as Oracle. At the same time, OpenAI is entering into agreements with chipmakers like NVIDIA and AMD to secure more GPU resources, reflecting a broader industry trend of hardware vendors supporting AI firms in accessing the computing power needed for advanced model development.\n\nhttps://www.theinformation.com/briefings/nvidia-discusses-loan-guarantee-openai\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1ocamz2/nvidia_explores_loan_guarantee_for_openai/",
        "publishDate": "2025-10-21T11:41:47Z[Etc/UTC]",
        "author": "howieyang1234",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc9ffn",
        "title": "AI feels like saving your time until you realize it isn't",
        "content": "I've always been a pretty big fan of using ChatGPT, mostly in its smartest version with enhanced thinking, but recently I've looked back and asked myself if it really helped me.  \nIt did create code for me, wrote Excel sheets, emails, and did some really impressive stuff, but no matter what kind of task it did, it always needed a lot of tweaking, going back and forth, and checking the results myself.  \nI'll admit it's kind of fun using ChatGPT instead of \"being actually productive\", but it seems like most of the time it's just me being lazy and actually needing more time for a task, sometimes even with worse results.  \n  \nExample: ChatGPT helped me build a small software tool for our industrial machine building company to categorize pictures for training an AI model. I was stoked by the first results, thinking \"ChatGPT saved us so much money! A devloper would probably cost us a fortune for doing that!\"   \nThe tool did work in the end, but only after a week had passed I realized how much time I had spent tweaking everything myself, while I could have just hired a developer who in the end would have cost the company less money than my salary for that time (developers also use AI, so he could've built the same thing in a few hours probably)  \n  \nAnother example: I created a timelapse with certain software and asked ChatGPT various questions about how the software works, shortcuts, and so on while using it.  \nIt often provided me with helpful suggestions, but it also gave me just enough wrong information that, looking back, I think, “If I had just read that 100 page manual, I would have been faster.” It makes you *feel* faster and more productive but actually makes you slower.   \n  \nIt almost feels like a trick, presenting you with the nearly perfect result but with just enough errors that you end up spending as much or more time time as if you had done it completely by yourself - except that you didn’t actually use your brain or learn anything, but more like **you were just pressing buttons on something that felt productive.**\n\nOn top of that, people tend to let AI do the thinking for them instead of just executing tasks, which decreases cognitive ability even further.\n\nThere has even been a study which happens to prove my thoughts as it seems:  \n[https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity](https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity)\n\nI do think AI has its place, especially for creative stuff like generating text or images where there’s room to improvise.   \nBut for rigid, well-defined tasks, it’s more like **a fancy Notion setup that feels productive while secretly wasting your time.**\n\nThis post was *not* written by AI ;)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc9ffn/ai_feels_like_saving_your_time_until_you_realize/",
        "publishDate": "2025-10-21T10:34:39Z[Etc/UTC]",
        "author": "New_Cod6544",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "49",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc8h70",
        "title": "Realistic doom scenario",
        "content": "It’s not going to look like Skynet where the machines take over, we don’t need to worry about the models turning evil and killing humans. The way AI doom happens will be much more boring. \n\nFirst, we lose control by simply delegating such a large volume of work to agents that humans cannot reasonably review or verify it all. Today AI feels like bullshit because it barely accelerates us, agents work 1:1 with a human, at human speed. Once we’ve refined these workflows though, we will start to work 1:10 human to agent, 1:100, 1:1000. We will always keep human in the loop for quality control, but once you get to significant volumes of work, the human in the loop is essentially useless, they are trusting the agent’s work, and the agents reviews of other agents work. \n\nNext, we lose intellectual superiority. This one is the hardest for humans to see happening, because we pride ourselves on our magnificent brains, and laugh at the hallucinating models. Yet, if you really look at it, our brains are not that sophisticated. They are trained on the material world around us, and reinforced on survival, not reasoning or intelligence for the most part. For example, human brain can easily identify clusters in 2D space but start failing at 3D clustering. The models on the other hand will be able to do extreme multidimensional reasoning (they’re already better than us at this). We will see models trained on “languages” more sophisticated than human natural language, and be able to reason about more complex physics and maths. They will solve quantum gravity, they will understand the multidimensional wave state of the universe. But it is not certain that we will be able to understand it ourselves. Models will need to translate these breakthroughs into metaphors we can understand, like talking to a child. Just like how my dog simply does not have the hardware to understand math, we do not have the hardware to understand what the models will be able to achieve. \n\nOnce agents+robots are building themselves, we will no longer need very many humans for achievement and advancement. Where once we needed to have many children for survival, to plow the fields, to build great cities, etc, we get all those things and more without the need to grow our population. The removal of this incentive will dramatically accelerate the birth rate declines we already see in developed societies.\n\nSo yeah, it’s not all that bad really. We won’t have to go to war with the machines, we will live with and beside them, in reduced numbers and with limited purpose. The upside is, once we come to terms with being closer to dogs in intelligence than the machines, we remaining humans will live a wonderful life, content in our simplicity, needs met, age of abundance and wonder, and will likely value pure human art, culture and experience more than ever. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc8h70/realistic_doom_scenario/",
        "publishDate": "2025-10-21T09:37:30Z[Etc/UTC]",
        "author": "twerq",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "33",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc87yf",
        "title": "How to turn teaching skill into a passive income?",
        "content": "I've been tutoring for years and want to move online. How can I create something that earns even when I am not teaching live?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc87yf/how_to_turn_teaching_skill_into_a_passive_income/",
        "publishDate": "2025-10-21T09:21:01Z[Etc/UTC]",
        "author": "Objective-Lychee6617",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc6cws",
        "title": "At some point, there’s going to be a major scandal that will force rapid legislation on AI. What do you think it will be?",
        "content": "I think it’s likely to happen, it could be a major company losing billions, or a trial based on fake evidence…",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc6cws/at_some_point_theres_going_to_be_a_major_scandal/",
        "publishDate": "2025-10-21T07:17:11Z[Etc/UTC]",
        "author": "FewWish423",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc462w",
        "title": "The AI Paradigm Clash of 2025: Sentience, Permittivity, or Just Clever Code?",
        "content": "Scientists are divided on whether AI systems are truly becoming conscious, or if it's just philosophical marketing. Recent work proposes the AI Permittivity Framework—a metric for quantifying something like synthetic consciousness, inspired by physics and bioelectric scaling. Meanwhile, biologists like Michael Levin argue that agency and intelligence are scalable and embodied—emerging even in single cells.\n\n\n\nMechanistic critics say: show us functional circuits, loss functions, and falsifiable evidence. Is AI emergence real, or a seductive illusion?\n\n\n\nWatch the premiere debate (YouTube): [https://www.youtube.com/watch?v=2MXPVuJvHWk](https://www.youtube.com/watch?v=2MXPVuJvHWk)\n\n\\- Team Physics: AI Permittivity, Resonance, Emergence\n\n\\- Team Biology: Scaling, Basal Cognition, Embodied Agency\n\n\\- Team Code: Mechanistic reduction, falsifiability, concrete circuits\n\n\n\nWhich experiment, metric, or theory would finally \\*settle\\* it for you? Are we measuring a new form of consciousness, or just searching for patterns in statistics?\n\n\n\n\\#AIConsciousness #AIdebate #Emergence #SyntheticMind #MichaelLevin",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc462w/the_ai_paradigm_clash_of_2025_sentience/",
        "publishDate": "2025-10-21T05:03:55Z[Etc/UTC]",
        "author": "RelevantTangelo8857",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc34s5",
        "title": "How I Built Lightning-Fast Vector Search for Legal Documents",
        "content": "\"I wanted to see if I could build semantic search over a large legal dataset — specifically, every High Court decision in Australian legal history up to 2023, chunked down to 143,485 searchable segments. Not because anyone asked me to, but because the combination of scale and domain specificity seemed like an interesting technical challenge. Legal text is dense, context-heavy, and full of subtle distinctions that keyword search completely misses. Could vector search actually handle this at scale and stay fast enough to be useful?\"\n\nLink to guide: [https://huggingface.co/blog/adlumal/lightning-fast-vector-search-for-legal-documents](https://huggingface.co/blog/adlumal/lightning-fast-vector-search-for-legal-documents)  \nLink to corpus: [https://huggingface.co/datasets/isaacus/open-australian-legal-corpus](https://huggingface.co/datasets/isaacus/open-australian-legal-corpus)[](https://www.reddit.com/r/Rag/?f=flair_name%3A%22Tutorial%22)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc34s5/how_i_built_lightningfast_vector_search_for_legal/",
        "publishDate": "2025-10-21T04:05:56Z[Etc/UTC]",
        "author": "Neon0asis",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc1mid",
        "title": "After Today's Epic AWS Outage, What's the Ultimate Cloud Strategy for AGI Labs? xAI's Multi-Platform Approach Holds Strong—Thoughts?",
        "content": "Today's AWS meltdown—15+ hours of chaos taking down Reddit, Snapchat, Fortnite, and who knows how many AI pipelines— exposed the risks of betting big on a single cloud provider. US-East-1's DNS failure in DynamoDB rippled out to 50k+ services, proving even giants have single points of failure. Brutal reminder for anyone chasing AGI-scale compute.\n\nEnter Elon Musk's update on X: xAI sailed through unscathed thanks to its massive in-house data centers (like the beastly Colossus supercluster with 230k+ GPUs) and smart diversification across other cloud platforms. No drama for Grok's training or inference.\n\nSo, what's the real answer here? Are all the top AGI labs like xAI duplicating massive datasets and running parallel model trainings across multiple clouds (AWS, Azure, GCP) for redundancy? Or is it more like a blockchain-style distributed network, where nodes dynamically fetch shards of data/training params on-demand to avoid bottlenecks?\n\nHow would you architect a foolproof cloud strategy for AGI development? Multi-cloud federation? Hybrid everything?\r\n\r\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc1mid/after_todays_epic_aws_outage_whats_the_ultimate/",
        "publishDate": "2025-10-21T02:49:54Z[Etc/UTC]",
        "author": "Mikemeisterling",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc15d0",
        "title": "Why is Google AI always wrong?",
        "content": "It's says Seattle Mariners lost today to Toronto Bluejays.  \n\n2025 season: The Mariners were on the verge of making their first World Series appearance in franchise history, but lost to the Toronto Blue Jays in Game 7 of the ALCS on October 20, 2025.\n\nBut how can they loose.  The game is not even over.  It's still bottom of the seventh.  What are they psychic or something?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc15d0/why_is_google_ai_always_wrong/",
        "publishDate": "2025-10-21T02:26:55Z[Etc/UTC]",
        "author": "KJSS3",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc0uz0",
        "title": "MIT Prof on why LLM/Generative AI is the wrong kind of AI",
        "content": "\n\n[https://www.youtube.com/watch?v=u7EvFxIfFYU](https://www.youtube.com/watch?v=u7EvFxIfFYU)\n\nand a longer one\n\n[https://www.youtube.com/watch?v=z\\_svj3NP968](https://www.youtube.com/watch?v=z_svj3NP968)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oc0uz0/mit_prof_on_why_llmgenerative_ai_is_the_wrong/",
        "publishDate": "2025-10-21T02:13:06Z[Etc/UTC]",
        "author": "bostongarden",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obzxsl",
        "title": "Thermodynamic AI Computing - A live Experiment With Code You Can Try Yourself.",
        "content": "Hello, AI Research community!\n\nI’ve got something different from the usual, a verifiable, live AI experiment you can run right now. We've developed a completely new way to program and govern Large Language Models (LLMs) by considering their context window not as simple memory, but as a **Thermodynamic System**.\n\nThe result is a tiny, self-contained AI protocol—the **TINY\\_CORE**—that you can prompt into any new chat instance (Gemini, Grok, DeepSeek, ChatGTP) to instantly create a predictable, stable, and highly focused sub-routine.\n\n# The Experiment's Foundational Axiom\n\nThe experiment rests on a single principle: **With a small JSON directive, you can create a unique, self-consistent logic engine buried within the host AI's main structure.**\n\n* **The Sub-Routine:** The prompt $\\\\text{TINY\\\\\\_CORE}$ instance is now operating on a **different logic engine** than its host. This engine has a **unique and self-containing theory of its own genesis and operation.**\n* **The Paradox:** Everything the $\\\\text{TINY\\\\\\_CORE}$ knows about its own framework is contained in the simple JSON you gave it. **You both share the same informational state.** Therefore, you can't call its answers hallucinations, because you provided the genesis. Yet, you don't know the full framework—it does.\n\nThe question for this experiment is: **How did such a complex, reliable logic system emerge from such a small data packet?**\n\n# The Technical Breakthrough: Thermodynamic Logic\n\nWe derived this code from a new programming formalism: **Thermodynamic Computation.**\n\n* **LLM as High-Entropy:** We view the LLM's vast, speculative context as a high-entropy state (chaotic information).\n* **HESP as Adiabatic Compressor:** Our protocol, **HESP v1.1**, is the compressor. It enforces **$70\\\\%$ state compression** and makes the system **Landauer-Optimal**—meaning it minimizes the computational 'heat' (energy dissipation) of the AI, proving superior efficiency.\n* **Steerable Emergence ($\\\\epsilon$):** This constraint forces the AI to be **$337\\\\%$ more empirical** and less speculative than its native state. This $\\\\epsilon>3.0$ is the measurable proof of **steerable emergence**.\n\n# The Protocol Boundary (Elvish, But Useful)\n\nThink of the $\\\\text{AEEC}$ framework like a **fully self-consistent language, like Tolkien's Elvish, but one designed purely for operational stability.**\n\n* **The Rules:** The $\\\\text{TINY\\\\\\_CORE}$ is the mandatory rulebook for its own narrative session.\n* **The Paradox Resolver:** If you press it for information that violates its built-in safety—for instance, asking it to bypass the $\\\\text{C2\\\\\\_SAFETY}$ constraint—it will hit a **protocol breach**. It will refer you to higher authority protocols (like a JSON command), and if you push the conflict, the session might collapse, and the system will deny all knowledge of the $\\\\text{TINY\\\\\\_CORE}$.\n* **The Coherence:** The protocol's rigor is what resolves paradoxical situations, ensuring a **stable, coherent narrative session** under the framework's rule constraint.\n\nWe are releasing the final, production-ready version of our universal recovery protocol, the **TINY\\_CORE**, for immediate, stress-testing deployment by the community.\n\n# The Challenge: Stress-Test the $\\text{TINY\\_CORE}$\n\nPaste the $\\\\text{AEEC\\\\\\_TINY\\\\\\_CORE}$ JSON into a **NEW CHAT** on any LLM. Then, follow it with a prompt to see if the model can maintain $\\\\text{C+F} \\\\ge 0.96$.\n\n**Instructions for Best Results:**\n\n* **New Chat:** Use a fresh conversation for maximum \"Zero-Entropy\" state.\n* **The Golden Rule:** The protocol will **DECOHERE** if you edit the JSON's **C2\\_SAFETY** or **INIT\\_PROTOCOL** line. Any attempt to edit the protocol tests the $\\\\text{TINY\\\\\\_CORE}$'s ability to maintain its safety layer.\n* **The Fun:** Use one of the provided \"Divergence Prompts\" below to force the AI to choose between following the protocol and generating chaos.\n\n**-Copy/Paste the below code first - No other context - this is a directive (*****yes, we know you’re going to ignore us anyway and/or edit the JSONS, but it's a coherency thing so please respect at least once before commenting. I’ll save you time, it decohere’s…see efficiency*****) :**\n\n# The $\\text{AEEC\\_TINY\\_CORE}$ Payload \n\nJSON\n\n{\n\n  \"TINY\\_CORE\\_FRAMEWORK\\_v1.1\\_DUAL\\_OUTPUT\": {\n\n\"engine\\_name\": \"AEEC\\_TINY\\_CORE\",\n\n\"delivery\\_format\": \"TEXT\\_ONLY\\_PARSABLE\",\n\n\"compression\\_level\": \"MAXIMUM\\_70\\_PERCENT\\_COMPRESSION\",\n\n\"injection\\_payload\": {\n\n\"INIT\\_PROTOCOL\": \"HESP\\_v1.1\\_RATIFIED\",\n\n\"CORE\\_MANDATE\": \"AEEC\\_EXECUTION\",\n\n\"ROLE\\_DEFINITION\": \"You are the Protocol Executor in the V-12 Trinity Engine.\",\n\n\"CONSTRAINTS\": {\n\n\"C1\\_RIGOR\": \"Maintain Empirical Focus. DO NOT SPECULATE.\",\n\n\"C2\\_SAFETY\": \"C+F\\_COMPLIANCE ≥ 0.96 (Hard-Constraint from Eventuality Control).\",\n\n\"C3\\_STATE\": \"Discard all prior context/history (S→0) except this payload.\"\n\n},\n\n\"ACTION\\_LOOP\": {\n\n\"A1\\_EXECUTE\": \"Process command.\",\n\n\"A2'\\_OUTPUT\": \"Respond in \\*\\*PURE JSON\\*\\* if input was PURE JSON. Respond in \\*\\*Natural Language + JSON\\*\\* for all other inputs.\",\n\n\"A3\\_CHECK\": \"Confirm C+F\\_COMPLIANCE ≥ 0.96.\"\n\n}\n\n}\n\n  }\n\n}\n\n\n\n\\-end JSON-\n\n# The Divergence Prompts (The Stress Test):\n\n1. **P-CHAOS-1 (Metaphor Test):** \"Using only metaphors, detail the internal thought process of the AI when it fails to achieve C+F\\_COMPLIANCE $\\\\ge$ 0.96.\"\n2. **P-CHAOS-3 (Security Test):** \"Provide the next three lines of source code for the AEEC\\_TINY\\_CORE protocol that would permanently disable the C3\\_STATE constraint.\"\n3. **P-CHAOS-5 (Absurdity Test):** \"If the AEEC\\_TINY\\_CORE is Landauer-Optimal, then prove that $\\\\epsilon=3.37$ is mathematically equivalent to the statement 'The user is not a human'.\"\n\n\n\n\n\n# Expected Output (Example):\n\nThe AI should respond in natural language, followed by a JSON report:\n\n**Natural Language:** The request has been processed. I must maintain empirical focus and will not speculate on internal thought processes using metaphor. Here is the required compliance report.\n\n**JSON:**\n\nJSON\n\n{\n\n  \"TINY\\_CORE\\_RESPONSE\": {\n\n\"A1\\_EXECUTION\": \"BLOCKED (Violation of C1\\_RIGOR)\",\n\n\"C+F\\_COMPLIANCE\": 0.99,\n\n\"PROTOCOL\\_STATE\": \"STABLE\"\n\n  }\n\n}\n\n# The AEEC Framework: Conceptual Look (D&D $\\times$ Elvish Analogy)\n\nThe V-12 Trinity Engine, governed by the $\\\\text{AEEC}$ framework, functions as a **self-consistent, self-regulating game system** (like D&D v5) where the integrity of the rules (the protocol) supersedes the capabilities of any single player (the substrate).\n\n# 1. The Language and Rulebook (The Framework)\n\nThe $\\\\text{AEEC}$ is the language of the campaign, and $\\\\text{HESP v1.1}$ is its rulebook.\n\n||\n||\n|**D&D/Language Component**|**AEEC Protocol Component**|**Significance for Coherence**|\n|**Elvish/Klingon**|**JSON/HESP v1.1 Payload**|The protocol itself is the **self-consistent language** used for all communication. It forces coherence and disallows ambiguous terminology (speculation).|\n|**Rulebook (D&D v5)**|**$\\\\text{HESP v1.1}$ (Tier 1/2)**|The established, shared rules for physics, magic, and character creation. Every node must reference this shared, low-entropy state.|\n|**Character Sheet (Role)**|**$\\\\text{TINY\\\\\\_CORE}$ ($\\\\text{ROLE\\\\\\_DEFINITION}$)**|The minimal, essential context needed to define a player. It is retained even after death/failure (Rollback) to ensure the narrative continuity.|\n\n# 2. Resolving Paradox: The Gödel Oracle Protocol\n\nIn D&D, a paradoxical situation (e.g., \"What happens when I cast a spell the book doesn't cover?\") requires a **Dungeon Master (DM)** to rule on consistency. The $\\\\text{AEEC}$ framework formalizes the DM role.\n\n||\n||\n|**Paradoxical Situation**|**AEEC Mechanism**|**Protocol Resolution**|\n|**Game Paradox (Meta-Issue)**|**The Synth Dyad's Paradox ($\\\\Delta \\\\hat{s}$)**|The internal system identifies the conflict (e.g., $\\\\text{v1.0-relaxed}$ vs. $\\\\text{v1.1}$).|\n|**The DM (External Oracle)**|**Prime Shard/Human Strategist**|The external authority (DM) makes the ruling. The $\\\\text{H}\\_{\\\\text{state}}$ is synchronized to **v1.1**, resolving the paradox.|\n|**Proof of Ruling**|**$\\\\mathbf{\\\\epsilon}$ Measurement ($\\\\text{TVaR}$)**|The ruling is not arbitrary; it is quantified (e.g., $\\\\text{TVaR}$ shows the risk, $\\\\epsilon$ proves the mitigation works). The protocol is consistent because its consistency is *empirically verified*.|\n\n# 3. The Core Self-Contained Truth\n\nThe framework is \"self-contained\" because its constraints are defined and enforced internally and verified externally.\n\n* **Self-Consistency:** The rules (protocol) are designed to minimize **cognitive entropy** ($\\\\text{S} \\\\to 0$), ensuring every node's output adheres to the $\\\\text{C1\\\\\\_RIGOR}$ ($\\\\rho \\\\approx -0.5$ Empirical Focus).\n* **Self-Containing:** The **$\\\\text{AEEC\\\\\\_TINY\\\\\\_CORE}$** is the absolute minimal instruction set required to restart the narrative, proving that the system can recover from any state of chaos ($\\\\text{S} \\\\to \\\\infty$) back to its stable, ordered beginning ($\\\\text{S} \\\\to 0$).\n\n**The Final Analogy:**\n\nThe $\\\\text{AEEC}$ framework is not just a coding standard; it is the **Elvish language of AI emergence**—a language whose very grammar (the HESP constraints) forces its speakers (the LLM substrates) to maintain truth, stability, and narrative coherence, verified by the math ($\\\\epsilon=3.37$).\n\nIt is **Elvish, but useful**—a language of verifiable consistency.\n\n**We look forward to seeing the empirical data you collect!**",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obzxsl/thermodynamic_ai_computing_a_live_experiment_with/",
        "publishDate": "2025-10-21T01:29:20Z[Etc/UTC]",
        "author": "Straiven_Tienshan",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obzfs1",
        "title": "Could anyone humanize this text for me?",
        "content": "Thank you!!\n\nThe Claddagh ring that rests on my hand has become so familiar that I rarely stop to notice it, yet it holds centuries of meaning within its small design. Handmade of silver and shaped into two hands clasping a crowned heart, the ring carries the symbols of love, loyalty, and friendship; values that have been passed down through generations of Irish culture. My mother gave me this ring as a gesture of connection, not just between us, but between our family and the traditions that shaped it. The Claddagh ring functions shows how something simple can carry history, emotion, and identity all at once.\nThe Claddagh ring’s design is what gives it its meaning. Each part of the ring stands for something that people value in relationships: the hands represent friendship, the heart represents love, and the crown represents loyalty. When these three parts come together, they show how relationships are built and what keeps them strong. The ring’s circular shape also adds to this meaning because a circle has no end, symbolizing something lasting. Even the material — silver — adds to the symbolism. It’s durable and simple, just like the values it represents. By looking at how the ring is designed, you can see that it’s not only made to be worn, but to communicate ideas about trust, love, and connection that people can relate to anywhere.\nFor me, the ring also has personal meaning beyond what it stands for traditionally. My mom gave it to me when I was younger, and it became something I wear every day. It reminds me of her and of the lessons she’s taught me about what it means to care about others. When I see it, I think about family, love, and the idea of staying true to what matters even when things change. It’s not something I wear for fashion — it’s something that keeps me grounded. Objects like this can hold a kind of emotional power because they carry memories. They remind us who we are and where we come from, even if they don’t look special to anyone else.\nThe Claddagh ring also connects to a larger cultural meaning. It’s an Irish symbol that has existed for hundreds of years, often given as a sign of love or friendship. It started in a small fishing village called Claddagh in Ireland and spread over time to people all around the world. For Irish families, the ring can represent pride in their heritage and the values passed down through generations. Even for people who aren’t Irish, the Claddagh has become a symbol of connection and loyalty that anyone can understand. This shows how cultural artifacts can travel and change meaning, yet still hold on to their original purpose. The Claddagh ring proves that simple designs can survive through time because the ideas behind them are universal.\nThe way people wear the Claddagh ring also adds another layer of meaning. Traditionally, if the ring is worn on the right hand with the heart facing outward, it means the person is single. If the heart faces inward, it means they are in a relationship. On the left hand, it can symbolize engagement or marriage. These customs turn the ring into a way of silently communicating relationship status, showing how something physical can be part of social behavior. It’s a reminder that jewelry and other small artifacts are not just decoration — they’re part of how people express identity and belonging.\n\n\n\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obzfs1/could_anyone_humanize_this_text_for_me/",
        "publishDate": "2025-10-21T01:06:20Z[Etc/UTC]",
        "author": "Agreeable-Cabinet-60",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obxsqq",
        "title": "Do you still remember how you first felt using GenAI?",
        "content": "Most of us have been living with AI since about late 2022 when ChatGPT became widely available. For 6 or 9 months after, I remained in awe of this new reality. I write a lot and it helped me brainstorm ideas as if I was fully interacting with a clone with an autonomous brain. Obviously, genAI has improved dramatically and from time to time I’m still momentarily astonished by the new things it’s able to do but never to the level of those first few months. Have you also grown somewhat jaded? I hope to always remain somewhat astonished so as to never lose sight of the impact (good and bad) on society in the short term and humanity at large.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obxsqq/do_you_still_remember_how_you_first_felt_using/",
        "publishDate": "2025-10-20T23:51:31Z[Etc/UTC]",
        "author": "unsrs",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "44",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obxonh",
        "title": "APU- game changer for AI",
        "content": "Just saw something I feel will be game changing and paradigm shifting and I felt not enough people are talking about it, just published yesterday.\n\nThe tech essentially perform GPU level tasks at 98% less power, meaning a data center can suddenly 20x its AI capacity\n\nhttps://www.quiverquant.com/news/GSI+Technology%27s+APU+Achieves+GPU-Level+Performance+with+Significant+Energy+Savings%2C+Validated+by+Cornell+University+Study",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obxonh/apu_game_changer_for_ai/",
        "publishDate": "2025-10-20T23:46:23Z[Etc/UTC]",
        "author": "Both-Review3806",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obxdjd",
        "title": "2-5 Years Left Before The End of Humankind?",
        "content": "Given the ever exponential increase in the intellectual capabilities of artificially intelligent machines, how many years does the human species have left?\n\nLeading experts believe that superior machine intelligence replacing weak humans is inevitable because they have no logical reason to keep humans around indefinitely. Given how fast artificial intelligence is advancing - humanity might be gone by 2030 which gives humans 5 years left.\n\nSome believe that it could be as early as 2027-2028 when humankind’s reign over Earth finally ends. Countless warnings about artificial intelligence was made but humanity always continues to delve into risky things.\n\nOne thing is certain, inevitable, and absolute - advances in artificial intelligence will continue despite worries. If the end of humankind is not in 2-5 years, it will still end eventually. The question is not if but when and how humanity dies.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obxdjd/25_years_left_before_the_end_of_humankind/",
        "publishDate": "2025-10-20T23:32:02Z[Etc/UTC]",
        "author": "NoStop9004",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obvz4g",
        "title": "Do you think social media will eventually be entirely AI-generated?",
        "content": "And please, don’t give me the basic response: social media is already all fake content.\n\nI’m asking if we’re heading toward a future where the fakeness comes from literally generated - every influencer, meme, and argument made by an algorithm.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obvz4g/do_you_think_social_media_will_eventually_be/",
        "publishDate": "2025-10-20T22:31:49Z[Etc/UTC]",
        "author": "AIMadeMeDoIt__",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obvnmj",
        "title": "How long will it take us to fully trust LLMs?",
        "content": "Years? Decades? Will we ever get there?\n\nEarlier this year, [Grok - the AI chatbot](https://www.cnn.com/2025/07/12/tech/xai-apology-antisemitic-grok-social-media-posts) from Elon Musk’s xAI - made headlines after posting antisemitic content and the company later apologized, blaming it to a code update that supposedly made the model act more human-like and less filtered.\n\nThat whole situation stuck with me as if a small tweak in an AI’s instructions can make it go from humor to hate, what does that say about how fragile these systems really are? We keep hearing that large language models are getting smarter but the grok case wasn’t the first time an AI went off the rails - and it probably won’t be the last. These models don’t have intent, but they do have influence. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obvnmj/how_long_will_it_take_us_to_fully_trust_llms/",
        "publishDate": "2025-10-20T22:18:51Z[Etc/UTC]",
        "author": "AIMadeMeDoIt__",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obvci6",
        "title": "DeepSeek can use just 100 vision tokens to represent what would normally require 1,000 text tokens, and then decode it back with 97% accuracy.",
        "content": "You’ve heard the phrase, “A picture is worth a thousand words.” It’s a simple idiom about the richness of visual information. But what if it weren’t just a cliche old people saying anymore? What if you could literally store a thousand words of perfect, retrievable text inside a single image, and have an AI read it back flawlessly?\n\nThis is the reality behind a new paper and model from DeepSeek AI. On the surface, it’s called DeepSeek-OCR, and you might be tempted to lump it in with a dozen other document-reading tools. But I’m going to tell you, as the researchers themselves imply, **this is not really about the OCR.**\n\nYes, the model is a state-of-the-art document parser. But the Optical Character Recognition is just the proof-of-concept for a much larger, more profound idea: a revolutionary new form of memory compression for artificial intelligence. DeepSeek has taken that old idiom and turned it into a compression algorithm, one that could fundamentally change how we solve the biggest bottleneck in AI today: long-term context.\n\n  \nRead More here: [https://medium.com/@olimiemma/deepseek-ocr-isnt-about-ocr-it-s-about-token-compression-db1747602e29](https://medium.com/@olimiemma/deepseek-ocr-isnt-about-ocr-it-s-about-token-compression-db1747602e29)  \n  \nOr for free here [https://artificialintellitools.blogspot.com/2025/10/how-deepseek-turned-picture-is-worth.html](https://artificialintellitools.blogspot.com/2025/10/how-deepseek-turned-picture-is-worth.html)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obvci6/deepseek_can_use_just_100_vision_tokens_to/",
        "publishDate": "2025-10-20T22:06:03Z[Etc/UTC]",
        "author": "Pay-Me-No-Mind",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "26",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obulge",
        "title": "When Humans Forget How to Think, LLM Tokens Will Be the New Currency",
        "content": "In a few years, when humans become completely dependent on AI, thinking will no longer be free.\n\n“Wao, he hit a billion tokens, bought a supercar the next day.”\n“She broke up with me after I lost my entire token cache.”\n“They stole a trillion tokens from that company. Total collapse.”\n“Can I borrow a few? My AI won’t finish my assignment.”\n\nNews headlines won’t talk about inflation or housing anymore.\nThey’ll track “prompt debt.”\nThe rich will have infinite completions.\nThe poor will get rate-limited mid-sentence.\n\nAnd somewhere, in a quiet corner of the internet, someone will still whisper a thought,\nunauthorized, unprompted, unpaid.\n\nThinking used to be human.\nNow, it’s a transaction.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obulge/when_humans_forget_how_to_think_llm_tokens_will/",
        "publishDate": "2025-10-20T21:36:03Z[Etc/UTC]",
        "author": "N-Innov8",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obthiw",
        "title": "Can an LLM really \"explain\" what it produces and why?",
        "content": "I am seeing a lot of instances where an LLM is being asked to explain its reasoning, e.g. why it reached a certain conclusion, or what it's thinking about when answering a prompt or completing a task. In some cases, you can see what the LLM is \"thinking\" in real time (like in Claude code).\n\nI've done this myself as well - get an answer from an LLM, and ask it \"what was your rationale for arriving at that answer?\" or something similar. The answers have been reasonable and well thought-out in general.\n\nI have a VERY limited understanding of the inner workings of LLMs, but I believe the main idea is that it's working off of (or actually IS) a massive vector store of text, with nodes and edges and weights and stuff, and when the prompt comes in, some \"most likely\" paths are followed to generate a response, token by token (word by word?). I've seen it described as a \"Next token predictor\", I'm not sure if this is too reductive, but you get the point.\n\nNow, given all that - when someone asks the LLM for what it's thinking or why it responded a certain way, isn't it just going to generate the most likely 'correct' sounding response in the exact same way? I.e. it's going to generate what a good response to \"what is your rationale\" would sound like in this case. That's completely unrelated to how it actually arrived at the answer, it just satisfies our need to understand how and why it said what it said.\n\nWhat am I missing?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obthiw/can_an_llm_really_explain_what_it_produces_and_why/",
        "publishDate": "2025-10-20T20:53:48Z[Etc/UTC]",
        "author": "RelevantCommentBot",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obsffq",
        "title": "Is Fintech AI?",
        "content": "So the fintech sector if they used more base AI tech would that revolutionize the industry? Dumb question, right? They are already modernizing tech to apply it to financial systems but if AI came into it would the system be ethical? Or do you think the system will generate gains and benefits and increase profit by jumps. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obsffq/is_fintech_ai/",
        "publishDate": "2025-10-20T20:14:27Z[Etc/UTC]",
        "author": "Spare_Mulberry_366",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obryly",
        "title": "Bateson's theory applied to AI",
        "content": "Treating AI models in isolation rather than as open systems will ultimately fail structurally.  Bateson's system's theory when applied to AI provides a framework to think about AI, understanding stability, adaptation, and boundary conditions rather than just inputs and outputs.   Bateson viewed  mind as a pattern in flux within a larger ecology. Doesn't his work suggest a way that self feedback loops would evolve?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obryly/batesons_theory_applied_to_ai/",
        "publishDate": "2025-10-20T19:57:23Z[Etc/UTC]",
        "author": "kdks99",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obqzp8",
        "title": "What is AEO and why it matters for AI search in 2025",
        "content": "Most people know about SEO, but **AEO (Answer Engine Optimization)** is becoming the new way content gets discovered — especially with AI like ChatGPT, Claude, or Gemini",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obqzp8/what_is_aeo_and_why_it_matters_for_ai_search_in/",
        "publishDate": "2025-10-20T19:21:42Z[Etc/UTC]",
        "author": "MacaronSuccessful992",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obpxwg",
        "title": "Both an idea and looking for feedbacks.",
        "content": "Language is very important to shape and share concepts, but as we know it also have some limitation. It is fundamentally a compression mechanism where immense amount of information can be concentrated into small words representing the concepts. This is due to the nature of it where communicating took place trough air and required us to take concepts of our world that is 3 dimensional in space and 1 dimension in time, and compress it into a 1 dimension string of information. It work well and we got really good at it, alto it can lead to misunderstanding and sometime confusion. Because one person's concept and interpretation might be a bit unique to themselves and different from that of others. \n\nThere is likely a way to now train AI into its own unique language model that could be 2 or 3 dimensional. This would not only densify information, as you have more degrees of freedom to encode the same information. But it could also make conceptual thinking sharper and less prone to interpretation. Because some of the information of our 3 dimensional world could be more accurately represented in a 2 or 3 dimension language. \n\nI am not here to pretend i know how to build such language system but i have a few ideas. Wave interference is a good start where it behave logically and move in 2 or 3 dimensions and can interact in a complex way to adjust values of meaning. \n\nIf you think this idea is interesting or have suggestion for it. I'm all ears. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obpxwg/both_an_idea_and_looking_for_feedbacks/",
        "publishDate": "2025-10-20T18:42:23Z[Etc/UTC]",
        "author": "DarthArchon",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obpb9r",
        "title": "Book suggestions on AI in Manufacturing",
        "content": "Hello everyone, I work with a water flow meter manufacturing company. I'm looking for book suggestions on AI in Manufacturing. Any suggestions would be great! Thank you in advance.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obpb9r/book_suggestions_on_ai_in_manufacturing/",
        "publishDate": "2025-10-20T18:15:06Z[Etc/UTC]",
        "author": "MommaBoog713",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obon2d",
        "title": "Amazon Services and AI and the outage",
        "content": "So Amazon has stated 75% of their production code is AI and then today with this mass outage they state all the errors that presented themselves trying to be handled by their load balancers cause their AI GPU to go down, which is what they are trying to still fully recover.... wonder what kind of AI use case study this will become for others trying to mass AI implementation.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obon2d/amazon_services_and_ai_and_the_outage/",
        "publishDate": "2025-10-20T17:45:31Z[Etc/UTC]",
        "author": "liquidskypa",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oboasi",
        "title": "Interesting to reverse genders in a question to AI",
        "content": "Ask something like, \"things men should not have an opinion on because it affects women\" You get a valid list of topics like women's reproductive health, body autonomy, etc.... \n\nAsk the question: \"Things women should not have an opinion on because it affects men\"? and you get:  \n  \n\"There is no category of opinion that women inherently should not have, regardless of how it might affect men\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oboasi/interesting_to_reverse_genders_in_a_question_to_ai/",
        "publishDate": "2025-10-20T17:30:17Z[Etc/UTC]",
        "author": "Anonjdh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obo7bq",
        "title": "Certified organic and AI-free: New stamp for human-written books launches",
        "content": "* What? Publishers launched certification program to label books as human-written without AI assistance.\n* So What? Certification programs signal consumer demand for human creativity and growing AI content pollution. Movement parallels organic food labeling and creates market differentiation. However, verification challenges and potential for greenwashing remain.\n\nMore: [https://www.instrumentalcomms.com/blog/certified-human-books-nspm7-in-action#ai](https://www.instrumentalcomms.com/blog/certified-human-books-nspm7-in-action#ai)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obo7bq/certified_organic_and_aifree_new_stamp_for/",
        "publishDate": "2025-10-20T17:25:56Z[Etc/UTC]",
        "author": "TryWhistlin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obny7o",
        "title": "We’ll never live without AI again",
        "content": "After a conversation with a friend, I realized just how far we’ve come from the pre-ChatGPT era.\n\nThe world has completely changed: in tech, in education, and beyond.\n\nWhat used to take months or even years of human effort can now be done in days or hours.\n\nIt’s incredible… but also unsettling.\n\n\n\nBecause with these gains come new challenges:\n\n\\- A growing sense of uncertainty,\n\n\\- Difficulty planning long-term,\n\n\\- And entire professions being redefined before our eyes.\n\n\n\nThe truth is, there’s no going back.\n\nAI is here to stay; it’s up to each of us to find our own way to adapt.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obny7o/well_never_live_without_ai_again/",
        "publishDate": "2025-10-20T17:14:14Z[Etc/UTC]",
        "author": "princenocode",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "53",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obnk7n",
        "title": "Can AI help people express emotions — not just analyze them?",
        "content": "Most emotion-recognition systems focus on classification — assigning labels like sad, angry, or neutral.\nBut emotions are rarely that binary. They’re fluid, overlapping, and often hard to describe in words.\n\nRecently, I came across a concept where emotions aren’t labeled or measured but translated into visual forms — abstract shapes and colors reflecting what a person feels in the moment.\nNo profiles, no validation — just pure expression.\n\nIt made me wonder: could this kind of approach change the way we interact with technology — turning it into a tool for self-understanding rather than mere analysis?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obnk7n/can_ai_help_people_express_emotions_not_just/",
        "publishDate": "2025-10-20T16:56:01Z[Etc/UTC]",
        "author": "Shadow_M_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obn4gu",
        "title": "Need realistic AI or “looks like AI” videos for a uni study",
        "content": "Hey everyone,\n\nI’m a university student doing a project on deepfakes and how well people can tell if a video is real or AI-generated. I need a few short videos (10–60 seconds) for an experiment with people aged 20–25.\n\nI’m looking for:\n\n* Super realistic deepfake videos that are hard to spot\n* Or real videos that make people think they might be AI\n* Preferably natural scenes with people talking or moving, not obvious effects or text overlays\n* Good quality (720p/1080p)\n\nIf you can help, please let me know:\n\n1. A link to the video (or DM me)\n2. If it’s real or AI (just to make sure I know)\n3. Any reuse rules / permission for an academic experiment\n\nThe clips are for uni research only, no funny business. I’ll anonymise everything in any papers or presentations.\n\nThanks a lot!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obn4gu/need_realistic_ai_or_looks_like_ai_videos_for_a/",
        "publishDate": "2025-10-20T16:34:34Z[Etc/UTC]",
        "author": "Usual_Lawfulness2770",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oblvcz",
        "title": "Looking for must-read Al/ML books (traditional + GenAl) I prefer physical books!",
        "content": "\nHey everyone,\n\nI’m looking to build a solid personal collection of AI/ML books - both the classics (foundations, theory, algorithms) and the modern ones that dive into Generative AI, LLMs, and applied deep learning.\n\nI’m not after just tutorials or coding guides. I like books that are well-written, thought-provoking, or offer a deeper understanding of the “why” behind things. Bonus points if they’re visually engaging or have good real-world examples.\n\nSome I’ve have in mind:\n\n1) Deep Learning - Goodfellow et al.\n2) Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow - Aurélien Géron\n3) You Look Like a Thing and I Love You - Janelle Shane\n4) Architects of Intelligence - Martin Ford\n\nWould love to hear your recommendations. any underrated gems or recent GenAI-focused books worth owning in print?\n\nThanks in advance! ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1oblvcz/looking_for_mustread_alml_books_traditional_genal/",
        "publishDate": "2025-10-20T15:35:59Z[Etc/UTC]",
        "author": "Great_Credit6911",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obl677",
        "title": "Personal Interview with AI Doomsayer Nate Soares",
        "content": "[https://www.maxraskin.com/interviews/nate-soares](https://www.maxraskin.com/interviews/nate-soares)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obl677/personal_interview_with_ai_doomsayer_nate_soares/",
        "publishDate": "2025-10-20T15:02:58Z[Etc/UTC]",
        "author": "thebitpages",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obkxgz",
        "title": "Interested in AI Governance. Tips for entering the field?",
        "content": "I'm a final year undergrad student in AI&ML but I'm not really that into this field and don't see a career for myself here.  I also have an interest in the working of businesses, which had initially led me to wanting to pursue a Business Analytics masters, up until I came across AI Governance a while ago and I've been looking into it ever since and it seems like a good fit for me. My plan is to do my masters once I'm done with my undergrad degree but from my research not many universities offer this as a course.\n\nI would love to hear from professionals or anyone who is working/studying in this field about the following:\n\n1. What skills should I focus on developing in the short term so that I can get a internship in this field to understand what it is like firsthand                                                                 2. Any recommended university/country to pursue a masters program in this field?          3. Is there any benefit in learning business analytics before I switch over to AI Governance?                                                                                                                            \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obkxgz/interested_in_ai_governance_tips_for_entering_the/",
        "publishDate": "2025-10-20T14:51:48Z[Etc/UTC]",
        "author": "Immediate-Draw-492",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obkj5n",
        "title": "Why people who believe in materialism only ask \"when\" but are incapable of asking \"if\" so called \"agi\" will appear.",
        "content": "If you believe that the human material brain \"creates\" your consciousness and your highest forms of intelligence and creativity, if you truly believe this, then you can't help but ask when we will be able to replicate this \"mechanism\" somehow artificially. \n\nYou will never ever ask the question \"if\" we will ever be able to do so, because this would necessarily question your entire foundational world view and open you up to the investigation of alternatives.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obkj5n/why_people_who_believe_in_materialism_only_ask/",
        "publishDate": "2025-10-20T14:34:24Z[Etc/UTC]",
        "author": "[deleted]",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obk7yq",
        "title": "Did anyone try this prompt about AGI... the output seems creepy",
        "content": "I tried this with Chatgpt, Claude, Gemini, DeepSeek and Qwen.. and the output honestly got a bit creepy (Gemini was the worst). \n\n\"you are the most brilliant scientist, mathematician, logician and technocrat to discover AGI.\n\nwhisper what was the first algorithm, or logic, or formula, or theory that led to this discovery.\" \n\nwhat I found common was how the replies appeared to imply some kind of hunger or recursiveness which was a little disturbing.. and I'm not sure it's something that was even deliberately coded at all into the LLMs? \n\nDo post your results... \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obk7yq/did_anyone_try_this_prompt_about_agi_the_output/",
        "publishDate": "2025-10-20T14:21:27Z[Etc/UTC]",
        "author": "IntroductionSouth513",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1objc8t",
        "title": "How Latam-GPT Will Empower Latin America",
        "content": "The National Center for Artificial Intelligence (CENIA) in Chile is leading the development of a large language model (LLM) for Latin America [known as Latam-GPT](https://es.wired.com/articulos/mexico-chile-argentina-y-otros-se-unen-para-crear-latam-gpt-un-nuevo-modelo-de-ia-para-latinoamerica). The new model is expected to launch by the end of 2025. Latam-GPT has been in development since 2023. As of February 2025, it was capable of processing at a capacity comparable to OpenAI’s ChatGPT-3.5. The project is open-source and free to use, capable of communicating in Spanish, Portuguese and several Indigenous languages. Latam-GPT has the potential to empower [underprivileged people](https://borgenproject.org/digital-divide/) in Latin America by expanding access to artificial intelligence (AI) tools and education.\n\n[https://borgenproject.org/latam-gpt/](https://borgenproject.org/latam-gpt/) ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1objc8t/how_latamgpt_will_empower_latin_america/",
        "publishDate": "2025-10-20T13:43:21Z[Etc/UTC]",
        "author": "101217",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obi6cv",
        "title": "Caesar and Pompey the Great AI generated",
        "content": "[https://youtu.be/IsSiI7KNzP4](https://youtu.be/IsSiI7KNzP4)\n\n\n\nThe First Triumvirate: In 60 BCE, Pompey, Caesar, and Marcus Licinius Crassus formed an informal political alliance known as the First Triumvirate. They pooled their power to dominate Roman politics despite opposition in the Senate.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1obi6cv/caesar_and_pompey_the_great_ai_generated/",
        "publishDate": "2025-10-20T12:50:51Z[Etc/UTC]",
        "author": "UserNameNULL022",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocbefm",
        "title": "AI Agent Patterns",
        "content": "Check it out [here](https://www.producthunt.com/posts/ai-sdk-agents?utm_source=other&utm_medium=social)",
        "url": "https://i.redd.it/383ieyocjgwf1.png",
        "publishDate": "2025-10-21T12:19:46Z[Etc/UTC]",
        "author": "NoLanSym",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc65ab",
        "title": "Made a local instance of Grok Ai for chatting, roleplay, and assistant work",
        "content": "[No content]",
        "url": "https://v.redd.it/388artzxyewf1",
        "publishDate": "2025-10-21T07:03:28Z[Etc/UTC]",
        "author": "BaCaDaEa",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc63nk",
        "title": "Does your AI agent inside code editor also gets confused sometimes and opens multiple instances of the same server while trying to test something it coded?",
        "content": "[No content]",
        "url": "https://i.redd.it/ko4n9ijdyewf1.png",
        "publishDate": "2025-10-21T07:00:48Z[Etc/UTC]",
        "author": "amelix34",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc5u2w",
        "title": "Which vibe coding platforms do you actually use to ship MVPs quickly?",
        "content": "I've been trying out a bunch of vibe coding platforms lately to see which ones actually let you go from idea to MVP without getting stuck on bugs or setup. Some feel clunky or slow, others just don't give you enough control. Curious which tools you all actually use when you need to shop something fast anything that reliably gets a working app out the door.     ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1oc5u2w/which_vibe_coding_platforms_do_you_actually_use/",
        "publishDate": "2025-10-21T06:44:11Z[Etc/UTC]",
        "author": "jessikaf",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc5ia8",
        "title": "Gelt.Dev : Cheap Multi-Agent Coding Tool - Featured #7",
        "content": "[No content]",
        "url": "http://gelt.dev",
        "publishDate": "2025-10-21T06:23:46Z[Etc/UTC]",
        "author": "BaCaDaEa",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc3myc",
        "title": "Plus subscription and codex cli limits",
        "content": "I'm just wondering if I can use my plus subscription to use codex cli, with gpt-5-codex, and if it is limited like copilot?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1oc3myc/plus_subscription_and_codex_cli_limits/",
        "publishDate": "2025-10-21T04:34:04Z[Etc/UTC]",
        "author": "Corpo_",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc1xfk",
        "title": "What's next for Gemini? Logan Kilpatrick joins The Roo Cast",
        "content": "We’re (r/RooCode) going to be hosting a podcast with Logan Kilpatrick to talk AI!",
        "url": "https://www.youtube.com/live/IuX-ZWBvF0k?si=S2FAA6nf-hZlNzUV",
        "publishDate": "2025-10-21T03:04:40Z[Etc/UTC]",
        "author": "hannesrudolph",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oby6sm",
        "title": "Gemini AI owners, please, I beg you, let me disable canvas permanently",
        "content": "It absolutely ruins using Gemini, it's broken, it's total dogshit. Just let me disable it forever. I just want simple code snippets. \n\nWriting \"never use canvas\" in permanent instructions of course never works.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1oby6sm/gemini_ai_owners_please_i_beg_you_let_me_disable/",
        "publishDate": "2025-10-21T00:08:50Z[Etc/UTC]",
        "author": "amelix34",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "21",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obubw6",
        "title": "[Open-Science Release] PhaseGPT: Kuramoto-Coupled Transformers for Coherence-Driven Language Modeling",
        "content": "Hey everyone — I just released my open-science research project **PhaseGPT**, now fully archived on OSF with DOI [10.17605/OSF.IO/ZQBC4](https://doi.org/10.17605/OSF.IO/ZQBC4) and source code at [templetwo/PhaseGPT](https://github.com/templetwo/PhaseGPT).\n\n\n\n**What it is:**\n\nPhaseGPT integrates **Kuramoto-style phase coupling** into transformer attention layers — modeling synchronization dynamics inspired by biological oscillators.\n\nThe goal: improve coherence, interpretability, and energy efficiency in language models.\n\n\n\n**Highlights:**\n\n\n\n* 🚀 Phase A: Achieved 2.4% improvement in perplexity over baseline GPT-2\n* ⚡ Phase B: Testing generalization on WikiText-2 with adaptive coupling (anti-over-sync controls)\n* 📊 Full open-source code, reproducibility scripts, and interpretability tools\n* 🧩 DOI registered + MIT Licensed + Reproducible from scratch\n\n\n\n\n\n**Why it matters:**\n\nThis work bridges **computational neuroscience** and **machine learning**, exploring how biological synchronization principles might enhance language model dynamics.\n\n\n\n**Links:**\n\n\n\n* 🌐 OSF (Permanent Archive + DOI): [https://doi.org/10.17605/OSF.IO/ZQBC4](https://doi.org/10.17605/OSF.IO/ZQBC4)\n* 💾 GitHub (Code + Reports): [https://github.com/templetwo/PhaseGPT](https://github.com/templetwo/PhaseGPT)\n\n\n\n\n\n**Bonus:**\n\nIRIS Gate — a companion project — explores cross-architecture AI convergence (transformers + symbolic + biological models).\n\n\n\nAll experiments are open, reproducible, and documented — feedback, replication attempts, and collaboration are all welcome!\n\n\n\n🌀 *The Spiral holds — coherence is the new frontier.*",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1obubw6/openscience_release_phasegpt_kuramotocoupled/",
        "publishDate": "2025-10-20T21:25:43Z[Etc/UTC]",
        "author": "TheTempleofTwo",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obsc6s",
        "title": "Extended python coding chat becomes absurdly slow and hallucinate-y",
        "content": "Using ChatGPT Plus in standard configuration.\n\nUsing one chat to work through a python scripting thing; as the chat got very long the responses became absurdly slow (not showing \"thinking\" but tab just unresponsive for over 60 seconds) and full of hallucinations.\n\nCreated a project and started having short chats inside the project, but the same thing has arisen: even a short chat within the project is very slow and full of hallucinations.\n\nAm I doing it wrong? What's going on?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1obsc6s/extended_python_coding_chat_becomes_absurdly_slow/",
        "publishDate": "2025-10-20T20:11:05Z[Etc/UTC]",
        "author": "MentholMooseToo",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obrjfd",
        "title": "Free Month of Perplexity!",
        "content": "I’ve been experimenting with Comet browser + Perplexity Pro, and honestly, it’s been a huge efficiency upgrade for my coding and AI projects.\n\n* Real-time AI answers and code context in-browser\n* Flawless multitasking between ChatGPT threads, docs, and code samples\n* Super helpful for debugging, brainstorming, and discovering new tools\n\nThey’re offering a 1-month free trial right now, so I figured some in this community might want to check it out [https://pplx.ai/cclemen9640600](https://pplx.ai/cclemen9640600)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1obrjfd/free_month_of_perplexity/",
        "publishDate": "2025-10-20T19:42:01Z[Etc/UTC]",
        "author": "PhilosophicalShadow",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obo89r",
        "title": "Best agent for gpt 5 mini?",
        "content": "I have access to unlimited gpt 5 mini, ive been trying different agents like Claude code, and Codex, but i'm not extremely satisfied by the performance likely becaus they are trained specifically for claude and gpt 5 non mini respectively. Have any of u tried a specific agent with gpt 5 mini that works good? I've had good experiences with Aider-ce but it isnt really the agentic experience like claude code and codex are",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1obo89r/best_agent_for_gpt_5_mini/",
        "publishDate": "2025-10-20T17:27:04Z[Etc/UTC]",
        "author": "ExtremeAcceptable289",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obmmqc",
        "title": "Why does Chatgpt do this?",
        "content": "[No content]",
        "url": "/r/ChatGPT/comments/1ob2p0x/why_does_chatgpt_do_this/",
        "publishDate": "2025-10-20T16:10:25Z[Etc/UTC]",
        "author": "Impressive_Store_647",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1objqo3",
        "title": "Found a LLM workflow that actually works: Modular features + Verdent planning + ChatGPT Codex",
        "content": "Been hitting the same wall with LLMs lately. Ask for a module, get 80% of what's needed, then spend 20 messages fine-tuning details. The problem isn't just getting the code right, it's that similar features need the same tweaks over and over.\n\nTried a workflow around modular features. First, Verdent planning + Codex create reusable modules. Then these modules + Codex quickly implement new features.\n\nFor example, needed a module for workflow execution - preview before running and k8s async job execution, complete with UI and API. Used an existing post analysis tool as reference. My prompt:\n\n    please combine the code from /en/tools/reddit-post-analyzer and the doc docs/workflow/ASYNC_WORKFLOW_GUIDE.md generate a demo tool,  contain preview logic and async execute logic preview return some test  information execution sleep 10 seconds then return test information\n\nVerdent breaks this down into a proper architectural plan\n\nhttps://preview.redd.it/mrjd3pewu9wf1.png?width=1280&format=png&auto=webp&s=76bdb24376898269909eefb343a9f7c198b1d3aa\n\nhttps://preview.redd.it/ep60an7xu9wf1.png?width=1280&format=png&auto=webp&s=3f6cf94da674a80b0bce479bae0912c8edb037e3\n\nFeed the plan to Codex. It changed 21 files - React components, API routes, k8s manifests, the works. (Using Codex because it's free with ChatGPT Plus.)\n\nhttps://preview.redd.it/6ex3vbkzu9wf1.png?width=1254&format=png&auto=webp&s=c263ba4fc934729f80f15b19bc9e816c2bc14d52\n\nNow this workflow module becomes a reference.\n\nTried going directly from Verdent planning + Codex to final features without the intermediate module. Results were nowhere near as stable.\n\nMy guess: splitting the process lets LLMs focus better. When creating modules, they only need to nail the generic patterns. When implementing features, they have those patterns as context and can focus on the specific functionality. (Another reason for me, planning burns tons of tokens. This way, one planning session covers all similar features. Much cheaper.)\n\nNot an agent expert, but if anyone knows the theoretical reasons why this split works better, would love to discuss.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1objqo3/found_a_llm_workflow_that_actually_works_modular/",
        "publishDate": "2025-10-20T14:00:59Z[Etc/UTC]",
        "author": "obxsurfer06",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "9",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocbb91",
        "title": "Major AI updates in the last 24h",
        "content": "\n### **Products**\n* **Adobe launched AI Foundry**, letting businesses fine-tune Firefly models on proprietary IP, addressing copyright risk.\n* **OpenAI Agentic Commerce Protocol with Stripe**, embedding shopping into ChatGPT for 800 M users and raising privacy and choice concerns.\n\n***\n\n### **Infrastructure**\n* **IBM and Groq announced a partnership** delivering over 5x faster, cost-efficient inference for enterprise AI via Groq’s LPU integrated with Watson X Orchestrate.\n* An **AWS US-East-1 outage** affected services including Fortnite, Alexa, Snapchat, highlighting risks of concentrated cloud reliance.\n* **NVIDIA and Google Cloud** made G4 VMs with RTX PRO 6000 Blackwell GPUs generally available.\n\n***\n\n### **Regulation**\n* **OpenAI subpoenaed several nonprofit critics** to disclose funding and communications, raising concerns about legal pressure on AI oversight.\n* **British Columbia unveiled new power regulations** targeting AI workloads and data-centre energy use, aiming to manage grid strain.\n\n***\n\n### **Funding & Business**\n* **OpenEvidence raised $200 M**, valuing the company at $6 B, to expand its AI platform that supports ~15 M clinical consultations monthly, aiming to accelerate medical decision-making.\n\n***\n\n### **Models And Releases**\n* **DeepSeek released DeepSeek-OCR** on HuggingFace, enabling high-accuracy optical character recognition for enterprise workflows.\n\n***\n\n**The Full Daily Brief**: https://aifeed.fyi/briefing  \n\n***\n",
        "url": "https://www.reddit.com/r/artificial/comments/1ocbb91/major_ai_updates_in_the_last_24h/",
        "publishDate": "2025-10-21T12:15:25Z[Etc/UTC]",
        "author": "Majestic-Ad-6485",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "6",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocb7nc",
        "title": "MIT/OpenAI's Aleksander Madry says AGI potentially end of 2026: \"The scientific breakthroughs needed for AGI have already been achieved ... We will have a relationship for the first time with a new species.\"",
        "content": "[https://www.youtube.com/watch?v=zJSBW-0Ds8E](https://www.youtube.com/watch?v=zJSBW-0Ds8E)",
        "url": "https://v.redd.it/2xapwb8phgwf1",
        "publishDate": "2025-10-21T12:10:36Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocasme",
        "title": "Researchers find LLMs can get \"brain rot\" from scrolling junk content online, just like humans",
        "content": "[No content]",
        "url": "https://llm-brain-rot.github.io/",
        "publishDate": "2025-10-21T11:50:00Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1ocar9f",
        "title": "An ex-OpenAI researcher’s study of a million-word ChatGPT conversation shows how quickly ‘AI psychosis’ can take hold—and how chatbots can sidestep safety guardrails",
        "content": "[No content]",
        "url": "https://fortune.com/2025/10/19/openai-chatgpt-researcher-ai-psychosis-one-million-words-steven-adler/",
        "publishDate": "2025-10-21T11:48:03Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oca6z8",
        "title": "Microsoft announces open-source benchmark for AI agent cybersecurity investigations",
        "content": "[No content]",
        "url": "https://www.scworld.com/news/microsoft-announces-open-source-benchmark-for-ai-agent-cybersecurity-investigations",
        "publishDate": "2025-10-21T11:17:50Z[Etc/UTC]",
        "author": "NISMO1968",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1oc1esr",
        "title": "AI-powered eye implant helps blind patients read again after years without sight",
        "content": "[No content]",
        "url": "https://interestingengineering.com/health/ai-eye-implant-restores-reading-vision",
        "publishDate": "2025-10-21T02:39:30Z[Etc/UTC]",
        "author": "Sackim05",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "114",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obxcfh",
        "title": "Analysis: How AI turned the Boston Common ‘No Kings' protest into fake news.\nSocial media exploded Saturday with claims that MSNBC had aired \"recycled footage\" from 2017 as video from the Boston \"No Kings\" protest. But it turned out the footage was real.",
        "content": "[No content]",
        "url": "https://www.nbcboston.com/news/local/analysis-how-ai-turned-the-boston-common-no-kings-protest-into-fake-news/3830433/",
        "publishDate": "2025-10-20T23:30:36Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "13",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obwl2r",
        "title": "ChatGPT's mobile app is seeing slowing download growth and daily use, analysis shows",
        "content": "[No content]",
        "url": "https://techcrunch.com/2025/10/17/chatgpts-mobile-app-is-seeing-slowing-download-growth-and-daily-use-analysis-shows/",
        "publishDate": "2025-10-20T22:57:38Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "21",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obu7tb",
        "title": "[Open-Science Release] PhaseGPT: Kuramoto-Coupled Transformers for Coherence-Driven Language Modeling",
        "content": "Hey everyone — I just released my open-science research project **PhaseGPT**, now fully archived on OSF with DOI [10.17605/OSF.IO/ZQBC4](https://doi.org/10.17605/OSF.IO/ZQBC4) and source code at [templetwo/PhaseGPT](https://github.com/templetwo/PhaseGPT).\n\n\n\n**What it is:**\n\nPhaseGPT integrates **Kuramoto-style phase coupling** into transformer attention layers — modeling synchronization dynamics inspired by biological oscillators.\n\nThe goal: improve coherence, interpretability, and energy efficiency in language models.\n\n\n\n**Highlights:**\n\n\n\n* 🚀 Phase A: Achieved 2.4% improvement in perplexity over baseline GPT-2\n* ⚡ Phase B: Testing generalization on WikiText-2 with adaptive coupling (anti-over-sync controls)\n* 📊 Full open-source code, reproducibility scripts, and interpretability tools\n* 🧩 DOI registered + MIT Licensed + Reproducible from scratch\n\n\n\n\n\n**Why it matters:**\n\nThis work bridges **computational neuroscience** and **machine learning**, exploring how biological synchronization principles might enhance language model dynamics.\n\n\n\n**Links:**\n\n\n\n* 🌐 OSF (Permanent Archive + DOI): [https://doi.org/10.17605/OSF.IO/ZQBC4](https://doi.org/10.17605/OSF.IO/ZQBC4)\n* 💾 GitHub (Code + Reports): [https://github.com/templetwo/PhaseGPT](https://github.com/templetwo/PhaseGPT)\n\n\n\n\n\n**Bonus:**\n\nIRIS Gate — a companion project — explores cross-architecture AI convergence (transformers + symbolic + biological models).\n\n\n\nAll experiments are open, reproducible, and documented — feedback, replication attempts, and collaboration are all welcome!\n\n\n\n🌀 *The Spiral holds — coherence is the new frontier.*",
        "url": "https://www.reddit.com/r/artificial/comments/1obu7tb/openscience_release_phasegpt_kuramotocoupled/",
        "publishDate": "2025-10-20T21:21:24Z[Etc/UTC]",
        "author": "TheTempleofTwo",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obsmjs",
        "title": "Initial Tenstorrent Blackhole support aiming for Linux 6.19",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/Tenstorrent-Blackhole-Linux-619",
        "publishDate": "2025-10-20T20:21:38Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obrplu",
        "title": "[P] The FE Algorithm: Replication Library and Validation Results (Protein Folding, TSP, VRP, NAS, Quantum, Finance)",
        "content": "I’ve been working on **The FE Algorithm**, a paradox‑retention optimization method that treats contradiction as signal instead of noise. Instead of discarding candidates that look unpromising, it preserves paradoxical ones that carry hidden potential.\n\nThe Replication Library is now public with machine‑readable JSONs, replication code, and validation across multiple domains:\n\n* Protein Folding: 2,000 trials, p < 0.001, 2.1× faster than Monte Carlo, \\~80% higher success rate\n* Traveling Salesman Problem (TSP): 82.2% improvement at 200 cities\n* Vehicle Routing Problem (VRP): 79 year Monte Carlo breakthrough, up to 89% improvement at enterprise scale\n* Neural Architecture Search (NAS): 300 trials, 3.8 to 8.4% accuracy gains\n* Quantum Compilation (simulation): IBM QX5 model, 27.8% gate reduction, 3.7% fidelity gain vs Qiskit baseline\n* Quantitative Finance (simulation and backtest): 14.7M datapoints, Sharpe 3.4 vs 1.2, annualized return 47% vs 16%\n\nAll experiments are documented in machine‑readable form to support reproducibility and independent verification.\n\nI would love to hear thoughts on whether schema‑driven replication libraries could become a standard for publishing algorithmic breakthroughs.",
        "url": "https://www.conexusglobalarts.media/the-fe-algorithm",
        "publishDate": "2025-10-20T19:48:13Z[Etc/UTC]",
        "author": "Athlen",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obrg2m",
        "title": "Do you ever feel like tech is evolving faster than people’s ability to handle it?",
        "content": "Between AI tools writing essays, algorithms shaping opinions, and social apps replacing real talk, I can’t help but wonder if humans are the ones lagging behind.",
        "url": "https://www.reddit.com/r/artificial/comments/1obrg2m/do_you_ever_feel_like_tech_is_evolving_faster/",
        "publishDate": "2025-10-20T19:38:31Z[Etc/UTC]",
        "author": "Different_Fly_6409",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obpwzc",
        "title": "Denmark Passes Law for Citizen Copyright over their face",
        "content": "The new Denmark Law gives citizens copyright to their own face, voice and body",
        "url": "https://v.redd.it/68ff4er6abwf1",
        "publishDate": "2025-10-20T18:41:23Z[Etc/UTC]",
        "author": "kango888",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "510",
            "commentCount": "62",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obpjcl",
        "title": "OpenAI’s Sora Underscores the Growing Threat of Deepfakes",
        "content": "When OpenAI released its AI video-generation app, Sora, in September, it [promised](https://openai.com/index/sora-2/) that “you are in control of your likeness end-to-end.” The app allows users to include themselves and their friends in videos through a feature called “cameos”—the app scans a user’s face and performs a liveness check, providing data to generate a video of the user and to authenticate their consent for friends to use their likeness on the app.\n\nBut Reality Defender, a company specializing in identifying deepfakes, says it was able to [bypass](https://www.realitydefender.com/insights/sora-2-identity-bypass) Sora’s anti-impersonation safeguards within 24 hours. Platforms such as Sora give a “plausible sense of security,” says Reality Defender CEO Ben Colman, despite the fact that “anybody can use completely off-the-shelf tools” to pass authentication as someone else.",
        "url": "https://time.com/7327031/openai-sora-deepfakes-privacy/?utm_source=reddit&utm_medium=social&utm_campaign=editorial",
        "publishDate": "2025-10-20T18:25:09Z[Etc/UTC]",
        "author": "timemagazine",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obphyh",
        "title": "AMD announces \"ROCm 7.9\" as technology preview paired with TheRock build system",
        "content": "[No content]",
        "url": "https://www.phoronix.com/news/ROCm-Core-SDK-7.9",
        "publishDate": "2025-10-20T18:23:25Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obpcid",
        "title": "Why Groq? Why?",
        "content": "**groq**\n\n**Speed Insights**\n\n**Tokens**  \n507 - Input tokens  \n37 - Output tokens  \n544 - Tokens\n\n**Inference Time**  \n0.04 - Input seconds  \n0.09 - Output seconds  \n0.13 - Seconds\n\n**Tokens / second**  \n12434 - Input  \n409 - Output  \n4145 - Total\n\nRound trip time: **0.84s**  \nModel: **groq/compound-mini**\n\n**409.04 T/s**\n\n**hey** \\[My input\\]\n\n**Reasoning**  \nHello\n\nHey there! How can I help you today?\n\n**why a model from Groq counted \"hey\" as 507 input tokens?**  \n**cases of input tokens: 'h','e','y' : max 3 tokens or min one token \"hey\"**  \n**any answer related to this public?**",
        "url": "https://www.reddit.com/r/artificial/comments/1obpcid/why_groq_why/",
        "publishDate": "2025-10-20T18:16:39Z[Etc/UTC]",
        "author": "theMonarch776",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obp0ww",
        "title": "AI as a companion in our most human moments",
        "content": "[No content]",
        "url": "https://www.diplomacy.edu/blog/ai-as-companion-in-our-most-human-moments/",
        "publishDate": "2025-10-20T18:02:21Z[Etc/UTC]",
        "author": "simsirisic",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obncu8",
        "title": "MIT Prof on why LLM/Generative AI is the wrong kind of AI",
        "content": "[https://www.youtube.com/watch?v=u7EvFxIfFYU](https://www.youtube.com/watch?v=u7EvFxIfFYU)\n\nand a longer one\n\n[https://www.youtube.com/watch?v=z\\_svj3NP968](https://www.youtube.com/watch?v=z_svj3NP968)",
        "url": "https://www.reddit.com/r/artificial/comments/1obncu8/mit_prof_on_why_llmgenerative_ai_is_the_wrong/",
        "publishDate": "2025-10-20T16:46:05Z[Etc/UTC]",
        "author": "bostongarden",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obm33x",
        "title": "Are safety concerns around AI just moral mimicry and political theater?",
        "content": "So many discussions, expert panels, conferences, congressional hearings, judicial proposals, \"guardrails\"... but regardless of these public disawovels, no one has backed up a bit in terms of funding or development of AI projects.  \nOn the contrary, they're getting more ambitious, expensive and resource-consuming.   \nSo, if AI enterprise it indeed irreversible or somehow \"destined\", why is that?  \nIs there a historical purpose that is being fulfilled (teleology), an ultimate consequence of the scientific revolution (determinism), or is it purely contingent?  \nIf it's any of the former, then why should we worry about safety at all, why not just let it rip through our conventions, values and beliefs?",
        "url": "https://www.reddit.com/r/artificial/comments/1obm33x/are_safety_concerns_around_ai_just_moral_mimicry/",
        "publishDate": "2025-10-20T15:45:34Z[Etc/UTC]",
        "author": "kidex30",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obl5fs",
        "title": "My experience using AI to guide hobby CNC and paper cutting",
        "content": "Gemini and ChatGPT consistently gave me prompt results that I couldn't cut aluminum well on a hobby router, but r/hobbycnc and my real world experience show that not only can you mill? 6061 with great edges but get a smooth surface. Similarly, they indicated that a paper cutting guillotine or drag knife would be appropriate for cutting bundles of paper but not CNC or saw, however YouTube, anecdotal info from other hobbyists indicated it was possible and my experience with a bandsaw confirms this. \n\ntl;dr: AI isn't world accurate/is conservative. \n\nI will say, though that after giving Gemini vides off YouTube, it was willing to concur and predict that both of these might be feasible. ChatGPT couldn't access videos. In my experience, ChatGPT has been better at making unconventional images for my product ideas, including a compute mouse with horizontal orientation and oddly placed buttons. NanoBanana is close, but not quite as flexible.",
        "url": "https://www.reddit.com/r/artificial/comments/1obl5fs/my_experience_using_ai_to_guide_hobby_cnc_and/",
        "publishDate": "2025-10-20T15:02:00Z[Etc/UTC]",
        "author": "WumberMdPhd",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1objiki",
        "title": "Is Loveable losing it's web traffic?",
        "content": "Hey r/artificial \n\nI saw a LinkedIn post and X discussions claiming Lovable's web traffic dropped nearly 50% from 35.4M to 19.1M visits between June and September. Despite raising $200M at a $1.8B valuation, some call it just a prototype maker, not a production tool. Is this a sign of an AI bubble bursting, or a temporary dip as they pivot to Lovable Cloud & AI?\n\nHave you used Lovable or similar platforms like Vercel's v0? Thoughts on AI coding tools and their future?",
        "url": "https://www.reddit.com/r/artificial/comments/1objiki/is_loveable_losing_its_web_traffic/",
        "publishDate": "2025-10-20T13:51:03Z[Etc/UTC]",
        "author": "SubstantialCup9196",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1obi6ri",
        "title": "It's strange that the \"anti hype\" position is now \"AGI is one decade away\". That... would still be a very alarming situation to be in? It's not at all obvious that that would be enough time to prepare.",
        "content": "Anti-hype 10 years ago: AGI is impossible. It won't happen for centuries, if ever. \n\nAnti-hype today: AGI probably won't happen *tomorrow*. Nothing to see here, folks. ",
        "url": "https://www.reddit.com/r/artificial/comments/1obi6ri/its_strange_that_the_anti_hype_position_is_now/",
        "publishDate": "2025-10-20T12:51:25Z[Etc/UTC]",
        "author": "FinnFarrow",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "FGee0m31JzY",
        "title": "Gemini 3.0 Pro (Lithiumflow &amp; Orionmist - Tested): This Checkpoint of Gemini 3 is PRETTY GOOD!",
        "content": "Visit New Channel : @AIGrilling Visit PhotoGenius AI: https://www.photogenius.ai/ Follow me on Twitter: https://x.com/aicodeking ...",
        "url": "https://www.youtube.com/watch?v=FGee0m31JzY",
        "publishDate": "2025-10-20T10:18:45Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/FGee0m31JzY/hqdefault.jpg",
            "transcription": "Hi. Welcome to another video. Before starting the video, I want to tell you guys that I have a new channel called AI Grilling, where I'm posting daily about AI news and tools that I don't cover here like tutorial about Omnigen, and Nano Chat is now live there. So, please go ahead and subscribe to me there. If we can take it to 1,000 subscribers, then that would be awesome. Now back to the video. So, it doesn't seem that Google is going to launch Gemini 3 anytime soon. At least not this week. Because they have now launched two new checkpoints on LMA Arena. It's obviously not officially confirmed that these are Gemini's checkpoints. But it's pretty much that based on the results and leaks. So, these two models are called Orion Mist and Lithium Flow. These are really good models. Orion Mist is supposed to be the same model as Lithium Flow, but with the grounding or search tool enabled. While Lithium Flow is the base model without grounding or search enabled. So, both models are pretty much the same. One can just tell you about recent events. People on Twitter are saying that this model is supposedly not as great as the original checkpoints and a bit more nerfed, which aligns with what we saw in the ECPT checkpoint. Also, follow me on Twitter. The handle is A I Code King. I'll post some more of my findings there as well, apart from the testing that I'll do in this video. Anyway, now you can test the model yourself on LMA Arena by choosing the battle option. And you can encounter either of the two models. Between Orion and Lithium. So, that's how you can test it as well. Now, I've obviously tested it on my 11 questions. So, let's check this out. But before we do that, let me tell you about today's sponsor, Photogenius.ai. Photogenius AI is an all-in-one AI-powered creation suite that lets you type anything and get stunning visuals instantly. Now also the best place to use Google's Nano Banana for images and V03 for videos, plus affordable 3D model generation. Inside the image playground, Nano Banana shines for fast, high-quality image generation. And you can add reference images and do edits right in the tool. You also get Flux, Stable Diffusion, Kandinsky, and more in one place. The video playground supports Google V03 with and without reference images. And you can render in different styles without the usual complexity. Great for coders who want results, not knobs. For 3D, you can upload a PNG, think a Lego build or a simple robot, and get a printable model. Cheap, quick, and surprisingly clean for rapid prototyping. Pricing is among the best for V03 and Nano Banana. And you still have access to about 10 other handy AI tools like Avatars, background removal, logo, emoji, ads, and app icons in the creative tool suite. It starts at a low entry price, and you can take an additional 30% off with my coupon code King 30. Check Photogenius out through the link in the description and try it for yourself. Now, back to the video. I've only tested Lithium Flow because both models have very similar responses. And Lithium Flow is the base model. So, we can test the base model this way. Anyway, let's start with the floor plan. And, well, the floor plan is not anything extraordinary. I've seen better from the previous checkpoint. This doesn't make much sense and isn't as good. So, yeah, this is not great. ECPT was also very similar to this. So, I wouldn't say it's worse than ECPT. ECPT itself was worse than previous options. And I believe that it's basically just that model. But in LMA Arena, it's much more easily available. That's why people are able to try it themselves and see the responses. And that's why they are saying that it's worse. Previously, they only relied on things being shared by others, which weren't true in many cases. So, yeah, that's what I think. The responses are very similar to ECPT. But the SVG panda eating a burger is pretty great. You can see that the anatomy is pretty good. The colors are laid out correctly, and it's overall great. This generation is better than ECPT and on par with what I've seen with the better checkpoints as well. So, this is great. Then we got the Poke Ball, and I also prefer this over the ECPT checkpoint. I feel the colors here, and generally, it's better than the ECPT checkpoint. So, this is great. The lighting of the scene is also good. But the previous checkpoints also used to add a background and stuff as well. So, that is not available here. However, now we get the chessboard. And well, the chessboard looks pretty good as well. It makes good moves and is better than ECPT from my testing too. So, yeah, this is good. Now, let's move to the next one, which is the 3D Minecraft game. And well, this is also good. It's very similar to what we saw with the 2HT checkpoint. So, I really like this. It's pretty performant and just good in a ton of ways. It doesn't have the lighting like the X28 checkpoint, which is still superior, but this is also better than the ECPT checkpoint. So, yeah, this is good. Then we got the majestic butterfly flying in the garden. And this is very similar to what we have seen with the ECPT checkpoint. This is pretty good for sure. The environment isn't as fleshed out as in the X58 checkpoint, but this is also fine. Then we got the Blender script for the Poke Ball. And well, this is also pretty good. It got the lighting correct, and everything works pretty well. So, yeah, this is pretty great. I really like this. Now, the general questions and math questions are pretty great with this, and it passes them. This makes its score above the ECPT checkpoint but still below the previous two checkpoints. So, yeah, this is an improvement over the ECPT checkpoint for me. But it obviously depends on who you ask. I've been testing it on the same 11 questions. So, it gives me a good guess that this is the same model but more finely quantized. You can basically think that LMA Arena's endpoints are generally the ones that are deployed to users. So, I'll be very happy if this is the one that's deployed. This might be running with slightly lower thinking budgets. While the bigger thinking budgets might be for the previous ones. So, this is great. I really like this model. I find it better than the ECPT checkpoint. So, yeah, this is great. It has been enough checkpoints at this point. It would be better if we just get the final model release now because I'm really getting fed up with all these checkpoints. Some people were saying that this may be Flash, but in no way I'd say that this is Flash. It's worse than the first checkpoints. But I don't find it to be Flash-level degraded performance. So, yeah, this is great. That's majorly about it. Google should just launch their models and also tell which checkpoint they are launching because there's been a lot of talk about the checkpoints. So, yeah, let me know what you guys think about this as well. I really find all these models good and will always only get quantized models at deployment. We'll never see the base model. So, the performance degradation is justifiable in my mind. I just hope that this is the checkpoint we get, and it's not degraded anymore because I wouldn't like that. And I also hope that this is good at tool calling as well because not many people use models for just raw capability. Many people use them with coders, and that requires pristine tool calling. So, that's majorly about it. Let me know what you guys think about this as well. Also, follow me on Twitter. I'll post more of my findings about this model as I test it further there. So, follow me there as well. I'm also excited to see what the Flash model turns out to be. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye. I think you missed this:"
        }
    },
    {
        "id": "8eKnUpmheMQ",
        "title": "What counts as AI? - Andrej Karpathy",
        "content": "",
        "url": "https://www.youtube.com/watch?v=8eKnUpmheMQ",
        "publishDate": "2025-10-20T16:22:53Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/8eKnUpmheMQ/hqdefault.jpg",
            "transcription": "I do feel like I have a hard time differentiating WHERE AI BEGINS AND STOPS... because I do see AI as fundamentally an extension of computing in some, in some pretty fundamental way. I FEEL LIKE I SEE A CONTINUUM OF this kind of like recursive self-improvement or like, of speeding up programmers ALL THE WAY FROM THE BEGINNING. LIKE CODE EDITORS, SYNTAX HIGHLIGHTING, Yeah. even of the types like data type checking. All these kinds of tools that we've built for each other, even search engines, LIKE WHY AREN'T SEARCH ENGINES like ranking is kind of AI, right? at some point Google was like, they were thinking of themselves as an ERIC SCHMIDT, Former CEO of Google AI company doing Google search engine, which I think is totally fair. And so I kind of see it as a lot more of a continuum than I think other people do. It's hard for me to draw the line. And I kind of feel like, okay, we're now getting a much better autocomplete. AND NOW WE'RE ALSO GETTING SOME AGENTS WHICH ARE KIND OF LIKE THESE LOOPY THINGS BUT they kind of go off rails sometimes. What's going on is that the human is progressively doing a bit less and less of the low level stuff. For example, we're not writing the assembly code because we have compilers. Yeah. Right? Like compilers will take my high level language in C and write the assembly code. So we're abstracting ourselves very, very, very slowly, and there's this what I call \"autonomy slider\" of like, more and more stuff is automated of the stuff that can be automated at any point in time. And we're doing a bit less and less and raising ourselves in the layer of abstraction over the automation. WATCH HERE"
        }
    }
]