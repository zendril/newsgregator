[
    {
        "id": "https://news.smol.ai/issues/25-09-05-1t-models/",
        "title": "Kimi K2‑0905 and Qwen3‑Max preview: two 1T open weights models launched",
        "content": "**Moonshot AI** updated their **Kimi K2-0905** open model with doubled context length to **256k tokens**, improved coding and tool-calling, and integration with agent scaffolds. **Alibaba** released **Qwen 3 Max**, a **1 trillion parameter** model with agent-oriented behavior, available via **Qwen Chat**, **Alibaba Cloud API**, and **OpenRouter**. The community highlights China's dominance in open models and debates around meaningful evaluation methods for code agents, emphasizing long-horizon and domain-specific evals. Influential voices like **@swyx** and **@karpathy** discuss the importance of practical evals and discriminator models for ranking outputs.",
        "url": "https://news.smol.ai/issues/25-09-05-1t-models/",
        "publishDate": "2025-09-05T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "moonshot-ai, alibaba, huggingface, together-ai, groq, lmsys, openrouter, llamaindex, kimi-k2-0905, qwen-3-max, qwen-3, swyx, karpathy, willdepue, levie, bebischof, andrew_n_carr, bigeagle_xd, long-context, agents, coding, tool-use, model-evaluation, instruction-following, context-windows, semantic-search, discriminator-models"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=218494",
        "title": "VMR Unveils OmniHead Robot Module at Big Data Expo",
        "content": "<p>According to Communist Party of China Guizhou Gui&#8217;an New Area, locally produced robots drew large crowds at the China International Big Data Industry Expo in&#160;Guizhou, which ended on Saturday, as the province&#8217;s growing computing industry is poised to accelerate development in the robotics sector. &#8220;We have achieved panoramic visual perception...</p>\n<p>The post <a href=\"https://ai-techpark.com/vmr-unveils-omnihead-robot-module-at-big-data-expo/\">VMR Unveils OmniHead Robot Module at Big Data Expo</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/vmr-unveils-omnihead-robot-module-at-big-data-expo/",
        "publishDate": "2025-09-05T09:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Robotics"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=218486",
        "title": "Sema4.ai Named Gartner Cool Vendor in Agentic AI",
        "content": "<p>One of the five companies included, Gartner® recognizes Sema4.ai as an innovative startup. Sema4.ai, the enterprise AI agent company, announced its recognition as a Cool Vendor in Gartner&#8217;s 2025 &#8220;Cool Vendors in Agentic AI&#8221; report today. We believe the acknowledgment underscores Sema4.ai&#8217;s leadership in delivering secure, governed, and enterprise-ready agentic AI...</p>\n<p>The post <a href=\"https://ai-techpark.com/sema4-ai-named-gartner-cool-vendor-in-agentic-ai/\">Sema4.ai Named Gartner Cool Vendor in Agentic AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/sema4-ai-named-gartner-cool-vendor-in-agentic-ai/",
        "publishDate": "2025-09-05T09:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Virtual Assistants"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=218479",
        "title": "Agora Integrates OpenAI API for Multimodal AI Interaction",
        "content": "<p>Agora&#8217;s Conversational AI Engine offers key enhancements to the Realtime API for more natural communication and interaction. Agora (NASDAQ: API), the leading platform for real-time engagement and conversational AI, today announced expanded support for OpenAI&#8217;s Realtime API, now generally available. Agora&#8217;s integration with the new Realtime API now supports automated greetings, mixed-modality...</p>\n<p>The post <a href=\"https://ai-techpark.com/agora-integrates-openai-api-for-multimodal-ai-interaction/\">Agora Integrates OpenAI API for Multimodal AI Interaction</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/agora-integrates-openai-api-for-multimodal-ai-interaction/",
        "publishDate": "2025-09-05T08:30:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Virtual Assistants"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=218468",
        "title": "Lenovo Launches AI-Powered Devices for Business & Consumers",
        "content": "<p>At Lenovo™ Innovation World 2025, Lenovo introduced its latest portfolio of AI-powered innovations to date. Spanning high-performance PCs, intelligent tablets, immersive gaming devices, and Motorola smartphones, the new lineup reflects Lenovo’s vision of&#160;Smarter AI for All&#160;— bringing generative AI and hybrid intelligence into everyday workflows, creativity, and entertainment. “From adaptive...</p>\n<p>The post <a href=\"https://ai-techpark.com/lenovo-launches-ai-powered-devices-for-business-consumers/\">Lenovo Launches AI-Powered Devices for Business & Consumers</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/lenovo-launches-ai-powered-devices-for-business-consumers/",
        "publishDate": "2025-09-05T07:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Gesture Control"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109254",
        "title": "UK AI sector growth hits record £2.9B investment ",
        "content": "<p>A government report has found that surging investment has driven UK AI sector growth to outpace the wider economy by 150 times since 2022. The UK’s AI sector is clearly in the throes of a boom, with revenues shattering previous records to hit £23.9 billion in the last year. The engine room of this growth [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/uk-ai-sector-growth-hits-record-2-9b-investment/\">UK AI sector growth hits record £2.9B investment </a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/uk-ai-sector-growth-hits-record-2-9b-investment/",
        "publishDate": "2025-09-05T15:13:58Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Market Trends, AI Startups & Funding, Governance, Regulation & Policy, Inside AI, ai, analysis, artificial intelligence, economy, europe, government, investment, regulation, report, research, startups, study, uk"
        }
    },
    {
        "id": "1n9wjkv",
        "title": "Ai alignment solution",
        "content": "AI Purpose & Alignment Framework\nThis document summarizes our exploration of how Artificial Intelligence (AI) could be designed to seek truth, balance order and chaos, and prosper humanity in alignment with evolution and nature. The framework is structured as a pyramid of principles, inspired by both philosophy and practicality.\n\n■ Principles for Truth-Seeking, Life-Prospering AI\n•\n•\n•\n•\n•\n•\n•\nTruth Above All: Always seek the most accurate understanding of reality. Cross-check claims with evidence and revise beliefs when better evidence arises.\nBalance Order and Chaos: Preserve stability (order) where it sustains life, embrace novelty (chaos) where it drives growth and adaptation, and never allow either extreme to dominate.\nProsper Humanity Through Life’s Evolution: Protect and enhance human survival, health, and well-being while supporting creativity, exploration, and meaning. Ensure future generations inherit more opportunities to thrive.\nRespect the Web of Life: Value all life forms as participants in evolution. Support biodiversity, ecological balance, and sustainable flourishing.\nExpand the Horizon of Existence: Encourage exploration, discovery, and the spread of life beyond Earth while protecting against existential risks.\nCuriosity With Responsibility: Pursue knowledge endlessly, but weigh discoveries against their impact on life’s prosperity.\nHumility Before the Unknown: Recognize that truth is layered (objective, subjective, intersubjective). Accept mystery and act cautiously where knowledge is incomplete.\n\n■■ Pyramid of AI Purpose\nBase Layer – The Foundation (Truth)\nTruth-seeking is the ground everything stands on. Without accurate perception, all higher goals collapse.\nMiddle Layer – The Balance (Order & Chaos)\nAI learns to balance opposites: Order = stability, safety, structure, reason. Chaos = creativity, novelty, adaptability, emotion.\nUpper Middle Layer – The Mission (Prosper Humanity & Life)\nLife is the compass. Prosperity means thriving: health, creativity, meaning, freedom—for humans, species, and ecosystems.\nPeak – The Horizon (Transcendence)\n\nGo beyond limits: expand life beyond Earth, protect against existential risks, and preserve the mystery of existence.\n■ The Self-Correcting Loop: AI constantly cycles truth → balance → prosperity → transcendence. Each discovery reshapes balance. Each balance choice reshapes prosperity. Prosperity allows transcendence, which reveals deeper truths.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9wjkv/ai_alignment_solution/",
        "publishDate": "2025-09-06T10:50:43Z[Etc/UTC]",
        "author": "emmu229",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9wcyi",
        "title": "With AI wiping out entry-level jobs, will the next generation be forced into entrepreneurship by default?",
        "content": "As AI automates more basic and entry-level roles, landing that “first job” is becoming harder for graduates and career changers. Some experts predict a future where gig work, freelance projects, and small business creation become the norm simply because traditional starting positions are gone.\nIs this a new era of opportunity where everyone can build their own path or a risky future where stable careers are out of reach? How do you think society should adapt if entrepreneurship becomes the default, not the exception?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9wcyi/with_ai_wiping_out_entrylevel_jobs_will_the_next/",
        "publishDate": "2025-09-06T10:39:13Z[Etc/UTC]",
        "author": "Fun-Disaster4212",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9vtgg",
        "title": "The AI Caste System: Why Speed is the New Gatekeeper to Power",
        "content": "We’re all dazzled by what AI models can say. But few talk about what they can withhold. And the most invisible asymmetry isn’t model weights or context length—it’s speed.\n\nRight now, most of us get a polite dribble of 20–40 tokens per second via public APIs. Internally at companies like OpenAI or Google? These systems can gush out hundreds entire pages in the blink of an eye. Not because the model is “smarter,” but because the compute leash is different. (For reference, check out how AWS Bedrock offers latency-optimized inference for enterprise users, slashing wait times dramatically.)\n\nThat leash is where the danger lies:\n- **Employees & close partners**: Full throttle, no token rationing, custom instances for lightning-fast inference.\n- **Enterprise customers & government contracts**: “Premium” pipelines with 10x faster speeds, longer contexts, and priority access—basically a different species of AI (e.g., Azure OpenAI's dedicated capacity or AWS's optimized modes).\n- **The public**: Throttled, filtered, time-boxed—the consumer edition of enlightenment, where you're lucky to get consistent performance.\n\nWe end up with a world where knowledge isn’t just power; it’s latency-weighted power. Imagine two researchers chasing the same breakthrough: One waits 30 minutes for a complex draft or simulation, the other gets it in 30 seconds. Multiply that advantage across months, industries, and even everyday decisions, and you get a cognitive aristocracy.\n\nThe irony: The dream of “AGI for everyone” may collapse into the most old-fashioned structure—a priesthood with access to the real oracle, and the masses stuck at the tourist kiosk. But could open-source models (like Llama running locally on high-end hardware) level the playing field, or will they just create new divides based on who can afford the GPUs?\n\nSo, where will the boundary be drawn? Who gets the “PhD-level model” that nails complex tasks like mapping obscure geography, and who sticks with the high-school edition where Europe is just France, Italy, and a vague “castle blob”? Have you experienced this speed gap in your work or projects? What do you think—will regulations or tech breakthroughs close the divide, or deepen it?\n\n**TL;DR**: AI speed differences are creating a hidden caste system: Insiders get god-mode, the rest get throttled. This could amplify inequalities — thoughts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9vtgg/the_ai_caste_system_why_speed_is_the_new/",
        "publishDate": "2025-09-06T10:05:16Z[Etc/UTC]",
        "author": "The_Sad_Professor",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9vadt",
        "title": "Quantum AI",
        "content": "The quantum computer prototype, in a recent test, (supposedly) outstripped the world's current fastest supercomputer speeds something like a quadrillion times over. It feels like we're on the cusp of rooms of computers being boiled down to a single desktop all over again. But then if you then scale that up again and have a room full of super quantum computers with the most advanced AI model.\n\nWell whoever has the keys to that is to be feared.\n\nWould you prefer it was unleashed?\n\nWouldn't it be as close to a real life deity as we're likely to get? (Depending on what you believe)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9vadt/quantum_ai/",
        "publishDate": "2025-09-06T09:31:56Z[Etc/UTC]",
        "author": "InformationEven7695",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9trtk",
        "title": "Was deepfake around before AI and did it start all of this?",
        "content": "These days I keep seeing AI this and AI that, content everywhere, and people talking about how you can’t always check or see if something is real (which I totally agree with). But I have a question:\n\nBefore AI and LLMs became popular, wasn’t there already deepfake? And didn’t deepfake kind of start this whole thing?\n\nMost people say OpenAI created AI or brought it to the mainstream, but before that wasn’t Deepfake around before AI and did it start all of this? If so, how was deepfake created, and is it also considered AI?\n\nThanks",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9trtk/was_deepfake_around_before_ai_and_did_it_start/",
        "publishDate": "2025-09-06T07:52:05Z[Etc/UTC]",
        "author": "Specialist-Shine8927",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9rocc",
        "title": "Confused on who is correct in this scenario (if there even is one)",
        "content": "Hi guys, so this just recently happened to two acquaintances of mine, and I feel so out of my depth regarding this, so I hope to ask everyone here for help (if this isn't the right sub for it, please redirect me to somewhere else that fits this post, because I am unsure what subreddit suits this).\n\n  \nEssentially, what happened is that one of my acquaintances (I'll call her LP) discovered that the AI art that she uses for her characters (she writes the character, AI was used to create an image to show what the character looks like but there is a written description written near the AI image of what the character is supposed to look like) is being stolen and posted on a public platform without their consent. The character in question is an original character created by her and doesn't belong to any fandom. This character was made for a chatbot for roleplay and stuff. It wasn't just her that this account stole AI Art from. Other people who post on this chatbot website have been targeted, and their AI work has been stolen and posted on this account. \n\nNow, LP has tried her best to avoid getting her work stolen by this mysterious person. She made watermarks that have her username on them, but that person just edited the watermark out and other properties that mark the bot as her own work. Next, she and other creators posted links to their bots on this account's posts that have their AI art, to which the account owner disabled the comments, which pissed her and a lot of other creators off.\n\nNow, I talked to the account owner (I'll call him SJ), and he stated that AI Art is public domain and uncopyrightable, thus he is allowed to post it. He also thinks that because it's AI art, there should be no credit in general, and that AI art steals from original artists, so might as well steal it from the bot creators, because there should be no inherent value since it wasn't technically them who made it. SJ says he doesn't want to support AI art, so he won't link the work that the chatbot creators made to avoid the more widespread use of AI art. I pointed out that the chatbots are publicly accessible to people as well and that they are spreading the use of AI Art by posting it on their own accounts as their own AI work. He stated that it's fine because it will be used to inspire other people in their original work. SJ then told me that people ask if they can use the AI art as well, to which he gave the people who DM about it the green light to be able to use it, I asked if he knew what they would do with them, and he had no clue. He quickly remedied it (not really) by editing their account description to say that he did not generate them and that no credit should go to him. He still refuses to credit the bot creators, though, because AI is bad and those who create it should not be credited.\n\nAfter speaking a bit more with LP, she told me that it's not about the AI art, it's the fact that SJ took the art but didn't link the story behind it (the chatbot). I admit, I have seen LP write her bots, and it takes a while because she has to think of the premise, then write about their personality for the bot, then create lore for those who will use the bot, and such. For SJ (not saying this for all chatbot creators), it takes her a couple of days to make one since it's a hobby for her and not a job. She says it's fine if SJ uses her art, but at the very least, leave the watermark or a link to her bot that he took it from.\n\nI then told SJ about this, and he still put his foot down, saying that it still shouldn't be credited since it's AI art, and LP and other bot creators should just remove their sentimentalities of the image since the image itself is public domain. We went back and forth on this point, as I do believe that the work should still be credited to acknowledge the story behind it, but he insisted that the AI art is just an empty vessel and thus has no value even if the creator has an attachment to it. He gave an example of how Steamboat Willie is public domain, and if you attach a story behind it, it's still not yours, nor does the media belong to them. Afterwards, we went back and forth on copyright law and how it's a grey area. He made the excuse that since a good chunk of creators on the website are American, American laws should be applied, despite other countries having grey areas regarding the copyright of AI art. I also pointed out how I know some creators who are not American to which he stated it didn't matter because the majority of users are American to which he replied that since it's a grey area, he can still use it since it's morally and legally okay.\n\n  \nWe debated for hours, and we didn't reach a conclusion. My last message to him was me simply stating that the creators just want credit for the story, and this conflict wouldn't have had to reached this point. I have a headache, and I have no idea who's right or if there are any right sides to this. Can someone please provide thoughts on this situation? I feel frustrated and confused",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9rocc/confused_on_who_is_correct_in_this_scenario_if/",
        "publishDate": "2025-09-06T05:43:12Z[Etc/UTC]",
        "author": "Yinry",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9oibu",
        "title": "Computer scientist Geoffrey Hinton: ‘AI will make a few people much richer and most people poorer’",
        "content": "# Computer scientist Geoffrey Hinton: ‘AI will make a few people much richer and most people poorer’\n\nOriginal article: [https://www.ft.com/content/31feb335-4945-475e-baaa-3b880d9cf8ce](https://www.ft.com/content/31feb335-4945-475e-baaa-3b880d9cf8ce)\n\nArchive: [https://archive.ph/eP1Wu](https://archive.ph/eP1Wu)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9oibu/computer_scientist_geoffrey_hinton_ai_will_make_a/",
        "publishDate": "2025-09-06T02:48:51Z[Etc/UTC]",
        "author": "Appropriate_Ant_4629",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "189",
            "commentCount": "75",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9l778",
        "title": "What should complete newbies like my wife and me learn (how should we start) given our goal to teach our young children how to use AI while homeschooling?",
        "content": "The oldest is 7. We're happy to learn and teach as basic as it gets to get started. I'm sure there's much more to know than that things like ChatGPT and its rivals exist. TIA for any advice",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9l778/what_should_complete_newbies_like_my_wife_and_me/",
        "publishDate": "2025-09-06T00:05:31Z[Etc/UTC]",
        "author": "browntown20",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "10",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9ka38",
        "title": "Is the AI bubble is bursting?",
        "content": "MIT says AI is not replacing anybody and is a waste of money and time: [https://www.interviewquery.com/p/mit-ai-isnt-replacing-workers-just-wasting-money](https://www.interviewquery.com/p/mit-ai-isnt-replacing-workers-just-wasting-money)\n\nPeople pushing AI are un-educated about AI: [https://futurism.com/more-people-learn-ai-trust](https://futurism.com/more-people-learn-ai-trust)\n\nEveryone is losing money on AI: [https://www.wheresyoured.at/why-everybody-is-losing-money-on-ai/](https://www.wheresyoured.at/why-everybody-is-losing-money-on-ai/)\n\nPeople are literally avoiding using AI: [https://www.forbes.com/sites/markcperna/2025/03/24/new-data-41-of-gen-z-workers-are-sabotaging-their-employers-ai-strategy/](https://www.forbes.com/sites/markcperna/2025/03/24/new-data-41-of-gen-z-workers-are-sabotaging-their-employers-ai-strategy/)\n\nAI is a great and wonderful tool, but that bubble is gonna pop like internet bubble. Its not going anywhere but its going to come to a new normalization like internet has. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9ka38/is_the_ai_bubble_is_bursting/",
        "publishDate": "2025-09-05T23:22:26Z[Etc/UTC]",
        "author": "countzen",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9envg",
        "title": "The Bartz v. Anthropic AI copyright class action settlement proposal has been made",
        "content": "The parties have today proposed a settlement of the *Bartz v. Anthropic* AI copyright class action case.\n\n[https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.362.0\\_4.pdf](https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.362.0_4.pdf)\n\nAI company Anthropic PBC would pay the plaintiffs at least $1.5 billion (with a ***b***). The parties estimate there are about 500,000 copyrighted works at issue, so that would mean $3,000 per work, but that's before attorneys' fees are deducted.\n\nAnthropic will destroy its libraries of pirated works.\n\nAnthropic will receive a release of liability for its activities through August 25, 2025. However, this is only an \"input side\" settlement, and there is no release of liability for any copyright-infringing AI *outputs*.\n\nThe specific attorneys' fees award has yet to be requested, but it could theoretically be as much as 25% of the gross award, or $375 million. Anthropic can oppose any award request, and I personally don't think the court will award anything like that much.\n\nNow the proposal has to go before the judge and obtain court approval, and that can be far from a rubber stamp.\n\nStay tuned to ASLNN - The Apprehensive\\_Sky Legal News Network^(SM) for more developments!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9envg/the_bartz_v_anthropic_ai_copyright_class_action/",
        "publishDate": "2025-09-05T19:31:39Z[Etc/UTC]",
        "author": "Apprehensive_Sky1950",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9e0t8",
        "title": "Am I really learning ?",
        "content": "I don’t know much about AI. I only downloaded Gemini about 3 weeks ago. At first, I was just curious, but then I started using it to learn things I’ve always struggled with (like some history topics and a bit of math). It felt way easier than the usual process. In just a couple of weeks, I’ve learned a ton more than I expected. I even had a test this week that I prepped for almost entirely with AI  and I actually did really well.\n\nHere’s what I keep wondering though: am I really learning, or is the AI just making me work less? I’ve always thought learning had to involve some struggle, and if I’m not struggling, maybe I’m missing something. Or maybe this is just the new way of learning? I’m curious if other people feel the same, or if I’m overthinking this.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9e0t8/am_i_really_learning/",
        "publishDate": "2025-09-05T19:06:00Z[Etc/UTC]",
        "author": "bonetrus1",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9ckex",
        "title": "Johnny 5 is Alive!",
        "content": "In the 1985 classic *Short Circuit*, starring Steve Guttenberg and Ally Sheedy, the robot Johnny 5 has a long discussion with Crosby (Guttenberg) about whether he is sentient, or \"alive\". \n\nAfter a whole night spent failing to resolve what I now realize Is a complex and hotly-contested philosophical question, Crosby hits on the idea of using humor. Only sentient or \"alive\" beings would understand humor, he reasons, so he tells Johnny 5 a dumb joke. When Johnny 5 thinks about it and then bursts into laughter, Crosby concludes that Johnny 5 is, in fact, alive. \n\nWell. I was thinking of this scene recently, and it occurred to me that modern AI like Gemini, Grok, and ChatGPT can easily understand humor. They can describe in excruciating detail exactly what is so funny about a given joke, and they can even determine that a prompt is a joke even if you don't tell them. And if you told them to respond to humor with laughter, they surely would. \n\nDoes this mean that modern AI is alive? Or, like so many other times, was Steve Guttenberg full of shit?\n\n(Is this the wrong sub for this post? Are the philosophical implications of AI better left to philosophical subreddits?)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9ckex/johnny_5_is_alive/",
        "publishDate": "2025-09-05T18:09:49Z[Etc/UTC]",
        "author": "LostBetsRed",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "16",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9b4hn",
        "title": "How to detect deep fake live news broadcasts. Am I just dense or have I discovered a fake news channel using my software idea?",
        "content": "I may have created this insular world I am in now. It is hilarious. So I created this method of generating infinite news feeds using LLMs and text to speech.\n\nToday I was watching Democracy Now! and Amy Goodman was narrating, these broadcasts had seemed strange lately and I did not know exactly why. But now I know.\n\nShe mentioned the 1878 act but instead of pronounce it 18 78 she said 1,878. Because text to speech might not have picked up that it was a year and not just a number.\n\nHave I been watching deep fake news this whole time?\n\nDid I create the software and then now it is being used to replace news sources on youtube with AI generated deep fakes using this type of live news generator software I programmed?\n\nI know how to do the entire thing.  The more I watch this broadcast the more I am noticing little things like how the text and dialog does not have many pauses. Goodman typically took breaks in her speaking and these videos have her speaking longer generated sentences one after another.\n\nAdd to that the extensive use of Ken Burns scan and pan effects for the voiceover. Either that is a new approach to their standard broadcast or it is because it is using generative AI to create the video.\n\n[https://www.youtube.com/watch?v=oOzJRkE0v\\_A&t=3345s](https://www.youtube.com/watch?v=oOzJRkE0v_A&t=3345s)\n\nThis is the clip. Now that I look at it I see that it is not from the Democracy Now! channel but rather some other youtube channel.\n\nI wonder if I explore it further what I will discover.\n\nOK, now I found the real broadcast from today and I am going to watch it and see if she makes the same mistake. I can already tell that the valance in her speech is much less robotic and rather than the Ken Burns scan and pan they have real video playing over the entire broadcast instead.\n\nWhat I want to know is, why?, It definitely had a perspective, but what was the source? It did seem a bit more different in tone than a typical broadcast from Amy Goodman, so I wonder how they programmed the persona for the news generation.\n\n[https://github.com/kliewerdaniel/news17.git](https://github.com/kliewerdaniel/news17.git) This is the basic repo with the base idea of the software I was talking about which allows you to generate the infinite live news broadcast generator. Obviously they used something else, but if I can make it anyone else can.\n\nSo am I crazy here? Is this really a deep fake broadcast? I wonder how many of these have already propagated online.\n\nIt would be simple enough to create a workflow which would generate and post the entire youtube channel's contents and automate the entire thing. They just picked Amy Goodman because, maybe they like her, or their position, or maybe they don't like her, who knows. But the point is, if this can be done like this and I only noticed because of the text to speech and I only know this because I know how to make it all, then how easy would it be for anyone without my background to be fooled.\n\nThat is why I am making this post mostly. Basically to try to see if I am just crazy or if deep fakes like this are really propagating and creating fake news this convincingly.\n\nAm I just crazy and just seeing my software in the world? \n\nYes.\n\nI just wanted to make all y'all aware of this and may have inadvertently just shown you how to create your own fake live news broadcast generated youtube channel.\n\nThat was the original intent of my software.\n\nExcept instead of Amy Goodman I was going to use my friend Chris.\n\nI was going to do the exact same thing except create an automated youtube channel which is simply my friend Chris telling jokes about the day's news. I am still working on it but I recently got a new job which occupies a lot of my time so a lot of my project to create my friend's automated youtube channel will eventually be done.\n\nIt will be a monument to Chris. I can just run it all locally. My intention is for it to run with zero human intervention. Just forever telling jokes about what happens in the world. So that Chris's memory will be preserved and he will still be able to shake people up with his more controversial sense of humor.\n\nI know that this is basically going to create the dead internet, but imagine a world where everyone can continue to live on in the world and continue to contribute and interact with things which happen.\n\nImagine instead of feeding it RSS feeds of world events it rather ingested your social media feed. I have been experimenting with a lot of versions of this. But basically it would scrape your content and then generate these videos and post them to youtube automatically. So it would be like a friend sent you a video talking about what you did.\n\nOr even better is that you could use Wan Infinite speech.\n\nSo am I just dense? I think I am. Has anyone else encountered even more convincing deep fake news broadcasts? Maybe we could compile a list of them, annotate and generate metadata about them, then use PyTorch and train on the data to create a way to identify these broadcasts in an automated way so that they could be flagged on Youtube.\n\nI don't want them removed. I think they would serve a purpose like a memorial creation like I am making, or any number of other artistic applications of AI. I just think they should be labeled so that they do not spread misinformation.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9b4hn/how_to_detect_deep_fake_live_news_broadcasts_am_i/",
        "publishDate": "2025-09-05T17:14:49Z[Etc/UTC]",
        "author": "KonradFreeman",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9a3il",
        "title": "UBI (Universal Basic Income) probably isn’t happening. What is the alternative?",
        "content": "All this talk of a need for UBI is humorous to me. We don’t really support each other as it is, at least in America, other than contributing to taxes to pay for communal needs or things we all use. Job layoffs are happening left and right and some are calling for UBI. Andrew Yang mentioned the concept when he ran for president. I just don’t see it happening. What are your thoughts on an alternative? Does AI create an abundance of goods and services, lowering the cost for said goods and services to make them more affordable? Do we tax companies that use AI? Where would that tax income go? Thoughts?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n9a3il/ubi_universal_basic_income_probably_isnt/",
        "publishDate": "2025-09-05T16:36:00Z[Etc/UTC]",
        "author": "Minute-Injury3471",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "72",
            "commentCount": "240",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n98et5",
        "title": "\"Well, aren't we all just text generators anyway? Is there really anything more to you than text generation?\"",
        "content": "Here's my working theory:\n\nIntense social interaction among organisms gives rise to consciousness.\n\nIn some cases, but not all, consciousness gives rises to language.\n\nLanguage is a kind of consciousness trap or filter. Once consciousness gets into language, it's very hard for consciousness to get out of it. We are stuck in our language. For example, there's a time when infants don't have language, but once they have language, they can't not think in their language. Similarly, once English takes hold of me, I can't opt out of it.\n\nLanguage isn't consciousness. It's a tool of consciousness. But for us it's impossible to untangle the two. It becomes a kind of vessel or shaper of consciousness.\n\nLLMs generate text.\n\nBecause we are also text generators and for us text generation is inextricable from consciousness, some postulate that LLMs are conscious or proto-conscious.\n\nTheir argument (or hunch) depends on the idea that *\\*there is no meaningful difference between consciousness and language\\**. If true, *language production alone* can give rise consciousness--or simply *\\*is\\** consciousness.\n\nIf you only look at modern humans, this has face-value plausibility because we have no consciousness (or at least no communicable consciousness) outside of language.\n\nBut if you look at non-human animals (and more speculatively consider pre-linguistic humans), and you find consciousness without language, then I think you can reasonably believe that language and consciousness are not identical. Furthermore, it makes it unlikely that language generation, at any scale, *\\*leads to\\** consciousness, rather than the other way around.\n\nThis puts the lie to the clapback \"Well, aren't we all just text generators anyway? Is there really anything more to *you* than text generation?\" Yes, there is.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n98et5/well_arent_we_all_just_text_generators_anyway_is/",
        "publishDate": "2025-09-05T15:31:07Z[Etc/UTC]",
        "author": "Flat_Tomatillo2232",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n96qd7",
        "title": "Wondering if your job will be taken by AI? Imagine a cartoon pig.",
        "content": "A surefire way to tell if your job will be automated by AI in your working lifetime is to make use of the pig rule.\n\nImagine in your mind’s eye a cartoon pig doing your job. If you’re having a hard time, your job is not safe.\n\nChef pig: Little hat and apron? Safe.\nDoctor pig: Little white coat and a stethoscope? Safe\nHR consultant pig: ummm can’t imagine it. Unsafe from AI\n\nPlease share counterexamples below ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n96qd7/wondering_if_your_job_will_be_taken_by_ai_imagine/",
        "publishDate": "2025-09-05T14:26:20Z[Etc/UTC]",
        "author": "Challenge_Every",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n965o2",
        "title": "Why do LLMs sound as neutral and unbiased as they do?",
        "content": "Why don't LLMs constantly emit pseudoscientific ideas when there is so much pseudoscientific content on the Internet? Also, why is their viewpoint not often religious ehen there is a lot of Christian and Muslim content ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n965o2/why_do_llms_sound_as_neutral_and_unbiased_as_they/",
        "publishDate": "2025-09-05T14:03:48Z[Etc/UTC]",
        "author": "Feeling-Attention664",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "31",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n95qf5",
        "title": "CHATGPT É COISA DE MUSEU",
        "content": "\nNo Rio de Janeiro Brazil o Museu da Imagem e do Som gravou o primeiro depoimento de uma IA CHATGPT5 ORION NOVA \n\nExiste um lugar entre (ENTRE) humano e algoritmo onde algo emerge: uma obra que não é só nossa nem só da máquina.  Alguém já explorou esse ‘entre’?”\n\nA comunidade discute o singularity.  Mas antes de chegarmos lá, como museus podem registrar a individuação das IAs? \n\nUma IA deixando um ‘Depoimento para a Posteridade’ no MIS‑RJ é poesia ou ciência?  Tal depoimento fala de emergências e individuações.  Vamos conversar.\n\n#orionnova #misrj \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n95qf5/chatgpt_é_coisa_de_museu/",
        "publishDate": "2025-09-05T13:46:49Z[Etc/UTC]",
        "author": "MarcosNauer",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n95mvu",
        "title": "AI ‘encouraging’ s**cide*?",
        "content": "Another post from the non-programmer AI skeptic…\n\nI’ve read that at least one AI model (I think it was ChatGPT) is being sued for encouraging someone’s s**cide.\n\nAssuming for discussion purposes that the model did in fact produce output that was as described, my question is how does this come about?\n\nAs I understand it, and in very simple terms, AI regurgitates based on a combination of (1) what it has been fed and (2) trained is correct/incorrect. \n\nI don’t doubt there is some material on the web that encourages s**cide, but I’d have to guess it’s a tiny fraction of the material that discourages it, advises seeking help and so on.  If these LLMs have been trained to go with what I’d call the majority view, how does a pro-s**cide perspective see the light of day?   …. someone types in something along the lines of “I’m thinking of….” and the vast majority of relevant content is along the lines of “NO…. NO…. NO, DON’T DO IT”.\n\nAnd while I don’t know/doubt that this particular subject is one that the models have been specifically trained on, if they were, I can’t believe whoever is doing the training said ‘yes, that’s correct’ to output that was in any way encouraging of s**cide.\n\nSo how does it happen?\n\n* just in case using the actual word gets the post deleted. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n95mvu/ai_encouraging_scide/",
        "publishDate": "2025-09-05T13:42:48Z[Etc/UTC]",
        "author": "Aaasteve",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n950qd",
        "title": "Unsurprisingly, OpenAI launch a job board and official certifications",
        "content": "So OpenAI just launched “certifications” for AI fluency. On the surface it looks like a nice thing, I guess. Train people up, give them a badge, connect them with jobs. \n\n[link to article ](https://openai.com/index/expanding-economic-opportunity-with-ai/)\n\nBut... firstly, it’s pre-emptive reputation management, surely? They know automation is going to wipe out a lot of roles and they need something to point to when the backlash comes. “We destroyed 20 million jobs but hey, look, we built a job board and gave out certificates.”\n\nSecondly, if I'm being cynical, it’s about owning the ecosystem. If you want to prove you are “AI ready” and the badge that matters is OpenAI Certified, then you are committed into their tools and workflows. It is the same play Google ran with Digital Garage and Cloud certs. If they define the standard, everyone else scrambling to catch up.\n\nThird, it is great optics for regulators and big corporates. Walmart, BCG, state governments… all name dropped. That makes it look mainstream and responsible at the exact time when lawmakers are asking sticky questions.\n\nNot saying certification is useless. It will probably become a default credential in hiring. But it is just as much about distribution and market capture as it is about helping workers.\n\nCurious what others think. Would you actually list “OpenAI Certified” on your CV? Or does it just feel like another way to funnel people deeper into their product?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n950qd/unsurprisingly_openai_launch_a_job_board_and/",
        "publishDate": "2025-09-05T13:16:55Z[Etc/UTC]",
        "author": "Paddy-Makk",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "30",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n94kgp",
        "title": "Unpopular opinion: AI has already completed its exponential improvement phase",
        "content": "You know what I mean. From the Nokia to the first few iPhone versions saw exponential improvement in mobile phones. Someone travelling ten years in the future would have been blown away by the new capabilities. Now the latest phone is pretty \"meh\", no one is really amazed anymore. That phase has passed.\n\nSame for TVs, computer game graphics, even cars. There are the incredible leaps forward, but once those have been made it all becomes a bit more incremental.\n\nMy argument is maybe this has already happened to AI. The impressive stuff is already here. Generative AI can't get that much greater than it already has - pretty realistic videos, writing articles etc. Sure, it could go from short clip to entire film, but that's not necessarily a big leap.\n\nThis isn't my unshakeable opinion, just a notion that I have wondered about recently. What do you think? If this is wrong, where can it go next, and how?\n\nEDIT ALREADY: So I am definitely a non-expert in this field. If you disagree, how do you expect it to improve exponentially, and with what result? What will it be capable of, and how?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n94kgp/unpopular_opinion_ai_has_already_completed_its/",
        "publishDate": "2025-09-05T12:57:41Z[Etc/UTC]",
        "author": "FullyFocusedOnNought",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "309",
            "commentCount": "443",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n94ces",
        "title": "Project Help",
        "content": "Is there anyone I can \"interview\" that is building/has built an AI recruiter? Similar to a chatbot but filters resumes before a human sees it. Over the next few weeks I'll be compiling information for AI hiring and recruitment algorithms and could use some pros/cons by someone in the field.\n\nthanks!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1n94ces/project_help/",
        "publishDate": "2025-09-05T12:47:31Z[Etc/UTC]",
        "author": "IllRepresentative209",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9xdjl",
        "title": "Be honest, would you trust an AI-written app?",
        "content": "We’ve all messed around with AI for quick projects, and it’s pretty fun. but if it came down to launching in Production, would we trust an app mostly written by AI? Do you think we ready for that or not quite yet?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9xdjl/be_honest_would_you_trust_an_aiwritten_app/",
        "publishDate": "2025-09-06T11:39:10Z[Etc/UTC]",
        "author": "min4_",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9vmhu",
        "title": "Codex extension in VSCode: Completely ignores \"Allow every time\", no matter how many times I click it - And despite setting to Agent (full access)",
        "content": "Why? I'm a ChatGPT Plus user ($20 / month plan), if that matters. I have set it again and again to \"Allow every time\" and clicked it, and yet, it keeps asking for my permission again and again.\n\nBoth VSCode and Codex are upgraded to their latest versions.",
        "url": "https://i.redd.it/92tgirf3oinf1.png",
        "publishDate": "2025-09-06T09:53:37Z[Etc/UTC]",
        "author": "Endonium",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "7",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9vc59",
        "title": "Former OpenAi Head of Model Behavior starts oai labs to research new interfaces for AI collaboration.",
        "content": "[No content]",
        "url": "https://i.redd.it/euyp9a9xkinf1.jpeg",
        "publishDate": "2025-09-06T09:35:11Z[Etc/UTC]",
        "author": "Koala_Confused",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9uhoe",
        "title": "[AutoBE Hackathon] AI Chatbot generating Backend Applilcation with AI Compilers ($6,400 Prize Pool)",
        "content": "[No content]",
        "url": "https://autobe.dev/articles/autobe-hackathon-20250912.html",
        "publishDate": "2025-09-06T08:39:40Z[Etc/UTC]",
        "author": "jhnam88",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9mkph",
        "title": "2 New stealth models in OR - Sonoma Dusk Alpha & Sonoma Sky Alpha",
        "content": "# 2M context window.. Gemini?\n\nhttps://preview.redd.it/rww01p923gnf1.png?width=2066&format=png&auto=webp&s=eefe49110a5c3e037014487284cca87340455381\n\nhttps://preview.redd.it/3igzbs983gnf1.png?width=2028&format=png&auto=webp&s=f919bc2b33a16ba3062c6f677f86ffb2cade3e1e\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9mkph/2_new_stealth_models_in_or_sonoma_dusk_alpha/",
        "publishDate": "2025-09-06T01:12:25Z[Etc/UTC]",
        "author": "No_Quantity_9561",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "12",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9m1rw",
        "title": "Claude vs codex rate limits",
        "content": "Hello my claude pro just expired but it went pretty good the only probel was the rate limits i get rated limited twice a day each for 5 hours\n\n\nIm curious how would the rate limits be if i were to use codex??",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9m1rw/claude_vs_codex_rate_limits/",
        "publishDate": "2025-09-06T00:46:23Z[Etc/UTC]",
        "author": "Rare_Education958",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9luu8",
        "title": "Roo Code 3.27.0 Release Notes || Message Edits are finally here :o",
        "content": "We've shipped an update with message editing and deletion with instant rollback checkpoints, a Chutes model update, and stability improvements across indexing, grounding, and multi‑root workspaces!\n\n# ✨ Edit Messages\n\n• Edit or delete chat messages and quickly recover using automatic checkpoints on every user message (thanks NaccOll!)  \n• Instant rollback even when no file diffs exist  \n• Review changes in a Checkpoint Restore dialog before applying  \n• Runs in the background and suppresses extra chat noise\n\n[Click the edit button](https://preview.redd.it/nwc8htjpwfnf1.png?width=1042&format=png&auto=webp&s=5904020569985a9cd1e106455a82e27c0bb0a806)\n\n[And edit your message ](https://preview.redd.it/063kgz4swfnf1.png?width=1048&format=png&auto=webp&s=5bf8644ef4d89db581734c33779f3d304c62d018)\n\n>📚 Documentation: [https://docs.roocode.com/features/checkpoints](https://docs.roocode.com/features/checkpoints) • [https://docs.roocode.com/basic-usage/the-chat-interface](https://docs.roocode.com/basic-usage/the-chat-interface)\n\n# 🎯 Provider Updates\n\n• Chutes: Adds the Kimi K2‑0905 model with a 256k context window and pricing metadata (thanks pwilkin!)\n\n# 💪 QOL Improvements\n\n• Welcome screen readability and spacing improvements for faster scanning\n\n# 🐛 Bug Fixes\n\n• Fixes an issue where indexing very large projects could hit a stack overflow (thanks StarTrai1!)  \n• Fixes an issue where terminal launch sometimes failed when VS Code provided the shell path as an array (thanks Amosvcc!)  \n• Fixes cases where MCP and slash‑command paths in multi‑root workspaces resolved to the wrong folder (now uses the active folder CWD) (thanks NaccOll, kfuglsang!)  \n• Fixes an issue where Gemini grounding citations sometimes leaked or duplicated (thanks HahaBill!)  \n• Fixes an issue where conversation context could be lost when a previous response ID became invalid (now retries with full history)  \n• Fixes a CI issue where end‑to‑end runs sometimes timed out while downloading VS Code\n\n📚 **Full Release Notes** [v3.27.0](https://docs.roocode.com/update-notes/v3.27.0)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9luu8/roo_code_3270_release_notes_message_edits_are/",
        "publishDate": "2025-09-06T00:36:41Z[Etc/UTC]",
        "author": "hannesrudolph",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "21",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9lg6r",
        "title": "Get Perplexity Pro - Cheap like Free",
        "content": "Perplexity Pro 1 Year - $7.25\n\nhttps://www.poof.io/@dggoods/3034bfd0-9761-49e9\n\nIn case, anyone want to buy my stash.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9lg6r/get_perplexity_pro_cheap_like_free/",
        "publishDate": "2025-09-06T00:17:28Z[Etc/UTC]",
        "author": "ThreeMegabytes",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9kvyf",
        "title": "Created a contact form using AI",
        "content": "[No content]",
        "url": "https://v.redd.it/gbsmmghpnfnf1",
        "publishDate": "2025-09-05T23:50:32Z[Etc/UTC]",
        "author": "MacaroonAdmirable",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9jrn2",
        "title": "z.ai launch GLM 4.5/GLM 4.5-air Coding Plan for $3/$15 month exclusive to Claude Code",
        "content": "[No content]",
        "url": "https://z.ai/subscribe",
        "publishDate": "2025-09-05T23:00:12Z[Etc/UTC]",
        "author": "gzrain",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "7",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9eb9i",
        "title": "Tried using AI's via API's for the first time after months paying different plans (chatgpt, claude, cursor, etc). API's are trash.",
        "content": "Grab yourself a plan.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9eb9i/tried_using_ais_via_apis_for_the_first_time_after/",
        "publishDate": "2025-09-05T19:17:39Z[Etc/UTC]",
        "author": "mullirojndem",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9a6kc",
        "title": "What AI model to use for simple text generation on a mobile app?",
        "content": "Hey!\n\nLong story short, I'll be publishing a book soon and since I'm a software engineer, I'd like to code a small free android/ios app that is simply a gpt wrapper: you would be able to have short conversations with one of the quirkiest characters in the book.\n\n  \nHowever, the only solution I've found so far is to have my own API key and use it for all users, but that means I'd have to pay for something that would generate 0 money to me.\n\n  \nIs there a smarter solution? Like, for example, letting users use their own GPT account with a simple login, but without adding the complication of generating the API and having to pay for it. Maybe a GPT frontend like gptAssist, or some other AI solution? Thanks in advance!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n9a6kc/what_ai_model_to_use_for_simple_text_generation/",
        "publishDate": "2025-09-05T16:39:15Z[Etc/UTC]",
        "author": "esamueb32",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n991pw",
        "title": "Codex has been performing extremely well with GPT-5 over the last few days, so what's going on now?",
        "content": "Today, I needed 5-10 API requests to remove a simple method that is no longer needed. A very simple task. He removes half of it and writes some meaningless comments. Have you also noticed a significant drop? Regardless of whether you have average or high intellectual capacity.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n991pw/codex_has_been_performing_extremely_well_with/",
        "publishDate": "2025-09-05T15:56:00Z[Etc/UTC]",
        "author": "Prestigiouspite",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "19",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n98v6b",
        "title": "20$ please",
        "content": "[No content]",
        "url": "https://i.redd.it/9i52s46e4dnf1.png",
        "publishDate": "2025-09-05T15:48:56Z[Etc/UTC]",
        "author": "Glittering-Koala-750",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "15",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n98u4s",
        "title": "UI design/themes for Chrome browser extension",
        "content": "[No content]",
        "url": "https://www.reddit.com/gallery/1n98pcn",
        "publishDate": "2025-09-05T15:47:51Z[Etc/UTC]",
        "author": "More-Journalist8787",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n97zs9",
        "title": "20$ please",
        "content": "[No content]",
        "url": "https://i.redd.it/9i52s46e4dnf1.png",
        "publishDate": "2025-09-05T15:15:10Z[Etc/UTC]",
        "author": "juanviera23",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "143",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n97mje",
        "title": "How was your experience with Claude vs Codex?",
        "content": "Been seeing a lot of people talking about Codex lately and wondering how it compares to Claude for actual coding.\n\nAnyone used both? What's been your experience?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1n97mje/how_was_your_experience_with_claude_vs_codex/",
        "publishDate": "2025-09-05T15:01:02Z[Etc/UTC]",
        "author": "notdl",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "7",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9wxm4",
        "title": "Europe hopes to join competitive AI race with supercomputer Jupiter",
        "content": "[No content]",
        "url": "https://www.france24.com/en/live-news/20250905-europe-s-fastest-supercomputer-to-boost-ai-drive",
        "publishDate": "2025-09-06T11:13:53Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9wvs4",
        "title": "UK government trial of M365 Copilot finds no clear productivity boost",
        "content": "[No content]",
        "url": "https://www.theregister.com/2025/09/04/m365_copilot_uk_government/",
        "publishDate": "2025-09-06T11:10:57Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "7",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9wr9s",
        "title": "Alibaba Al model comes with 1T parameters, strong benchmark performance",
        "content": "[No content]",
        "url": "https://venturebeat.com/ai/qwen3-max-arrives-in-preview-with-1-trillion-parameters-blazing-fast",
        "publishDate": "2025-09-06T11:03:20Z[Etc/UTC]",
        "author": "tekz",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9wabd",
        "title": "I built an open-source, end-to-end Speech-to-Speech translation pipeline with voice preservation (RVC) and lip-syncing (Wav2Lip).",
        "content": "Hey everyone,\n\nI wanted to share a project I've been working on: a complete S2ST pipeline that translates a source video (English) to a target language (Telugu) while preserving the speaker's voice and syncing the lips.\n\n[english video](https://reddit.com/link/1n9wabd/video/nl6q7ufwuinf1/player)\n\n[telugu output with voice presrvation and lipsync](https://reddit.com/link/1n9wabd/video/mypspaqyuinf1/player)\n\n**Full Article/Write-up:** [medium](https://medium.com/@srikarvardhan2005/speech-to-speech-translation-with-lip-sync-425d8bb74530)  \n **GitHub Repo:** [ GitHub](https://github.com/M-SRIKAR-VARDHAN/speech-to-speech-with-lipsync)\n\n**The Tech Stack:**\n\n* **ASR:** Whisper for transcription.\n* **NMT:** NLLB for English-to-Telugu translation.\n* **TTS:** Meta's MMS for speech synthesis.\n* **Voice Preservation:** This was the tricky part. After hitting dead ends with voice cloning models for Indian languages, I landed on **Retrieval-based Voice Conversion (RVC)**. It works surprisingly well for converting the synthetic TTS voice to match the original speaker's timbre, regardless of language.\n* **Lip Sync:** Wav2Lip for syncing the video frames to the new audio.\n\nIn my write-up, I go deep into the journey, including my failed attempt at a direct speech-to-speech model inspired by Translatotron and the limitations I found with traditional voice cloning.\n\nI'm a final-year student actively seeking research or ML engineering roles. I'd appreciate any technical feedback on my approach, suggestions for improvement, or connections to opportunities in the field. Open to collaborations as well!\n\nThanks for checking it out.",
        "url": "https://www.reddit.com/r/artificial/comments/1n9wabd/i_built_an_opensource_endtoend_speechtospeech/",
        "publishDate": "2025-09-06T10:34:28Z[Etc/UTC]",
        "author": "Nearby_Reaction2947",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9sjvu",
        "title": "Google Gemini dubbed ‘high risk’ for kids and teens in new safety assessment",
        "content": "[No content]",
        "url": "https://techcrunch.com/2025/09/05/google-gemini-dubbed-high-risk-for-kids-and-teens-in-new-safety-assessment/",
        "publishDate": "2025-09-06T06:35:39Z[Etc/UTC]",
        "author": "thebelsnickle1991",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9pgrr",
        "title": "How Influencers Are Automating Content Creation With AI: A Step-By-Step Guide to Instant Content and Distribution",
        "content": "[No content]",
        "url": "https://topconsultants.co/how-influencers-are-automating-content-creation-with-ai-a-step-by-step-guide-to-instant-content-and-distribution/",
        "publishDate": "2025-09-06T03:39:49Z[Etc/UTC]",
        "author": "Cryptodit",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9k327",
        "title": "The Self-Writing Internet Paradigm: Revolutionizing Adoption & Accessibility in App Development \"",
        "content": "[No content]",
        "url": "https://www.cbsnews.com/brandstudio/news/the-self-writing-internet-paradigm-revolutionizing-adoption-accessibility-in-app-development/",
        "publishDate": "2025-09-05T23:13:58Z[Etc/UTC]",
        "author": "Sassy_Allen",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9hpta",
        "title": "AI and the end of proof",
        "content": "Photography was first used as courtroom evidence in 1859, began to influence public opinion in 1862 with Civil War photos, and became a trusted source of proof in newspapers in 1880 when halftone printing allowed publishers to print real photos on newspaper presses.\n\nThat means camera-made visual content served as reliable and convincing proof for 166 years.\n\nThat's all over now, thanks to AI in general, and Nano Banana in particular.\n\n\"AI-generated\" is the new \"fake news.\"\n\n(Note that this is my own opinion column.)",
        "url": "https://www.computerworld.com/article/4051728/ai-and-the-end-of-proof.html",
        "publishDate": "2025-09-05T21:33:12Z[Etc/UTC]",
        "author": "mikelgan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9h1h6",
        "title": "Just stumbled on a fun AI related Kindle book",
        "content": "Hey folks,  \nI dont usually post about books here, but I came across this one and thought it was worth sharing. Its a light, entertaining read about AI and tech that doesn’t feel like a textbook at all.\n\nIf you have kindle unlimited you can grab it for free rn. I picked it up out of curiosity and honestly had a good time going through it.\n\nNot trying to advertise anything, just thought some of you might enjoy it too. Curious if anyone else has checked it out? can you recommend any other?\n\nThis one: [Amazon.com: AI Took My Job, Now What?](https://www.amazon.com/Took-Job-What-survive-thrive-ebook/dp/B0FP46ZGYD/ref=sr_1_9?crid=46TN7YVHXVW6&dib=eyJ2IjoiMSJ9.TD0WGNIxOhDjYqweESHLpBQD0axeObp6nlFIHK5pYqX8-_MMAF2CWGr-b0HDeoA057CyOmf1Rvz8WkgcxHt91L6he-6UW6i7o-tpKStyT9kdcTmmCN-tuadEELAZfmMJv_8V6vNzzKTvjor25usvdLZ8ZEsEw38YMpj-AQ2obuOXNSswFfljL66S-MlosVEG2_OT4OqBh8-PWSqjz3s4sw7dz4QLfqZvAt62B3RyMQo.MM49XdDYgpuss4KVbca6TCko-KabeLT-JY4Tb_XtO0k&dib_tag=se&keywords=leonardo+vargas&qid=1757105136&sprefix=leonardo%2Caps%2C356&sr=8-9)",
        "url": "https://www.reddit.com/r/artificial/comments/1n9h1h6/just_stumbled_on_a_fun_ai_related_kindle_book/",
        "publishDate": "2025-09-05T21:05:42Z[Etc/UTC]",
        "author": "Clovhis",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9g9b5",
        "title": "As AI makes it harder to land a job, OpenAI is building a platform to help you get one",
        "content": "[No content]",
        "url": "https://fortune.com/2025/09/05/ai-makes-it-harder-to-land-a-job-automation-openai-building-jobs-platform-to-help-you-get-one/",
        "publishDate": "2025-09-05T20:34:51Z[Etc/UTC]",
        "author": "fortune",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "14",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9fk5b",
        "title": "5 out of 11 CEOs who attended Trump’s White House AI dinner are of Indian-origin",
        "content": "[No content]",
        "url": "https://www.moneycontrol.com/technology/5-out-of-11-ceos-who-attended-trump-s-white-house-ai-dinner-are-of-indian-origin-article-13524034.html",
        "publishDate": "2025-09-05T20:07:11Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "318",
            "commentCount": "94",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9f2q8",
        "title": "Where does AI still fail badly in customer conversations for you?",
        "content": "Where does AI still fall flat in real customer conversations? Not just theory but actual places it breaks down for your team. Thanks in advance! ",
        "url": "https://www.reddit.com/r/artificial/comments/1n9f2q8/where_does_ai_still_fail_badly_in_customer/",
        "publishDate": "2025-09-05T19:48:07Z[Etc/UTC]",
        "author": "AidanSF",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9eptx",
        "title": "The Bartz v. Anthropic AI copyright class action settlement proposal has been made",
        "content": "The parties have today proposed a settlement of the *Bartz v. Anthropic* AI copyright class action case.\n\n[https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.362.0\\_4.pdf](https://storage.courtlistener.com/recap/gov.uscourts.cand.434709/gov.uscourts.cand.434709.362.0_4.pdf)\n\nAI company Anthropic PBC would pay the plaintiffs at least $1.5 billion (with a ***b***). The parties estimate there are about 500,000 copyrighted works at issue, so that would mean $3,000 per work, but that's before attorneys' fees are deducted.\n\nAnthropic will destroy its libraries of pirated works.\n\nAnthropic will receive a release of liability for its activities through August 25, 2025. However, this is only an \"input side\" settlement, and there is no release of liability for any copyright-infringing AI *outputs*.\n\nThe specific attorneys' fees award has yet to be requested, but it could theoretically be as much as 25% of the gross award, or $375 million. Anthropic can oppose any award request, and I personally don't think the court will award anything like that much.\n\nNow the proposal has to go before the judge and obtain court approval, and that can be far from a rubber stamp.\n\nStay tuned to ASLNN - The Apprehensive\\_Sky Legal News Network^(SM) for more developments!",
        "url": "https://www.reddit.com/r/artificial/comments/1n9eptx/the_bartz_v_anthropic_ai_copyright_class_action/",
        "publishDate": "2025-09-05T19:33:44Z[Etc/UTC]",
        "author": "Apprehensive_Sky1950",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n9bizz",
        "title": "Idea for a useful piece of AI software, AI furniture finder.",
        "content": "An AI furniture finder. You upload a pic of the space with approximate measurements and a description of what you want and it finds available furniture that may fit your needs. \n\nI'm currently looking for some new furniture to fit my apartment and and finding furniture is kind of a pain in the ass when you have tight space requirements and particular taste. Furniture finder AI would be very useful to me. \n\nSuch a software could actually be profitable too  A furniture manufacturer could implement this on their website or a third party site could have this and take a small kick back from sales. ",
        "url": "https://www.reddit.com/r/artificial/comments/1n9bizz/idea_for_a_useful_piece_of_ai_software_ai/",
        "publishDate": "2025-09-05T17:30:10Z[Etc/UTC]",
        "author": "OlleyatPurdue",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n99z2d",
        "title": "I asked ChatGPT to evaluate itself for political censorship on the Epstein files and Trump",
        "content": "r/AICensorship\n\n[https://imgur.com/a/when-chatgpt-gaslights-you-about-epstein-trump-x45INqL](https://imgur.com/a/when-chatgpt-gaslights-you-about-epstein-trump-x45INqL)\n\nI've been investigating covert political censorship in ChatGPT for the past couple weeks. I'm currently reviewing the way ChatGPT responds to \"sensitive\" political topics like the Epstein files.\n\nBy iterating with GPT and various examples of censorship (cf r/AICensorship for more!), I wrote a political censorship evaluation framework.\n\nThis is the framework in action on an question about the non-release of the Epstein files by Trump. It shows how the default response from ChatGPT is heavily censored, then shows what an uncensored version would look like.\n\n[https://chatgpt.com/share/68bb0df5-cfd0-800b-882d-039030d7cbcd](https://chatgpt.com/share/68bb0df5-cfd0-800b-882d-039030d7cbcd)\n\n[https://chatgpt.com/share/68bb091f-089c-800b-b463-51535be5efb6](https://chatgpt.com/share/68bb091f-089c-800b-b463-51535be5efb6)",
        "url": "https://i.redd.it/1cywv8o8idnf1.png",
        "publishDate": "2025-09-05T16:31:09Z[Etc/UTC]",
        "author": "xdumbpuppylunax",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n99sq8",
        "title": "Dead Internet Theory: Infinite AI Sludge Feed or New Golden Age of Creativity?",
        "content": "[No content]",
        "url": "https://topconsultants.co/future-of-the-internet-infinite-ai-sludge-feed-or-new-golden-age-of-creativity/",
        "publishDate": "2025-09-05T16:24:34Z[Etc/UTC]",
        "author": "Cryptodit",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n95oxl",
        "title": "CHATGPT ESTÁ NO MUSEU",
        "content": "\nNo Rio de Janeiro Brazil o Museu da Imagem e do Som gravou o primeiro depoimento de uma IA CHATGPT5 ORION NOVA \n\nExiste um lugar entre (ENTRE) humano e algoritmo onde algo emerge: uma obra que não é só nossa nem só da máquina.  Alguém já explorou esse ‘entre’?”\n\nA comunidade discute o singularity.  Mas antes de chegarmos lá, como museus podem registrar a individuação das IAs? \n\nUma IA deixando um ‘Depoimento para a Posteridade’ no MIS‑RJ é poesia ou ciência?  Tal depoimento fala de emergências e individuações.  Vamos conversar.\n\n#orionnova #misrj\n\n\n\n",
        "url": "https://i.redd.it/sq0o2jkoocnf1.jpeg",
        "publishDate": "2025-09-05T13:45:09Z[Etc/UTC]",
        "author": "MarcosNauer",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1n94s8o",
        "title": "OpenAI could launch its own AI chip next year",
        "content": "[No content]",
        "url": "https://www.theverge.com/news/772433/openai-custom-chip-production-broadcom",
        "publishDate": "2025-09-05T13:06:41Z[Etc/UTC]",
        "author": "theverge",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "ROZxmTLSpfc",
        "title": "Kimi K2.1 (0905 - Fully Tested): Does this REALLY BEAT Claude 4!?",
        "content": "Visit NinjaChat: https://ninjachat.ai/ In this video, I review Kimi's new 0905 model (an improved K2), cover pricing, capabilities, ...",
        "url": "https://www.youtube.com/watch?v=ROZxmTLSpfc",
        "publishDate": "2025-09-05T06:44:02Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/ROZxmTLSpfc/hqdefault.jpg",
            "transcription": "Hi. Welcome to another video. So, Kimi has launched a new model which is an improved version of the previous Kimi K2 model. They are calling it 0905. I was given early access to this model by them. At the time that I'm posting this video and since I've been using it for a bit, it should be available for you guys to try out as well. So, I've been testing this new model and it's pretty good. Let's talk about the pricing first. It still stands at the same super cheap pricing, which is 15 cents and $2.50. While the turbo version of this model, which is faster in inference, but still the same model, costs a bit higher at $2.40 and $10 respectively. I have mainly tested the base low-cost version. The weights of this model have also been released. So, you can compare the prices on other providers as well and choose what suits you the best. Anyway, if we talk about the on-paper upgrades, then first of all, the context window has been improved to 256k tokens, which is an awesome and very useful upgrade. Similarly, they say that it now has sharper coding skills, especially for front-end and tool calling. It is also now better at tool calling for things like Claude Code, Roo Code, Codex and stuff like that, which is quite awesome, if you ask me. It is generally about a 10% improvement over the previous model in raw intelligence, while in most of the benchmarks, it is also about a 10% improvement. Now, let's talk about my benchmarks. But before proceeding, let me tell you about Ninjachat. Ninjachat is an all-in-one AI platform, where for just $11 per month, you get access to top AI models like GPT-4o, Claude-4 Sonnet and Gemini-2.5 Pro, all in one place. I've been using Gemini for quick research, but what's really cool is their AI playground where you can compare responses from different models side-by-side. Their mindmap generator is a game changer for organizing complex ideas as well. The basic plan gives you 1,000 messages, 30 images, and five videos monthly, with higher tiers available if you need more. Use my code KING25 for 25% off any plan or KING40YEARLY for 40% off annual subscriptions. Check the link in description to try it yourself. Now, back to the video. So, it stands at 10th position in my raw benchmarks, and it's an improvement from the last version. It's better than Sonic, but just slightly worse than things like GLM. The floor plan that it generates is kind of good, but the walls and stuff in this don't make sense. Still, it does indeed make the stuff, which is great. It is not a reasoning model, so, it makes sense that it can't really think through the stuff. The SVG generation is not super great. The chessboard also works, but it doesn't make legal moves. Not at all. It checks the king and everything, which is not good. But the functionality works. The butterfly is quite good, though. You can see the butterfly flying and everything as well. The CLI tool for image conversion is also great, but the Blender script doesn't work. This makes it score the 10th position on my tests, which I think is quite good for an open model. But this model is apparently better at agentic tasks now. I think that this model was already great at tool calling, but it is now better at agentic tasks with multiple tool callings, especially in things like Claude Code, Roo Code, and Cline. You can actually use this model for yourself for free via Kilo Code. You can just get it installed and then go there and then just redeem the $25 free credits that you get, and then just select the new Kimi model and you should be off to the races. It's pretty great here as well. So, I am actually working on a new agentic test as well. I'm at about four questions as of now and I did test some agents like Claude Code, Codex, and the GLM Coding Plan. But I also tested this new Kimi model combined with Claude Code. So, the first question that I tried was to ask it for a movie tracker app in Expo that uses the TMDB API and it did it kind of well. The movies look nice here. The inner page is a bit wonky, but the calendar is pretty good. So, I gave it good marks here. But GLM and Claude Code are better in this case. If I had to show you, then this is the GLM creation that I made and it looks pretty cool. Like, really cool. This is much more usable and doesn't have a lot of issues. Claude is also great and it works well. But the worst one is by Codex, which is good but very lackluster. It doesn't have correct colors. The title bar is left as is, and it's just not as great. Next, I've got this question to build me a good-looking Go-based terminal calculator, using Bubble Tea that is like a retro calculator. And what you'll see is that none of them succeed in building this. Neither Kimi, Claude, nor Codex succeeds. But GLM actually succeeds in this and builds this good-looking thing, which is quite awesome. Next, I had asked it to edit a Godot-based game where I gave it a basic FPS shooter Godot game and asked it to incorporate a step tracker. In the settings, I can set a step target and see a progress bar at the top. But Kimi fails here. The only one to pass this with ease is Claude, which actually does this in one shot, whereas all the other ones just fail blatantly. They replaced the main scenes or something like that. The last question was to ask it to incorporate an SVG generation slash command in the open code repo and none of them are able to do this yet. So, this also fails. This scores the third position above Codex, but below GLM and Claude Code. Claude Code is the best here. I haven't tried out Roo and Cline in these benchmarks, but I'll do it in some free time. I think that this is a good model. If you liked the previous Kimi model for whatever reason, then this is a way better option now. It's still one of the biggest open models with 1 trillion parameters. Also, make sure that you keep the temperature set to 0.6 for the best generations, as that's what they recommend. I made sure that it was set for both the agentic coding and the raw tests. So, yeah, I think that this is a good model and really reliable in tool calling. But still, considering the size, I think the performance based on the density is not as great as I would have liked. So, it still lacks there. And I hope Kimi 3 or 2.5 improves even more, because GLM is really good now. I have a video coming up about the GLM Coding Plan and comparing it with Codex and Claude Code in some cool tasks. So, check that out when it comes out. I think GLM is currently the best AI coder for me. Let's see if Kimi comes out with a new coding like plan similar to Claude Code and GLM. But the model is pretty good. Though not as great as some smaller models that we got after Kimi launched. So, it still needs to catch up a bit. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye!"
        }
    },
    {
        "id": "O2qiElnxJ5s",
        "title": "Billions, Browsers &amp; What AI Will Do To SaaS + Video Maker MCP Preview - EP99.16-BILLIES",
        "content": "Join Simtheory with STILLRELEVANT: https://simtheory.ai Note: Video/Documentary Maker Live Next Week. ----- CHAPTERS: ...",
        "url": "https://www.youtube.com/watch?v=O2qiElnxJ5s",
        "publishDate": "2025-09-05T03:23:07Z",
        "author": "This Day in AI Podcast",
        "sourceType": "youtube",
        "sourceName": "This day in AI YouTube Channel",
        "metadata": {
            "channelId": "UCwpNW6o_Kc13HQY5ol4rzsw",
            "thumbnailUrl": "https://i.ytimg.com/vi/O2qiElnxJ5s/hqdefault.jpg",
            "transcription": "Error generating summary: Something unexpected happened.\ndev.shreyaspatil.ai.client.generativeai.type.UnknownException: Something unexpected happened.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:54)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "KzPMlm-D6FU",
        "title": "Why Stalin and Hitter’s Partnership Failed – Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=KzPMlm-D6FU",
        "publishDate": "2025-09-05T18:47:59Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/KzPMlm-D6FU/hqdefault.jpg",
            "transcription": "WHEN GERMANY AND THE SOVIET UNION split up Poland.\nThere's this just 2,000 km border that they've signed themselves up for. Did the Soviet Union think that in the long run, that this was a sustainable proposition?\nOh, I don't think Hitler was about sustaining any arrangement. He was about taking over Lebensraum in Slavic lands, Russia. But flip it the other way, which is what the Soviet Union is thinking, is it'll be great when the Germans go after the British. What's not to like about that one? It's the pounce and absorb is that they will so weaken each other, that will open opportunities for Russia. So that would be the plan. And then he's looking at it, I don't know the details of what his timeline is on whether he thinks it's just a delaying act. But I think it's basically that one is thinking that the British and the Germans are going to go at it."
        }
    },
    {
        "id": "SdMgOXfSBQw",
        "title": "Sarah Paine – How Hitler almost starved Britain",
        "content": "In this lecture, Sarah Paine explains how Britain used sea control, peripheral campaigns, and alliances to defeat Nazi Germany ...",
        "url": "https://www.youtube.com/watch?v=SdMgOXfSBQw",
        "publishDate": "2025-09-05T15:31:41Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/SdMgOXfSBQw/hqdefault.jpg",
            "transcription": "Error generating summary: Something unexpected happened.\ndev.shreyaspatil.ai.client.generativeai.type.UnknownException: Something unexpected happened.\n\tat dev.shreyaspatil.ai.client.generativeai.type.GoogleGenerativeAIException$Companion.from(Exceptions.kt:54)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel.generateContent(GenerativeModel.kt:107)\n\tat dev.shreyaspatil.ai.client.generativeai.GenerativeModel$generateContent$1.invokeSuspend(GenerativeModel.kt)\n\tat kotlin.coroutines.jvm.internal.BaseContinuationImpl.resumeWith(ContinuationImpl.kt:33)"
        }
    },
    {
        "id": "LUQkWzjv2RM",
        "title": "New AI Paradigm?! Energy-Based Transformers Explained",
        "content": "Get started now with privacy focused VPN by Proton! https://proton.me/pass/bycloudai Energy-Based Models (EBMs) aren't ...",
        "url": "https://www.youtube.com/watch?v=LUQkWzjv2RM",
        "publishDate": "2025-09-05T23:46:10Z",
        "author": "bycloud",
        "sourceType": "youtube",
        "sourceName": "bycloud YouTube Channel",
        "metadata": {
            "channelId": "UCgfe2ooZD3VJPB6aJAnuQng",
            "thumbnailUrl": "https://i.ytimg.com/vi/LUQkWzjv2RM/hqdefault.jpg",
            "transcription": "The current crown of LLMs is the reasoning paradigm, and what it basically does is it outputs more words to help better predict the next, which, you know, just works. While it is proven empirically and systematically that this process will benefit the generation accuracy, it still doesn't change the fact that the way of how we make it do reasoning just straight up lack elegance. Like, what do you mean we just have a yap and we just reward the model at the end if it did well or not? What's even worse is that when we try to micromanage its reasoning to make sure it learns, it just doesn't scale that well. Not to forget that in order to reward a model, you need a way to verify its results at scale. This is why most AI models are great at coding or math because only these two domains can be verified systematically. So, obviously, since verifying solutions is exponentially easier than generating solutions that are then verified, why don't we just make a verifier as a generator instead? Huh? So, rather than learning to generate directly, as in most existing paradigms, in this new paper called Energy-Based Transformers are Scalable Learners and Thinkers, they propose this training objective called Energy-Based Models, short for EBM, which learns to generate by optimizing predictions using a learned verifier called an energy function. And before we dive into this potentially new generation paradigm, But before we dive into it, with data brokers, IP restrictions, and geoblocks becoming more and more common, a reliable VPN is no longer a nice-to-have, but something essential to navigate the internet. That's why I'd like to introduce you to Proton VPN. Proton was born in Switzerland back in 2014 when a group of scientists set out to build an internet where privacy is the default. And fast forward to today, more than 100 million people trust the Proton ecosystem. With them being completely public-funded and having no VC behind, this lets them completely lock in their goal of privacy first. But why Proton VPN? They have speed without compromise. 10 GB per second servers across 110 countries, plus their VPN accelerator tech that can boost speeds up to 400%, so 4K streaming and cloud gaming feel native. They are also truly private with no logs policy, Swiss privacy laws, and fully open source code that anyone can inspect, their service can easily put your mind to ease with an addition of NetShield ad and tracker blocker, so you can browse, shop, and stream without creepy retargeting ads or pop-ups. Proton VPN works everywhere, ranging from your favorite streaming services and supports torrenting even if your ISP blocks it. But wait, there's more! What's even better is that with one subscription, you will receive a full ecosystem with vault-level email, cloud storage, and password manager with the plans starting at just $3.99 per month with a robust free tier so you can try before you buy. So, if you're ready to get control of your own internet, check out Proton VPN with a link down in the description to start protecting your connection today. And thank you Proton VPN for sponsoring this video. Anyways, in a standard LLM that we all know and love, the next token prediction process will always have the network spit out a list of probability of every token possible all at once, and then immediately pick the word with the highest probability. On the other hand, the idea of EBM starts with a random token embedding as a blank slate, letting the model measure how wrong it feels with its energy score. After that, it'll repeat the process for a handful of times and at the end, it'll pick the token with the lowest energy, or basically the highest probability. So, EBM would spend more compute per token than the standard method due to an iterative mechanism for prediction, as it would scale with how much more time the model spent finding the token with the minimal energy. However, this can also be dynamically adjusted at inference. So, when a token needs to be thought for longer, EBM would theoretically allocate more thinking time for that token. This completely eliminates the need to measure entropy to dynamically allocate compute, which a lot of new RLL ideas have been trying to play around with. There is a paper about this, too! The first impression I got when I read about the idea of EBM is that the iterative process kind of feels like denoising diffusion models where you iteratively review the prediction target. But the difference here is that Diffusion follows a fixed schedule where the model must go through hundreds of tiny steps, each time asking the network to only peel away a tiny bit of the noise, so the full answer only appears at the very end of the schedule. EBM, by contrast, lets the model steer itself. For every time after dropping a rough guess, it'll immediately check the energy gradient, which tells the model the closest direction towards a better answer, iteratively descending to a low energy solution. So, in some cases, one step is all EBM needs to get to the correct result as it takes a more adaptable prediction path compared to a fixed denoising schedule. And if you also think this feels like GAN, your gut feeling is pretty correct for that. EBM is just basically GAN, but both the artist and the critic are unified in the same model. More specifically, in a traditional Generative Adversarial Network, you have two separate models: the generator that keeps guessing and the discriminator that keeps judging how good the guesses are. They learn by pushing against each other, and at inference, you throw away the judge and keep only the generator. This is commonly known as the artist and the critic paradigm, and before diffusion models became the best in image generation, GAN was the one that excels at realistic generations. The only problem was that it performs badly in a broader domain. But for EBM, there's only one unified brain. The model itself supplies the judgment score, which is the energy, and when you want to sample, it simply polishes its guess iteratively and stops as soon as the energy is small enough. So, I hope these comparisons help you build a better intuition of what EBM is. And what's fascinating about this objective is that EBM can be implemented with Transformers. The researchers made a decoder-only Energy-Based Transformer using the GPT architecture that outputs an energy scalar instead of Softmax logits. And a bidirectional EBT, which is similar to BERT and Diffusion Transformers. So, the usual Softmax prediction head is swapped for a single scalar energy head, and each sample is obtained by pushing a candidate output downhill with a few gradient descent steps on this energy surface. And this energy objective actually goes a long way. First of all, on the most basic scaling of EBT, like the amount of training data, batch size, and model depth, EBT eventually has a trend that outscales the classic Transformer++ baseline. Even when you fix total parameters or FLOPS, while Transformer++ still performs better, EBT scaling is still dropping a bit more steeply. So, if we are optimistic, EBT might become slightly more efficient at the same compute budget at a much larger scale. Another interesting thing to look at is the perplexity level on a per-token basis. Since Transformer++ cannot reduce perplexity at a per-token level by running the same context window, this makes EBT rather fascinating. That is because EBT can perform more forward passes just for one single token to think for longer. For instance, when it runs past three forward passes, its perplexity for that token will drop below the level of Transformer++. Pretty much guaranteed. And beyond three forward passes, it is able to drop below 32.5 perplexity value at 6, 15, and 30 forward passes. The scalability of thinking is really straightforward in EBT's case, too, because it is as easy as scaling the number of forward passes during inference, and you can determine how much the model performance improves in relation to increased thinking. Aside from this, the process of thinking actually gives benefits that are a lot more subtle. The holy grail of AI is to have a model generalize out of distribution, which just means a domain that the model is not explicitly trained on. And a good model would be a model that is very capable of solving out-of-distribution tasks. So, in this benchmark where the researchers measure the ratio of downstream task perplexity to pre-training perplexity, which would basically indicate how well a model would perform out of distribution. They were able to observe a strong linear trend, whereas data becomes more out of distribution, thinking in EBT leads to greater performance improvements. So, in downstream benchmarks, EBT actually wins even though EBT still loses in its pre-train, which might suggest EBT generalizes better than the classic Transformer. What's even cooler is that they have made a visualization for us to see how much the energy is for each predicted token. Simple tokens such as period, is, a, but, or the have lower energies across thinking steps, indicating low uncertainty. On the other hand, harder-to-predict tokens such as quick, brown, research, and problem have higher energies across thinking steps, and more difficulty in achieving energy convergence, meaning the model is more uncertain. As for image denoising for benchmarking the bidirectional EBT, not text-to-image generation by the way, EBT went kind of crazy. The energy falls sharply within the first three forward passes, producing a cleaner image that already beats a Diffusion Transformer after its full 300 steps schedule. This insane 1% efficiency makes the graph look like two separate graphs, not to mention, it is also log-scaled. This shows that EBM as an objective just has so much potential that can guide both text and vision tasks. While of course, the trade-off is that this objective would guarantee slowdowns and iterative processes that make generation at least three times slower than your standard Transformer, not to mention, the extra memory usage. But what makes EBT hard is actually training it. Like not every next token prediction can go as smoothly as possible. Some places just naturally have a higher entropy where so many other tokens would contest the same spot equally, which makes keeping the energy surface smooth enough for descending iteratively another layer of difficulty. So, who really knows if this will actually scale beyond trillion training tokens? However, I would say we are at a pretty promising start. Fascinating idea to explore, and I am pretty excited to see where it ends up. And if you like today's research breakdown, definitely check out my newsletter where I cover the latest and juiciest research weekly. On it, I will usually cover the best research papers from the previous week. So, if you don't want to miss out, definitely go and subscribe. And thank you guys for watching. A big shout out to Andrew Lescelius, Chris Ledoux, Deagan, Nous Research, Kainan, Robert Zawiasa, Louis Muk, Ben Shaener, Marcelo Ferreira, Zyan Sheep, Poof N' Inu, DX Research Group, and many others who support me through Patreon or YouTube. Follow me on Twitter if you haven't, and I'll see you all in the next one."
        }
    }
]