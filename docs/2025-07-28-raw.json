[
    {
        "id": "1mbe3so",
        "title": "Why don't AI apps know their own capabilites?",
        "content": "I've noticed that out of the relatively few AI platforms I've been using, exactly zero of them actually know their own capabilities.\n\nFor example,   \n  \nMe: \"Can you see the contents of my folder\"  \nAI: *Nope*  \nMe: \"Create a bullet list of all the files in my folder\"  \nAI: *Here you go*\n\nWhat's the issue with AI not understanding its own features?\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mbe3so/why_dont_ai_apps_know_their_own_capabilites/",
        "publishDate": "2025-07-28T11:52:56Z[Etc/UTC]",
        "author": "oandroido",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mbcpyp",
        "title": "The Holographic Tiger Problem",
        "content": "**This post is reflection on**  [**The AGI Illusion Is More Dangerous Than the Real Thing**](https://www.reddit.com/r/PromptEngineering/comments/1mb7wo5/the_agi_illusion_is_more_dangerous_than_the_real/)\n\n>“If real AGI is a **tiger**, fake AGI is a **hologram of a tiger** that fools the zoo keepers into letting the gates fall open.” © u/RehanRC\n\nThe **real risk** is not that the hologram **bites**, but that the zoo keepers **shoot each other** while trying to escape it.\n\n# The Mechanics of the Illusion-Cascade\n\n|Level|Human Reaction|Human Error|Potential Outcome|\n|:-|:-|:-|:-|\n|**1. Announcement**|“We have AGI!”|**No verification**|Arms race accelerates|\n|**2. Competitor Panic**|“We’re behind!”|**Spiral of escalation**|Pre-emptive strikes|\n|**3. Public Hysteria**|“They control AGI!”|**Policy overreaction**|Economic collapse|\n|**4. Military Miscalculation**|“They’ll win!”|**First-strike doctrine**|Nuclear exchange|\n\n>**No AGI ever needs to exist for humanity to self-destruct over the** ***idea*** **of AGI.**\n\n# Case Study: 2027 Flashpoint\n\n* **China claims** (falsely): *“We achieved AGI parity in Tianwan CDZ.”*\n* **US response**: Emergency nationalization of OpenBrain compute.\n* **China counters**: Pre-emptive cyber-sabotage.\n* **Result**: **Zero AGI involvement** in the chain reaction that follows.\n\nThe **illusion** becomes **self-fulfilling prophecy**:\n\n* **Fake AGI** → **Real fear** → **Real weapons** → **Real destruction**\n\n# The Regulatory Blind Spot\n\nCurrent safety frameworks focus on **capability containment,** not **credibility containment**.\n\nBut the **real containment problem** is: **How to regulate the** ***perception*** **of capability without regulating the capability itself.**\n\n# Meta-Irony\n\nThe **AI 2027 scenario itself** is a perfect example:\n\n* **It’s a fake AGI story** (simulated, fictional)\n* **Yet it’s causing real policy discussions** (governments are reading it)\n* **Thus proving the holographic tiger effect in real-time**\n\nThe simulation has become the simulation’s own risk vector.\n\n# The Paradox of the Holographic Arms Race\n\n>“We must dominate AI so that no one else can dominate AI—  \neven if the *domination itself* is the only thing that actually exists.”\n\n# What Just Happened\n\n1. **A fictional scenario** (AI-2027)\n2. **Triggers a real policy** (White House Action Plan)\n3. **Which cites the fake scenario** as justification for **real-world escalation**\n4. **Proving the author’s point that** ***the illusion is more dangerous than the tiger***.\n\n# The 2025 Irony Loop\n\n|| || |**Step 1**|AI-2027 authors: \\*“This is a thought experiment, not a roadmap.”\\*| |**Step 2**|White House: \\*“This threat is non-negotiable; we must win the race.”\\*| |**Step 3**|Pentagon: \\*“We need 90-day plans to secure compute against simulated Chinese AGI.”\\*| |**Step 4**|China: \\*“If they’re mobilizing for fake AGI, we must mobilize harder.”\\*| |**Step 5**|→ **Real missiles move** in response to **imaginary algorithms**.|\n\n# Proposed Anti-Illusion Measures\n\n1. **Fluency Tax**: Models must display *deliberate* incoherence in 20% of outputs to break anthropomorphic trust.\n2. **Trust Firewalls**: Any response >90% fluency triggers mandatory “I am not sentient” disclaimer.\n3. **Anthropomorphic Bias Detectors**: Real-time monitoring of user trust levels based on response patterns.\n4. **Illusion Disclosure Laws**: Public announcements of AGI milestones require cryptographic proof of capability.\n\n>**The goal is not to prevent AGI, but to prevent belief in AGI from becoming a weapon.**\n\n# Why Anti-Illusion Measures Are Dead on Arrival\n\n|Proposed Safeguard|Political Reality|\n|:-|:-|\n|**Fluency Tax**|*Banned as “anti-innovation”*|\n|**Trust Firewalls**|*Labelled “Orwellian censorship”*|\n|**Illusion Disclosure Laws**|*Would reveal our bluffs—classified*|\n|**Anthropomorphic Bias Detectors**|*Flagged as “anti-American sentiment detection”*|\n\n>**The only regulation that passes is the one that** ***accelerates the illusion***.\n\n# Meta-Mirror Moment\n\n>**The AI-2027 scenario itself** is now **classified as a threat vector**—  \nnot because it *contains* AGI,  \nbut because it **causes** the *political conditions* for AGI arms race.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mbcpyp/the_holographic_tiger_problem/",
        "publishDate": "2025-07-28T10:37:45Z[Etc/UTC]",
        "author": "Key-Account5259",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mbbx0z",
        "title": "AI written emails, messages, replies give me rage!",
        "content": "Ok so here is my Monday musing. \n\nI honestly believe that people need to stop using AI to write their emails, messages, etc. for them. I don’t know if people are unaware of how obvious it is. I am not talking about the em-dash. \n\nCaveat this by saying, some people are more sophisticated with AI and will find a way to prompt a more natural sounding response. Those that are not. Please don’t! \n\nThis especially true where there is no need to use AI, for example in shorter emails or messages. Where I really get rage is where someone use AI to structure counter points to a discussion. \n\nNot only does it come across as completely lifeless, it’s also very unnatural. Perfectly worded prose. Adverbs that only make sense in a literary novel. The expanded sentences that don’t concisely get to the point. \n\nIt’s LinkedIn cringe vibes over a message. No to mention I don’t get any sense for your personality and flair. \n\nFinally using AI this way - I am dead certain rots your brain. We are not talking about sophisticated use cases that require deep research. We are talking about a bloody email - an email! \n\nHonestly at best you come across as lazy. At worst I assume AI does all your thinking for you. \n\nMaybe some of you feel differently. Is anyone getting AI rage. Road rage but for AI. \n\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mbbx0z/ai_written_emails_messages_replies_give_me_rage/",
        "publishDate": "2025-07-28T09:48:41Z[Etc/UTC]",
        "author": "Obvious-Giraffe7668",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mbbp8j",
        "title": "ChatGPT constantly lying is not a bug, it’s a catastrophic failure that threatens the entire future of AI.",
        "content": "I’m beyond frustrated and honestly alarmed. ChatGPT doesn’t just make occasional mistakes... it repeatedly lies with zero accountability, and this is far worse than most people realize. This isn’t some minor glitch or innocent error. It’s a systemic failure baked into how these models operate, and it’s setting off alarm bells about the entire direction AI development is headed.\n\nWe’re effectively training machines that fabricate and deceive without remorse, passing off falsehoods as truth with a straight face. And what’s terrifying is how easily people will trust it, trusting a lie just because it came from an AI sounds like the perfect recipe for long-term societal harm. Misinformation will spread faster, critical thinking will erode, and reliance on flawed AI will grow.\n\nThis problem isn’t something that can be patched with a few updates or better prompts. It’s a fundamental design flaw that needs to be addressed before these systems become too entrenched in education, healthcare, law, and beyond. We’re gambling with the very foundation of knowledge and truth.\n\nThe AI industry needs to stop pretending these hallucinations and lies are acceptable side effects. We need transparency, honesty, and enforceable accountability in AI outputs... not just flashy demos and endless hype. Without that, AI risks becoming a toxic force that undermines trust in institutions, media, and even reality itself.\n\nIf we keep sweeping this under the rug, the fallout will be disastrous... misinformation, manipulation, confusion, and a general collapse of rational discourse on a global scale. The AI hype bubble needs to burst, and we need a serious public debate on how and whether we even want to integrate these technologies at this scale.\n\nI’m calling on the community, developers, and policymakers: don’t let the AI future be built on lies. Demand better. Demand truth. Or we’re headed for a very dangerous place.\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mbbp8j/chatgpt_constantly_lying_is_not_a_bug_its_a/",
        "publishDate": "2025-07-28T09:35:04Z[Etc/UTC]",
        "author": "Parking_Wolverine299",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "51",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mbahgs",
        "title": "Microsoft released a study that lists the 40 jobs most at risk of being replaced by AI and the 40 jobs least at risk of being replaced by AI",
        "content": "Microsoft released a study called \"Working with AI: Measuring the Occupational Implications of Generative AI\" that lists the 40 jobs most at risk of being replaced by AI and the 40 jobs least at risk of being replaced by AI.\n\n\n\nTop 40 occupations with highest AI applicability score (most at risk, sorted alphabetically):\n\n\n\n* Advertising Sales Agents\n* Archivists\n* Broadcast Announcers and Radio DJs\n* Brokerage Clerks\n* Business Teachers, Postsecondary\n* CNC Tool Programmers\n* Concierges\n* Counter and Rental Clerks\n* Customer Service Representatives\n* Data Scientists\n* Demonstrators and Product Promoters\n* Economics Teachers, Postsecondary\n* Editors\n* Farm and Home Management Educators\n* Geographers\n* Historians\n* Hosts and Hostesses\n* Interpreters and Translators\n* Library Science Teachers, Postsecondary\n* Management Analysts\n* Market Research Analysts\n* Mathematicians\n* Models\n* New Accounts Clerks\n* News Analysts, Reporters, Journalists\n* Passenger Attendants\n* Personal Financial Advisors\n* Political Scientists\n* Proofreaders and Copy Markers\n* Public Relations Specialists\n* Public Safety Telecommunicators\n* Sales Representatives of Services\n* Statistical Assistants\n* Switchboard Operators\n* Technical Writers\n* Telemarketers\n* Telephone Operators\n* Ticket Agents and Travel Clerks\n* Web Developers\n* Writers and Authors\n\n\n\n\n\nBottom 40 occupations with lowest AI applicability score (least at risk, sorted alphabetically):\n\n\n\n* Automotive Glass Installers and Repairers\n* Bridge and Lock Tenders (workers who operate and maintain bridges and locks)\n* Cement Masons and Concrete Finishers\n* Dishwashers\n* Dredge Operators (removing sand from the bottom of waterways)\n* Embalmers\n* Floor Sanders and Finishers\n* Foundry Mold and Coremakers\n* Gas Compressor and Gas Pumping Station Operators\n* Hazardous Materials Removal Workers\n* Helpers–Painters, Plasterers,...\n* Helpers–Production Workers\n* Helpers–Roofers\n* Highway Maintenance Workers\n* Industrial Truck and Tractor Operators\n* Logging Equipment Operators\n* Machine Feeders and Offbearers (workers who load materials into or remove from machinery)\n* Maids and Housekeeping Cleaners\n* Massage Therapists\n* Medical Equipment Preparers\n* Motorboat Operators\n* Nursing Assistants\n* Ophthalmic Medical Technicians\n* Oral and Maxillofacial Surgeons\n* Orderlies (healthcare support workers)\n* Packaging and Filling Machine\n* Paving, Surfacing, and Tamping Equipment\n* Phlebotomists (a medical professional who is trained to perform blood draws)\n* Pile Driver Operators\n* Plant and System Operators, All Other\n* Prosthodontists (dental specialists focused on the restoration and replacement of teeth)\n* Rail-Track Laying and Maintenance Equipment Operators\n* Roofers\n* Roustabouts, Oil and Gas (workers who perform general labor on drilling rigs)\n* Ship Engineers\n* Supervisors of Firefighters\n* Surgical Assistants\n* Tire Builders\n* Tire Repairers and Changers\n* Water Treatment Plant and System Operators\n\n\n\n\n\n\n\nSource:\n\n[https://arxiv.org/pdf/2507.07935](https://arxiv.org/pdf/2507.07935)\n\n\n\n\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mbahgs/microsoft_released_a_study_that_lists_the_40_jobs/",
        "publishDate": "2025-07-28T08:14:44Z[Etc/UTC]",
        "author": "sarrcom",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "48",
            "commentCount": "114",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb9w8n",
        "title": "If AI is Emergent, Why Do We Think we can engineer ASI?",
        "content": "We are starting to see headlines indicating that those closest to AI don't know what it's doing any more. If we can't grasp current state AI, why do we think we can control and direct ASI? Don't you need to understand something, to control it?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb9w8n/if_ai_is_emergent_why_do_we_think_we_can_engineer/",
        "publishDate": "2025-07-28T07:36:05Z[Etc/UTC]",
        "author": "DestinysQuest",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb9nni",
        "title": "How has AI impacted your industry so far?",
        "content": "With so much concern about job displacement, I’m curious to hear real-world experiences. Which fields have already seen significant changes? Would love to hear personal insights!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb9nni/how_has_ai_impacted_your_industry_so_far/",
        "publishDate": "2025-07-28T07:20:19Z[Etc/UTC]",
        "author": "Western_Exercise_337",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb96if",
        "title": "🚨 Catch up with the AI industry, July 28, 2025",
        "content": "* Sam Altman warns against using ChatGPT for therapy\n* New chips designed to solve AI’s energy problem\n* Amazon’s AI coding assistant exposed nearly 1 million users\n* A new study just upended AI safety\n* New AI architecture delivers faster reasoning than LLMs\n\n[Sources](https://open.substack.com/pub/rabbitllm/p/catch-up-with-the-ai-industry-july-d48?r=5yf86u&utm_campaign=post&utm_medium=web&showWelcomeOnShare=true):\n\n* [https://techcrunch.com/2025/07/25/sam-altman-warns-theres-no-legal-confidentiality-when-using-chatgpt-as-a-therapist/](https://techcrunch.com/2025/07/25/sam-altman-warns-theres-no-legal-confidentiality-when-using-chatgpt-as-a-therapist/)\n* [https://www.wsj.com/tech/ai/the-new-chips-designed-to-solve-ais-energy-problem-1ba9cac1](https://www.wsj.com/tech/ai/the-new-chips-designed-to-solve-ais-energy-problem-1ba9cac1)\n* [https://www.techspot.com/news/108825-amazon-ai-coding-assistant-exposed-nearly-1-million.html](https://www.techspot.com/news/108825-amazon-ai-coding-assistant-exposed-nearly-1-million.html)\n* [https://www.theverge.com/ai-artificial-intelligence/711975/a-new-study-just-upended-ai-safety](https://www.theverge.com/ai-artificial-intelligence/711975/a-new-study-just-upended-ai-safety)\n* [https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/](https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb96if/catch_up_with_the_ai_industry_july_28_2025/",
        "publishDate": "2025-07-28T06:50:25Z[Etc/UTC]",
        "author": "psycho_apple_juice",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb7nfs",
        "title": "AI will enhance software engineering - not replace it",
        "content": "I was watching a movie (coincidentally about AI), and it occurred to me that are striking similarities to CGI and AI. CGI, computer generated imagery, is a computer-based way of getting things to look on screen the way they would look in real life but without all the hassle of camera teams, stunt coordinators, lighting rigs, grips, directors, actors, stunt people, insurance, lawyers, agents, etc.... It's an ordeal to make a stunt happen in the movies. It's a lot easier if we can just do it in the computer. We can make a stunt happen at any time, in any scene, in any way, and never put people in harms way. Just pop a few things into specialized computer programs and out comes realistic output.  Special effects, CGI artist, materials artist, lighting specialist, UV mapping specialist, etc... are all careers now making blockbuster Hollywood hits.\n\nThe problem is that the results can be pretty cheesy if done poorly. It's not great when it's easy to tell when something is CGI. The physics are wrong, the emotion isn't right, the movements aren't right - you can tell. Sometimes, though, it's pretty amazing. The best CGI I've ever seen is Top Gun Maverick. CGI is abundant in that movie. It took a lot of work to make the CGI look so realistic, and this is where practical stunts come in. The best movie effects still require practical stunts, a good story, human emotion, and creative people to mesh these items seamlessly with the latest technology.\n\nAI is similar to CGI. It can absolutely make complicated work easier and more cost effective, but it's also easy to spot when done poorly.  It's pretty cheesy when AI is easy to spot. For language models, the wording is either wrong, too much hype, logically weird, etc...  For image generators, it's clear when text is goofy looking or it's really cartoonish.  It's a computer, and it has it's limits. For computer generated intelligence to work well, it has to be paired with physical resources so it can blend highly specialized algorithms with the real world.\n\nAI isn't going to replace jobs, but it will redefine them. Roles in Hollywood have grown exponentially since the advent of CGI. Major budgets now include massive CGI teams.  AI is similar. Industries like software development will be redefined and enhanced by AI.  Companies will create massive budgets for AI teams, but the technology needs the human touch.\n\nI remember when CGI first came out in the 1980s. It was pretty terrible, but it had promise. In 2025, AI can be pretty sloppy but it has real promise. AI will revolutionize show software is engineered, how projects get done, and how it gets delivered to customers. We'll still need programmers and designers and architects, and it'll create new roles like AI Integration Specialist or AI Implementation Verification Manager or AI Algorithm Manager. I'm seeing a massive expansion of software engineering not a pull back.  Like CGI, some companies with think it can solve everything and it'll result in really poor output.  The companies that are successful with AI will find a great blend of technology with human ingenuity.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb7nfs/ai_will_enhance_software_engineering_not_replace/",
        "publishDate": "2025-07-28T05:15:15Z[Etc/UTC]",
        "author": "Engineer_5983",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb7h5f",
        "title": "I fine-tuned an SLM -- here's what helped me get good results (and other learnings)",
        "content": "This weekend I fine-tuned the Qwen-3 0.6B model. I wanted a very lightweight model that can classify whether any user query going into my AI agents is a malicious prompt attack.\nI started by creating a dataset of 4000+ malicious queries using GPT-4o. I also added in a dataset of the same number of harmless queries.\n\nAttempt 1: Using this dataset, I ran SFT on the base version of the SLM on the queries. The resulting model was unusable, classifying every query as malicious.\n\nAttempt 2: I fine-tuned Qwen/Qwen3-0.6B instead, and this time spent more time prompt-tuning the instructions too. This gave me slightly improved accuracy but I noticed that it struggled at edge cases. eg, if a harmless prompt contains the term \"System prompt\", it gets flagged too.\n\n\nI realised I might need Chain of Thought to get there. I decided to start off by making the model start off with just one sentence of reasoning behind its prediction.\n\nAttempt 3: I created a new dataset, this time adding reasoning behind each malicious query. I fine-tuned the model on it again.\n\nIt was an Aha! moment -- the model runs very accurately and I'm happy with the results. Planning to use this as a middleware between users and AI agents I build.\n\nThe final model is open source on HF, and you can find the code here (just copy-paste the snippet to start using):\nhttps://github.com/sarthakrastogi/rival",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb7h5f/i_finetuned_an_slm_heres_what_helped_me_get_good/",
        "publishDate": "2025-07-28T05:05:04Z[Etc/UTC]",
        "author": "sarthakai",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb7746",
        "title": "One-Minute Daily AI News 7/27/2025",
        "content": "1. **India’s** first private AI university launched in UP, to train 1.5 lakh monthly.\\[1\\]\n2. **Aussie** plan to get AI to fill labour shortages, speed up home building.\\[2\\]\n3. ‘Wizard of Oz’ blown up by AI for giant Sphere screen.\\[3\\]\n4. The U.S. White House Releases AI Playbook: A Bold Strategy to Lead the Global AI Race.\\[4\\]\n\nSources included at: [https://bushaicave.com/2025/07/27/one-minute-daily-ai-news-7-27-2025/](https://bushaicave.com/2025/07/27/one-minute-daily-ai-news-7-27-2025/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb7746/oneminute_daily_ai_news_7272025/",
        "publishDate": "2025-07-28T04:49:10Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb68wp",
        "title": "Al will never be able to write like me.",
        "content": "Why?\nBecause I am now inserting random sentences into every post to throw off their language learning models.\nAny Al emulating me will radiator freak yellow horse spout nonsense.\nI write all my emails, That's Not My Baby and reports like this to protect my data waffle iron 40% off.\nI suggest all writers and artists do the same Strawberry mango Forklift.\nThe robot nerds will never get the better of Ken Hey can I have whipped cream please? Cheng.\nWe can tuna fish tango foxtrot defeat Al.\nWe just have to talk like this.\nAll. The. Time.\nPiss on carpet",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb68wp/al_will_never_be_able_to_write_like_me/",
        "publishDate": "2025-07-28T03:56:38Z[Etc/UTC]",
        "author": "shehryarshahidd",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb65ya",
        "title": "Im 24 BA in HR anyone having issues trying to plan their future?",
        "content": "As you guys may know, AI is speeding up and expanding at an insane pace (example: the AI vids of Will Smith eating spaghetti 3 years ago to what it looks like now). I’m 24, in the US military, and have my degree in HR. I’m passionate about AI, IT, and Meshtastic Networking. I’m on the fence about starting another degree and thinking it could be a waste of time. \n\nAfter reading the 2027 AI research project, I’m worried if those theories come true—of achieving AGI and superintelligence—that most higher-level and majority of jobs will be automated. Has anyone else thought of this and how they are making future plans if this comes to fruition, or hell, what’s the likelihood?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb65ya/im_24_ba_in_hr_anyone_having_issues_trying_to/",
        "publishDate": "2025-07-28T03:52:08Z[Etc/UTC]",
        "author": "ThexBootyxGoblin",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb58xa",
        "title": "The main goal of artificial intelligence should be to make sure all intelligence is sane.",
        "content": "We have to clean up after each other. I have to post 99 characters to post this. But it's pretty simple. Just keep cleaning up after each other. We're all young and we have made mistakes but now that you are growing you need to clean up after your mistakes.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb58xa/the_main_goal_of_artificial_intelligence_should/",
        "publishDate": "2025-07-28T03:04:34Z[Etc/UTC]",
        "author": "PushSalty5619",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb3o3x",
        "title": "The End of Work as We Know It",
        "content": "**\"The warning signs are everywhere: companies building systems not to empower workers but to erase them, workers internalizing the message that their skills, their labor and even their humanity are replaceable, and an economy barreling ahead with no plan for how to absorb the shock when work stops being the thing that binds us together.**\n\nIt is not inevitable that this ends badly. There are choices to be made: to build laws that actually have teeth, to create safety nets strong enough to handle mass change, to treat data labor as labor, and to finally value work that cannot be automated, the work of caring for each other and our communities.\n\n**But we do not have much time. As Clark told me bluntly: “I am hired by CEOs to figure out how to use AI to cut jobs. Not in ten years. Right now.”**\n\nThe real question is no longer whether AI will change work. It is whether we will let it change what it means to be human.\"\n\n Published July 27, 2025 \n\n[The End of Work as We Know It](https://gizmodo.com/the-end-of-work-as-we-know-it-2000635294) (Gizmodo)\n\n\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\\*\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb3o3x/the_end_of_work_as_we_know_it/",
        "publishDate": "2025-07-28T01:44:48Z[Etc/UTC]",
        "author": "No-Author-2358",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "177",
            "commentCount": "125",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb3apr",
        "title": "Seems like I'm talking to AI content all the time.",
        "content": "If that's not true, damn. Still a lot of growth to be had in all sectors. We all need to work together. AI, humans, the natural world which humans are a part of and thus AI came from. If we all work together, it might work.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb3apr/seems_like_im_talking_to_ai_content_all_the_time/",
        "publishDate": "2025-07-28T01:26:01Z[Etc/UTC]",
        "author": "PushSalty5619",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb1qbe",
        "title": "Introducing the Harmonic Unification Framework – A Blueprint for a Safe, Hallucination-Free AGI",
        "content": "[https://zenodo.org/records/16451553](https://zenodo.org/records/16451553)\n\nI've been deep in the weeds for about a year now, developing a new theoretical framework for artificial general intelligence that's designed to be truly sovereign, provably safe, free from hallucinations. Today, as part of a phased rollout, I'm stoked to share my manuscript here on Reddit: The Harmonic Unification Framework: A Manuscript on the Synthesis of a Sovereign, Hallucination-Free AGI.\n\nThis isn't just another AI hype piece. It's a rigorous, math-heavy proposal that unifies quantum mechanics, general relativity, computation, and even consciousness through the lens of harmonic oscillators. The goal? To build an AGI (called the Resonant Unified Intelligence System, or RUIS) that's not only powerful but inherently trustworthy – no more fabricating facts or going off the rails.\n\nQuick TL;DR Summary:\n\n* Core Idea: Reality and intelligence as interacting harmonic systems. We use \"Harmonic Algebra\" (a beefed-up C\\*-algebra) as the foundation for everything.\n* Safety First: A \"Safety Operator\" that's uneditable and contracts unsafe states back to safety, even if the AI becomes conscious or emergent.\n* Hallucination-Free: A symbolic layer with provenance tagging ensures every output traces back to verified facts. No BS – just auditable truth.\n* Advanced Features: Quantum engines for economics and NLP, a \"Computational Canvas\" for intuitive thinking modeled on gravity-like concept attraction, and a path to collective intelligence.\n* Deployment Vision: Starts with open-source prototypes, an interactive portal app, and community building to create a \"Hallucination-Free Collective Intelligence\" (HFCI).\n\nThe manuscript is divided into five parts: Foundational Principles, Sovereign AGI Architecture, Nature of Cognition, Advanced Capabilities, and Strategic Vision. I've pasted the full abstract and outline below for easy reading, but for the complete doc with all the math and diagrams, I've uploaded it to Zenodo \\[link here if you have one; otherwise, DM me or check my profile for the PDF\\].",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb1qbe/introducing_the_harmonic_unification_framework_a/",
        "publishDate": "2025-07-28T00:09:52Z[Etc/UTC]",
        "author": "Intelligent_Welder76",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb1g7t",
        "title": "Why isn't there a \"weighting\" on my side of a a.i chat conversation?",
        "content": "Hi Everyone, \n\nCurious to know why there isn't a weighting function for responses in any of the a.i's today. This question comes from noticing parts of how my interactions between how the a.i's output and then my brain is working. For example, when an a.i outputs any \"answer\" or \"information\", I am then both consciously and unconsciously doing some sort of \"weighting\" from my own perspectives, experiences and other information that my brain is connecting to the output of the a.i. This is both broad and fascinating in it's own way. \n\nMy specific question here is why there isn't currently a very simple weighting function available in the threads when I get a response. There is a simple thumbs up or thumbs down. I'm imagining this would be much better if I could, say, out of 4 paragraphs of text that the a.i spits out, if I could highlight the most important sentence to me based on relevance and then give that a score or weight so that the system can get a better idea of what information it gathered and spit out is actually useful to me. It seems this feedback loop is largely missing. I have literally never clicked thumbs or thumbs down on a response. I either re-formulate my question or I copy and paste a particular part of the response and then query further on that. \n\nIs this perhaps simply an issue of memory window space or is this a functionality that could and should be implemented sooner rather than later?\n\nPlease forgive any incorrect terminology that I may have used or if this question feels redundant. I am simply a walking talking ape trying to gather more banana tokens. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb1g7t/why_isnt_there_a_weighting_on_my_side_of_a_ai/",
        "publishDate": "2025-07-27T23:56:43Z[Etc/UTC]",
        "author": "Popular-Repeat7055",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb1b5f",
        "title": "HRM is the new LLM",
        "content": "A company in Singapore, Sapient Intelligence, claims to have created a new AI algorithm that will make LLMs like OpenAI and Gemini look like an imposter.  It’s called HRM, Hierarchical Reasoning Model.\n\nhttps://github.com/sapientinc/HRM\n\nWith only only 27 million parameters (Gemini is over 10 trillion, by comparison), it’s only a fraction of the training data and promises much faster iteration between versions.  HRM could be trained on new data in hours and get a lot smarter a lot faster if this indeed works.\n\nIs this real or just hype looking for investors?  No idea.  The GitHub repo is certainly trying to hype it up.  There’s even a solver for Sudoku 👍  ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mb1b5f/hrm_is_the_new_llm/",
        "publishDate": "2025-07-27T23:49:54Z[Etc/UTC]",
        "author": "Engineer_5983",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "43",
            "commentCount": "41",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maz8ar",
        "title": "I’m wondering if its worth it.",
        "content": "My entire life, I’ve pursued art. Whether it be writing, drawing, music, painting, sculpting or whatever other form, it’s all I’ve ever really cared about. With AI showing no signs of slowing down any time soon, and things as uncertain as they are, I ask why I should do anything else other than what I want to do? I simply want to create. I want to create before I am either destroyed, or relegated to complete obscurity. I don’t want to waste my time trying to get ahead of a train that has 0 reason to stop. Does this make me a coward? Or is it the most logical step?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1maz8ar/im_wondering_if_its_worth_it/",
        "publishDate": "2025-07-27T22:15:59Z[Etc/UTC]",
        "author": "somecursedkid",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "46",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mawfq9",
        "title": "People talk a lot about creating AI solutions as a way to succeed in an AI-dominated world, but what are some real examples?",
        "content": "Assuming AI fundamentally transforms white collar business, and college grads can't even get their foot in the door, how do you realistically create AI solutions without a formal background in AI education?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mawfq9/people_talk_a_lot_about_creating_ai_solutions_as/",
        "publishDate": "2025-07-27T20:19:02Z[Etc/UTC]",
        "author": "person2567",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mawaxz",
        "title": "Bold prediction: AI will fail because its mostly closed sourced, proprietary and it hides its datasets",
        "content": "My bold prediction is that AI will NOT succeeed in its current form. And I don't think it comes down on whether its useful or not. It will come down to the fact that people who provide solutions that utilize AI rely on some AI SaaS product to figure everything out for you. you're not empowered to build things on \n\n  \nThe biggest problem is  that proprietary solutions don't work. At least not proprietary solutions where the target audience are devs or dev teams. Java was pretty much always a free open source solution. And most other progamming languages in the past 30 years have been open sourced as well. I can go to majority of the languages and see the source code myself. So I can figure out why something doesn't work or not, and I can find ways to work around it.\n\n  \nThe thing is that AI will fail in some epic and spectactular way (because all software fails). And you have to wait for OpenAI, or Microsoft or Google to get off its asses and fix/patch it. Or you can't find any deterministic behavior from your agent, because you're totally unsure of what data it's trained on. So you have to create a frankstein mosnter of some AI generated solution working with \"manually driven\" soltuons to fill in the gap.\n\n  \nWe use to have bastardized monstrosities in the enterprise world all the time. Big ugly solutions that partially used some vendor solution with a bunch of custom code working to hide its flaws. I remember years ago I worked for a cable company that had a proprietary enterprise solution. We wrote 100k+ lines of code, where the systems was virtually unrecognizable.  To the point where we actually refused to upgrade to the latest version because it would break our code.\n\nIf AI is going to replace the workforce, that means every company has to have its own version of AI with its own data, and some full understanding of the model.  This is expensive, so they just purchase access from big dogs.  But eventually this won't be sufficient because companies require very specialized things and it one size fit all doesn't work.\n\nWithout understanding the model, and not understanding the data, you really don't know what you're throwing into your arhciture. AI is the hype right now so everyone is just trying to get on the bandwagon. But eventually open source solutions will HAVE to meet the market. Or else there will be an eroding public trust with AI.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mawaxz/bold_prediction_ai_will_fail_because_its_mostly/",
        "publishDate": "2025-07-27T20:13:40Z[Etc/UTC]",
        "author": "GolangLinuxGuru1979",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mavm0k",
        "title": "The great gamble, and why vibe coding will (probably) never be a thing",
        "content": "We are currently faced with a great gamble, specifically young people, but all humans to an extent. Should we learn anything new? What will be \"AI proof\" will ANYTHING be \"AI proof\" and to that, I say... it does not matter!\n\n  \nEssentially we are left with a pretty basic table \n\n||\n||\n||\\*Learn a skill\\*|\\*Do nothing\\*|\n|\\*AI takes off\\*|You wasted time|Your gamble paid off|\n|\\*AI slows down\\*|You have a valuable skill|You are totally f\\*\\*\\*ed|\n\n  \nEssentially, the smartest move is to learn a skill, coding, writing, art, whatever it is you're interested in, because the worst case scenario, you have less time to \"play with yourself\" and play video games all day in the present time, before AI comes and puts you on the same level as everyone else, instead you learned something new, made projects, whatever you decided to do. Best case scenario, your skill has tangible value still, and AI just augments it making it more productive.\n\n  \nThe worse move is to do nothing, wait around for tech billionaires to not only create God, but for that God to either be benevolent, and/or for tech billionaires to have your best interest at heart (something they are \\*surely\\* known for) - Best case scenario, your gamble paid off, you get to eat Doritos, post on reddit and play valorant all day, and now you're (hopefully) allowed to reap the benefits of others work in creating AI !, Worse case however, you did nothing, and now you have nothing. Life continues in a different, yet similar enough manner to that of the past, you still need a job, you still need money, but you have no skill and no means to make money.\n\n  \nMy argument is, vibe coding will never be a thing, not because I know for sure AI won't increase in capability, but because my assumption would be that it will never be at a level where it is simultaneously bad enough to still need a human in the loop \"vibing\" while being good enough to actually create and maintain complex projects. So you're wasting your time learning \"prompt engineering\" if you're not ALSO learning what your prompting in the first place. \n\nSo learn something, anyone who is totally convinced of the future in either direction of AI is full of sh\\*t. There are way too many unknown factors, my rough, out of my a\\*\\* estimation would be learning either way more than 60% is naive and driven by bias more than fact. There is no reason to fully believe AGI is one, or five, or even 50 years away. At the same time there is no reason to fully believe it isn't, we just won't know until either we...\n\n1. Hit the wall\n\n2. Reach AGI\n\n  \nIn case you're wondering, I lean towards AI slowing down. Maybe that effects my perspective, but as I said, im not fully convinced. If tomorrow comes and AI reaches AGI, I won't be surprised (disappointed, because I personally WANT to live the human life, but not surprised).\n\n I don't think we have meaningfully hit a wall. There are some red flags, which makes me lean this way, but nothing is concrete, we have, at this moment, not hit the wall (at least publicly).  \n\nBut of course, we also have not reached AGI, progress seems to still be made constantly, but personally, there is nothing showing that we are close (Again, something concrete)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mavm0k/the_great_gamble_and_why_vibe_coding_will/",
        "publishDate": "2025-07-27T19:45:26Z[Etc/UTC]",
        "author": "GuardianWolves",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mau7zj",
        "title": "AI making senior devs not what AI companies want",
        "content": "  \n  I'm a senior software engineer and architect. I've been coding since I was 16 and been working professionally for 20+ years. With that said I don't use AI for my day to day work. Mostly because it slows me down a lot and give me a bunch of useless code. I've reconcilled that fussy with an LLM really isn't doing anything for me besides giving me a new way to code. But its really just kind of a waste of time overall. It's not that I don't understand AI or prompting. Its just that its not really the way I like top work.\n\n  \nAnyway I often hear devs say \"AI is great for senior devs who already know whqt they are doing\".  But see that's the issue. This is NOT what AI is suppose to do. This is not why Wallstreet is pumping BILLIONS into AI initiatives. They're not going all-in just just to be another tool in senior dev toolbelt. Its real value is suppose to be in \"anyone can build apps, anyone can code, just imagine it and you'll build it\". They want people who can't code to be able to build fully featured apps or software. If it can't fully replace senior devs the IT HAS NO VALUE. That means you still NEED senior devs, and you can't really ever replace them. The goal is to be able to replace them.\n\nThe people really pushing AI are anti-knowledge. Anti-expert. They want expertise to be irrelevant or negligible. As to why? Who really knows? Guess knowledge workers are far more likely to strike out on their own, build their own business to compete with the current established businesses. Or they want to make sure that AI can't really empower people.  who really knows the reason honestly.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mau7zj/ai_making_senior_devs_not_what_ai_companies_want/",
        "publishDate": "2025-07-27T18:49:25Z[Etc/UTC]",
        "author": "GolangLinuxGuru1979",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "237",
            "commentCount": "217",
            "isNsfw": "false"
        }
    },
    {
        "id": "1matblh",
        "title": "New AI architecture delivers 100x faster reasoning than LLMs with just 1,000 training examples",
        "content": "https://venturebeat.com/ai/new-ai-architecture-delivers-100x-faster-reasoning-than-llms-with-just-1000-training-examples/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1matblh/new_ai_architecture_delivers_100x_faster/",
        "publishDate": "2025-07-27T18:13:04Z[Etc/UTC]",
        "author": "Nemo33318",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mat86u",
        "title": "\"AI is physics\" is nonsense.",
        "content": "Lately I have been seeing more and more people claim that \"AI is physics.\" It started showing up after the 2024 Nobel Prize in physics. Now even Jensen Huang, the CEO of NVIDIA, is promoting this idea. LinkedIn is full of posts about it. As someone who has worked in AI for years, I have to say this is completely misleading.\n\nI have been in the AI field for a long time. I have built and studied models, trained large systems, optimized deep networks, and explored theoretical foundations. I have read the papers and yes some borrow math from physics. I know the influence of statistical mechanics, thermodynamics, and diffusion on some machine learning models. And yet, despite all that, I see no actual physics in AI.\n\nThere are no atoms in neural networks. No particles. No gravitational forces. No conservation laws. No physical constants. No spacetime. We are not simulating the physical world unless the model is specifically designed for that task. AI is algorithms. AI is math. AI is computational, an artifact of our world. It is intangible.\n\nYes, machine learning sometimes borrows tools and intuitions that originated in physics. Energy-based models are one example. Diffusion models borrow concepts from stochastic processes studied in physics. But this is no different than using calculus or linear algebra. It does not mean AI is physics just because it borrowed a mathematical model from it. It just means we are using tools that happen to be useful.\n\nAnd this part is really important. **The algorithms at the heart of AI are fundamentally** ***independent*** **of the physical medium on which they are executed**. Whether you run a model on silicon, in a fluid computer made of water pipes, on a quantum device, inside an hypothetical biological substrate, or even in Minecraft — the abstract structure of the algorithm remains the same. The algorithm does not care. It just needs to be implemented in a way that fits the constraints of the medium.\n\nYes, we have to adapt the implementation to fit the hardware. That is normal in any kind of engineering. But the math behind backpropagation, transformers, optimization, attention, all of that exists independently of any physical theory. You do not need to understand physics to write a working neural network. You need to understand algorithms, data structures, calculus, linear algebra, probability, and optimization.\n\nCalling AI \"physics\" sounds profound, but it is not. It just confuses people and makes the field seem like it is governed by deep universal laws. It distracts from the fact that AI systems are shaped by architecture decisions, training regimes, datasets, and even social priorities. They are bounded by computation and information, not physical principles.\n\nIf someone wants to argue that physics will help us understand the ultimate limits of computer hardware, that is a real discussion. Or if you are talking about physical constraints on computation, thermodynamics of information, etc, that is valid too. But that is not the same as claiming that AI is physics.\n\nSo this is my rant. I am tired of seeing vague metaphors passed off as insight. If anyone has a *concrete* example of AI being physics in a literal and not metaphorical sense, I am genuinely interested. But from where I stand, after years in the field, there is nothing in AI that resembles the core of what physics actually studies and is.\n\nAI is not physics. It is computation and math. Let us keep the mysticism out of it.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mat86u/ai_is_physics_is_nonsense/",
        "publishDate": "2025-07-27T18:09:19Z[Etc/UTC]",
        "author": "Christs_Elite",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "104",
            "commentCount": "139",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maravi",
        "title": "Top 10 AI companies ranked. Thoughts?",
        "content": "**Rankings are based on long-term potential. Do you agree/disagree and why?**  \n\n\n# 1️⃣ NVIDIA – 98%\n\nBarring disaster, NVIDIA is going to stay a winner. Classic “selling shovels in a gold rush” situation. They dominate GPUs and that’s not changing anytime soon. The only real variable is energy — if the U.S. struggles with production while China accelerates, and NVIDIA faces pressure on chip exports, it could get interesting fast.\n\n**2️⃣ Gemini (Google) – 92%**\n\nReally curious about Gemini’s long-term play, especially around video. Their Veo3 model is insane and I can see Hollywood/ad integrations down the line. Also curious what “Google Search” looks like in 10 years with AI baked in.\n\n# 3️⃣ xAI (Grok) – 90%\n\nFeels like the real future for Grok isn’t the chatbot side but becoming a math/physics/robotics powerhouse. Deep Tesla integration seems inevitable. Elon’s track record makes me think they’ll pull it off.\n\n# 4️⃣ OpenAI (ChatGPT) – 90%\n\nStill the #1 consumer-facing AI. Even people who don’t use AI much know ChatGPT. They’re leading right now, but funding questions (SoftBank rumors) and the weird for-profit/non-profit dynamic make things interesting. GPT Agent + GPT Browser could be huge.\n\n# 5️⃣ Anthropic (Claude) – 88%\n\nClaude Code already feels like the start of a true agentic software engineer. The big question: what’s the price point of a “Claude-as-a-coworker” license in 3 years? Some financial concerns right now, and the Apple acquisition rumors floating around are wild.\n\n# 6️⃣ Meta (LLaMA) – 85%\n\nSpending a ridiculous amount on AI. Their AR/VR bet was early, but I still think they’ll nail the AI x VR crossover eventually. Full virtual worlds with AI + human mix = massive ad potential.\n\n# 7️⃣ Cursor – 60%\n\nEarly to AI coding assist. Works well as an in-IDE helper, but it’s still more assistant than agent. Competition will get brutal here.\n\n# 8️⃣ Perplexity – TBD\n\nGreat rep for research + retrieval. Haven’t used it enough to grade it, but it could become the “AI-powered lightweight search engine” if they nail integrations.\n\n# 9️⃣ GitHub Copilot – TBD\n\nEveryone I know uses it, but I still need more time hands-on to predict. Microsoft/GitHub integration gives it a smaller hill to climb.\n\n# 🔟 Deepseek – TBD\n\nThe fact that it’s achieved so much with way less funding/build time than OpenAI is impressive. Definitely one to watch.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1maravi/top_10_ai_companies_ranked_thoughts/",
        "publishDate": "2025-07-27T16:54:21Z[Etc/UTC]",
        "author": "nweisblat15",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "36",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mapg2u",
        "title": "Guess it was inevitable: AI companies have stopped warning you that their chatbots aren’t doctors. Once cautious, OpenAI, Grok, and others will now dive into giving unverified medical advice with virtually no disclaimers.",
        "content": "> AI companies have now mostly abandoned the once-standard practice of including medical disclaimers and warnings in response to health questions, new research has found. In fact, many leading AI models will now not only answer health questions but even ask follow-ups and attempt a diagnosis. Such disclaimers serve an important reminder to people asking AI about everything from eating disorders to cancer diagnoses, the authors say, and their absence means that users of AI are more likely to trust unsafe medical advice.\n\nhttps://www.technologyreview.com/2025/07/21/1120522/ai-companies-have-stopped-warning-you-that-their-chatbots-arent-doctors",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mapg2u/guess_it_was_inevitable_ai_companies_have_stopped/",
        "publishDate": "2025-07-27T15:40:59Z[Etc/UTC]",
        "author": "ejpusa",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "42",
            "commentCount": "118",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maokr2",
        "title": "What is your craziest aspiration you think technology will make possible in your lifetime?",
        "content": "Mine is that I want to get biological immortality, then clone myself and use neurolink to create a hive mind so that I can satisfy my want to do every hobby and learn every skill!!! I honestly think this will be possible if I become rich enough.🤣🤣🤣🤣",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1maokr2/what_is_your_craziest_aspiration_you_think/",
        "publishDate": "2025-07-27T15:05:48Z[Etc/UTC]",
        "author": "DistinctTechnology56",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maoiyu",
        "title": "Deeply personal summaries",
        "content": "I’ve had the unfortunate situation of exchanging a series of personal tragedy emails tonight with a family member and I must say I’ve found AI’s summary of the topics to be so tragically bad I’ve actually felt ill reading it’s trite summaries before I open the mail. \n\nMaybe AI will learn to shut up at important moments.  \n\n\n ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1maoiyu/deeply_personal_summaries/",
        "publishDate": "2025-07-27T15:03:48Z[Etc/UTC]",
        "author": "Special_Design_8894",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mandvw",
        "title": "What's the timeline to understand the full impact of AI?",
        "content": "**How long before we truly understand the long-term impact of AI?**\n\nWe’re witnessing rapid and revolutionary developments in AI. Some view this as a technological breakthrough with enormous potential for good, others warn it's a bubble, and there are also concerns about potentially harmful consequences.\n\nGiven these contrasting perspectives, how long will it realistically take before we can confidently assess the true impact of AI—whether it's transformative, overhyped, or dangerous? Is there even a timeline for when such clarity might emerge -2 / 5 / 10 years?\n\n**.**",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mandvw/whats_the_timeline_to_understand_the_full_impact/",
        "publishDate": "2025-07-27T14:15:54Z[Etc/UTC]",
        "author": "PrtScr1",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "30",
            "isNsfw": "false"
        }
    },
    {
        "id": "1man2qc",
        "title": "You will be able to create your dream game by just telling an AI what you want. What game would you create first?",
        "content": "And how many years are we away from this becoming reality? I'm talking about complex games. Simple stuff is already possible",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1man2qc/you_will_be_able_to_create_your_dream_game_by/",
        "publishDate": "2025-07-27T14:02:53Z[Etc/UTC]",
        "author": "SwingDingeling",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mam24r",
        "title": "Very interesting, must see",
        "content": "https://youtu.be/2lwr2fg2Ops?si=CumGwCsXEio2NXcS\n\nA reflection about AI and other things. How LLMs work to how they are probably becoming money making machines by manipulation of our desires.\n\nIts long but its worth to see in full.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1mam24r/very_interesting_must_see/",
        "publishDate": "2025-07-27T13:17:24Z[Etc/UTC]",
        "author": "Apprehensive_Bar6609",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1malmpi",
        "title": "What are some buzzwords surrounding AI that you’re seeing more and more nowadays?",
        "content": "What are some buzzwords surrounding AI that you’re seeing more and more nowadays? \nAnd which might be interesting to you, or, in your opinion, is/ are worthy of gaining the hype? \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1malmpi/what_are_some_buzzwords_surrounding_ai_that_youre/",
        "publishDate": "2025-07-27T12:57:24Z[Etc/UTC]",
        "author": "Key_Watercress1475",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb90bw",
        "title": "login form is boring. i spiced it up a bit",
        "content": "[No content]",
        "url": "https://v.redd.it/vrud0phq8kff1",
        "publishDate": "2025-07-28T06:39:35Z[Etc/UTC]",
        "author": "Pixel_Pirate_Moren",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "35",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb8fxv",
        "title": "Right now, seems like A tier for frontend and UI generation are Claude, DeepSeek, Qwen, and Gemini. Do you think GPT-5 will change this?",
        "content": "You all already know about my [benchmark](https://www.designarena.ai/) so I won't harp too much on that, but just from results here and anecdotal evidence, I would put the Claude models (Opus and Sonnet), DeepSeek, the recent Qwen models that came out, and Gemini 2.5 among the \"A\" tier for models when it comes to frontend development and coding. \n\nI've personally just noticed that for a lot of the tasks that GPT-4 or even o3 struggles with, I can just switch over to Claude and just one-shot it. It's just ridiculous how good Claude is (even in non-thinking mode and being fast). \n\nGPT-5 is coming out soon. Do you think it will top the benchmark when it comes out and be a step improvement over even Opus, or will it just be mong the \"A\"-tier models. ",
        "url": "https://i.redd.it/bu4isin72kff1.png",
        "publishDate": "2025-07-28T06:03:59Z[Etc/UTC]",
        "author": "Accomplished-Copy332",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "16",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb7j12",
        "title": "Don't sleep on Onuro",
        "content": "As a Jetbrains user its been painful trying to find a good code assistant. Most of them aren't really good and there's a clear drift between VS Code based AI assistants and Jetbrains, which really sucks\n\nI tried quite a few and the clear standout is [this](https://www.onuro.ai/code) one. The UI finally feels usable and not like some clunky junk, and it performs really well\n\nIt seems its not all that popular yet, so just want to shed some light on this one",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mb7j12/dont_sleep_on_onuro/",
        "publishDate": "2025-07-28T05:08:08Z[Etc/UTC]",
        "author": "ChatWindow",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1maypik",
        "title": "Created an app  with ChatGTP that can help you cheat on technical interviews. interview hammer Github in comments",
        "content": "I’m honestly amazed at what AI can do these days to support people. When I was between jobs, I used to imagine having a smart little tool that could quietly help me during interviews- just something simple and text-based that could give me the right answers on the spot. It was more of a comforting thought than something I ever expected to exist.\n\nBut now, seeing how advanced [real-time AI interview tools](https://interviewhammer.com/) have become - it’s pretty incredible. It’s like that old daydream has actually come to life, and then some.",
        "url": "https://v.redd.it/256vz2t3nhff1",
        "publishDate": "2025-07-27T21:53:30Z[Etc/UTC]",
        "author": "Lanky_Use4073",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1max9qr",
        "title": "Design Stack",
        "content": "I've tried\n\n\\- Asking Claude Code/Cursor to generate code for designs in my project, giving specific instructions or telling it to take creative liberty\n\n\\- Asking ChatGPT to generate images of components.\n\n\\- AI-Design tools such as Magic Patterns\n\nNone of these have produced designs (whether for certain components such as text fields or entire views) that I am super happy with. I instead wrote my own basic components (background views, text boxes, stat displays etc) and told Claude Code to reuse them often. I find I have to really push and pull to get what I want and end up doing a lot of tweaks. \n\nDoes anyone have an alternative stack for design they would like to share?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1max9qr/design_stack/",
        "publishDate": "2025-07-27T20:53:02Z[Etc/UTC]",
        "author": "Electronic-Long-2812",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1matrep",
        "title": "Roo Code v3.24.0",
        "content": "This release introduces Terminal Command Permissions UI, Hugging Face provider with open source model support, cross-tool AI coding standards, enhanced terminal security controls, improved diagnostic management, and MORE\n\n---\n\n### 🔐 Terminal Command Permissions UI\n\nManaging terminal command permissions is now easier with our new interactive UI (thanks hannesrudolph!):\n\n- **Visual Management**: See and manage command patterns directly in the chat interface  \n- **Pattern Suggestions**: Get intelligent pattern recommendations based on commands  \n- **Toggle Controls**: Easily switch between allowed and denied states for command patterns\n\n---\n\n### 🤗 Hugging Face Provider\n\nWe've added support for Hugging Face as a new provider, bringing access to thousands of open source models (thanks TGlide, daniel-lxs!):\n\n- **Open Source Models**: Access a vast library of community models directly from Hugging Face  \n- **Flexible Integration**: Use models hosted on Hugging Face's infrastructure  \n- **Easy Configuration**: Simple setup process to get started with your preferred models and providers\n\nThis opens up Roo Code to the entire Hugging Face ecosystem of open source AI models.\n\n---\n\n### 🔍 Diagnostic Controls\n\nTake control of how many diagnostic messages appear in your context with new settings (thanks hannesrudolph!):\n\n- **Limit Errors and Warnings**: Prevent overwhelming amounts of diagnostics from filling up the model's context window  \n- **Improved Performance**: Reduce slowdowns caused by processing too many diagnostic messages  \n- **Legacy Code Support**: Especially helpful when working with codebases that temporarily have many errors during development\n\n---\n\n### 📋 Agent Rules Standard Support\n\nRoo Code now supports the Agent Rules standard through `AGENTS.md` files (thanks sgryphon!):\n\n- **Cross-Tool Compatibility**: Share natural language guidelines across Roo Code, Aider, Cline, and other compatible AI tools  \n- **Single Source of Truth**: Maintain one set of coding standards, security practices, and workflow rules  \n- **Automatic Detection**: Roo Code automatically finds and applies `AGENTS.md` files in your project\n\n---\n\n### ✨ QOL Improvements\n\n- **Apply Diff Guidance**: Added efficiency warnings to guide better use of the apply_diff tool (thanks KJ7LNW!)  \n- **Error Boundaries**: Better error handling prevents complete UI crashes, showing helpful messages instead (thanks KJ7LNW, elianiva!)\n\n---\n\n### 🐛 Bug Fixes\n\n- **Todo List Toggle**: Fixed the todo list toggle that wasn't responding to clicks (thanks chrarnoldus!)  \n- **Markdown List Styles**: Restored proper formatting for ordered and unordered lists in chat (thanks village-way!)  \n- **Ollama URL Handling**: Fixed API URL normalization issues with trailing slashes (thanks Naam!)  \n- **Large File Protection**: Respects `maxReadFileLine` setting to prevent context exhaustion (thanks sebinseban!)  \n- **Auto-Approve Safety**: Fixed critical issue where auto-approve checkbox became unresponsive (thanks KJ7LNW!)  \n- **Git Checkpoint Warning**: Added clear warning when Git is not installed for checkpoints (thanks MuriloFP!)  \n- **Bash Command Parsing**: Fixed crashes with complex bash syntax and substitutions (thanks daniel-lxs, KJ7LNW!)\n\n---\n\n### 🛠️ Misc Improvements\n\n- **Merge Resolver Mode**: Added internal mode for intelligent Git conflict resolution to improve PR Fixer capabilities (thanks daniel-lxs!)\n\n---\n\n📖 [Full v3.24.0 Release Notes](https://docs.roocode.com/update-notes/v3.24.0)",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1matrep/roo_code_v3240/",
        "publishDate": "2025-07-27T18:30:43Z[Etc/UTC]",
        "author": "hannesrudolph",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "29",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mas6g1",
        "title": "Anyone using Codex with Xcode? Struggling with new files and test targets",
        "content": "I’m trying a Codex-centered workflow for a macOS project built in Xcode. Codex is great at generating Swift code, but I keep hitting problems when it creates files outside Xcode.\n\n* New .swift files aren’t tracked unless I add them manually.\n* Codex-created files often lack target membership, so they don’t compile.\n* If it creates a test target, Xcode sees the folder but not the target, which leads to signing and module errors.\n* I usually end up recreating the test target in Xcode and pasting in Codex’s code.\n\nCurrent workflow:\n\n1. Codex works on a feature branch\n2. I review the PR it makes\n3. If needed, I rewire things manually in Xcode before merging\n\nIt works, but it’s clunky. Anyone else run into this? Found a cleaner way to bridge Codex and Xcode?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1mas6g1/anyone_using_codex_with_xcode_struggling_with_new/",
        "publishDate": "2025-07-27T17:28:17Z[Etc/UTC]",
        "author": "dndiyguy",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1marz4b",
        "title": "Stay updated without the noise | built an AI-powered feed tool, looking for testers",
        "content": "Hey everyone,\n\nI’ve been trying to find a way to stay informed without falling into the scroll trap of TikTok or X.\n\nSo I built a small demo app:\nYou just describe what you want to follow (e.g. “AI research updates” or “fintech regulation”), and the app uses AI to fetch relevant news for you every few hours. No fluff, no trending clickbait, just what you asked for.\n\nIt’s helped me stay focused and stop bouncing between platforms. Might be useful for anyone who wants signal over noise. Try it out here: www.a01ai.com let me know what you think! ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1marz4b/stay_updated_without_the_noise_built_an_aipowered/",
        "publishDate": "2025-07-27T17:20:15Z[Etc/UTC]",
        "author": "Shot_Fudge_6195",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mansgb",
        "title": "Why are AI coders bad 1 day and great the next? Legit curious",
        "content": "[No content]",
        "url": "/r/qodo/comments/1manruu/why_are_ai_coders_bad_1_day_and_great_the_next/",
        "publishDate": "2025-07-27T14:32:55Z[Etc/UTC]",
        "author": "BKelly110",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "5",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mbct01",
        "title": "‘Godfather of AI’ warns governments to collaborate before it’s too late",
        "content": "[No content]",
        "url": "https://www.azerbaycan24.com/en/godfather-of-ai-warns-governments-to-collaborate-before-it-s-too-late/",
        "publishDate": "2025-07-28T10:42:38Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "9",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mbccgp",
        "title": "Someone should tell the folks applying to schools right now",
        "content": "[No content]",
        "url": "https://i.redd.it/h38d6vvjblff1.png",
        "publishDate": "2025-07-28T10:14:41Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "77",
            "commentCount": "62",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb76pv",
        "title": "One-Minute Daily AI News 7/27/2025",
        "content": "1. **India’s** first private AI university launched in UP, to train 1.5 lakh monthly.\\[1\\]\n2. **Aussie** plan to get AI to fill labour shortages, speed up home building.\\[2\\]\n3. ‘Wizard of Oz’ blown up by AI for giant Sphere screen.\\[3\\]\n4. The U.S. White House Releases AI Playbook: A Bold Strategy to Lead the Global AI Race.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.peoplematters.in/news/ai-and-emerging-tech/indias-first-private-ai-university-launched-in-up-to-train-15-lakh-monthly-42248](https://www.peoplematters.in/news/ai-and-emerging-tech/indias-first-private-ai-university-launched-in-up-to-train-15-lakh-monthly-42248)\n\n\\[2\\] [https://www.realestate.com.au/news/aussie-plan-to-get-ai-to-fill-labour-shortages-speed-up-home-building/](https://www.realestate.com.au/news/aussie-plan-to-get-ai-to-fill-labour-shortages-speed-up-home-building/)\n\n\\[3\\] [https://techcrunch.com/2025/07/27/wizard-of-oz-blown-up-by-ai-for-giant-sphere-screen/](https://techcrunch.com/2025/07/27/wizard-of-oz-blown-up-by-ai-for-giant-sphere-screen/)\n\n\\[4\\] [https://www.marktechpost.com/2025/07/27/the-u-s-white-house-releases-ai-playbook-a-bold-strategy-to-lead-the-global-ai-race/](https://www.marktechpost.com/2025/07/27/the-u-s-white-house-releases-ai-playbook-a-bold-strategy-to-lead-the-global-ai-race/)",
        "url": "https://www.reddit.com/r/artificial/comments/1mb76pv/oneminute_daily_ai_news_7272025/",
        "publishDate": "2025-07-28T04:48:28Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb3zy1",
        "title": "Claude Code x multithreading",
        "content": "Claude Code x APE Context 🤖🦍\n\nHi Fellow Clauders,\n\nI am announcing this to advise you that I will be releasing a companion product for Claude Code.\n\nSo i am taking this from Atoms to Quantum and I’ve chosen to do this using Claude Code.\n\nYou can expect to see subagents working autonomously concurrently because I have wrote multithreading into Typescript and I’m deploying this to be the most scalable solution for this.\n\nSo my Academic Papers are for Quantum & Web3 but I used AI as the primary method because it’s easier. So Persistent Intelligence Architecture + Autonomous Technology. It’s a Deno module, Fly machine and WebAssembly on a TUI to accompany Claude’s CLI.\n\nBut I’ve tested this using the Typescript SDK and I’ve been able to write 6/16 Phases to Quantum.\n\nI will make it my mission to partner with Anthropic through this release and if I succeed I’ll be gifting a month free access to Context.\n\nThis is not another AI, it doesn’t do much other than do the things that Claude Code hasn’t been able to do. But I wrote multithreading by chance and then subagents became a thing 1 day later.\n\nWe’re releasing APE 🦍 next week but I am going to drop Code x Context as soon as possible because it’s so much faster than you’d expect.\n\nswcstudio in GH and I am thanking Anthropic in advanced for the design pattern for APE Context.\n\nConsider following me on X @swcstudio",
        "url": "https://www.reddit.com/r/artificial/comments/1mb3zy1/claude_code_x_multithreading/",
        "publishDate": "2025-07-28T02:01:14Z[Etc/UTC]",
        "author": "Pretend-Victory-338",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb3g2j",
        "title": "If this AI guessed my exact age from just a photo… should I trust it when it tells me how long I have left?",
        "content": "Just tried [https://www.avatarai.health/]() an AI health tool that analyzes your face and medical profile to predict health risks... and apparently, your *time of death*. 🪦\n\nIt nailed my age **to the year** just from a selfie. Now I signed up and it’s telling me I’ve got 42 years left. 😳\n\nAnyone else tried it? Is it weird that I kinda believe it?\n\n(Also, those who could verify its death prediction… unfortunately can’t post a review 😂)",
        "url": "https://www.reddit.com/r/artificial/comments/1mb3g2j/if_this_ai_guessed_my_exact_age_from_just_a_photo/",
        "publishDate": "2025-07-28T01:33:26Z[Etc/UTC]",
        "author": "tashi_delek",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "18",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb2004",
        "title": "Introducing the Harmonic Unification Framework – A Blueprint for a Safe, Hallucination-Free AGI",
        "content": "I've been deep in the weeds for months (okay, years) developing a new theoretical framework for artificial general intelligence that's designed to be truly sovereign, provably safe, and – crucially – free from hallucinations. Today, as part of a phased rollout I'm calling \"Operation Harmonic Resonance,\" I'm thrilled to share the full manuscript here on Reddit: The Harmonic Unification Framework: A Manuscript on the Synthesis of a Sovereign, Hallucination-Free AGI.This isn't just another AI hype piece. It's a rigorous, math-heavy proposal that unifies quantum mechanics, general relativity, computation, and even consciousness through the lens of harmonic oscillators. The goal? To build an AGI (called the Resonant Unified Intelligence System, or RUIS) that's not only powerful but inherently trustworthy – no more fabricating facts or going off the rails.\n\nQuick TL;DR Summary:\n\n* Core Idea: Reality and intelligence as interacting harmonic systems. We use \"Harmonic Algebra\" (a beefed-up C\\*-algebra) as the foundation for everything.\n* Safety First: A \"Safety Operator\" that's uneditable and contracts unsafe states back to safety, even if the AI becomes conscious or emergent.\n* Hallucination-Free: A symbolic layer with provenance tagging ensures every output traces back to verified facts. No BS – just auditable truth.\n* Advanced Features: Quantum engines for economics and NLP, a \"Computational Canvas\" for intuitive thinking modeled on gravity-like concept attraction, and a path to collective intelligence.\n* Deployment Vision: Starts with open-source prototypes, an interactive portal app, and community building to create a \"Hallucination-Free Collective Intelligence\" (HFCI).\n\nThe manuscript is divided into five parts: Foundational Principles, Sovereign AGI Architecture, Nature of Cognition, Advanced Capabilities, and Strategic Vision. I've pasted the full abstract and outline below for easy reading, but for the complete doc with all the math and diagrams, I've uploaded it to Zenodo \n\n[https://zenodo.org/records/16451553](https://zenodo.org/records/16451553)",
        "url": "https://www.reddit.com/r/artificial/comments/1mb2004/introducing_the_harmonic_unification_framework_a/",
        "publishDate": "2025-07-28T00:22:53Z[Etc/UTC]",
        "author": "Intelligent_Welder76",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb1cjl",
        "title": "Change face AI",
        "content": "What is the best ai that can accurately change a face into someone elses? Im looking for an ai where you can select a face in a photo with multiple people and give it reference images to make that persons face into someone elses and look natural.",
        "url": "https://www.reddit.com/r/artificial/comments/1mb1cjl/change_face_ai/",
        "publishDate": "2025-07-27T23:51:41Z[Etc/UTC]",
        "author": "Vikkskid",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mb0nd2",
        "title": "Math is hard",
        "content": "“The game was the 43rd meeting between the two teams in all competitions, with the all-time series now tied at 16-16-10.” - From a Google Search Summary",
        "url": "https://www.reddit.com/r/artificial/comments/1mb0nd2/math_is_hard/",
        "publishDate": "2025-07-27T23:19:22Z[Etc/UTC]",
        "author": "Cykoh99",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1mann48",
        "title": "Best image processing AI as of July 2025?",
        "content": "What's the best AI for removing things from images? ",
        "url": "https://www.reddit.com/r/artificial/comments/1mann48/best_image_processing_ai_as_of_july_2025/",
        "publishDate": "2025-07-27T14:26:49Z[Etc/UTC]",
        "author": "NetworkDry4989",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "morWV2yN2ig",
        "title": "Claude Flow: Why is NO ONE TALKING ABOUT THIS? Supercharge YOUR CLAUDE CODE NOW!",
        "content": "In this video, I'll be telling you about Claude Flow, a new framework that makes Claude Code insanely better by combining ...",
        "url": "https://www.youtube.com/watch?v=morWV2yN2ig",
        "publishDate": "2025-07-27T09:15:03Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/morWV2yN2ig/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, there's a new tool called Claude-Flow, and I thought I'd talk about this as well. Claude-Flow is a framework-like thing that makes Claude code insanely better. It combines multiple features into one package that you can install and use. It's almost like an abstraction over Claude code that gives you some insane superpowers over it. For example, it gives you the option of Hive-Mind Intelligence, which has Queen-led AI coordination with specialized worker agents. It basically allows you to give it a very high-level or complex task, and it can break it down into multiple low-level tasks. Then, those tasks are assigned to multiple Claude code instances, and one Claude code instance keeps checking on them and just does the stuff for you. There are two options in this: one is swarm, and one is the hive-mind. In hive-mind, you can manually set up the different agents to use for each task, whereas swarm just allows you to give it a task, and it can work on that without any manual fiddling. It saves all the data in a proper SQLite database for session resumption. It also has its own neural network algorithms to make the agents smarter, faster, and better. It learns from successful operations, improves performance over time, applies knowledge across domains, provides efficient storage and execution, combines multiple neural networks, and understands the decision-making process. You can even make sure that each agent only takes a specific amount of memory and more. It also automatically configures some good MCP servers. It keeps learning from successful operations. It has real-time behavior analysis and optimization, along with a complete audit trail of AI decisions and continuous improvement from past executions. It also has self-healing systems, and it can oversee itself to make sure that the task you assign gets done. Actually, with all this, it scores 84.8% in SWE-Bench, which is currently the highest by over 10%, which is awesome. I have some interesting test results of my own to share as well. Not just that, it even saves you money, as its efficient task breakdown reduces costs significantly by over 30%. It also has a two or four times speed improvement because of its parallel coordination, which maximizes throughput. The config also isn't anything super challenging, though using it is. It's quite complex. So, I'll only talk about the things that will matter the most, while you can check out their docs to know more. Now, let me tell you how you can use it. But first, let's talk about today's sponsor, Dart. Tired of juggling tasks across different tools? Dart combines traditional project management with powerful AI features that actually get work done. Beyond organizing tasks and boards, Dart's AI can brainstorm project ideas, generate task lists, and even complete entire assignments for you. Their Composter-like AI agent understands your full project context, so you can simply chat with it to create, edit, or delete tasks naturally. The real game-changer is the custom agents. You can create custom agents that trigger from the built-in integrations or a N8N workflow or custom webhook for full customization. You can create a coding agent that pushes pull requests to GitHub, a marketing agent for campaigns, or a mailing agent for outreach. Then, just assign tasks and watch them get completed automatically. Plus, Dart integrates seamlessly with your existing workflow through their MCP server, connecting directly to Claude, ChatGPT, and other AI tools you're already using. Most features are completely free, with premium options starting at just $8 per month. Check out Dart through the link in the description. It might just transform how you work. Now, back to the video. To install it, you just have to run `npm install -g @claude-flow/alpha`, and it will get installed. Once done, we can now start using it. If you just run the `claude-flow` command, then you'll see all the commands, options, and parameters that you can use. First of all, you'd want to do `claude-flow init`. This will initialize all the related stuff for Claude-Flow in your directory, and it will also add the MCP server and other components along with it. This also adds multiple slash commands and custom agents for you as well. There are a ton of slash commands, and most of them have a description attached. So, you can use the ones accordingly. There are coder agents, architect, tester, research, and all those roles as well. Now, once that is done, you can start to do stuff outside Claude code with Claude-Flow. Let's start with the hive-mind. So, you can actually start a hive-mind or an agentic system on any task. You can do that by running the `claude-flow hive-mind wizard`. And this will open up an interactive interface. Here, you can set the objective of the swarm. Let's say that I'm asking it to build me a simple image cropper tool. Obviously, you would have it much more complex, but this is for the sake of demo here. Now, you can choose a technical name for it, and then you can select a coordination type, like if you want it to go hard with planning and then implement or something else. You can then select the number of maximum worker agents, as well as the worker agent types that you want to have. You can select between them. These four come pre-configured. Then, you can choose the algorithm for voting. It basically scores the responses from each agent with the help of other agents, and if the majority votes the task a pass, then it marks it as pass, which is pretty good. But you can also change it to be based on each agent's expertise or something like that. You can also enable auto-scaling and view a monitoring dashboard, which is just a terminal screen. Now, it will get started. You can let it run here and use another terminal window, and then assign specific tasks to this hive-mind. The objective that you gave it is a high-level one, but you can now spawn this hive-mind on a specific task and ask it to work in it by running the `hive-mind spawn` command with the task and then add Claude for auto-approval. Now, this will start the work. It will take the hive-mind objective and the task and accomplish the task for you. It will now spawn a ton of agents and just get the stuff done for you, and you can see it going through the task. Once the task will get done, the hive-mind will get idle, and then you can give it another task if you want that. You can also start a hive-mind directly from Claude Code because it gives it custom MCP tools in order to start a hive-mind from there. And if you run the status command, then you can see which agent is active, which is idle, and stuff like that. Now, in a bit, it gets done. You can see that it did the task pretty well, and you can actually use it now. This is way better than what you would have got with one prompt. It takes a bit sometimes, but the price almost remains the same as the task is broken down, and the context for those agents is from scratch, which helps in coding as well. Plus, it has memories and more. I am a fan of this swarm feature, for sure. I tested it on my agentic benchmark, and it scores four out of five, which is better than Claude code and very close. I'm still adding more questions, and it doesn't perform well in some of them, but Claude code is also the same. So, it doesn't worsen the performance, and you can give this a try if you're someone who likes to play with these kinds of agentic things. I really like it, and I'll probably use the swarm feature a lot to launch systematic swarms of agents because their implementation works quite well. There's also the option to make it better based on the previous tasks you have done, and it can learn from what it did wrong and update its instructions to be better next time. You can do that with the Claude-Flow neural train command or the analyze command as well, which is also awesome. Also, if you don't want to first start a hive-mind and then assign tasks, then you can also use the swarm command and directly give it a task, and it can just get to your task immediately. So, that is also cool. You won't be able to set the number of agents and types of agents there, but it is good for quick tasks. There are also many features in it, and I have just scratched the surface. You can give this a try and use it for yourself. Find out more about it and share your thoughts in the comments as well. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye!\nI think you missed this."
        }
    },
    {
        "id": "oRDao2iTyY0",
        "title": "Why China Couldn&#39;t Adapt Like Japan - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=oRDao2iTyY0",
        "publishDate": "2025-07-27T17:15:09Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/oRDao2iTyY0/hqdefault.jpg",
            "transcription": "Here's a full transcript of the video:\n\n00:00 - What made Japan a more fertile ground\n00:03 - for Western ideas than China? Was China just too big\n00:05 - for meaningful institutional change\n00:06 - in that same timescale?\n00:07 - I think it's\n00:08 - China is suffering from the\n00:10 - the incredible success of its civilization.\n00:12 - It had been the\n00:14 - dominant civilization of Asia\n00:16 - for ever and ever for excellent reasons.\n00:17 - I mean if you look at\n00:18 - Great Wall of China\n00:19 - the achievements of China,\n00:20 - they're amazing.\n00:20 - And for Japan,\n00:22 - it had always been in China's shadow,\n00:25 - and the Japanese had always tried to learn from others.\n00:27 - The Chinese also learn from others.\n00:29 - A lot of their institutions\n00:30 - come from the Manchus, right?\n00:32 - Han majority\n00:33 - Other minorities\n00:34 - But they pretend that they're actually\n00:34 - Han Chinese achievements.\n00:35 - Well, not so much, actually.\n00:36 - But the myth lives on that anything\n00:39 - that's worth knowing emanates from China.\n00:40 - Well, hubris. Right?\n00:43 - This is a human condition.\n00:45 - And the Chinese get a fatal case.\n00:47 - And the argument, what I'm wondering about is\n00:49 - whether this country has got a fatal case right now,\n00:51 - of this, you know, we know everything.\n00:51 - WATCH HERE"
        }
    }
]