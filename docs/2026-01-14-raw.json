[
    {
        "id": "https://ai-techpark.com/?p=232567",
        "title": "CallTrackingMetrics Rebrands to CTM",
        "content": "<p>Conversation analytics leader unveils new identity alongside enterprise-grade AI capabilities and strategic product expansion CallTrackingMetrics, a global conversation analytics company, today announced its rebrand to CTM, unveiling a new name, visual identity and website that reflect the company&#8217;s evolution into an AI-driven communications intelligence platform. The refreshed CTM brand signals...</p>\n<p>The post <a href=\"https://ai-techpark.com/calltrackingmetrics-rebrands-to-ctm/\">CallTrackingMetrics Rebrands to CTM</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/calltrackingmetrics-rebrands-to-ctm/",
        "publishDate": "2026-01-13T12:45:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI capabilities, AI news, ai tech news, AItech news, artificial intelligence news, CallTrackingMetrics"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232566",
        "title": "OutSystems Welcomes SaaS Veteran Fay Sien Goon as Chief Financial Officer",
        "content": "<p>Former AppFolio CFO and ServiceNow executive joins leading AI development platform to drive global financial strategy and operational excellence OutSystems, a&#160;leading AI development platform, today announced the appointment of Fay Sien Goon as Chief Financial Officer (CFO). In this role, Goon will oversee the company’s global financial operations, planning, and...</p>\n<p>The post <a href=\"https://ai-techpark.com/outsystems-welcomes-saas-veteran-fay-sien-goon-as-chief-financial-officer/\">OutSystems Welcomes SaaS Veteran Fay Sien Goon as Chief Financial Officer</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/outsystems-welcomes-saas-veteran-fay-sien-goon-as-chief-financial-officer/",
        "publishDate": "2026-01-13T12:30:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI development, AI news, ai tech news, AItech news, artificial intelligence news, OutSystems"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232525",
        "title": "Cast AI Valued at Over $1 Billion With the Launch of Its GPU Marketplace",
        "content": "<p>OMNI Compute is a unified compute marketplace that enables enterprises to access, provision, and operate GPUs across any cloud or region, with no code changes required Cast AI, the leading Application Performance Automation platform, today introduced&#160;OMNI Compute, a unified compute control plane that automatically discovers available resources across cloud providers...</p>\n<p>The post <a href=\"https://ai-techpark.com/cast-ai-valued-at-over-1-billion-with-the-launch-of-its-gpu-marketplace/\">Cast AI Valued at Over $1 Billion With the Launch of Its GPU Marketplace</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/cast-ai-valued-at-over-1-billion-with-the-launch-of-its-gpu-marketplace/",
        "publishDate": "2026-01-13T11:45:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, AI platforms, ai tech news, AItech news, artificial intelligence news, Cast AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232526",
        "title": "1Password Appoints Nancy Wang as Chief Technology Officer to Lead AI Strategy",
        "content": "<p>New leadership role underscores continued innovation in identity security for modern SaaS and AI-forward organizations 1Password, a leader in identity security, today announced the appointment of Nancy Wang as Chief Technology Officer (CTO), where she will lead the global engineering organization and drive the company’s AI strategy, shaping the future...</p>\n<p>The post <a href=\"https://ai-techpark.com/1password-appoints-nancy-wang-as-chief-technology-officer-to-lead-ai-strategy/\">1Password Appoints Nancy Wang as Chief Technology Officer to Lead AI Strategy</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/1password-appoints-nancy-wang-as-chief-technology-officer-to-lead-ai-strategy/",
        "publishDate": "2026-01-13T10:45:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, 1Password, AI news, ai tech news, AItech news, artificial intelligence news"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232542",
        "title": "DDN Earns Top Spot on CRN’s Cloud 100 List for 2026",
        "content": "<p>DDN, the world’s leading AI data platform provider, today announced that it has been recognized on the 2026 Cloud 100 list by CRN®, a brand of The Channel Company. This prestigious list spotlights 100 leading channel-focused cloud companies across five key categories: cloud infrastructure, cloud monitoring and management, cloud security,...</p>\n<p>The post <a href=\"https://ai-techpark.com/ddn-earns-top-spot-on-crns-cloud-100-list-for-2026/\">DDN Earns Top Spot on CRN’s Cloud 100 List for 2026</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/ddn-earns-top-spot-on-crns-cloud-100-list-for-2026/",
        "publishDate": "2026-01-13T09:00:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI Data Platform, AI news, ai tech news, AI workloads, AItech news, artificial intelligence news"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232488",
        "title": "Contextual Intelligence Becomes the New Standard For Exceptional CX in 2026",
        "content": "<p>APAC consumers call for explainable, transparent AI as over three-quarters register higher demands compared to a year ago Zendesk releases today its 2026 Customer Experience (CX) Trends report, revealing that Contextual Intelligence – the ability to combine AI, data, and human understanding in real time – is redefining what great...</p>\n<p>The post <a href=\"https://ai-techpark.com/contextual-intelligence-becomes-the-new-standard-for-exceptional-cx-in-2026/\">Contextual Intelligence Becomes the New Standard For Exceptional CX in 2026</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/contextual-intelligence-becomes-the-new-standard-for-exceptional-cx-in-2026/",
        "publishDate": "2026-01-13T07:30:00Z[Etc/UTC]",
        "author": "Zendesk",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai tech news, AItech news, artificial intelligence news, Customer Experience, Zendesk"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111580",
        "title": "Allister Frost: Tackling workforce anxiety for AI integration success",
        "content": "<p>Navigating workforce anxiety remains a primary challenge for leaders as AI integration defines modern enterprise success. For enterprise leaders, deploying AI is less a technical hurdle than a complex exercise in change management. The reality for many organisations is that, while algorithms offer efficiency, the human element dictates the speed of adoption. Data from the [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/allister-frost-tackling-workforce-anxiety-for-ai-integration-success/\">Allister Frost: Tackling workforce anxiety for AI integration success</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/allister-frost-tackling-workforce-anxiety-for-ai-integration-success/",
        "publishDate": "2026-01-13T13:39:53Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI and Us, AI Business Strategy, Features, Governance, Regulation & Policy, Human-AI Relationships, Inside AI, Interviews, Opinion, Trust, Bias & Fairness, World of Work, adoption, ai, culture, enterprise, ethics, governance, integration, society, workforce"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111576",
        "title": "The latency trap: Smart warehouses abandon cloud for edge",
        "content": "<p>While the enterprise world rushes to migrate everything to the cloud, the warehouse floor is moving in the opposite direction. This article explores why the future of automation relies on edge AI to solve the fatal &#8220;latency gap&#8221; in modern logistics. In the sterilised promotional videos for smart warehouses, autonomous mobile robots (AMRs) glide in [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/the-latency-trap-smart-warehouses-abandon-cloud-for-edge/\">The latency trap: Smart warehouses abandon cloud for edge</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/the-latency-trap-smart-warehouses-abandon-cloud-for-edge/",
        "publishDate": "2026-01-13T10:53:45Z[Etc/UTC]",
        "author": "Bazoom",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Sponsored Content"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111572",
        "title": "Why Apple chose Google over OpenAI: What enterprise AI buyers can learn from the Gemini deal",
        "content": "<p>Apple&#8217;s multi-year agreement to integrate Google&#8217;s Gemini models into its revamped Siri offers a rare window into how one of the world&#8217;s most selective technology companies evaluates foundation models – and the criteria should matter to any enterprise weighing similar decisions. The stakes were considerable. Apple had been publicly integrating ChatGPT into its devices since [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/apple-gemini-siri-enterprise-foundation-models/\">Why Apple chose Google over OpenAI: What enterprise AI buyers can learn from the Gemini deal</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/apple-gemini-siri-enterprise-foundation-models/",
        "publishDate": "2026-01-13T07:00:00Z[Etc/UTC]",
        "author": "Dashveenjit Kaur",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Deep Dives, ai, apple, consumer space, google"
        }
    },
    {
        "id": "1qclze7",
        "title": "Which AI to use",
        "content": "Hey guys, this post will deal with a problem a lot of people frequently have, which AI should they use. With so many new AI in the world nowadays, users are often split in their opinions, below I have listed my opinion on which AI to use for what with my reasoning behind it as well, if you wish to deny any of the claims then please first do your research and understand why I'm saying what I'm saying,\n\n  \n1. ***Politics/Geopolitics and Social matters:*** Want to know which country Trump has attacked? Which country has made which trade deal with who? Well the best AI for that would be **Grok**,  \nGrok is trained off of data from Twitter which gives it superior updates in social matters when compared to other AI's, and as much as some people may dislike it, Twitter is one of, if not the best source of global news in todays world.\n\n2. ***Coding:*** This one is **Github Co-pilot**, this one is obvious, Claude used to be the really good for it but Github Co-pilot is undoubtedly the best as of today. An Honorable mention would be *v0* by Vercel.\n\n3. ***Office work:*** Let me explain what I mean by this category, I mean those boring tasks where you make a spreadsheet or need to do some long boring task, then you can use **Claude**, Claude is more of a functional bot, I like to see him as a very thorough office worker and use him as such, he used to be much better in coding than other AIs for that very reason, he *worked*.\n\n4. ***Creativity:*** The creative aspect of an AI depends on how much data it is trained on, and in this scenario the AI with the most training is **ChatGPT**, it has huge data reserves and is hence automatically very good when it comes to Creativity.\n\n5. ***All round:*** While I have listed multiple AI for different purposes, a dependable AI you can use in most situations while not worrying too much about the quality of the result would be ***Gemini***.\n\nKeep in mind these are all just my opinions on which AI should be used for what, feel free to comment if you find something out of place or incorrect :) .",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qclze7/which_ai_to_use/",
        "publishDate": "2026-01-14T12:26:57Z[Etc/UTC]",
        "author": "Accomplished-Mud7790",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcle5q",
        "title": "AI tool for marketing and sales?",
        "content": "Does anyone know of an AI tool that can assist with marketing and sales stuff?\n\nI have a shopify store side project and I'm trying to get it off the ground.\n\nI was thinking if there's AI where I can use its intelligence gathered from thousands to millions of successful examples to help me set up my marketing campaigns, remind me of proven marketing basics and strategies, explain to me in details why my ad campaign didn't have the impact that I'd like and how I can improve it etc.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcle5q/ai_tool_for_marketing_and_sales/",
        "publishDate": "2026-01-14T11:56:14Z[Etc/UTC]",
        "author": "toymongoz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qck7eg",
        "title": "Can AI sing in my voice",
        "content": "Hi I wanted to know is it possible to make songs which are already known in my voice using my vocals . If possible can you please tell how can we do it or anyone who can help me do it",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qck7eg/can_ai_sing_in_my_voice/",
        "publishDate": "2026-01-14T10:47:49Z[Etc/UTC]",
        "author": "Harvey_R1008",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcjy8s",
        "title": "has ai changed how you approach refactoring old code?",
        "content": "\n\nbefore ai, i usually avoided touching older parts of a codebase unless i had to. now it’s easier to step in and make changes, which is mostly a good thing.\n\nthe tradeoff i’ve noticed is how easy it is to refactor quickly without fully understanding the original intent. i tend to use chatgpt, claude, and cosine together, with cosine helping when i need to follow how logic moves across files before changing anything. it’s less about speed and more about not breaking something subtle.\n\ncurious how others think about this. does ai make you more comfortable refactoring, or more cautious than before?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcjy8s/has_ai_changed_how_you_approach_refactoring_old/",
        "publishDate": "2026-01-14T10:32:10Z[Etc/UTC]",
        "author": "Tough_Reward3739",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcjm2f",
        "title": "Prompting alone doesn’t seem sufficient for visual consistency, what actually works?",
        "content": "I keep running into the same wall: even with strong prompts, image outputs drift stylistically over time.\n\nCurious what’s actually working beyond “better prompts.”",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcjm2f/prompting_alone_doesnt_seem_sufficient_for_visual/",
        "publishDate": "2026-01-14T10:11:19Z[Etc/UTC]",
        "author": "Glass-Lifeguard6253",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcjik1",
        "title": "What is the best AI for long videos?",
        "content": "I’m looking for an AI that can make long videos for a project I’m working on. The videos must be 1-10 minutes each. The videos should be animated / cartoon style. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcjik1/what_is_the_best_ai_for_long_videos/",
        "publishDate": "2026-01-14T10:05:04Z[Etc/UTC]",
        "author": "Annual_Awareness740",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qci23m",
        "title": "Current Acceleration v/s required acceleration for Singularity 2040",
        "content": "Here’s a simple acceleration/prediction model for what the world would need in 2026 to plausibly reach an ASI “singularity” by 2040, and how that compares to the current (recent) rate, expressed on a 0–10 acceleration scale.\n1) A minimal model: “Effective Capability Momentum” (ECM)\nTo avoid pretending we can measure “ASI distance” directly, we track a proxy for how fast the frontier can advance:\nECM multiplier per year (×/yr) is a weighted geometric mean of four measurable-ish drivers:\nCompute scaling (frontier training compute growth)\nAlgorithmic efficiency (how much less compute is needed for the same performance)\nAdoption/diffusion (how widely AI is being used)\nInvestment (fuel for scaling, talent, infra)\nFormula (conceptual):\nThese weights are subjective, but sane: compute + efficiency dominate; diffusion/investment matter but are second-order.\nConverting to a 0–10 acceleration score\nWe map “×/yr” onto a log scale:\nScore 0 = 1×/yr (no acceleration)\nScore 10 = 10×/yr (extreme acceleration)\n2) What acceleration is “required” in 2026 to hit ASI by 2040?\nWe still need one assumption: how much total “effective capability” gain is required from now until 2040. Nobody knows—so I model a sensitivity band:\nConservative: need 10,000× total improvement by 2040\nMid: need 1,000,000× total improvement by 2040\nAggressive: need 100,000,000× total improvement by 2040\nFrom 2026 → 2040 is 14 years, so the required annual multipliers are:\n10⁴× total ⇒ ~1.93×/yr (score 2.86/10)\n10⁶× total ⇒ ~2.68×/yr (score 4.29/10)\n10⁸× total ⇒ ~3.73×/yr (score 5.71/10)\n(These are just math—no hype.)\n3) What’s the “current rate” (proxy), using recent trend data?\nUsing widely cited trend trackers:\nInputs (recent trend proxies)\nFrontier training compute growth: ~4–5×/yr in recent years (Epoch AI). �\nEpoch AI +1\nAlgorithmic efficiency: compute required for a given LM performance halving about every ~8 months (Epoch AI) ⇒ ~2.83×/yr efficiency. �\nEpoch AI +1\nAdoption: org AI use 55% → 78% (2024 vs prior year) (Stanford AI Index 2025) ⇒ 1.42×. �\nStanford HAI\nInvestment (GenAI): +18.7% private investment (2024 vs 2023) ⇒ 1.187×. �\nStanford HAI\nECM observed proxy (weighted)\nThat yields an overall ECM ≈ 3.02×/yr, which corresponds to:\nObserved acceleration score ≈ 4.80 / 10\nThis is already around the “mid” requirement band (the 10⁶× scenario needs ~2.68×/yr).\n4) The chart (0–10 scale)\nYou should see two charts above:\nRequired acceleration (three scenarios) vs observed proxy\nObserved proxy component breakdown\nInterpretation:\nRequired (mid): ~4.29/10\nObserved proxy: ~4.80/10\nMeaning: if the “mid” assumption (10⁶× by 2040) is the right order of magnitude, then current momentum is slightly ahead.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qci23m/current_acceleration_vs_required_acceleration_for/",
        "publishDate": "2026-01-14T08:31:00Z[Etc/UTC]",
        "author": "DifficultyFlaky9655",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qchtz8",
        "title": "Better AI?",
        "content": "I’ve tried so many different AI generators, and while some might use more powerful models, A2E has consistently given me great pictures, and image to video once you iterate on prompts works super well. Also haven’t found a site that offers as much unlimited generations!\n\nhttps://video.a2e.ai/?coupon=OemJ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qchtz8/better_ai/",
        "publishDate": "2026-01-14T08:16:27Z[Etc/UTC]",
        "author": "steviolol",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qch8dh",
        "title": "For about 6 months or so I stopped reading or having predictions. Then this morning it hit me.",
        "content": "I think Jensen Huang was the closest one: natural language operators. \n\nToday every business has an opportunity to build custom tool with AI. No need for SaaS, no need for pricey platforms. \n\nIf you know what your business needs, you tell it to AI to build it. \n\n  \nWhich justifies AI infrastructure investments - they know it will come to this. What they don't know yet is how it'll be achieved. \n\nAll these AI tools operators will become a bridge between the business and AI. They'll help the business owners learn to work with AI, will probably build those custom platforms in the beginning pricey but as the competition grows for cheap. \n\nI'm telling you it'll be cheaper to build something custom than to pay pricey platforms. \n\nLet's see.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qch8dh/for_about_6_months_or_so_i_stopped_reading_or/",
        "publishDate": "2026-01-14T07:40:14Z[Etc/UTC]",
        "author": "decixl",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qch5cs",
        "title": "Most people still don’t realize that AI layoffs at massive scale are inevitable and close",
        "content": "There is still too much cope around this topic. For now, AI is still seen as “just a tool,” but with every single day we move closer to AI agents handling more and more of our work. Professions like software engineering will be hit first and hardest. Some examples:\n\nNo, you don’t need 100 developers to define strategy and architecture. You need 10, at best. And yes, backlogs are endless, but in that case, companies will simply onboard additional AI agents to take on even more work. \n\nNo, if AI and AI agents become better and better, this won’t automatically create massive technical debt, at least not more than hiring large numbers of junior and mid-level developers. Besides, the most important factor here is whether management considers quality important at all. In reality, they care more about speed than quality. Sure, this might lead to some companies failing, but that won’t help you with your job loss in the short term.\n\nNo, the government will not take care of you when you lose your job. In the end, the most important thing in our society is that rich people get richer. If this becomes a huge global problem, there might be civil unrest but even then, AI is not going away. The transition is going to be very, very painful, and it may take years until we find some sort of balance.\n\nNo, “learning to use AI” will not save most jobs. If a single person with AI tools can now do the work of five or ten, companies will not keep the other four or nine out of goodwill. Upskilling helps individuals stay relevant longer, but it does not change the underlying math.\n\nNo, new “AI-related jobs” will not offset the losses at scale. A few highly specialized roles will be created, but far fewer than the number of jobs being automated away.\n\nNo, \"I've been hearning this for years\" is not a valid counterargument. The progress is real, steady and not slowing down in any kind of way.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qch5cs/most_people_still_dont_realize_that_ai_layoffs_at/",
        "publishDate": "2026-01-14T07:34:46Z[Etc/UTC]",
        "author": "Own-Sort-8119",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "20",
            "commentCount": "127",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qch499",
        "title": "AI turned software into something closer to clay than code",
        "content": "AI turned software into something closer to clay than code\n\nIt feels like building is less about writing perfect blocks and more about shaping something that’s always moving, I don’t open a project thinking this is the final structure anymore, I start rough, poke it, bend it, throw parts away. With tools BlackBox I’ll spin up a backend idea in minutes, with Claude I’ll explore an approach or rewrite a chunk just to see how it feels. Nothing feels locked in\n\nBefore, every decision felt heavy. You planned more because changing later was expensive. Now change is cheap. You can try three directions in an hour,that shifts your mindset. Features become soft,architecture becomes flexible,even “done” feels temporary\n\nIt’s powerful but also strange, software used to feel like stone, once placed it stayed, now it feels like clay, always reshapeable, I’m not sure yet if that makes better products, but it definitely changes how we think while building",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qch499/ai_turned_software_into_something_closer_to_clay/",
        "publishDate": "2026-01-14T07:32:51Z[Etc/UTC]",
        "author": "dartanyanyuzbashev",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcg25t",
        "title": "Snyone else feel like AI tools are making mvp validation too easy? or am i missing something?",
        "content": "I have been building stuff while doing my mba for the past few months and honestly it's kinda scary how fast you can go from idea to working prototype now. like i can spin up a landing page, add some backend logic, even get a chatbot running... all in a weekend but here's what's messing with my head - i think i'm skipping the part where i actually talk to users? because building feels productive and talking to strangers feels hard lol\n\nlike before when building took weeks you HAD to validate first because you couldn't afford to waste time. now i catch myself building first and then being like \"ok who wants this\" after\n\nthis is becoming a problem imo? feels like the barrier to build dropped but the barrier to validate is still the same…",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcg25t/snyone_else_feel_like_ai_tools_are_making_mvp/",
        "publishDate": "2026-01-14T06:30:41Z[Etc/UTC]",
        "author": "ZenithFlow_65",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcfp6m",
        "title": "Google went from being \"disrupted\" by ChatGPT, to having the best LLM as well as rivalling Nvidia in hardware (TPUs). The narrative has changed. Is it genuine or just PR hype",
        "content": "The public narrative around Google has changed significantly over the past 1 year. (I say public, because people who were closely following google probably saw this coming). Since Google's revenue primarily comes from ads, LLMs eating up that market share questioned their future revenue potential. Then there was this whole saga of selling the Chrome browser. But they made a great comeback with the Gemini 3 and also TPUs being used for training it.\n\nNow the narrative is that Google is the best position company in the AI era.\n\nAs a user do you really find Gemini 3 better than Claude?\n\n[How has the narrative around Google changed over the past 1 year?](https://decodingthefutureresearch.substack.com/p/how-has-the-narrative-around-google)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcfp6m/google_went_from_being_disrupted_by_chatgpt_to/",
        "publishDate": "2026-01-14T06:10:12Z[Etc/UTC]",
        "author": "No_Turnip_1023",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "168",
            "commentCount": "70",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcfdv4",
        "title": "One-Minute Daily AI News 1/13/2026",
        "content": "1. **Slackbot**, the automated assistant baked into the Salesforce-owned corporate messaging platform Slack, is entering a new era as an AI agent.\\[1\\]\n2. **Pentagon** task force to deploy AI-powered UAS systems to capture drones.\\[2\\]\n3. **Stanford** researchers use AI to monitor rare cancer.\\[3\\]\n4. **Anthropic** Releases Cowork As **Claude’s** Local File System Agent For Everyday Work.\\[4\\]\n\nSources included at: [https://bushaicave.com/2026/01/13/one-minute-daily-ai-news-1-13-2026/](https://bushaicave.com/2026/01/13/one-minute-daily-ai-news-1-13-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcfdv4/oneminute_daily_ai_news_1132026/",
        "publishDate": "2026-01-14T05:53:24Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcdsrz",
        "title": "How are AI/LLMs progressing?",
        "content": "Feel free to explain it to me like I’m 5, as I am genuinely interested. \n\nMy assumption from YouTube and quick research : \n \nSo the largest LLMs are already trained on all of the publicly (as well as probably not public) text and data on the internet. I have heard people talking about how now to expand the training data they are having LLMs produce extra data and in essence feeding this back into the LLM. So we are producing synthetic data, that is likely reinforced to specify specific outcomes. Though wouldn’t this not allow for the creation of new ideas, but more so more accurate responses to already solved problems. \n\nHow is this supposed to create an AGI? \n\nIn my understanding this means current capabilities are close to maxed out, and the only improvement possible is from a context window size increase. Either by expanding vertically (more memory) or scaling horizontally (more tiny agents that specialize). But even with this I feel we are at are nearly at a cap, at-least with this current model.\n\nSo, to make a meaningful change at this point, a new method needs to emerge. \n\nPlease tell me what I am missing or if I have anything wrong in these assumptions. \n\nEdit : Thank you for the discussion!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcdsrz/how_are_aillms_progressing/",
        "publishDate": "2026-01-14T04:29:42Z[Etc/UTC]",
        "author": "connorjpg",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcbhng",
        "title": "Anyone use Section Ai?",
        "content": "Has anyone tried Section Ai for their courses and community? I am looking to learn more about AI and building agents. I have a 40% off promo so wanted to give it a real look.\n\nhttps://www.sectionai.com ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qcbhng/anyone_use_section_ai/",
        "publishDate": "2026-01-14T02:41:10Z[Etc/UTC]",
        "author": "Pampered_Penguin77",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc8ps2",
        "title": "My biggest issue with AI...",
        "content": "So as an older Gen-Z (1997), I actually don't use AI for anything (Wikipedia and google run through my veins)\n\nHowever, over the past few weeks, now on 2 occasions I have somehow run into issues with AI, despite not using it.\n\nOn 2 of my posts on various subreddits, the top upvoted comment has been something along the lines of \"get this AI crap out of here\".\n\nAnd it's honestly really annoying. I don't use AI, but I'm not against it either, no firm opinions, and I think it can be handy for making images I'd be unable to, mainly concept kits for sports teams lol (I tried it out for the first time on google gemini a few days ago)\n\nBut is this going to be the first major issue with AI? People hating it so much, that they will see literally anything online, call it out as AI, discredit it, and we get to a point where nobody believes anything ISN'T AI.\n\nFor context, as I write this I'm mildly crashing out because I used BULLET POINTS AND ITALICS to highlight the major point of my question in a subreddit, and that's the reason why they said it was AI. Formatting.\n\nAm I going crazy, or is this person just brain dead?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc8ps2/my_biggest_issue_with_ai/",
        "publishDate": "2026-01-14T00:38:10Z[Etc/UTC]",
        "author": "John_0Neill",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "27",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc7zuo",
        "title": "The end of human software development. 5 AIs begin work",
        "content": "My prediction: In 6 months, I will end my involvement in software development other than\n\n* Setting goals/requirements\n* Pointing to analogies\n* Kibitzing on Architecture and security\n* Participation in Requirements, Preliminary, Intermediate, and final reviews\n\nBy the end of 2026, most of you will join me.\n\nIn the blob, you can see a discussion of this by my roundtable of frontier AIs.\n\n[https://jsonblob.com/019bb9c9-c7fe-74e1-90b5-5db731915ecb](https://jsonblob.com/019bb9c9-c7fe-74e1-90b5-5db731915ecb)\n\nEver safety conscious, you might want to skip the \"yes mom (rolling eyes)\" opening.\n\nI also spared you the details of their draft implementation later in this, as I'm sure many of you can do better.  But I think it is clear, we are months away, and this, when it is done, is another step function into the Singularity.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc7zuo/the_end_of_human_software_development_5_ais_begin/",
        "publishDate": "2026-01-14T00:07:32Z[Etc/UTC]",
        "author": "Natural-Sentence-601",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc7qbs",
        "title": "Do you think this is art?",
        "content": "This is the latest work I've done thanks to Chat Got. What do you think? Is it art or just working circuits?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc7qbs/do_you_think_this_is_art/",
        "publishDate": "2026-01-13T23:56:50Z[Etc/UTC]",
        "author": "Daydream696969",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc6u2m",
        "title": "Awesome Physical AI – A curated list of VLA, world model, and robotics foundation model papers",
        "content": "I've been compiling papers on Physical AI — the intersection of foundation models and robotics. This covers Vision-Language-Action (VLA) models like RT-2 and π₀, world models (DreamerV3, Genie 2, JEPA), diffusion policies, real-world deployment and latency problems, cross-embodiment transfer, scaling laws, and safety/alignment for robots.\n\nThe field has exploded in the past 18 months. We went from \"lets try llms on robotics\" to having so many dimensions to optimize for. so felt right to maintain a running list of resources.\n\nOrganized by: foundations → architectures → action representations → world models → learning paradigms → deployment → applications.\n\nContributions welcome — especially corrections and missing papers.  \n[https://github.com/keon/awesome-physical-ai](https://github.com/keon/awesome-physical-ai)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc6u2m/awesome_physical_ai_a_curated_list_of_vla_world/",
        "publishDate": "2026-01-13T23:19:18Z[Etc/UTC]",
        "author": "kwk236",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc6b2y",
        "title": "Do you think most companies realize they are dependent on having employees to actually stay operational?",
        "content": "This is a super interesting idea to me: most companies are directly dependent on having employees in order to function. It might seem illogical at first, but it is true.\n\nThink of it like this. You have 100 companies that all pay their employees a salary. These employees collect their paychecks and go out and spend. As a result, other companies make money, which is then paid out to their employees, and the cycle continues.\n\nThis cycle is a necessity for most companies to remain operational. Say one company lays off 50 percent of its staff because of AI. This will not be widely felt and will have essentially zero impact on the overall economy. But now imagine when all companies do that. What was previously a zero-impact event now becomes a death sentence in the aggregate. All companies see essentially zero revenue coming in, forcing them to lay off even more employees, cut costs, and reduce spending overall. This only exacerbates the problem further, leading to a classic death spiral in which basically all companies go out of business.\n\nSo when these companies are salivating at the thought of laying off every single human soul in the name of insatiable and evil greed, do they realize they are effectively signing their own death warrant as well?\n\nClarification: Companies are not *directly* dependent on employees; they are dependent on *demand*. But demand flows from consumers having money to spend, and if the consumer has no money (because they are laid off, perhaps) then there is no demand.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc6b2y/do_you_think_most_companies_realize_they_are/",
        "publishDate": "2026-01-13T22:58:02Z[Etc/UTC]",
        "author": "Nissepelle",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "24",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc4rdu",
        "title": "Regarding why X/Grok on the news recently. How do you ban the feature, won't that make you an offender as a result ?",
        "content": "To ban the generation of indecent images of big and small people don't you have to teach grok or feed it data as part of banning process ? How does it technically work ? The people banning the feature, won't that make them offenders as part of the process ? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc4rdu/regarding_why_xgrok_on_the_news_recently_how_do/",
        "publishDate": "2026-01-13T21:59:15Z[Etc/UTC]",
        "author": "Such_Dimension2040",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "true"
        }
    },
    {
        "id": "1qc4f4w",
        "title": "Serious Question: Is The CES Craze Around AI Just A Way To Re-Invent Slavery?",
        "content": "Hey folks,\n\nI've been watching and listening to some of the coverage of CES recently, and one thing that seems to keep coming up again and again are companies that take an existing product - especially a robot of some kind - and stick ChatGPT or some other LLM inside it, and then call it a whole new thing. Some of their showroom floor presenters even play up the idea that this is a digital personal assistant, or a robot towel folder or whatever the case may be, that has a personality. It has preferences, it has memories.\n\nNow, that's not actually how these things work; that's just hype. But it seems to point to the eventual goal of these AI-focused tech companies. Or, at least, it points to what they think *we* all want from AI.\n\nMy concern is that... what they're describing seems functionally identical to a slave. This robot is, at least eventually, supposed to be an intelligence (artificial, in this case) that has thoughts, feelings, preferences, memories, a whole personality... but it is required to serve you, and, presumably, it cannot refuse your requests, your orders, your demands. Isn't that functionally the same thing as a slave? Or, isn't the *experience* of *having* that functionally identical to owning a slave?\n\nWhy is it that these tech developers seem so intent on creating a new form of slavery in the modern era? Or, is it just that they want to *feel* what it's *like* to own slaves without as much of the moral problem there? Or is it that they've convinced themselves that *we* all want slaves?\n\nNow, you might say: it's not really a slave! It's just a robot! They can't actually create anything like a \"\"\"real\"\"\" artificial intelligence right now anyway, and even if they figure it out later, the thing is still a machine. It doesn't actually feel things; it only *acts* like it does.\n\nTo which I would respond: Sure, yeah, but... why? Why do that? You could get the same level of convenience without giving the thing a personality, right? I mean, the functionality is great! If you put a couple of retractable robot arms inside my washer/dryer combo, so that it could fold my clothes for me after running its cycle, that would be rad! We'd all love that. If you made a dish washer with a detachable drone that could put all the dishes away after washing them, that would be awesome. Extremely helpful (if a bit unwieldy, I guess, to have a drone flying around your kitchen, but we'll work out the kinks). \n\nSo why does it need to be - or *pretend* to be - a thinking, feeling being with a personality and memories? That doesn't seem like it would make it a better dryer or dishwasher, would it? \n\nThe more I see, the more I hear, coming out of the craze around AI at CES, the more I feel like this is just another way that the wealthy and powerful - the people who are stratified so high above the rest of us that it has chemically affected their brains - have tried to re-invent slavery. They did it with share cropping, company towns, and now this is their new way of doing it. And sure, I suppose, if I *had* to pick between people and robots being enslaved - who's making me choose this, I have no idea - I *guess* I'd rather it be the robots, but... why do they have to act like they're self-aware? In the immortal words of that one robot from the Simpsons: \"Why? Why was I programmed to feel pain??\"",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc4f4w/serious_question_is_the_ces_craze_around_ai_just/",
        "publishDate": "2026-01-13T21:46:03Z[Etc/UTC]",
        "author": "IkujaKatsumaji",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "26",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc41ym",
        "title": "I’m a P&C student trying to figure out liability for AI agents. Here are 9 insurance traps.",
        "content": "I’m currently grinding through the pre-licensing course for my Property & Casualty broker license here in CA. While everyone is building AI agents, I’m trying to figure out how to insure them without getting wrecked.\n\nMy youngest brother is building agents on n8n, so I’m compiling these \"hacks\" to help him in future and to sanity-check my own understanding.\n\n**Disclaimer**: I’m a student, not a licensed broker yet. This isn't legal advice, just study notes.\n\nHere is what I learned about AI insurance reading forms in 2026:\n\n# 1. Silent AI exclusions\n\nMost older policies were written for deterministic software, not LLMs. If your policy has a \"Silent AI\" exclusion or doesn't explicitly cover \"non-deterministic output\" (hallucinations), you are paying for air. You need Affirmative AI Coverage. Ask for it by name.\n\n# 2. E&O is a Formality\n\nLet's be real: you are buying this to unlock a $1M contract. But don't confuse **E&O** (your code fails/hallucinates and costs the client money) with **Cyber Liability** (you get hacked/leak data). Clients ask for E&O, but their real fear is often the data breach. You usually need both, but E&O is the specific key to signing the deal.\n\n# 3. \"Description of Operations\" Matters\n\nIf your definition of **\"Professional Services\"** doesn’t match what you actually ship, the insurer will fight the claim. If you build agents, your wording must clearly include:\n\n\\- Software development + deployment / integration.\n\n\\- Orchestration / tool-calling workflows.\n\n\\- Configuration / monitoring / maintenance.\n\n\\- Advice / recommendations if clients rely on outputs.\n\n# 4. Claims-made and retroactive date\n\nUnlike car insurance, E&O is Claims-Made. You need coverage when the bug happens **AND** when you get sued. If you switch providers to save money, ensure you keep your Retroactive Date. If a broker resets this to \"Inception,\" your entire past history is uninsured.\n\n# 5. Who pays the lawyers? \n\nUS lawsuits are expensive. Check if your defense costs are **\"Outside the Limits\"**. Otherwise, a $400k legal bill eats into your $1M coverage, leaving you with only $600k to settle the actual claim. “Duty to Defend” vs “Duty to Reimburse” matters. Some policies reimburse defense after the fact instead of running point.\n\n# 6. Reimbursement vs. Pay-on-Behalf\n\nThis is rarely discussed but vital for startups.\n\n\\- **Pay-on-Behalf:** The insurer pays the lawyers directly. You don't touch your bank account.\n\n\\- **Reimbursement:** You pay the lawyers $50k/month from your own runway, and the insurer pays you back 90 days later (after \"reviewing\" the bills). \n\n\\- **Trap:** Most startups don't have the cash flow to float legal defense. Ensure your policy is \"Pay-on-Behalf.\"\n\n# 7. SIR vs. Deductible \n\nThey look the same (e.g., \"you pay the first $10k\"), but they are different animals.\n\n\\- **Deductible:** You pay the first $10k, insurer handles everything else. Easy.\n\n\\- **Self-Insured Retention:** You are responsible for managing the claim and defense until you hit $10k. You have to hire the lawyer, answer the letters, and do the admin work before the insurer even picks up the phone. Avoid SIR if you are a small team.\n\n# 8. Hammer clause \n\nThis is the one that may become the real headache. It's technically called the \"Consent to Settle\" clause.\n\n\\- **Scenario:** A client sues you for $100k. You know you are right and want to fight to clear your reputation. The insurer wants to settle because it's cheaper than court.\n\n\\- **The Trap:** If you refuse to settle, the \"Hammer Clause\" says the insurer will only pay the amount of the proposed settlement ($100k). If you go to court, lose, and get hit with a $1M judgment — you pay the $900k difference out of pocket.\n\n\\- **The Fix:** Look for a \"Soft Hammer\" clause (e.g., 50/50 sharing of extra costs) or full Mutual Consent.\n\n# 9. The \"Forensics\" Founders Forget\n\nFor E&O claims, “forensics” often means reconstructing behavior:\n\n\\- what inputs the agent saw\n\n\\- what tools it called\n\n\\- what guardrails were enabled\n\n\\- what prompt/policy/model version was live\n\n\\- who could change prompts/keys\n\n\\- what logs prove intended use vs misuse\n\nNo magic tool, but you need **defensible logging:** prompt / tool-call logs (careful with PII), versioning, RBAC, eval / monitoring signals, incident runbooks.\n\n\n\nIf I missed something or got wording wrong, please roast me — this is exactly why I’m posting.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc41ym/im_a_pc_student_trying_to_figure_out_liability/",
        "publishDate": "2026-01-13T21:32:27Z[Etc/UTC]",
        "author": "Illustrious_Slip331",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc2pxp",
        "title": "Anyone build a model from the ground up?",
        "content": "So I've been working on creating a small scalable model.  Starting with roughly 12k parameters.  It doesn't function like a standard LLM. I've been spending a majority of my time fixing the code 😂 and finding errors. \n\nAny tips or tricks, or pitfalls to avoid once training starts?(Also if anyone knows some decent sources for CSVs it would be greatly appreciated ) If curious about the model details I can expand. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc2pxp/anyone_build_a_model_from_the_ground_up/",
        "publishDate": "2026-01-13T20:42:05Z[Etc/UTC]",
        "author": "True-Beach1906",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "8",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc2494",
        "title": "Is anyone else burnt out by \"Model Chasing\"? The argument for Intelligent Routing.",
        "content": "I used to treat every new AI model release (Sora, Veo, Midjourney updates) like a holiday. Recently, though, it just feels like administrative overhead. I’m spending more time canceling/subscribing to tools and testing benchmarks than actually creating anything.\n\nI stumbled on this breakdown regarding **\"Intelligent Model Routing,\"** and it put words to exactly what I’ve been feeling.\n\nThe core argument is that we need to stop treating AI models like distinct apps we manually toggle between. Instead, the future is an orchestration layer-a \"General Contractor\"-that analyzes your prompt (e.g., \"Text-heavy infographic\" vs. \"Cinematic video\") and routes it to the specific model optimized for that task on the backend.\n\nIf you’re interested in the architecture of how a \"Routing Agent\" actually makes those decisions, this write-up is worth a read: [Intelligent AI Model Routing: Solving Model Fatigue](https://truepixai.com/blog/intelligent-ai-model-routing.html)\n\nDo you prefer having total manual control over which model you use, or are you ready for an abstraction layer to handle the selection for you?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc2494/is_anyone_else_burnt_out_by_model_chasing_the/",
        "publishDate": "2026-01-13T20:19:23Z[Etc/UTC]",
        "author": "ProgrammerForsaken45",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc01dc",
        "title": "NotebookLM - Quizzes and Flashcards not following my prompts - help",
        "content": "I am currently using Notebook to help me study for an exam certification. I had done this for my previous exam, uploaded separate pdf documents from each \"module\" and then asked Notebook to create quizzes and flashcards for each \"lesson\" within the module. I created separate notebooks for each Module.\n\nThe issue I am having is that the quizzes and flashcards are not pulling the right information, and are sometimes giving me questions or flashcards relevant to material that isn't even included in the source document for that module/notebook. It's almost like there is a cache issue or something? I have tried deleting and recreating flashcards and quizzes, and the same issue keeps happening, have restarted chrome etc. Some of the flashcards are right, and are relevant to the lesson I mentioned in the prompt, but some have nothing to do with the lesson I mentioned in the prompt, and some of them aren't even relevant to the source material I uploaded in that notebook.\n\nHas anyone had a similar issue to this?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qc01dc/notebooklm_quizzes_and_flashcards_not_following/",
        "publishDate": "2026-01-13T19:03:42Z[Etc/UTC]",
        "author": "tayims",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbzsv5",
        "title": "McKinsey CEO Bob Sternfels says the firm now has 60,000 employees: 25,000 of them are AI agents",
        "content": "[https://www.businessinsider.com/mckinsey-workforce-ai-agents-consulting-industry-bob-sternfels-2026-1](https://www.businessinsider.com/mckinsey-workforce-ai-agents-consulting-industry-bob-sternfels-2026-1)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbzsv5/mckinsey_ceo_bob_sternfels_says_the_firm_now_has/",
        "publishDate": "2026-01-13T18:55:16Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "22",
            "commentCount": "51",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbyqaj",
        "title": "OpenAI just killed half the “AI agent builder” startups, without even trying",
        "content": "There’s an enormous number of startups whose whole pitch was “build AI agents easily” or “no-code AI workflows.”\n\nBut now that OpenAI dropped their own agent builder… most of those startups are suddenly looking redundant.\n\nIf you want to see what that looks like in practice on the Google Cloud side with real tooling, governance, and enterprise workflows; Vertex AI Agent Builder is a good reference point. It’s less about shiny no-code UIs and more about production-ready agents that connect to data, APIs, and business systems: [**Vertex AI Agent Builder training**](https://www.netcomlearning.com/course/vertex-ai-agent-builder)\n\nare we heading toward the “death of no-code AI tools,” ?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbyqaj/openai_just_killed_half_the_ai_agent_builder/",
        "publishDate": "2026-01-13T18:17:46Z[Etc/UTC]",
        "author": "IT_Certguru",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "83",
            "commentCount": "49",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbx9dg",
        "title": "Observation: AI adoption fails most often among experienced professionals — not beginners",
        "content": "An interesting pattern I’ve noticed:\nPeople with 10–25 years of experience often struggle more with AI adoption than beginners.\n\nNot because of ability — but because:\n\nThey don’t have time to experiment\n\nThey need reliability, not novelty\n\nThey want systems, not tools\n\nAI becomes valuable for experienced professionals only when it’s:\n\nStructured\n\nRepeatable\n\nIntegrated into existing workflows\n\nI first encountered this workflow-based approach while learning from Be10X, which positions AI as a productivity system rather than a tech trend.\n\nCurious to hear how professionals here (30–50 age group) are integrating AI into real work without increasing cognitive load.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbx9dg/observation_ai_adoption_fails_most_often_among/",
        "publishDate": "2026-01-13T17:25:56Z[Etc/UTC]",
        "author": "Coffee_Talkerr",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "38",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbwz5f",
        "title": "AI Applied to the Automation and Governance of Procurement Documents",
        "content": "Hello everyone,\n\nI currently work in a strategic role within the procurement and governance area of a large organization, with the mission of structuring, standardizing, and modernizing institutional processes—especially those related to the production of technical documents essential to procurement processes, such as price surveys, terms of reference, bidding documents, and contracts.\n\nThe business problem we are addressing is very concrete: today, these documents are produced in a decentralized manner, with significant variations in language, structure, and technical depth across business units and requesting areas. This results in rework, risks of technical and legal inconsistencies, longer cycle times, and limited scalability.\n\nThe first step of this initiative—already underway—is the development of standardized document templates, which will be reviewed and approved by the various involved areas (procurement, legal, technical departments, etc.). The idea is that these approved templates will serve as the official baseline, from which any future document can be quickly adapted to the requested object and the requesting business unit, while maintaining regulatory compliance, technical quality, and governance.\n\nThe medium-term vision is to go beyond static standardization and evolve toward the structured use of Artificial Intelligence. The ultimate goal is to have pre-trained AI agents that, based on one or a few commands (structured input regarding the object, business unit, type of procurement, and specific requirements), are able to:\n\n* Select the appropriate approved template;\n* Adapt the text according to the context of the request;\n* Maintain adherence to technical, legal, and institutional guidelines;\n* Significantly reduce drafting time and human rework.\n\nI was hired specifically to lead this integration between deep knowledge of procurement processes and the applied use of AI, and I am currently in the technical design phase of the solution. Before moving forward with procurement of tools and implementation, I want to build a solid foundation for decision-making.\n\nWith that in mind, I would appreciate insights from those who have practical experience with similar projects or with corporate AI agent architectures, particularly regarding the following topics:\n\n# Type of AI / Most Suitable Approach\n\nFor this type of problem (structured documents, technical language, clear rules, and the need for traceability), does it make more sense to work with:\n\n* General-purpose LLMs combined with advanced prompt engineering?\n* RAG (Retrieval-Augmented Generation) based on approved templates?\n* Fine-tuning domain-specific models?\n* A combination of these approaches?\n\n# Agent Architecture\n\nIs it more advisable to adopt:\n\n* A single “procurement document specialist” agent?\n* A multi-agent system (e.g., object-understanding agent, drafting agent, compliance-review agent)?\n* How have you handled versioning, validation, and quality control for autonomous agents?\n\n# Tools and Frameworks\n\nWhich frameworks or technology stacks have proven more mature for this type of corporate application?\n\n* LangChain, LlamaIndex, AutoGen, CrewAI, or others?\n* What key precautions are necessary to avoid fragile or overly experimental solutions?\n\n# Degree of Autonomy vs. Human Control\n\nBased on your experience, what is the safest path:\n\n* Starting with AI as a copilot (human-in-the-loop)?\n* Gradually evolving toward more autonomous agents?\n* How do you structure validation checkpoints without losing efficiency gains?\n\n# Governance, Security, and Compliance\n\nIn institutional and regulated environments, what best practices do you recommend for:\n\n* Access control and document versioning;\n* Logging and traceability of AI-generated decisions;\n* Mitigating legal and operational risks?\n\n# Practical Implementation Path\n\nThinking in phases, would you recommend something like:\n\n* Phase 1: document standardization + structured prompts;\n* Phase 2: RAG using an approved knowledge base;\n* Phase 3: specialized agents;\n* Phase 4: broader automation integrated with corporate systems?\n\nThis is a strategic, institutionally relevant initiative with leadership support, including budget for tools, provided that the solution is technically sound, scalable, and defensible. Therefore, any practical insights, real-world experiences (including lessons learned from mistakes), or technical references would be extremely valuable.\n\nThank you in advance to everyone who can contribute.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbwz5f/ai_applied_to_the_automation_and_governance_of/",
        "publishDate": "2026-01-13T17:15:48Z[Etc/UTC]",
        "author": "duhribeiro",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbv0kl",
        "title": "AI to improve website content and UX",
        "content": "I am looking for an AI that can thoroughly analyze my website, identify flaws in both content and UX, and suggest improvements. Is there a tool for this in Claude or ChatGPT?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbv0kl/ai_to_improve_website_content_and_ux/",
        "publishDate": "2026-01-13T15:56:05Z[Etc/UTC]",
        "author": "Hologram-boi",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbuf2c",
        "title": "The peak and decline of the smartphone",
        "content": "\nThe reason we likely move toward less visible tech is not preference. It’s efficiency.\n\nSmartphones exist because digital action currently requires manual intervention. You must open, check, scroll, respond. That is labor. As systems become better at handling routine decisions automatically, the optimal amount of interaction drops. Not because people want less tech, but because interacting becomes redundant.\n\nThe replacement is automation plus delegation, not abstinence. Background systems handle navigation, scheduling, filtering, reminders, payments, and coordination without continuous input. You only step in when judgment is required. At that point, pulling out a phone is slower than letting the system run. Less interaction is not a lifestyle choice. It’s the rational outcome of reduced marginal benefit.\n\nSo the solid point is this: when the cost of interacting exceeds the value of interacting, usage declines. That’s not cultural. That’s economic. Smartphones decline because they require too much work relative to what they add. The future doesn’t use less technology. It touches technology less.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbuf2c/the_peak_and_decline_of_the_smartphone/",
        "publishDate": "2026-01-13T15:33:52Z[Etc/UTC]",
        "author": "Small_Accountant6083",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbrtk3",
        "title": "Challenge: share impossible tasks for AI in this thread and people can try to solve them",
        "content": "I have two:\n\n1. Create an image of alphabet with every letter being in a shape of an object or animal that starts with that letter eg A in a shape of an airplane.\n\n**Important: using just a cutout shape of a letter is not permitted** eg to have a Y shaped hole masking an image of a yacht on the sea. it needs to be Y shaped yacht or another y shaped object.\n\n2. Generate an image for ad for electric toothbrush. \n\nThe brief: robot toothbrush is defending a sci fi city from aliens that look like bacteria and the city is actually **human mouth with buildings shaped like teeth.** \n\nIt should look realistic, high budget and fun like marvel movies. \n\nImportant: teeth should look **anatomically correct** but still like sci fi buildings. **It must include both upper and lower teeth. No random teeth anywhere, all need to look exactly how they look in human mouth eg no roots exposed, no weird proportions.**",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbrtk3/challenge_share_impossible_tasks_for_ai_in_this/",
        "publishDate": "2026-01-13T13:50:56Z[Etc/UTC]",
        "author": "NoNote7867",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "20",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbraxp",
        "title": "Jumping ai platforms",
        "content": "I want to jump from chatgpt to gemini but ive already trained chatgpt to know so much about me; the work i do, psychology, values. How do I migrate all of it to gemini? Is it possible or am I stuck at gpt…",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbraxp/jumping_ai_platforms/",
        "publishDate": "2026-01-13T13:28:46Z[Etc/UTC]",
        "author": "Choice_Ad3305",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbr0g8",
        "title": "Privacy win: We are finally reaching the point where you can run massive 200B models on a standard laptop.",
        "content": "I’ve been following the local LLM scene for a while, and the recent progress with things like AirLLM is honestly mind-blowing. The idea that we can now run a 70B or even a 200B model on consumer-grade hardware (like a 16GB RAM MacBook) seemed impossible a year ago.\n\nFor me, the biggest game-changer isn't just the tech itself, but the privacy aspect. Being able to feed sensitive documents or company data into a model knowing that not a single byte leaves your local disk is the only way I’ll ever fully trust AI for serious work.\n\nIs anyone else here making the switch to fully local setups? Or do you think the convenience of \"paying with your data\" to big tech giants is still going to win for most people?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbr0g8/privacy_win_we_are_finally_reaching_the_point/",
        "publishDate": "2026-01-13T13:15:43Z[Etc/UTC]",
        "author": "Key-Glove-4729",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "25",
            "commentCount": "28",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc0fhl",
        "title": "Agent observability is way different from regular app monitoring - maintainer's pov",
        "content": "Work at [Maxim](https://getmax.im/Max1m) on the observability side. Been thinking about how traditional APM tools just don't work for agent workflows.\n\nAgents aren't single API calls. They're multi-turn conversations with tool invocations, retrieval steps, reasoning chains, external API calls. When something breaks, you need the entire execution path, not just error logs.\n\nWe built distributed tracing at multiple levels - sessions for full conversations, traces for individual exchanges, spans for specific steps like LLM calls or tool usage. Helps a lot when debugging.\n\nThe other piece that's been useful is running automated evals continuously on production logs. Track quality metrics (relevance, faithfulness, hallucination rates) alongside the usual stuff like latency and cost. Set thresholds, get alerts in Slack when things go sideways.\n\nAlso built custom dashboards since production agents need domain-specific insights. Teams track success rates for workflows, compare model versions, identify where things break.\n\nHardest part has been capturing context across async operations and handling high-volume traffic without killing performance. Making traces actually useful for debugging instead of just noise takes work.\n\nWanted to know how others are handling observability for multi-step agents in production? DMs are always welcome for discussion!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qc0fhl/agent_observability_is_way_different_from_regular/",
        "publishDate": "2026-01-13T19:17:50Z[Etc/UTC]",
        "author": "dinkinflika0",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "10",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcjtln",
        "title": "I got tired of hunting for good AI tools, so I made\"top ai sites\"",
        "content": "Like a lot of people here, I keep seeing *new AI tools pop up every single day*. Some are amazing, some are half-baked, and some disappear a month later. After bookmarking many random sites, I realized there wasn’t a clean, centralized place to explore solid AI tools without the noise.\n\nSo I ended up building [**top-ai-sites.com**](http://top-ai-sites.com) \n\n# What it is\n\nA curated directory of AI websites and tools, organized so you can actually *find something useful* instead of scrolling endlessly.\n\n# What makes it different\n\n* 🔍 **Hand-picked** AI tools (not auto-scraped junk)\n* 🧠 Covers multiple categories: writing, coding, design, productivity, and more\n* 🚀 Easy to browse when you just want inspiration or a specific solution\n* 🆓 Free to use — no sign-up required\n\n# Who it’s for\n\n* People experimenting with AI and want to discover new tools\n* Founders looking for AI services to speed up work\n* Developers & creators who want to stay updated without doomscrolling\n* Anyone overwhelmed by “Top 500 AI tools” lists 😅\n\n# Why I’m sharing here\n\nI built this because.... **I wanted it**, and I figured others here might find it useful too :). I’m actively improving it, so feedback (good or bad) is genuinely welcome.\n\n👉 **Check it out:** [https://top-ai-sites.com](https://top-ai-sites.com)\n\nIf you have favorite AI tools you think should be listed - or ideas to make it better - drop a comment. Happy to iterate based on what the community actually wants.\n\nThanks!🙌I got tired of hunting for good AI tools, so I made\"top ai sites\"",
        "url": "https://www.reddit.com/r/artificial/comments/1qcjtln/i_got_tired_of_hunting_for_good_ai_tools_so_i/",
        "publishDate": "2026-01-14T10:24:15Z[Etc/UTC]",
        "author": "M3ltd0wn_",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcfdh1",
        "title": "One-Minute Daily AI News 1/13/2026",
        "content": "1. **Slackbot**, the automated assistant baked into the Salesforce-owned corporate messaging platform Slack, is entering a new era as an AI agent.\\[1\\]\n2. **Pentagon** task force to deploy AI-powered UAS systems to capture drones.\\[2\\]\n3. **Stanford** researchers use AI to monitor rare cancer.\\[3\\]\n4. **Anthropic** Releases Cowork As **Claude’s** Local File System Agent For Everyday Work.\\[4\\]\n\nSources:\n\n\\[1\\] [https://techcrunch.com/2026/01/13/slackbot-is-an-ai-agent-now/](https://techcrunch.com/2026/01/13/slackbot-is-an-ai-agent-now/)\n\n\\[2\\] [https://www.defensenews.com/unmanned/2026/01/13/pentagon-task-force-to-deploy-ai-powered-uas-systems-to-capture-drones/](https://www.defensenews.com/unmanned/2026/01/13/pentagon-task-force-to-deploy-ai-powered-uas-systems-to-capture-drones/)\n\n\\[3\\] [https://www.almanacnews.com/health-care/2026/01/13/stanford-researchers-use-ai-to-monitor-rare-cancer/](https://www.almanacnews.com/health-care/2026/01/13/stanford-researchers-use-ai-to-monitor-rare-cancer/)\n\n\\[4\\] [https://www.marktechpost.com/2026/01/13/anthropic-releases-cowork-as-claudes-local-file-system-agent-for-everyday-work/](https://www.marktechpost.com/2026/01/13/anthropic-releases-cowork-as-claudes-local-file-system-agent-for-everyday-work/)",
        "url": "https://www.reddit.com/r/artificial/comments/1qcfdh1/oneminute_daily_ai_news_1132026/",
        "publishDate": "2026-01-14T05:52:47Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcfcm6",
        "title": "Google went from being \"disrupted\" by ChatGPT, to having the best LLM as well as rivalling Nvidia in hardware (TPUs). The narrative has changed",
        "content": "The public narrative around Google has changed significantly over the past 1 year. (I say public, because people who were closely following google probably saw this coming). Since Google's revenue primarily comes from ads, LLMs eating up that market share questioned their future revenue potential. Then there was this whole saga of selling the Chrome browser. But they made a great comeback with the Gemini 3 and also TPUs being used for training it.\n\nNow the narrative is that Google is the best position company in the AI era.\n\n# ",
        "url": "https://decodingthefutureresearch.substack.com/p/how-has-the-narrative-around-google",
        "publishDate": "2026-01-14T05:51:27Z[Etc/UTC]",
        "author": "No_Turnip_1023",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "17",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qceq2y",
        "title": "kyutai just introduced Pocket TTS: a 100M-parameter text-to-speech model with high-quality voice cloning that runs on your laptop—no GPU required",
        "content": "Blog post with demo: Pocket TTS: A high quality TTS that gives your CPU a voice: https://kyutai.org/blog/2026-01-13-pocket-tts\n\nGitHub: https://github.com/kyutai-labs/pocket-tts\n\nHugging Face Model Card: https://huggingface.co/kyutai/pocket-tts\n\narXiv:2509.06926 [cs.SD]: Continuous Audio Language Models; Simon Rouard, Manu Orsini, Axel Roebel, Neil Zeghidour, Alexandre Défossez\nhttps://arxiv.org/abs/2509.06926\n\nFrom kyutai on 𝕏: https://x.com/kyutai_labs/status/2011047335892303875",
        "url": "https://www.reddit.com/gallery/1qbpz5l",
        "publishDate": "2026-01-14T05:17:25Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qccvkb",
        "title": "Apple Creator Studio Is Here: A New Creative Suite Challenging Adobe",
        "content": "Could this challenge Abobe Creative Cloud?",
        "url": "https://techputs.com/apple-creator-studio/",
        "publishDate": "2026-01-14T03:45:20Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "14",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qcazo8",
        "title": "zai-org/GLM-Image · Hugging Face",
        "content": "Z.ai (creators of GLM) have released an open weight image generation model that is showing benchmark performance competitive with leading models like Nano Banana 2.\n\n\"GLM-Image is an image generation model adopts a hybrid autoregressive + diffusion decoder architecture. In general image generation quality, GLM‑Image aligns with mainstream latent diffusion approaches, but it shows significant advantages in text-rendering and knowledge‑intensive generation scenarios. It performs especially well in tasks requiring precise semantic understanding and complex information expression, while maintaining strong capabilities in high‑fidelity and fine‑grained detail generation. In addition to text‑to‑image generation, GLM‑Image also supports a rich set of image‑to‑image tasks including image editing, style transfer, identity‑preserving generation, and multi‑subject consistency.\n\nModel architecture: a hybrid autoregressive + diffusion decoder design.\n\n*  Autoregressive generator: a 9B-parameter model initialized from GLM-4-9B-0414, with an expanded vocabulary to incorporate visual tokens. The model first generates a compact encoding of approximately 256 tokens, then expands to 1K–4K tokens, corresponding to 1K–2K high-resolution image outputs.\n\n* Diffusion Decoder: a 7B-parameter decoder based on a single-stream DiT architecture for latent-space image decoding. It is equipped with a Glyph Encoder text module, significantly improving accurate text rendering within images.\n\nPost-training with decoupled reinforcement learning: the model introduces a fine-grained, modular feedback strategy using the GRPO algorithm, substantially enhancing both semantic understanding and visual detail quality.\n\n* Autoregressive module: provides low-frequency feedback signals focused on aesthetics and semantic alignment, improving instruction following and artistic expressiveness.\n\n* Decoder module: delivers high-frequency feedback targeting detail fidelity and text accuracy, resulting in highly realistic textures as well as more precise text rendering.\n\nGLM-Image supports both text-to-image and image-to-image generation within a single model.\n\n* Text-to-image: generates high-detail images from textual descriptions, with particularly strong performance in information-dense scenarios.\n\n* Image-to-image: supports a wide range of tasks, including image editing, style transfer, multi-subject consistency, and identity-preserving generation for people and objects.\"",
        "url": "https://huggingface.co/zai-org/GLM-Image",
        "publishDate": "2026-01-14T02:18:42Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc8vl7",
        "title": "Is the \"Water Argument\" getting on anyone else's nerves?",
        "content": "In my daily life those around me always complain about how much water is used when we do a single prompt on chatGPT or Gemini, I just get annoyed now. If it bothers you so much, stop eating meat, every pound of beef is costs 1200 gallons of water or more. Like, can we stop the scorekeeping yet?",
        "url": "https://www.reddit.com/r/artificial/comments/1qc8vl7/is_the_water_argument_getting_on_anyone_elses/",
        "publishDate": "2026-01-14T00:45:11Z[Etc/UTC]",
        "author": "Fluid-Volume4213",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "66",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc1dif",
        "title": "Jeff Bezos Says the AI Bubble is Like the Industrial Bubble",
        "content": "Jeff Bezos: financial bubbles like 2008 are just bad. Industrial bubbles, like biotech in the 90s, can actually benefit society. \n\nAI is an industrial bubble, not a financial bubble – and that's an important distinction. \n\nInvestors may lose money, but when the dust settles, we still get the inventions.",
        "url": "https://v.redd.it/3y4w265n86dg1",
        "publishDate": "2026-01-13T19:52:04Z[Etc/UTC]",
        "author": "SunAdvanced7940",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "85",
            "commentCount": "95",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qc0xb4",
        "title": "Beyond the Transformer: Why localized context windows are the next bottleneck for AGI.",
        "content": "Everyone is chasing larger context windows (1M+), but the retrieval accuracy (Needle In A Haystack) is still sub-optimal for professional use. I’m theorizing that we’re hitting a physical limit of the Transformer architecture.\n\nThe future isn't a \"bigger window,\" but a better \"active memory\" management at the infrastructure level. I’d love to hear some thoughts on RAG-Hybrid architectures vs. native long-context models. Which one actually scales for enterprise knowledge bases?",
        "url": "https://www.reddit.com/r/artificial/comments/1qc0xb4/beyond_the_transformer_why_localized_context/",
        "publishDate": "2026-01-13T19:35:52Z[Etc/UTC]",
        "author": "Foreign-Job-8717",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "14",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qby3z0",
        "title": "Signal creator Moxie Marlinspike wants to do for AI what he did for messaging",
        "content": "\"Moxie Marlinspike—the pseudonym of an engineer who set a new standard for private messaging with the creation of the Signal Messenger—is now aiming to revolutionize AI chatbots in a similar way.\n\nHis latest brainchild is Confer, an open source AI assistant that provides strong assurances that user data is unreadable to the platform operator, hackers, law enforcement, or any other party other than account holders. The service—including its large language models and back-end components—runs entirely on open source software that users can cryptographically verify is in place.\n\nData and conversations originating from users and the resulting responses from the LLMs are encrypted in a trusted execution environment (TEE) that prevents even server administrators from peeking at or tampering with them. Conversations are stored by Confer in the same encrypted form, which uses a key that remains securely on users’ devices.\"",
        "url": "https://arstechnica.com/security/2026/01/signal-creator-moxie-marlinspike-wants-to-do-for-ai-what-he-did-for-messaging/",
        "publishDate": "2026-01-13T17:55:58Z[Etc/UTC]",
        "author": "jferments",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbvab6",
        "title": "How do you see AI in 2026?",
        "content": "We are moving from experimentation to deployment while confronting economic and physical limits to the current development model. \n\n* Data center capital will become more selective. \n* Enterprise buyers will demand RoI accountability, reliability, and integration.\n* Architectural innovation needs to expand beyond model scaling.\n* AI will be a feature in the US elections given labor dislocation concerns. \n\nThese are my takes. How do you see 2026 unfolding?",
        "url": "https://www.forbes.com/sites/paulocarvao/2026/01/05/ai-in-2026-the-year-ai-meets-enterprise-and-politics/",
        "publishDate": "2026-01-13T16:06:02Z[Etc/UTC]",
        "author": "BubblyOption7980",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbqiro",
        "title": "Claude recently dropped Cowork, and this feels like a real step forward.",
        "content": "I recently read Claude's blog, and to be honest, this could really change how we use AI on a daily basis.\n\nBefore we got Claude Code for developers, Claude was excellent at chats. However, Anthropic recently introduced Cowork, which is essentially Claude Code for everyone else.\n\nWhat differentiates Cowork?\n\nYou instruct Claude to do something by pointing to a folder on your computer. The files in that folder can then be read, edited, and created by Claude.\n\nThey provided Examples:\n\nOrganize your Downloads folder automatically.\n\nCreate a spreadsheet from a stack of screenshots.\n\nInstead of relying solely on text responses, draft a report using your messy notes.\n\nAdditionally, the environment is similar to having a real coworker complete tasks while you work on something else. Claude creates a plan, carries it out, and keeps you informed.\n\nThe truth is, though, that this feels both strong and a little scary. If your prompt isn't clear, Claude can actually take action on your files, which could cause problems. Additionally, there are real worries regarding file access and safety.\n\nHas anyone here used Cowork yet?\n\nBlog link is in the comments. ",
        "url": "https://www.reddit.com/r/artificial/comments/1qbqiro/claude_recently_dropped_cowork_and_this_feels/",
        "publishDate": "2026-01-13T12:52:51Z[Etc/UTC]",
        "author": "Shot-Hospital7649",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "25",
            "isNsfw": "false"
        }
    },
    {
        "id": "8wyJ9dOgwHQ",
        "title": "Claude Cowork (Fully Tested): I might get ADDICTED to this NEW CLAUDE CODE FEATURE!",
        "content": "In this video, I'll be walking you through Anthropic's new tool called Cowork. It's essentially Claude Code packaged in a ...",
        "url": "https://www.youtube.com/watch?v=8wyJ9dOgwHQ",
        "publishDate": "2026-01-13T13:05:40Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/8wyJ9dOgwHQ/hqdefault.jpg",
            "transcription": "[ 0m0s694ms ] Hi.\n[ 0m5s674ms ] Welcome to\n[ 0m6s914ms ] another video.\n[ 0m8s249ms ] So,\n[ 0m9s189ms ] Anthropic has launched something that is called Cowork.\n[ 0m13s19ms ] This is basically Claude Code in a graphical interface.\n[ 0m19s119ms ] But it is made more for working alongside you on stuff that is not very coding related.\n[ 0m22s999ms ] They say that when they released Claude Code,\n[ 0m26s169ms ] they expected developers to use it for coding.\n[ 0m28s699ms ] They did, and then quickly began using it for almost everything else.\n[ 0m35s369ms ] This prompted them to build Cowork.\n[ 0m38s99ms ] A simpler way for anyone, not just developers, to work with Claude in the very same way.\n[ 0m43s999ms ] Cowork is available today as a research preview for Claude Max subscribers on our Mac OS app, and we will improve it rapidly from here.\n[ 0m47s409ms ] How is using Cowork different from a regular conversation?\n[ 0m49s39ms ] In Cowork, you give Claude access to a folder of your choosing on your computer.\n[ 0m54s749ms ] Claude can then read, edit, or create files in that folder.\n[ 1m0s119ms ] It can, for example, re-organize your downloads by sorting and renaming each file, create a new spreadsheet with a list of expenses from a pile of screenshots, or produce a first draft of a report from your scattered notes.\n[ 1m16s589ms ] In Cowork, Claude completes work like this with much more agency than you'd see in a regular conversation.\n[ 1m23s899ms ] Once you've set it a task, Claude will make a plan and steadily complete it, while looping you in on what it's up to.\n[ 1m32s89ms ] If you've used Claude Code, this will feel familiar.\n[ 1m37s459ms ] Cowork is built on the very same foundations.\n[ 1m40s739ms ] It is built basically with the Claude Code Agent SDK.\n[ 1m45s699ms ] They say that this means Cowork can take on many of the same tasks that Claude Code can handle, but in a more approachable form for non-coding tasks.\n[ 1m56s169ms ] When you've mastered the basics, you can make Cowork more powerful still.\n[ 2m1s139ms ] Claude can use your existing connectors, which link Claude to external information, and in Cowork we've added an initial set of skills that improve Claude's ability to create documents, presentations, and other files.\n[ 2m17s679ms ] If you pair Cowork with Claude in Chrome, Claude can complete tasks that require browser access, too.\n[ 2m25s399ms ] Cowork is designed to make using Claude for new work as simple as possible.\n[ 2m30s549ms ] You don't need to keep manually providing context or converting Claude's outputs into the right format.\n[ 2m38s779ms ] Nor do you have to wait for Claude to finish before offering further ideas or feedback: you can queue up tasks and let Claude work through them in parallel.\n[ 2m49s389ms ] It feels much less like a back-and-forth and much more like leaving messages for a coworker.\n[ 2m56s659ms ] Stay in control.\n[ 2m58s969ms ] In Cowork, you can choose which folders and connectors Claude can see: Claude can't read or edit anything you don't give it explicit access to.\n[ 3m6s919ms ] Claude will also ask before taking any significant actions, so you can steer or course-correct it as you need.\n[ 3m16s869ms ] That said, there are still things to be aware of before you give Claude control.\n[ 3m22s79ms ] By default, the main thing to know is that Claude can take potentially destructive actions (such as deleting local files) if it's instructed to.\n[ 3m33s49ms ] Since there's always some chance that Claude might misinterpret your instructions, you should give Claude very clear guidance around things like this.\n[ 3m43s569ms ] You should also be aware of the risk of \"prompt injections\": attempts by attackers to alter Claude's plans through content it might encounter on the internet.\n[ 3m54s719ms ] We've built sophisticated defenses against prompt injections, but agent safety—that is, the task of securing Claude's real-world actions—is still an active area of development in the industry.\n[ 4m10s479ms ] These risks aren't new with Cowork, but it might be the first time you're using a more advanced tool that moves beyond a simple conversation.\n[ 4m20s729ms ] We recommend taking precautions, particularly while you learn how it works.\n[ 4m25s869ms ] We provide more detail in our Help Center.\n[ 4m27s369ms ] That is all that they say here.\n[ 4m29s89ms ] It is quite a well-written article.\n[ 4m32s39ms ] Basically, they are trying to make a coworker that is not very Claude Code and developer thingy.\n[ 4m39s29ms ] If you know about things like Claude Bot, then I think that they might expand this to be something like that as well.\n[ 4m46s959ms ] With something like Cowork on the web, or something that integrates with WhatsApp or Discord, which will be cool to see if that is the direction they move in.\n[ 4m58s179ms ] Anyway, now let's have a look into it directly.\n[ 5m2s49ms ] You can open up the Claude desktop app and then you get the coworker option.\n[ 5m6s669ms ] You just open it up and you are good to go.\n[ 5m11s459ms ] Now, you can see the prompt box here.\n[ 5m14s359ms ] You can type in whatever you want to do.\n[ 5m19s19ms ] And then you would also have to select the folder that you wanted to work on as well.\n[ 5m23s89ms ] I'm going to select my Obsidian Vault where I write my scripts.\n[ 5m28s179ms ] These are just markdown files.\n[ 5m30s659ms ] I don't have time to manage them all, and I just write the scripts and leave it like that.\n[ 5m36s279ms ] One of the things that Anthropic boasts about Cowork is that it can help me in this.\n[ 5m40s709ms ] It can go through the files and organize them for you.\n[ 5m45s39ms ] I have about 1,200 files here and each one of them is a proper script with like 10,000 characters each.\n[ 5m54s569ms ] So, it's quite a good one to test on.\n[ 5m59s339ms ] So, I asked it to put all my scripts about GLM into a new folder named GLM.\n[ 6m6s109ms ] I asked it to make a copy of these scripts and told it that just the title matching will probably not work as I have weird naming schemes.\n[ 6m14s499ms ] This will require it to do probably a lot of stuff.\n[ 6m19s649ms ] So, if we have a look at what it did, then it's kind of interesting for sure.\n[ 6m25s799ms ] I am saying interesting because it wasn't able to do it at least in the first try.\n[ 6m31s499ms ] So, it didn't give me any response and kept the loading spinner for like 30 minutes.\n[ 6m37s929ms ] Then I thought that it may be that I'm doing something wrong, or there's a network error or something.\n[ 6m44s689ms ] So, I closed it and opened it up again, and that thread is super buggy.\n[ 6m51s639ms ] It now shows me two messages sent, whereas I only sent the prompt once.\n[ 6m58s79ms ] It also now shows this error which says that RPC error failed to mount vault.\n[ 7m4s339ms ] I guess it uses something like a virtual file system to do this.\n[ 7m9s29ms ] I think that it basically copies the whole thing over to work on it, I believe, which is good for security, but it's finicky in working.\n[ 7m18s739ms ] Anyway, it gave me that.\n[ 7m20s779ms ] I then tried a bit again and then it started working after a bit.\n[ 7m25s819ms ] So, to start, I asked it to do that and it did kind of well.\n[ 7m31s639ms ] It was pretty fast and it did some stuff.\n[ 7m35s349ms ] It didn't show me any progress or anything though.\n[ 7m38s989ms ] It just dived straight in and it asked me a dumb question about what GLM is.\n[ 7m46s369ms ] And I had to tell it that it's an LLM, which was fine, but it was a dumb question.\n[ 7m50s679ms ] So, I told it that and then it went ahead and did it quite well.\n[ 7m55s39ms ] It put my scripts very well managed in a folder, which was awesome.\n[ 8m2s189ms ] And it did check the file contents in order to make sure of the stuff and things.\n[ 8m7s169ms ] You can also see the added context in the session and you can click and see a preview of it, which is also pretty good to see.\n[ 8m15s649ms ] So, this is like one of the use cases where you ask it to organize your notes, files, and stuff.\n[ 8m24s769ms ] Another one is reports.\n[ 8m25s469ms ] So, you can ask it to build reports and stuff like that.\n[ 8m30s349ms ] So, I gave it my scripts and I asked it to build me a rewind report of 2025 about my scripts, and it did it in the first try.\n[ 8m40s759ms ] It made some tasks, went through the scripts, and did everything.\n[ 8m46s179ms ] And it is very snappy, which is awesome.\n[ 8m49s69ms ] Anyway, it got it done and made me a document file, and this is what it looks like.\n[ 8m55s539ms ] This looks kind of awesome.\n[ 8m58s79ms ] You get the total number of scripts in 2025, total words, and average words per script.\n[ 9m4s969ms ] It did a monthly breakdown as well, about how my busiest month was March with 93 scripts.\n[ 9m11s649ms ] December was the lightest month with 43 scripts.\n[ 9m17s19ms ] This checks out when you put the model releases in context as most of them launched in March.\n[ 9m23s239ms ] And it also did an analysis of the scripts and told me that I covered AI tools a lot, followed by Gemini and Chinese models and CLI tools and Claude and stuff.\n[ 9m39s29ms ] It also told me about the longest scripts with the most effort, and key insights were also added, which is kind of good.\n[ 9m45s389ms ] It's a really good one for sure.\n[ 9m48s19ms ] One more thing that it can do is make prototypes.\n[ 9m52s29ms ] Basically, it can code something for you and make artifacts for it, which is kind of cool for sure.\n[ 9m58s209ms ] It delves into the more Claude Code section of it, but it is quite good.\n[ 10m4s99ms ] I think that you could have used Claude Code itself for most of this stuff.\n[ 10m9s179ms ] However, there was more of a barrier for entry for newer people, and I think that this fixes that.\n[ 10m14s359ms ] It is kind of made well.\n[ 10m17s549ms ] The errors still seem very technical, like the RPC error is something that I can fix.\n[ 10m24s429ms ] But I mean someone who is using Cowork as they can't figure out Claude Code, they might not be able to figure out these errors.\n[ 10m31s239ms ] So, the error handling should be improved, and more things like calling Claude from WhatsApp or Discord can also be beneficial for co-working with it.\n[ 10m43s79ms ] There have been things like Verdent, which is also really good and I use it a lot.\n[ 10m50s479ms ] It is a very graphical interface with all kinds of models, and the UI there is super fleshed out.\n[ 10m57s719ms ] If you don't want to look at the code, then you don't.\n[ 11m0s369ms ] And you can easily change the system prompt to make it behave like a simple AI agent that does stuff like Cowork.\n[ 11m8s129ms ] So, I would still recommend that, but I think that Cowork is still good to have for sure.\n[ 11m15s479ms ] I like this one for sure.\n[ 11m17s169ms ] Overall, it's pretty cool.\n[ 11m18s649ms ] Anyway, share your thoughts below and subscribe to the channel.\n[ 11m21s349ms ] You can also donate via super thanks option or join the channel as well and get some perks.\n[ 11m27s349ms ] I'll see you in the next video.\n[ 11m28s189ms ] Bye."
        }
    },
    {
        "id": "yMjEc81WY8E",
        "title": "Gorbachev&#39;s Biggest Mistake - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=yMjEc81WY8E",
        "publishDate": "2026-01-13T16:30:34Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/yMjEc81WY8E/hqdefault.jpg",
            "transcription": "Gorbachev believed that if the Warsaw Pact, if that disappeared, then NATO would disappear. Not quite, because it turns out that organizations that are coercive versus those that are voluntary, they dissolve for different reasons. And then Gorbachev also assumed that the United States would share a continental outlook of not wanting strong powers and that the United States therefore would not want a unified Germany, let alone a strong unified Germany. So when all the unrest is happening in Germany, Gorbachev is off taking a vacation for life choice... because at that moment, President George Bush Sr. and Chancellor Kohl of Germany are working on fast-tracking German unification of a fully sovereign, unified Germany, both halves in NATO."
        }
    },
    {
        "id": "82DyXL0ZXI8",
        "title": "The New China AI Trifecta",
        "content": "Check out HubSpot's FREE AI Resource Holiday Bundle! https://clickhubspot.com/2396f8 A new wave of Chinese open source AI ...",
        "url": "https://www.youtube.com/watch?v=82DyXL0ZXI8",
        "publishDate": "2026-01-13T15:27:50Z",
        "author": "bycloud",
        "sourceType": "youtube",
        "sourceName": "bycloud YouTube Channel",
        "metadata": {
            "channelId": "UCgfe2ooZD3VJPB6aJAnuQng",
            "thumbnailUrl": "https://i.ytimg.com/vi/82DyXL0ZXI8/hqdefault.jpg",
            "transcription": "In the past few months, we witnessed some of the craziest developments in open-source LLMs. From July to December, there was a back-to-back-to-back-to-back state-of-the-art open weight releases, all coming from different research labs. What's even crazier is that they were all achieved with different techniques and model sizes, with each model containing different strengths themselves. And every single one of these labs are pioneering with their own philosophy at the pinnacle of AI right now. What's also surprising is that, out of these five, three of them are actually reaching the top for the very first time, which is insanely impressive. So, in today's video, I'll be covering what I love to call \"The Modern Open-Source Chinese AI Trifecta\" as they have defied the odds and challenged the closed-source models at a pace no one thought was possible. And before I dive into it, with this AI trifecta being one more thing that'll create even more useful AI tools, it's getting weirdly easy to waste hours testing apps that don't actually move your work forward. And the real difference between casual users and power users usually isn't which tool is best. It's having a simple system of tools, workflows, and prompts that helps you turn AI tools into something practical and that you actually can reuse instead of constantly starting over. So, if you want a faster way to level up in 2026, HubSpot has this limited-time free bundle that's built for exactly that. It gives you instant access to their six most popular resources, including 50+ curated productivity tools, 200+ monetization strategies, advanced prompt engineering, and a bunch of copy-paste workflows that could save you more than three hours per day. And what I like about it is that it's so useful. You get practical breakdowns for picking the right tools like the 40+ free versus paid AI tools guide. So, you can start lean, then upgrade only when it actually makes sense. So, it's not just a pile of links, it's a bundle with guidance you can actually use. And it's designed to meet you where you are, whether you're a solo entrepreneur buried in admin, a marketing manager trying to do more with less, or a consultant who wants to add AI services without reinventing your whole process. So, if you want to skip the trial and error phase and actually use AI more effectively, check out this bundle from HubSpot using the link down in the description, and thank you, HubSpot for sponsoring this video. Anyways, there's a recent trend in model development where the focus is no longer purely on reasoning or raw knowledge, but rather on practicality in certain key aspects. If you compare the current headlining benchmarks that are used in a big model release versus what we used about a year ago, the evaluation criteria are so much different. In the good old days, people always look at MMLU, GSM8K, ARC-c, HellaSwag, Winogrande. But nowadays, it's all about SWE-bench, LiveCodeBench, OJBench, Tau2-bench, AIME 2025, and GPQA-Diamond. Well, naturally, as key benchmarks from the past get saturated, the industry would shift towards harder and more advanced benchmarks, but this shift also introduces increasingly specific metrics that are narrower in scope than what we used to see. Like nowadays, it is much less common to see a model dominate across different benchmarks. A major contributor to this diversion is thanks to Agentic AI, which has created a landscape filled with narrow use cases where models can specialize. This current landscape then allows smaller AI labs to compete head-to-head with top-tier giants like Google and OpenAI. Another major shift has also immersed as the demand for practical usage becomes clearer, where pretty benchmarks are no longer a credible first impression. The real impression now is how good the model actually feels when using it. So, this has created a gap between purely research-focused labs like DeepSeek and Qwen, who publish a lot of research, and what the market actually needs right now. Which brings us to the first lab in the trifecta that is Moonshot AI. Their first ripple through the industry was Kimi K2, released in July 2025. In terms of pioneering open research, they are probably the most risk-taking company of the three I am talking about today. From Kimi K2 being the first large-scale model to replace AdamW optimizer with Muon, which is the most basic building block of training a model, to making Kimi Linear, which is a hybrid attention model that outperforms state-of-the-art models on one-million context window recall, this AI lab has shown a research spirit similar to DeepSeek, which makes their research papers so interesting to read. I actually have a deep dive video on Kimi K2 already that you can check out, and I'm also planning a video on Kimi Linear hybrid attention, so stay tuned. But what's most impressive is their latest release, Kimi K2 Thinking! Which was the state-of-the-art open-source model on the Artificial Analysis leaderboard as of Dec 2025. Not only that, their open-source release made considerations for inference efficiency. So, usually, there's some difference between a model that is made in a lab to beat benchmarks versus one that is served to everyone. Because in reality, when you use a model from a service provider, the server that serves the model to you actually doesn't need to run at full precision. They can just serve it at a lower precision to improve speed and lower cost, all while losing only a tiny bit of performance. So, generally, there's really not much reason to run at full precision unless you are training the model. However, it is often that benchmarks only reflect the performance of the full-precision model. On top of that, if a provider fails to quantize the model properly for serving or sets up the prompt incorrectly, you might think the model sucks, when in reality, it's the service provider's fault. This is why different providers often offer varying performance levels for the same model, which happens quite often for models like DeepSeek. However, Moonshot AI already took that into account. They applied quantization-aware training during the post-training of Kimi K2 Thinking, which allows the model's MoE components to run at INT4 precision, doubling generation speed during inference. And since their state-of-the-art performance on the benchmarks directly reflects their quantized model, they accurately represent a real user's experience. In the current economy of benchmark maxing, this is a move worthy of respect. Aside from that, what I also love about Moonshot AI is how open their researchers are when it comes to discussing research. And let me put you on this blog by one of their key researcher, called Su Jianlin. He started this blog in 2009 when he was 16 and has been posting till this day. Even though it's in Chinese, his latest posts explain some of the most technical topics in the field, including Muon, one of the key components behind Kimi K2. He not only covers the thought process behind it, but also the mathematical proofs and implementation guides. A complete knowledge gold mine of a website. Moonshot AI had a rapid rise as the company was only started back in March 2023. And now, their valuation is already sitting at a whopping $2.5 billion USD, while holding the best overall open-source model, topping DeepSeek and Qwen. They are without a doubt a key player in this AI frontier. The second lab in the trifecta that had a sudden rise this year is Z AI, or short for Zhipu AI. They are the oldest AI lab out of all the current top-tier Chinese AI startups. Originally, a research group within Tsinghua University, they spun out in 2019 to form Zhipu AI. Their journey kind of started in the visual generation era, started back in 2021 with their first text-to-image model called CogView, and by mid-2025, they had formally rebranded to Z AI and acquired the \".ai\" domain, which definitely wasn't cheap. For comparison, \"j.ai\" is selling for at least $7 million USD. So, \"z.ai\" likely cost even more. While they had amazing releases like ChatGLM in June 2024, what surprised everyone was the release of GLM-4.5 in July 2025, which topped the open-source leaderboard. And the latest version, GLM-4.7, beating DeepSeek V2 and Kimi K2 Thinking, the actual open-source state-of-the-art right now. The design of this model is interesting. They still use grouped-query attention, the same mechanism as the Llama 3 series, but their optimizer choice is like Moonshot's, which is Muon. However, what's really impressive is that their model is three times smaller than Kimi K2 while performing better in certain aspects. Even their smaller model, GLM-4.5 Air, is competitive despite being a third of its size. And the training of the model is highly deliberate, focusing on agentic formatting and practicality, which are things standard general models often overlook. For instance, they address how character escaping in function call templates creates problems, as coding is frequently escaped. So, when a model is predominantly used for coding, this becomes a learning burden. To solve this, they switched from the standard JSON format to an XML format so that the majority of the code can be represented in its native form without escaping. And this focus on practicality might be why their latest model, GLM-4.7, topped the Tau2-bench, which is an agentic tool use benchmark, as well as getting top spots in Web Design Arena. As they want to position themselves as a Model as a Service, their current aim right now for the model is to be a cheaper alternative to Claude Code, with Z AI officially serving it at only $3 per month. It is a really compelling option as Anthropic's Claude Code is pretty much a luxury dev tool that ranges from 20 bucks all the way to 100 bucks. Another great thing about being open-source is that companies like Cerebras are able to implement GLM onto their own dedicated high-speed inference chips, achieving insanely high throughput, like up to 1500 tokens per second, which pretty much feels like an instant generation. On top of their latest release, GLM-4.6 VL and GLM-4.6 VL Air, which has vision capabilities that can do things like refer to existing web pages or even Figma designs to convert it into actual code. Can you believe that with all these, their valuation is only $5.6 billion USD. Yet, they are contending with Anthropic that's worth 350 billion on their strongest moat right now, which is Claude Code. What a lovely competition. And as of recent, they just became the first ever public-traded LLM company, with a market cap of nearly 70 billion Hong Kong Dollars, which is around $9 billion USD. And for the third lab out of the trifecta, we have MiniMax. While they started their company all the way back in 2021 with focus on AI roleplay apps, similar to character.ai, though, didn't find much success in. They kind of just took off after a surprising release of a closed-source video generator called Haiku AI, which became one of the best text-to-video models during the mid-2024 boom. Shortly after, they expanded into text-to-speech, taking over the state-of-the-art in March 2025 with Speech-02 HD. But until this point, these were all private models. That is until they started getting into LLMs in 2025, with them first releasing MiniMax Text-01 and MiniMax VL-01 in January 2025, all under MIT license. And right off the bat, these two LLM models were massive, sitting at 456 billion parameters with 46 active parameters, and hitting one million context window. On top of that, they decided to tackle long context window by proposing their own variant of linear attention called Lightning Attention. Which, by the way, this is their first proper LLM release. And five months later, they released MiniMax M1, which is a reasoning model based on their previous Text-01. It was clear that their goal was to pump out a top-tier agentic model as soon as possible. However, there was a problem. Linear attention is notoriously bad at the exact thing they wanted to be good at, which is multi-hop reasoning. Multi-hop reasoning is basically the process of answering a query by combining information from multiple intermediate steps rather than relying on a single fact. For example, if you ask \"What profession does the wife of the 44th U.S. president have?\", the model must one, identify the 44th president, two, identify his wife, and three, identify her profession. Since their goal was an agentic model, and it needs to rely on these type of reasoning, M1 was not off to a great start. So, they pulled an Uno reverse pretty suddenly and released MiniMax M2 in October 2025, using GQA, returning to standard attention. Well, there are more reasons to why they did an insane pivot, which I'll cover probably in my future video, but long story short, the M2 model was an accident. The standard attention model they were experimenting was so good that they had to release it. How good you ask? Well, it is currently ranked number one on SWE-bench among all open-source models, and number two on the instruction following benchmark among all models, and is two times cheaper than Kimi K2 on Context-Bench while outperforming it. It also performed incredibly well on this private agentic benchmark made by AILCodeKing, though, it does suffer from a bad case of hallucination. But with their ability to pivot so freely and top the leaderboards, MiniMax is definitely a company with strong tempo and skill. And I think it's a bit surprising that the company has the lowest valuation out of all three, sitting $4 billion USD, even though they have quite a state-of-the-art lineup. And for a little bit of contrast, in February 2025, some Chinese economists estimated that DeepSeek has a valuation of around $2 to $30 billion USD. But anyways, looking at the current trend, there seems to be a new spectrum of development that companies can compete in, and this new Chinese trifecta is expanding aggressively into the application side of the spectrum, rather than just the research side. From their clear goal of tackling agentic coding, terminal use, tool use, code reasoning, and context window, which are all application-level capabilities, to using pre-existing and more conservative attention techniques like GQA, their activity doesn't look as much like DeepSeek, which spends time releasing research on niche topics, like their DeepSeek sparse attention. So, these labs are definitely moving in a straight line to make LLMs practical, accessible, and affordable as soon as possible. Well, you could also argue that they aren't as strong at pure research compared to DeepSeek or even Qwen, but that might be a good thing. As this kind of creates a yin and yang balance in AI, where there are labs that are research-oriented and there are labs that are application-driven. With this dynamic, it will definitely help to accelerate AI progress for everyone as much of the knowledge is shared openly. So, going into 2026, you should definitely keep an eye on this new Chinese trifecta, because not only Chinese open-source is already getting ahead on research, but the application side is now also challenging top U.S. labs like Anthropic and OpenAI. Google is just Google though. For them, the more competition, the better they are. And thank you guys for watching. A big shout out to Spam Maj, Chris Ledoux, Deagan, Robert Zawiasa, Marcelo Ferreira, Poofin' Ginuup, DX Research Group, Alex, and many others that support me through Patreon or YouTube. Follow me on Twitter if you haven't and I'll see you in the next one."
        }
    }
]