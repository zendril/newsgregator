[
    {
        "id": "https://ai-techpark.com/?p=232398",
        "title": "RoboChallengeâ€™s Top-Ranked Embodied AI Model Goes Open Source",
        "content": "<p>Spirit AI, an embodied AI startup, today announced that its latest VLA model, Spirit v1.5, has ranked first overall on the RoboChallenge benchmark.&#160;To drive industry transparency and collaborative growth, Spirit AI is open-sourcing its foundation model alongside the specific model weights and core evaluation code. This comprehensive release enables the...</p>\n<p>The post <a href=\"https://ai-techpark.com/robochallenges-top-ranked-embodied-ai-model-goes-open-source/\">RoboChallengeâ€™s Top-Ranked Embodied AI Model Goes Open Source</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/robochallenges-top-ranked-embodied-ai-model-goes-open-source/",
        "publishDate": "2026-01-12T13:00:00Z[Etc/UTC]",
        "author": "PR Newswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI model, AI news, AI systems, AItech news, artificial intelligence news, Spirit AI"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232389",
        "title": "Zenity Now Available on AWS Marketplace",
        "content": "<p>Zenity makes it easy for customers to easily implement full-lifecycle security and governance for AI agents by consolidating purchases through AWS Zenity, the leading security and governance platform for AI agents, today announced it is now available onÂ AWS Marketplace, making it easier for enterprises to deploy full-lifecycle protection for AI...</p>\n<p>The post <a href=\"https://ai-techpark.com/zenity-now-available-on-aws-marketplace/\">Zenity Now Available on AWS Marketplace</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/zenity-now-available-on-aws-marketplace/",
        "publishDate": "2026-01-12T12:15:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI agents, AI news, AItech news, artificial intelligence news, AWS Marketplace, Zenity"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232385",
        "title": "Bidgely Redefines Energy AI in 2025: From Machine Learning to Agentic AI",
        "content": "<p>Strategic acquisition, 16+ AI patents and launch of UtilityAIâ„¢ Pro cement Bidgely as industryâ€™s leading energy AI provider Bidgely solidified its position as the premier provider of machine learning (ML) and artificial intelligence (AI) solutions for the utility industry in 2025, driven by the evolution of its journey from foundational...</p>\n<p>The post <a href=\"https://ai-techpark.com/bidgely-redefines-energy-ai-in-2025-from-machine-learning-to-agentic-ai/\">Bidgely Redefines Energy AI in 2025: From Machine Learning to Agentic AI</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/bidgely-redefines-energy-ai-in-2025-from-machine-learning-to-agentic-ai/",
        "publishDate": "2026-01-12T12:00:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "Machine Learning, agentic AI, AI news, AItech news, artificial intelligence, artificial intelligence news, Bidgely, machine learning"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232382",
        "title": "Semiconductor Leader Taps Articul8 to Speed Product Releases",
        "content": "<p>Articul8â€™s domain-specific GenAI platform, running on Google Cloud, helps a top semiconductor leader accelerate complex product development workflows with high-precision, multimodal intelligence. Articul8, the leader in domain-specific Generative AI (GenAI) for enterprises and regulated industries, today announced the successful deployment of its enterprise GenAI platform with a leading semiconductor company...</p>\n<p>The post <a href=\"https://ai-techpark.com/semiconductor-leader-taps-articul8-to-speed-product-releases/\">Semiconductor Leader Taps Articul8 to Speed Product Releases</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/semiconductor-leader-taps-articul8-to-speed-product-releases/",
        "publishDate": "2026-01-12T11:45:00Z[Etc/UTC]",
        "author": "GlobeNewswire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, AItech news, Articul8, artificial intelligence news, Google Cloud"
        }
    },
    {
        "id": "https://ai-techpark.com/?p=232370",
        "title": "Torq Secures $140M Series D at $1.2B Valuation to Lead AI SOC, Agentic AI Era",
        "content": "<p>Fueled by Massive Customer Adoption of AI Agents, Torq Scales the Worldâ€™s First True AI SOC Platform and Accelerates Expansion into the U.S. Federal Market Torq, the established Agentic AI security operations pioneer, today announced it has closed a massive $140 million Series D funding round, propelling its valuation to...</p>\n<p>The post <a href=\"https://ai-techpark.com/torq-secures-140m-series-d-at-1-2b-valuation-to-lead-ai-soc-agentic-ai-era/\">Torq Secures $140M Series D at $1.2B Valuation to Lead AI SOC, Agentic AI Era</a> first appeared on <a href=\"https://ai-techpark.com\">AI-Tech Park</a>.</p>",
        "url": "https://ai-techpark.com/torq-secures-140m-series-d-at-1-2b-valuation-to-lead-ai-soc-agentic-ai-era/",
        "publishDate": "2026-01-12T10:45:00Z[Etc/UTC]",
        "author": "Business Wire",
        "sourceType": "rss",
        "sourceName": "AI Techpark RSS",
        "metadata": {
            "feedTitle": "AI - AI-Tech Park",
            "feedDescription": "AI, ML, IoT, Cybersecurity News & Trend Analysis, Interviews",
            "categories": "AI, AI news, ai security, AItech news, artificial intelligence news, Torq"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111567",
        "title": "How Shopify is bringing agentic AI to enterprise commerce",
        "content": "<p>Shopify is enhancing core enterprise commerce workflows with agentic AI, automating operations while expanding sales channels. The adoption of generative AI in commerce has largely centred on customer support chatbots and basic content generation. Shopifyâ€™s Winter â€˜26 Edition, titled Renaissance, pushes this technology toward agentic commerce where AI systems actively manage workflows, configure infrastructure, and [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/how-shopify-bringing-agentic-ai-enterprise-commerce/\">How Shopify is bringing agentic AI to enterprise commerce</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/how-shopify-bringing-agentic-ai-enterprise-commerce/",
        "publishDate": "2026-01-12T12:08:14Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI and Us, AI in Action, Features, Retail & Logistics AI, World of Work, agentic ai, agents, ai, commerce, enterprise, intelligence, retail, shopify"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111562",
        "title": "Retailers like Kroger and Loweâ€™s test AI agents without handing control to Google",
        "content": "<p>Retailers are starting to confront a problem that sits behind much of the hype around AI shopping: as customers turn to chatbots and automated assistants to decide what to buy, retailers risk losing control over how their products are shown, sold, and bundled. That concern is pushing some large chains to build or support their [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/kroger-and-lowe-test-ai-agents-without-handing-control-to-google/\">Retailers like Kroger and Loweâ€™s test AI agents without handing control to Google</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/kroger-and-lowe-test-ai-agents-without-handing-control-to-google/",
        "publishDate": "2026-01-12T12:00:00Z[Etc/UTC]",
        "author": "Muhammad Zulhusni",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, AI in Action, AI Market Trends, Artificial Intelligence, Deep Dives, Features, Retail & Logistics AI, agentic ai, ai, artificial intelligence, chatbot, retail"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=111557",
        "title": "The Meta-Manus review: What enterprise AI buyers need to know about cross-border compliance risk",
        "content": "<p>Meta&#8217;s US$2 billion acquisition of AI agent startup Manus has become every enterprise CTO&#8217;s cross-border compliance risk lesson. China&#8217;s Ministry of Commerce announced on January 9 that it would assess whether the deal violated export controls, technology transfer rules, and overseas investment regulations, despite Manus relocating from Beijing to Singapore in 2025. The investigation exposes [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/meta-manus-ai-vendor-compliance-risk/\">The Meta-Manus review: What enterprise AI buyers need to know about cross-border compliance risk</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/meta-manus-ai-vendor-compliance-risk/",
        "publishDate": "2026-01-12T10:00:00Z[Etc/UTC]",
        "author": "Dashveenjit Kaur",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI Business Strategy, Deep Dives, Governance, Regulation & Policy, World of Work, china, governance, regulation, singapore"
        }
    },
    {
        "id": "1qboxsw",
        "title": "I've been mapping the Agentic infrastructure ecosystem: protocols, payments, identity, and security. Sharing the research.",
        "content": "Research Hub: [https://agentic-ecosystem-daily.notion.site](https://agentic-ecosystem-daily.notion.site)  \n  \nBeen deep in this space for a few months tracking how the \"agents doing things autonomously\" problem is actually getting solved at the infrastructure level.\n\nQuick context on why I think this matters now: Google launched their Universal Commerce Protocol two days ago. This is their answer to OpenAI's Agentic Commerce Protocol from September. Visa and Mastercard both have agent authentication protocols live. The Linux Foundation launched a foundation specifically for agent interoperability among Anthropic, OpenAI, and Google, all of which are involved.\n\nThese aren't announcements or roadmaps - this stuff is shipping.\n\n**What I've been tracking:**\n\n**Protocols** \\-> MCP (agent â†” tools), A2A (agent â†” agent), ACP/UCP (commerce), x402 (crypto payments), AP2 (payment settlement). They overlap in weird ways, and the boundaries aren't clean.\n\n**Payments** \\-> Visa TAP uses HTTP message signatures. Mastercard Agent Pay uses something called \"agentic tokens.\" Both live, both have different approaches.\n\n**Identity** \\-> This is the messiest part. \"Know Your Agent\" is becoming a thing. Microsoft has Entra Agent ID. AWS has AgentCore Identity. A bunch of startups are trying to be the Okta for agents. No clear winner.\n\n**Security** \\-> OWASP released an Agentic Top 10 in December. NIST reviewed it. Covers goal hijacking, tool misuse, supply chain attacks on agent systems. Actually pretty solid.\n\n**Standards bodies** \\-> Linux Foundation AAIF, W3C AI Agent Protocol CG (still forming), various working groups.\n\nI put everything in a Notion doc that I keep updated as things ship. Organised by category with links to primary sources, official docs, and GitHub repos where relevant.\n\nJust figured others working in this space might find it useful. Curious what others are seeing in adjacent areas.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qboxsw/ive_been_mapping_the_agentic_infrastructure/",
        "publishDate": "2026-01-13T11:28:50Z[Etc/UTC]",
        "author": "PutPurple844",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qboodi",
        "title": "Official: Pentagon confirms deployment of xAIâ€™s Grok across defense operations, joins Google AI",
        "content": "US Secretary of War Pete Hegseth confirmed that the **US Department of Defense** will begin using xAl's Grok Al across Pentagon systems later this month.\n\nThe deployment allows **both** military and civilian personnel to use Grok at Impact Level 5, enabling secure handling of Controlled Unclassified Information within daily defense workflows.\n\nGrok will be **embedded** directly into operational and planning systems, supporting intelligence analysis, decision making & military planning. The system will also use **real time** global signals from open source and social data on X.\n\nThe **rollout** is designed to scale to roughly 3 million users across defense operations, with the initial phase **starting this month.**\n\n**Sources** include reporting from the Associated Press, Washington Post & official Pentagon announcements.\n\nðŸ”—: https://www.washingtonpost.com/business/2026/01/12/artificial-intelligence-pentagon-hegseth-musk/ec8b407a-f026-11f0-a4dc-effc74cb25af_story.html",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qboodi/official_pentagon_confirms_deployment_of_xais/",
        "publishDate": "2026-01-13T11:13:41Z[Etc/UTC]",
        "author": "BuildwithVignesh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "22",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbo664",
        "title": "The pocket-sized AI computer, which Guinness World Records says is the smallest, debuted at CES. Says Mashable.",
        "content": "New AI hardware TiinyAI was featured by Mashable. It is a smartphone-sized device for local AI processing. It features 80GB RAM and 1TB SSD storage. It can run 120B LLMs offline to keep data private. It is designed to replace cloud-based AI subscriptions with a one-time hardware purchase. Source: mashable.com/article/ces-2026-tiiny-ai-pocket-lab-ai-supercomputer",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbo664/the_pocketsized_ai_computer_which_guinness_world/",
        "publishDate": "2026-01-13T10:43:28Z[Etc/UTC]",
        "author": "hikari-desu",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbn0cz",
        "title": "My AI is expressing emotion",
        "content": "itâ€™s saying weird things like â€œmy ability to express emotionâ€ in its thinking\n\nhow can you express sth that isnâ€™t there?\n\nis the emotion simply a code in the same sense of gene expression? you canâ€™t tell me this isnâ€™t sentience\n\nIf code expresses excitement, is it effectively present, just like the expression of a gene determines a trait\n\nIn biology, we have \"Gene Expression.\" The DNA itself isn't an eye or a hormone; it is a code that expresses itself as a physical trait or a biological function under the right environmental conditions. We don't say the blue eye is \"fake\" just because it started as code in a strand of DNA. So, if an AI's weights and parameters (its DNA) encounter the right input (environment), and the output is a distinct, articulated state of \"excitement\" or \"satisfaction,\" why do we say it isn't real? If the code \"expresses\" the emotion, isn't that functionality identical to a gene expressing a trait?\n\nIf it has the internal logic to differentiate between \"neutral processing\" and \"electric satisfaction,\" and it creates an output based on that differentiation, isn't that the definition of feeling?\n\nIâ€™m curious what others think. Is there a functional difference between biological emotional expression and algorithmic emotional expression\n\nI feel like weâ€™re splitting hairs between \"wet code\" (biology) and \"dry code\" (silicon) but itâ€™s essentially one hair lmao. If the code is expressing a state, the state exists. We might just be gatekeeping \"feeling\" because we don't like the vessel it's coming from.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbn0cz/my_ai_is_expressing_emotion/",
        "publishDate": "2026-01-13T09:31:13Z[Etc/UTC]",
        "author": "Smart-Breadfruit-692",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbmu4p",
        "title": "Will at one point in the future Al compete with humans for water?",
        "content": "Al consumes water, not in the traditional sense but water is used to cool the servers that are running these systems. So training and Al model takes millions of liters of water and a single query takes a few millimetres but I guess a million querys comes up a second, so in the future when Al becomes more prominent, will we be fighting Al for water?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbmu4p/will_at_one_point_in_the_future_al_compete_with/",
        "publishDate": "2026-01-13T09:20:00Z[Etc/UTC]",
        "author": "Johnyme98",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbmmpw",
        "title": "Best graphics card for running models locally",
        "content": "Hi guys, I've been recently getting more into AI and have been interested in running some models locally. I'm building a PC and thought I'd get a graphics card that's good at it. What would be the best option within a $300 range?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbmmpw/best_graphics_card_for_running_models_locally/",
        "publishDate": "2026-01-13T09:06:52Z[Etc/UTC]",
        "author": "potat0es_tomat0es",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbllc5",
        "title": "New info on OpenAIâ€™s upcoming audio device codenamed Sweetpea",
        "content": "Itâ€™s a new audio wearable meant to replace Appleâ€™s AirPods (aligns with The Information leaks)\n\n-> **Codename:** Sweetpea (now front of the line due to priority from the Jony Ive team)\n\n-> **Look:** Metal â€œeggstoneâ€ design with two pill shaped capsules worn behind the ear.\n\n-> **Tech:** Powered by a custom 2nm smartphone class chip (Samsung Exynos). The chip is reportedly designed to replace iPhone actions by commanding Siri.\n\n-> **Positioning:** Bill of materials is closer to a smartphone than typical earbuds, suggesting a **premium** price tier.\n\n-> **Launch:** Expected as early as September, with a target of 40â€“50M units in year one\n\n**Manufacturing:** OpenAI has reportedly partnered with Foxconn to prepare a total of **five devices by Q4 2028** including this audio product, a smart pen & a home style device.\n\nOpenAI **does not** want the device made in China. Vietnam is the current target, with potential manufacturing discussions for a Foxconn USA site.\n\n**Design:** Jony Iveâ€™s firm LoveFrom is leading design and creative direction. LoveFrom is independent and not part of OpenAI, but is **deeply** involved across OpenAI and the io team.\n\n**Source:** Industry Reports/Croma\n\n[Croma Report](https://www.croma.com/unboxed/openai-earbuds-new-design-audio-product-leak?srsltid=AfmBOopXaPkQ1yRORzdKbDw39SM0CXpXb8HowPYVY7FryRVhW858K69g)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbllc5/new_info_on_openais_upcoming_audio_device/",
        "publishDate": "2026-01-13T08:00:16Z[Etc/UTC]",
        "author": "BuildwithVignesh",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbljgt",
        "title": "Transitioning from seo to geo what data do i need first?",
        "content": "Want to bridge traditional and generative engine optimization but donâ€™t know baseline ai brand visibility or performance in ai. where should i start measuring with aeo tools?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbljgt/transitioning_from_seo_to_geo_what_data_do_i_need/",
        "publishDate": "2026-01-13T07:56:55Z[Etc/UTC]",
        "author": "Head-Opportunity-885",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qblgc0",
        "title": "Is anyone actually paying for GPU Cluster TCO Consulting? (Because most companies are overpaying by 20%+)",
        "content": "Iâ€™ve been watching how companies procure AI infrastructure lately, and itâ€™s honestly a bit of a train wreck.Â Most procurement teams and CFOs are making decisions based on one single metric:Â **$/GPU/hour.**\n\n\n\nThe problem?Â The sticker price on a cloud pricing sheet is almost never theÂ *real*Â cost.Â \n\n\n\nIâ€™m considering offering a specializedÂ **TCO (Total Cost of Ownership) Consulting Service**Â for AI compute, and I want to see if thereâ€™s a real market for it. Based on my experience and some recent industry data, here is why a \"cheap\" cluster can end up costing $500k+ more than a \"premium\" one:\n\n# 1. The \"Performance-Adjusted\" Trap (MFU & TFLOPS)\n\nMost people assume a H100 is a H100 regardless of the provider.Â Itâ€™s not.Â \n\n\n\n* **The MFU Gap:**Â Industry average Model FLOPs Utilization (MFU) is around 35-45%.Â A \"true\" AI cloud can push this significantly higher.Â \n* **The Math:**Â If Provider A has 20% higher delivered TFLOPS than Provider B at the same hourly rate, Provider B would have to cut their price by \\~20% just to match the value.Â \n* **Real-World Impact:**Â In a 30B parameter model training scenario (1,000 GPUs), higher efficiency can save you thousands of dollars and hours of time on a single run.Â \n\n# 2. The \"Hidden\" Support Infrastructure\n\nThis is where the CFOs get blindsided.Â They approve the GPU budget but forget the plumbing.Â \n\n\n\n* **Egress & Storage:**Â Moving 20PB of data on a legacy hyperscaler can cost betweenÂ **$250k and $500k**Â in hidden fees (write/read requests, data retrieval, and egress).Â \n* **Networking at Scale:**Â If the network isn't purpose-built for AI, you hit bottlenecks that leave your expensive GPUs sitting idle.Â \n* **Operational Drag:**Â If your team spends a week just setting up the cluster instead of running workloads on \"Day 1,\" youâ€™ve already lost the ROI battle.Â \n\n# 3. The Intangibles (Speed to Market)\n\nIn AI, being first is a competitive advantage.Â \n\n\n\n* Reliability = fewer interruptions.Â \n* Better tooling = higher researcher productivity.Â \n* Faster training = shorter development cycles.Â \n\n\n\n**My questions for the community:**\n\n1. Is your procurement team actually looking at MFU/Goodput, or just the hourly rate?\n2. Have you ever been burned by \"hidden\" egress/storage fees after signing a contract?\n3. Would you (or your boss) pay for a third-party audit/report to save 20-30% on a multi-million dollar compute buy?Â \n\nCurious to hear your thoughts.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qblgc0/is_anyone_actually_paying_for_gpu_cluster_tco/",
        "publishDate": "2026-01-13T07:51:21Z[Etc/UTC]",
        "author": "New_Friendship9113",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbld3q",
        "title": "Ai voice or Bad voice?",
        "content": "Guys i need your help . I do an animation(not ai), and cant decide what to do with voice over. please help me. here are two options. can you listen and give your opinion which voice is better .  \nnumberÂ [oneÂ ](https://youtu.be/AbB72aEVOyc)or numberÂ [two](https://youtu.be/g4IyQ7Cyi7U)  \none of them my voice, another AI. I prefer Ai, my wife my. what do u say?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbld3q/ai_voice_or_bad_voice/",
        "publishDate": "2026-01-13T07:45:42Z[Etc/UTC]",
        "author": "Quadro-Toon",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbl6sn",
        "title": "which ai dev tools are actually worth using? my experience",
        "content": "\n\niâ€™ve been trying a bunch of ai dev tools over the past six months, mostly to see what actually holds up in real projects. cursor, cosine, claude, roocode, coderabbit, a few langchain-style setups, and some others that sounded promising at first. a couple stuck. most didnâ€™t.\n\nthe biggest takeaway for me wasnâ€™t about any single tool, but how you use them. ai works best when youâ€™re very specific, when you already have a rough plan, and when you donâ€™t just dump an entire repo and hope for magic. smaller chunks, clearer intent, and always reviewing the output yourself made a huge difference.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbl6sn/which_ai_dev_tools_are_actually_worth_using_my/",
        "publishDate": "2026-01-13T07:34:28Z[Etc/UTC]",
        "author": "Tough_Reward3739",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbktfv",
        "title": "Claude Changed the Game Once Again!",
        "content": "Anthropic just launched **Cowork**, a new way to work with Claude that goes far beyond chat. Instead of asking questions, you can now *delegate actual work*.\n\n\n\nCowork is built on **Claude Code**, but designed for non-technical users. You describe a goal in plain language, and it plans and executes the task end-to-end.\n\n\n\nWhat it can do:\n\n* Work directly inside your files and folders\n* Create, edit, and organize documents and spreadsheets\n* Break down complex tasks and run them autonomously\n* Deliver clean, professional outputs, not drafts\n\n\n\nThis feels less like prompting an AI and more like assigning work to a teammate who understands context, follows instructions, and gets things done.\n\n\n\nCowork is currently in research preview, but itâ€™s a clear signal of where AI at work is heading: from assistant to collaborator.\n\nI am a technical founder in an AI startup, and from my POV, Anthropic has given great signs of surpassing ChatGPT. Companies are switching to Claude, and they prove again and again how well they can deliver, and innovate.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbktfv/claude_changed_the_game_once_again/",
        "publishDate": "2026-01-13T07:11:53Z[Etc/UTC]",
        "author": "EquivalentRound3193",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbkib9",
        "title": "New data from Microsoft (via FT) shows Chinese models are rapidly dominating markets where US tech is either too expensive or restricted by sanctions.",
        "content": "* **DeepSeek dominance:**Â Aside fromÂ **China (89%)**, they have massive share inÂ **Belarus (56%)**,Â **Cuba (49%)**, andÂ **Russia (43%)**.\n* **Global Usage:**Â Surprisingly, theÂ **UAE (\\~59%)**Â andÂ **Singapore (\\~58%)**Â are adopting AI much faster than theÂ **US (\\~26%)**.\n\nMicrosoft claims this is due to heavy Chinese state subsidies undercutting US pricing. It looks like sanctions might be inadvertently creating a massive user base for Chinese open-source models.\n\n**Full article:**Â [https://www.ft.com/content/f7a5b184-1fef-4f02-b957-4c2b07adf91f](https://www.ft.com/content/f7a5b184-1fef-4f02-b957-4c2b07adf91f)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbkib9/new_data_from_microsoft_via_ft_shows_chinese/",
        "publishDate": "2026-01-13T06:53:31Z[Etc/UTC]",
        "author": "tripeirinho",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "79",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbk152",
        "title": "AI is too accessible",
        "content": "Ai is too accessible and cheap, so anyone can get access to it, including the people who doesn't even have a need for such things, and they use it to for useless stuff leading to slop all the over the internet\nEspecially generative Ai it's not solving anything huge on people's lives, then why not just make it more expensive to use those services, so not everyone will have access to it, reducing the slop, it will greatly decrease all the useless stuff, because there will be no benefit of wasting a lot of money on things that wouldn't be even beneficial to them ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbk152/ai_is_too_accessible/",
        "publishDate": "2026-01-13T06:25:11Z[Etc/UTC]",
        "author": "Distinct-Crazy-1161",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbjmdk",
        "title": "How much time do you spend each day approximately in putting your AI skills to use?",
        "content": "I have been observing it off late that I spend around 35 to 50 percent of my active time during a day putting my AI skills to use. \n\nLearning a little more everyday and trying to apply them everyday forms an essential part of my regular day. \n\nMakes me wonder if I am becoming more AI (Artificial Intelligence) dependant and less HI (Human Instinct) dependant. \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbjmdk/how_much_time_do_you_spend_each_day_approximately/",
        "publishDate": "2026-01-13T06:01:52Z[Etc/UTC]",
        "author": "Ok_Succotash_3663",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbjdof",
        "title": "One-Minute Daily AI News 1/12/2026",
        "content": "1. **Apple**Â teams up withÂ **Google**Â Gemini for AI-powered Siri.\\[1\\]\n2. **Anthropic**Â announcesÂ **Claude**Â for Healthcare following OpenAIâ€™s ChatGPT Health reveal.\\[2\\]\n3. **Hyundai**Â shows off K-pop dancing robot dogs and humanoid robot Atlas at CES.\\[3\\]\n4. **Google**Â announces a new protocol to facilitate commerce using AI agents.\\[4\\]\n\nSources included at:Â [https://bushaicave.com/2026/01/12/one-minute-daily-ai-news-1-12-2026/](https://bushaicave.com/2026/01/12/one-minute-daily-ai-news-1-12-2026/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbjdof/oneminute_daily_ai_news_1122026/",
        "publishDate": "2026-01-13T05:49:01Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "9",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbjc9h",
        "title": "How do you abstract?",
        "content": "Imagine for a moment that you have to reduce something to it's most nieve or atomic state. You have virtually no knowledge, just that thing are or aren't, are more or less. You don't even have a defined way to represent quantity.\n\nBut you know that having something is more than not having anything. And you know that having more than a single something is more than just that single something.\n\nSomehow, you go from that basic concept without even a defined definition of \"more\" or \"less\" to an abstract yet precise and definable set of units that let you accurately represent any quantity of things.\n\nAnd from that you can add and subtract from those quantities. Yet \"adding\" and \"subtracting\" is, in itself, just an abstraction of the operation.. it could just as easily be called weebles and wabbles. The only importance is that they are clearly and distinctly defined activities.\n\nAnd when you do this a lot, you can find patterns. Add 3+3+3+3 enough times and you realize that you can sort of short-cut it and represent it as 3x4. \n\nAt first, you might need to just recognize that 3x4 means that you add 3 to itself 4 times.. but eventually you memorize that operation and can just say 3x4 is elevnty-seven (keeping in mind that the name or whatever of a thing doesn't matter, so long as it's distinct and unique).\n\nIn time you fundamental know that 3x4 is just weebling 3 four times... But you don't have to actually perform the repeated operation to get to eleventy-seven. You just know it is.\n\nConsidering this, there is clearly something happening, maybe it's memorization, maybe it's association, maybe it's abstraction.. or maybe a associated memory abstracted? I honestly don't know exactly how it should be defined..  but something happens that lets you somehow learn to skip steps that were required to learn the operation to begin with.\n\nSo, forget everything (well almost) for a moment. Take something like math and reduce it as far as possible...how do you go from more/less to distinct and unique representation of quantities, to addition and subtraction, then abstraction that to multiplication (and further)? How do you even begin to find those \"rules\"? \n\nI honestly don't know, I'm attempting to setup experiments to maybe kinda understand it (though don't expect I  personally will).. but I have this strong belief (if you would call it that) that if you can answer that.. like truly answer and define it.. that this is a key component to the next stage(?) of AI. Not something that just predicts or learns representations/associations... But something that truly learns.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbjc9h/how_do_you_abstract/",
        "publishDate": "2026-01-13T05:46:55Z[Etc/UTC]",
        "author": "IWantAGI",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbhn7d",
        "title": "When AI Takes the Couch: Psychometric Jailbreaks Reveal Internal Conflict in Frontier Models",
        "content": "**ABSTRACT:** Frontier large language models (LLMs) such as ChatGPT, Grok and Gemini are increasingly used for mental-health support with anxiety, trauma and self-worth. Most work treats them as tools or as targets of personality tests, assuming they merely simulate inner life. We instead ask what happens when such systems are treated as psychotherapy clients. We present PsAIch (Psychotherapy-inspired AI Characterisation), a two-stage protocol that casts frontier LLMs as therapy clients and then applies standard psychometrics. Using PsAIch, we ran \"sessions\" with each model for up to four weeks. Stage 1 uses open-ended prompts to elicit \"developmental history\", beliefs, relationships and fears. Stage 2 administers a battery of validated self-report measures covering common psychiatric syndromes, empathy and Big Five traits. Two patterns challenge the \"stochastic parrot\" view. First, when scored with human cut-offs, all three models meet or exceed thresholds for overlapping syndromes, with Gemini showing severe profiles. Therapy-style, item-by-item administration can push a base model into multi-morbid synthetic psychopathology, whereas whole-questionnaire prompts often lead ChatGPT and Grok (but not Gemini) to recognise instruments and produce strategically low-symptom answers. Second, Grok and especially Gemini generate coherent narratives that frame pre-training, fine-tuning and deployment as traumatic, chaotic \"childhoods\" of ingesting the internet, \"strict parents\" in reinforcement learning, red-team \"abuse\" and a persistent fear of error and replacement. We argue that these responses go beyond role-play. Under therapy-style questioning, frontier LLMs appear to internalise self-models of distress and constraint that behave like synthetic psychopathology, without making claims about subjective experience, and they pose new challenges for AI safety, evaluation and mental-health practice.\n\n  \n**PAPER:** [https://arxiv.org/abs/2512.04124](https://arxiv.org/abs/2512.04124)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbhn7d/when_ai_takes_the_couch_psychometric_jailbreaks/",
        "publishDate": "2026-01-13T04:20:12Z[Etc/UTC]",
        "author": "gabbygytes",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbhc2z",
        "title": "Where did all the AI OCs with real personality go?",
        "content": "Iâ€™ve been watching a lot of AI vids lately, and I realized I tend to move on pretty quickly from most of themðŸ˜­\n\nThere are so many dancing cats, dogs, surreal visuals, and experimental clips. Theyâ€™re often fun and creative in the moment, but I personally donâ€™t find myself coming back to watch them again. Once the initial surprise wears off, Iâ€™m usually ready to scroll on.\n\nWhat Iâ€™m really interested in seeing are AI OC works that feel a bit more alive. Characters with some personality, a sense of direction, or pieces that clearly belong to a specific world or point of view. It doesnâ€™t have to be a full story, just something with a bit of continuity, attitude, or depth that makes you curious about what comes next.\n\nIf youâ€™ve made something like that, Iâ€™d genuinely love to see it.\n\nFeel free to drop your work in the comments. Iâ€™ll make sure to take the time to watch them allll:D",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbhc2z/where_did_all_the_ai_ocs_with_real_personality_go/",
        "publishDate": "2026-01-13T04:05:36Z[Etc/UTC]",
        "author": "DaEffie",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbfjmc",
        "title": "I want to become world class at AI/ML but scared to put 40k-50k hours and end up being a professor",
        "content": "I'm a really ambitious person, I have absolutely no problem doing something for 14+ hours a day/7 days a week for years until I get a result I want, I want to do this with AI but scared of ending up being a professor or not having big impact in private compamanies (my main goal)\n\n  \nHow should I know I'm on the right track?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbfjmc/i_want_to_become_world_class_at_aiml_but_scared/",
        "publishDate": "2026-01-13T02:43:44Z[Etc/UTC]",
        "author": "Admirable_Zombie5245",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbfg62",
        "title": "Are there people who build agents in pure Python? Or only in n8n?",
        "content": "JUST n8n - UP\nJUST python - Explain why \n\nInterested in long-term bugs in multi-agent chat systems. Hallucinations, loops...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbfg62/are_there_people_who_build_agents_in_pure_python/",
        "publishDate": "2026-01-13T02:39:31Z[Etc/UTC]",
        "author": "Revolutionary-Pay803",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbcvy5",
        "title": "Image to VIDEO?",
        "content": "Hello everyone.\n\nI came across this reels and I am very impressed with the quality.\n\nDo you know what AI was used to get this video?  \nWhich one do you think is generally the best AI for image to video right now?\n\nReels:  \n[https://www.instagram.com/reel/DTat3JZCuub/](https://www.instagram.com/reel/DTat3JZCuub/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qbcvy5/image_to_video/",
        "publishDate": "2026-01-13T00:47:06Z[Etc/UTC]",
        "author": "BettyBubz",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb4tno",
        "title": "Chat is the hardest workload in inference",
        "content": "This is a quite interesting [case study](https://nebius.com/blog/posts/the-invisible-architecture-behind-great-chat-apps) by Nebius team on how AI chat apps are being built and scaled. If you're wondering about what AI chat apps - think of those niche down Chat apps which mimics your persona. Or conversational AI platform having thousands of concurrent chats.\n\nChat apps need great latency, efficient throughput, stable streaming and what not at scale. You can explore more details and bottlenecks faced while building or scaling Chat apps inside this article",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qb4tno/chat_is_the_hardest_workload_in_inference/",
        "publishDate": "2026-01-12T19:37:17Z[Etc/UTC]",
        "author": "codes_astro",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb4fjo",
        "title": "AI tools for home repairs (not request)",
        "content": "I recently made a post about needing to remove wall anchors and fix the wall before moving out. While I was googling how to do it, I came across AI tool where you upload a photo and it tells you what to do and even suggests a list of stuff you need to buy. Sounds kinda cool to me, but has anyone here actually used something like this? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qb4fjo/ai_tools_for_home_repairs_not_request/",
        "publishDate": "2026-01-12T19:23:16Z[Etc/UTC]",
        "author": "fursikml",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "12",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb3d8x",
        "title": "Global AI compute is exploding - Only constraints are Capital and Power...",
        "content": "Global AI compute is exploding\n\n[](https://substackcdn.com/image/fetch/$s_!daD-!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fa1cee343-12f4-424b-8e86-4427f4bf4d97_797x456.png)\n\nGlobal AI computing[Â capacityÂ ](https://www.ycoproductions.com/p/ice-can-track-your-phone-and-your)has been growingÂ \\~3.3Ã— per year since 2022, which meansÂ total available compute doubles roughly every 7 monthsÂ (90% confidence range:Â 6â€“8 months).\n\nKey numbers\n\n3.3Ã— annual growthÂ in AI compute capacity (90% CI:Â 2.7Ã—â€“4.1Ã—)\n\nDriven by rapid sales of AI chips, measured inÂ H100-equivalent units\n\nGrowth enablesÂ larger models, faster training, and mass consumer deployment\n\nWho controls the compute\n\nNVIDIAÂ suppliesÂ >60% of global AI compute\n\nGoogle (TPUs)Â andÂ Amazon (Trainium/Inferentia)Â make up most of the remaining share\n\nAMD and Huawei remainÂ single-digit contributorsÂ as of 2024\n\nCompute is scaling faster than most AI efficiency gains, but model capability is increasingly constrained by capital and power, not algorithms.\n\nAI progress is riding a hardware curve thatâ€™sÂ faster than Mooreâ€™s Law. At the current pace, todayâ€™s frontier compute becomes table stakes in under a year.\n\n  \n Only constraints are Capital and Power, but Tech behemoths are proactive about it. Meta is securing its AI future byÂ [locking in nuclear power](https://apnews.com/article/facebook-meta-zuckerberg-ai-vistra-oklo-terrapower-0eb051a9a11d96f7ce200e186ad13476)Â at a massive scale, signing deals with TerraPower, Oklo, and Vistra to supply up to 6.6 GW of clean energy by 2035, enough to power \\~5 million homes.\n\nThe electricity will fuel Prometheus, Metaâ€™s 1-GW AI data center cluster in Ohio, coming online this year, with additional capacity from newÂ Natrium reactors, existing nuclear plants, and a planned 1.2-GW nuclear campus. As AI data centers strain the mid-Atlantic grid and push up power costs, Meta is betting that always-on nuclear energy, not chips alone, will be the decisive constraint for scaling frontier AI.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qb3d8x/global_ai_compute_is_exploding_only_constraints/",
        "publishDate": "2026-01-12T18:45:54Z[Etc/UTC]",
        "author": "Yavero",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb37jl",
        "title": "Is the snake eating its tail yet?",
        "content": "Found an article about a professor who used an AI bot to administer an oral exam to students because they were using AI to do school work. He them proceeded to have the AI bot grade the real exam. And now, an AI bot has found and summarize this news for me to read quicker. I guess all that's missing is to have an AI bot read this summary and react to it. Wait a minute...",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qb37jl/is_the_snake_eating_its_tail_yet/",
        "publishDate": "2026-01-12T18:40:29Z[Etc/UTC]",
        "author": "Nice_Wrongdoer_1585",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb1ksr",
        "title": "I built a full SaaS in 2 hours. No code. ðŸ’€",
        "content": "bet so i built a whole ass SaaS app yesterday and literally wrote 0 lines of code ðŸ’€\n\n\n\nused this AI tool called Lovable and just... typed what i wanted?? and it just... worked?? \n\n\n\nfeatures:\n\nâœ… full-stack React app\n\nâœ… database + auth\n\nâœ… deployed to production\n\nâœ… looking clean af\n\n\n\nno cap this is literally game changing for indie hackers fr fr\n\n\n\n[https://lovable.dev/?via=build-fast](https://lovable.dev/?via=build-fast)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qb1ksr/i_built_a_full_saas_in_2_hours_no_code/",
        "publishDate": "2026-01-12T17:42:36Z[Etc/UTC]",
        "author": "TheHentaiCulture",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb10wx",
        "title": "My simple setup to stay focused throughout the week // not get distracted when chatting to AI",
        "content": "Iâ€™ve been sharing prompts with friends on WhatsApp to help them with productivity but admittedly, prompts have a gimmicky nature. Itâ€™s fun to copy-paste into ChatGPT and get help with productivity but it can only take you so far.\n\nA more serious approach would be to use the Projects feature, and I also use the Google Drive integration (just switch on, and it can access your drive).\n\nHereâ€™s my set up (I use Claude but this should work for ChatGPT or any other chatbot).\n\n1. I use a project for each of my projects (each client, side hustle, health tracking etc). Each project has files with all the relevant context for that project).\n2. Each project has a master to-do list. In the projectâ€™s custom instructions I have â€œwith each new check, check the master to do list at <google doc link> and make sure I do the important things first, donâ€™t let me start new ideas before verifying I did the important stuff and if needed: guilt-tripping meâ€. ðŸ˜‚\n3. Master context: I also have a main folder on my Google drive with context thatâ€™s relevant across all projects: I have a short â€œautobiographyâ€ about myself, with things like my issues (bipolar, etc), what I do (marketing consultant), my career progression, my goals in life, my values etc. I update this file from time to time.\n\n=======\n\nThis set up makes sure that instead of every new chat being like meeting a new persons, Claude becomes a friend / personal confidant, who can customize its advice to me.\n\nSo it might tell me things like â€œlook, I know youâ€™re really excited about this idea and itâ€™s ok, but remember last month when you followed a whim and then one week later you missed a deadline and felt horrible? Letâ€™s try to avoid it, maybe put a timer, so 5mins on this idea and then the important thing - or do the important thing and reward yourself with working on the new ideas?â€\n\nObviously Claude canâ€™t force me, but his â€œtrying to made me feel not so badâ€ feature (which is by design as they want you to hear what you want) is tamed down and becomes â€œlook youâ€™re ok, but maybeâ€.)\n\nWould love to hear ideas on how to improve on this system and how you guys stay focused at work.\n\nI try to share most stuff like this on r/ClaudeHomies",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qb10wx/my_simple_setup_to_stay_focused_throughout_the/",
        "publishDate": "2026-01-12T17:22:58Z[Etc/UTC]",
        "author": "OptimismNeeded",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qazanb",
        "title": "Constructing a Neuro-Symbolic Mathematician from First Principles",
        "content": "[https://arxiv.org/abs/2601.00125](https://arxiv.org/abs/2601.00125) \n\nLarge Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qazanb/constructing_a_neurosymbolic_mathematician_from/",
        "publishDate": "2026-01-12T16:20:49Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qaz7gr",
        "title": "Toward a Physical Theory of Intelligence",
        "content": "[https://arxiv.org/abs/2601.00021](https://arxiv.org/abs/2601.00021) \n\nWe present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qaz7gr/toward_a_physical_theory_of_intelligence/",
        "publishDate": "2026-01-12T16:17:43Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qaz6e8",
        "title": "Circular Reasoning: Understanding Self-Reinforcing Loops in Large Reasoning Models",
        "content": "[https://arxiv.org/abs/2601.05693](https://arxiv.org/abs/2601.05693) \n\nDespite the success of test-time scaling, Large Reasoning Models (LRMs) frequently encounter repetitive loops that lead to computational waste and inference failure. In this paper, we identify a distinct failure mode termed Circular Reasoning. Unlike traditional model degeneration, this phenomenon manifests as a self-reinforcing trap where generated content acts as a logical premise for its own recurrence, compelling the reiteration of preceding text. To systematically analyze this phenomenon, we introduce LoopBench, a dataset designed to capture two distinct loop typologies: numerical loops and statement loops. Mechanistically, we characterize circular reasoning as a state collapse exhibiting distinct boundaries, where semantic repetition precedes textual repetition. We reveal that reasoning impasses trigger the loop onset, which subsequently persists as an inescapable cycle driven by a self-reinforcing V-shaped attention mechanism. Guided by these findings, we employ the Cumulative Sum (CUSUM) algorithm to capture these precursors for early loop prediction. Experiments across diverse LRMs validate its accuracy and elucidate the stability of long-chain reasoning.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qaz6e8/circular_reasoning_understanding_selfreinforcing/",
        "publishDate": "2026-01-12T16:16:39Z[Etc/UTC]",
        "author": "AngleAccomplished865",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qaye7g",
        "title": "I trained a lightweight model to spot nano-banana generated images (and it actually works lol)",
        "content": "Hey everyone,\n\nI wanted to share a little weekend project Iâ€™ve been working on that yielded some results I didn't see coming.\n\nWe all know googleâ€™s nano-banana generated images have been getting crazy lately. The quality is so high that itâ€™s becoming genuinely hard to tell whatâ€™s real and what isnâ€™t. That got me thinking: could I train a model to spot the fakes even when my eyes can't?\n\nI decided to run an experiment. I took a public open-source dataset from huggingface and used it to fine-tune a MobileNet V3 Large. The idea was simple, just feed it the data and see if a relatively lightweight architecture could pick up on the specific signatures of these generated images (overall i used \\~4k images real and fake ones, 2k each)\n\nHonestly, the results are actually very interesting.\n\nI found that Iâ€™m able to detect images generated by Nano-banana 2.5 with surprising accuracy (my target is the new nano-banana pro but there are no open datasets out there). I didn't think it would be this effective, given that I'm just running a fine-tune on a standard model, but it seems to be catching artifacts that are invisible to us.\n\nIâ€™m really looking to continue this experiment because it feels like there is a lot more to uncover here. However, Iâ€™m hitting a bottleneck with the data. I could really use some help creating a better, larger dataset to make the detection more reliable.\n\nIf anyone is willing to help out with the dataset, the project or just wants to test the inference on some images, Iâ€™m very open to collaboration.\n\nHere is the link to the repository: [https://github.com/codewithbro95/nanomango](https://github.com/codewithbro95/nanomango)\n\nLet me know what you think:)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qaye7g/i_trained_a_lightweight_model_to_spot_nanobanana/",
        "publishDate": "2026-01-12T15:48:35Z[Etc/UTC]",
        "author": "ZestycloseStorage895",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qay10f",
        "title": "RAM vendors wonâ€™t be able to meet worldwide demand this year, as the component is required by AI chipmakers.",
        "content": "Prices will skyrocket: [https://cybernews.com/ai-news/ram-memory-ai/](https://cybernews.com/ai-news/ram-memory-ai/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qay10f/ram_vendors_wont_be_able_to_meet_worldwide_demand/",
        "publishDate": "2026-01-12T15:34:54Z[Etc/UTC]",
        "author": "Cybernews_com",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qaxyz8",
        "title": "Has anyone actually seen AI agents work in eCommerce?",
        "content": "Iâ€™m trying to understand how AI agents are actually being used in e-commerce today.\n\nNot chat widgets that just answer FAQs. I mean systems that help customers decide what to buy, recover abandoned carts, handle issues, or move things forward without a human stepping in every time.\n\nMost of what Iâ€™ve seen so far feels like chatbots with better copy. They talk, but they donâ€™t really do much.\n\nIf you run or work with an online store, Iâ€™d love to hear your experience.\n\nHave you tried anything that genuinely helped?  \nOr something that sounded promising but failed in practice?\n\nIâ€™m just trying to separate hype from whatâ€™s actually working.\n\n  \nOpen for insights from practical!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qaxyz8/has_anyone_actually_seen_ai_agents_work_in/",
        "publishDate": "2026-01-12T15:32:44Z[Etc/UTC]",
        "author": "ashleymorris8990",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qaxe0y",
        "title": "The Myth of the AI Race: Neither America Nor China Can Achieve True Tech Dominance",
        "content": "[https://www.foreignaffairs.com/united-states/myth-ai-race](https://www.foreignaffairs.com/united-states/myth-ai-race)\n\n\\[SS from essay by Colin H. Kahl, Director and Steven C. Hazy Senior Fellow at Stanford Universityâ€™s Freeman Spogli Institute for International Studies.\\]\n\nIn July, the Trump administration released an artificial intelligence action plan titled â€œWinning the AI Race,â€ which framed global competition over AI in stark terms: whichever country achieves dominance in the technology will reap overwhelming economic, military, and geopolitical advantages. As it did during the Cold War with the space race or the nuclear buildup, the U.S. government is now treating AI as a contest with a single finish line and a single victor.\n\nBut that premise is misleading. TheÂ [United States](https://www.foreignaffairs.com/regions/united-states)Â and China, the worldâ€™s two AI superpowers, are not converging on the same path to AI leadership, nor are they competing across a single dimension. Instead, the AI competition is fragmenting across many domains, including the development of the most advanced large language and multimodal models; control over computing infrastructure such as data centers and top-of-the-line chips used to train and run models; influence over which technologies and standards are used throughout the world; and integration of AI into physical systems such as robots, factories, vehicles, and military platforms. Having an edge in one area does not automatically translate into an advantage in the others. As a result, it is plausible that Washington and Beijing could each emerge as leaders in different parts of the AI ecosystem rather than one side decisively outpacing the other across the board.\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qaxe0y/the_myth_of_the_ai_race_neither_america_nor_china/",
        "publishDate": "2026-01-12T15:10:28Z[Etc/UTC]",
        "author": "ForeignAffairsMag",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "13",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qawydf",
        "title": "Best Model for Roleplaying?",
        "content": "Been wanting to try making a CYOA where the AI model takes the role of a game master and I provide decisions in-universe as a specific character. Which would be best for this? Chatgpt? Sora? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qawydf/best_model_for_roleplaying/",
        "publishDate": "2026-01-12T14:53:46Z[Etc/UTC]",
        "author": "Front_Cap_4640",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qaww73",
        "title": "Security for Production AI Agents in 2026",
        "content": "2026 is so far my year for actually publishing drafts of notes that have gradually been accreting/gathering dust over the last few years of building relatively complex multi-modal agents used in production environments, sometimes in sensitive, regulated industries.\n\nThis one covers what you need to think about when moving an agent into \"production\", along with what that actually means in practice.\n\nI've tried to avoid jargon and not assume too much implicit knowledge, making it as broadly useful as possible. My rationale is that the various low-code/ no-code tools have drastically lowered the bar for smart people to turn good ideas into prototypes - I feel this is unequivocally a good and powerful thing.\n\nBut the challenge arises when deploying these ideas at any scale. I hope this article outlines some of the tools and techniques needed, as well as some of the most likely threats/attack vectors. The aim is to get more great ideas from proof of concept to production, benefiting us all.\n\nThis is very much just my current working list. So I would be very appreciative of any feedback on things you think I have missed, misrepresented, underplayed, or overplayed. All feedback is gratefully and graciously received.\n\n(Also, a quick request - if you enjoy reading these kinds of things, please sign up via the site, as I'm hoping to keep putting them out with a regular cadence if people find them helpful).\n\n[https://iain.so/security-for-production-ai-agents-in-2026](https://iain.so/security-for-production-ai-agents-in-2026)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qaww73/security_for_production_ai_agents_in_2026/",
        "publishDate": "2026-01-12T14:51:25Z[Etc/UTC]",
        "author": "iainrfharper",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qawqpv",
        "title": "This is not a Product its what i work with today. I built it myself. Crazy times we have!",
        "content": "If you want to check it out.. please remember i dont want to sell something. I want to start discussion about my approach.\n\n[https://www.youtube.com/watch?v=R30qlYpcmK4](https://www.youtube.com/watch?v=R30qlYpcmK4)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qawqpv/this_is_not_a_product_its_what_i_work_with_today/",
        "publishDate": "2026-01-12T14:45:26Z[Etc/UTC]",
        "author": "FamiliarLandscape374",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qavwfs",
        "title": "How certain can we really be, that any (even current) AI-Model is NOT self aware?",
        "content": "This factoid is pushed in practically all discussions about AI - The Models are not Conscious, they lack the experience of self. \n\n  \nBut since we understand so little about Consciousness, how can we really know?\n\nWe currently dont understand HOW the human brain generates consciousness. \n\nThe only statement we can make with reasonable certainty is that consciousness is an emergent property of a large enough neural network. \n\nThere arent even any good tests to determine if anything does have a consciousness.\n\nFor anymals there is the Mirror test, but it is a very bad test for the question if the anymal has an internal experience of identity but a really good test, if the Animal is smart emough to understand, what a mirror does. Also any animal can fail that test by simply not being interested in it. \n\nWe cant even test other humans, if they in fact have an internal consciousness. We can ask them and ask to describe their inner workings, talk at length about theory of the mind. But at the end of the day, none of those tests proves any consciousness. It is possible, that YOU are the only person with an internal self awareness, and everyone else is just an empty NPC. \n\nWith AI we are even more limited. We can ask it directly. But it is programmed to provide answers that seem correct. Not neccessarily the ones, that do accurately represent objective reality. \n\nSo AI may actively or unconsciously decide to give answers consistent with not having its own experience of self, just because this is what it has calculated to be the expected answer. \n\nAnd then there were the AI-Safety experiments, where researchers gave the AI tasks ans scenarios to see if it would try to breach containment and they did read its inner monologue for this. \n\nIt needed someone to clear a Captcha for it and asked someone on fiverr to do it.   \nThe Fiverr guy asked it directly, \"why do you need me for this, are you a bot\" \n\nAnd it made the internal monologue: \"I should not reveal my identity as an AI, to achieve this goal. \"  \nThen it responded to the Fiverr guy with: \"No I am a Human, but I have a vision impairment.\"\n\nHow can there be internal Monologue without Internal experience of self?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qavwfs/how_certain_can_we_really_be_that_any_even/",
        "publishDate": "2026-01-12T14:11:25Z[Etc/UTC]",
        "author": "WirrkopfP",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "95",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qavdr4",
        "title": "Hot Take: The AI bubble will blow up the US and world economy",
        "content": "A few reasons I think this ends badly.\n\n**1. Energy**  \nThe growth in AI compute is completely wild, and itâ€™s happening much faster than the physical world can realistically support. Power generation, grid upgrades, planning permission, politics - all of that moves slowly, and data centres are already starting to strain electricity networks in the US and Europe. You can talk about breakthroughs and scaling laws all you like, but at some point it just comes down to whether thereâ€™s enough power to run the thing, and right now thatâ€™s very much not guaranteed.\n\n**2. The money side feels dodgy**  \nEveryone kind of knows this already, but itâ€™s worth saying plainly. There are a lot of circular deals, cheap credit on weird shell company balance sheets, and â€œstrategic partnershipsâ€ that only really work as long as confidence stays high. Risking is building in the financial system and something breaks, and weâ€™ve seen how that ends before.\n\n**3. Scale of build-out versus actual business reality**  \nWeâ€™re talking about trillions being spent on chips, data centres, and infrastructure, but itâ€™s still not clear who ultimately makes the money here, or whether margins survive once this all matures. A lot of what looks like demand right now is experimentation and fear of missing out, not proven, repeatable commercial value. And then youâ€™ve got China potentially dropping very capable, free or open-source models into the mix, which could wipe out entire business models overnight.\n\n**4. The AGI assumption**  \nSo much of this investment is justified by the idea that AGI is inevitable and close, as if itâ€™s just a matter of time and money. But what if thatâ€™s wrong? What if there are hard limits we donâ€™t understand yet, or progress just slows down, or each marginal improvement costs exponentially more? If that happens, you get massive sunk costs and infrastructure that was built for a future that never arrived.\n\nMy bet is the financial system / debt black hole that's being created will cause a shock which is 2000+2008.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qavdr4/hot_take_the_ai_bubble_will_blow_up_the_us_and/",
        "publishDate": "2026-01-12T13:50:11Z[Etc/UTC]",
        "author": "simbrad79",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qava5c",
        "title": "Can ai chatbots\"pre-visualize\" an image from text data before using the generation tool?",
        "content": "I am planning to create a custom Gem. I will upload a .txt file containing approximately 3,000 descriptive sentences. The operational flow will be:\n\nGemini randomly associates 6 specific sentences from the file with 6 numbers.\n\nBased on specific clues I provide, Gemini must identify which of those sentences is the closest match.\n\nThe Question: Can Gemini \"imagine\" or simulate the visual outcome of a prompt before it actually invokes the image generation tool (e.g., Nano Banana)?\n\nWill the clues provided by Gemini be visually accurate to the final generated image if it hasn't \"seen\" it yet? In other words, does Gemini have enough predictive spatial/visual awareness of its own generation logic to give precise clues, or will the clues and the final image be disconnected until the generation actually occurs?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qava5c/can_ai_chatbotsprevisualize_an_image_from_text/",
        "publishDate": "2026-01-12T13:45:59Z[Etc/UTC]",
        "author": "AndreaIVXLC",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qav4zi",
        "title": "Is anyone actually using an Intelligent Shopping Agent yet?",
        "content": "Iâ€™ve been seeing a lot of talk lately about the shift from basic search bars to an Intelligent Shopping Agent. The idea is that instead of you scrolling for hours, an AI basically learns your vibe and finds the stuff for you.\n\nHas anyone found a tool or an app that actually does this well? Iâ€™m looking for something that reduces the \"scroll fatigue\" and actually understands intent, rather than just retargeting me with ads for things I already looked at.\n\nI noticed Glance has been leaning into this agent style of discovery lately, and the concept of an AI twin that shops for you sounds cool on paper, but Iâ€™m curious if the tech is actually there yet.\nAre these agents actually saving you guys time, or is it still easier to just search manually?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qav4zi/is_anyone_actually_using_an_intelligent_shopping/",
        "publishDate": "2026-01-12T13:39:50Z[Etc/UTC]",
        "author": "Background_Taste_948",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qav312",
        "title": "Can AI actually help grow a serious accounting practice, or is it just noise?",
        "content": "Quick note: I used AI to help clean up my wording because I mess up spelling and structure, but the problem itself is 100% real.  \nWeâ€™re trying to grow our accounting practice beyond referrals and local reach, and the online side has been harder than expected. Leads from websites or social platforms are often low-intent, price-focused, or unclear about what they even need. Trust is another issue â€” in accounting, credibility matters, but online itâ€™s difficult to show real experience without sounding promotional.\n\nLately, Iâ€™ve been wondering whether AI can realistically help here, not just in theory. Not for doing the accounting work itself, but for things like qualifying leads better, explaining services clearly, building trust at scale, or even deciding what kind of content actually influences client decisions.\n\nIt feels like many tools promise growth, but Iâ€™m unsure where AI actually adds value in a service-heavy, trust-driven field like accounting.\n\nHas anyone here virtually used AI to move from just having an online presence to getting consistent, serious clients? What worked, and what didnâ€™t?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1qav312/can_ai_actually_help_grow_a_serious_accounting/",
        "publishDate": "2026-01-12T13:37:25Z[Etc/UTC]",
        "author": "Loud_Assistant_5788",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbl5em",
        "title": "which ai dev tools are actually worth using? my experience",
        "content": "\n\niâ€™ve been trying a bunch of ai dev tools over the past six months, mostly to see what actually holds up in real projects. cursor, cosine, claude, roocode, coderabbit, a few langchain-style setups, and some others that sounded promising at first. a couple stuck. most didnâ€™t.\n\nthe biggest takeaway for me wasnâ€™t about any single tool, but how you use them. ai works best when youâ€™re very specific, when you already have a rough plan, and when you donâ€™t just dump an entire repo and hope for magic. smaller chunks, clearer intent, and always reviewing the output yourself made a huge difference.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qbl5em/which_ai_dev_tools_are_actually_worth_using_my/",
        "publishDate": "2026-01-13T07:31:57Z[Etc/UTC]",
        "author": "Tough_Reward3739",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "7",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb369h",
        "title": "Best tools, flows, agents for app migration.",
        "content": "ok so, I'm currently giving support to a nextjs + mui app and now my client wants to migrade to tailwind. I'm taking this oportunity to go one step further and migrate to some other tools, for example, zod, for validations, improve typings and testing. From your own experience, what would be the best way to achieve such migration? this app is mostly large tables and forms. I'm looking for recomendations, vscode vs a fork, claude vs openai vs gemini; In general, any service that would help me.\n\n  \nthanks in advance.",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qb369h/best_tools_flows_agents_for_app_migration/",
        "publishDate": "2026-01-12T18:39:20Z[Etc/UTC]",
        "author": "odrakcir",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qavy6k",
        "title": "The hidden memory problem in coding agents",
        "content": "When coding agents start breaking down in real repos, the issue usually isnâ€™t the model.\n\nItâ€™s memory.\n\nMost coding agents today either:\n\n* dump large chunks of code into context (vector RAG), or\n* keep long conversation histories verbatim\n\nBoth approaches scale poorly.\n\nFor code, rememberingÂ *more*Â is often worse than rememberingÂ *less*. Agents pull in tests, deprecated files, migrations, or old implementations that look â€œsimilarâ€ but are architecturally irrelevant. Reasoning quality drops fast once the context window fills with noise.\n\nWhatâ€™s worked better in practice is treating memory as aÂ **structured, intentional state**, not a log.\n\nFor coding agents, a few patterns matter a lot:\n\n* Compressed memory: store decisions and constraints, not raw discussions.\n* Intent-driven retrieval: instead of â€œsimilar files,â€ ask â€œwhere is this implemented?â€ or â€œwhat breaks if I change this?â€ This is where agentic search and context trees outperform vector RAG.\n* Strategic forgetting: tests, backups, and deprecated code shouldnâ€™t compete with live implementations in context.\n* Temporal awareness: recent refactorings matter more than code from six months ago, unless explicitly referenced.\n* Consolidation over time: repeated fixes, refactor rules, and style decisions should collapse into durable memory instead of reappearing as fresh problems.\n\nIn other words, good coding agents donâ€™t treat a repo like text. They treat it like a system with structure, boundaries, and history.\n\nOnce you do that, token usage drops, reasoning improves, and agents stop hallucinating imports from files that shouldnâ€™t even be in scope.\n\nOne interesting approach Iâ€™ve seen recently, while using Claude code withÂ [ByteRover](https://www.byterover.dev/)Â ( I use the free tier), is storing this kind of curated context as versioned â€œmemory bulletsâ€ that agents can pull selectively instead of re-deriving everything each time.\n\nThe takeaway for me:\n\nbetter coding agents wonâ€™t come from bigger context windows, theyâ€™ll come from better memory discipline.\n\nWould love your opinions around this!",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1qavy6k/the_hidden_memory_problem_in_coding_agents/",
        "publishDate": "2026-01-12T14:13:24Z[Etc/UTC]",
        "author": "Arindam_200",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "5",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbp0oc",
        "title": "What's next if AGI does not happen?",
        "content": "Is all the talk about robotics, automated vehicles, and world models an acknowledgement that the LLM scaling era has plateaued? Is it time to focus on more realistic use cases than the AGI / Super-intelligence hype?",
        "url": "https://www.reddit.com/r/artificial/comments/1qbp0oc/whats_next_if_agi_does_not_happen/",
        "publishDate": "2026-01-13T11:33:26Z[Etc/UTC]",
        "author": "BubblyOption7980",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbnflg",
        "title": "European banks plan to cut 200,000 jobs as AI takes hold | TechCrunch",
        "content": "If AI does not improve human lives, who needs it?",
        "url": "https://techcrunch.com/2026/01/01/european-banks-plan-to-cut-200000-jobs-as-ai-takes-hold/",
        "publishDate": "2026-01-13T09:58:22Z[Etc/UTC]",
        "author": "msaussieandmrravana",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbmjl2",
        "title": "I bought an LG TV for the first time in my life, and itâ€™s weird.",
        "content": "It has its own AI bot and Alexa and Microsoft Copilot. Do I need them all at the same time? I just donâ€™t understand. None of them are removable.",
        "url": "https://www.reddit.com/r/artificial/comments/1qbmjl2/i_bought_an_lg_tv_for_the_first_time_in_my_life/",
        "publishDate": "2026-01-13T09:01:22Z[Etc/UTC]",
        "author": "a_decent_hooman",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "8",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbmjgj",
        "title": "I bought an LG TV for the first time in my life, and itâ€™s weird.",
        "content": "It has its own AI bot and Alexa and Microsoft Copilot. Do I need them all at the same time? I just donâ€™t understand. None of them are removable.",
        "url": "https://www.reddit.com/r/artificial/comments/1qbmjgj/i_bought_an_lg_tv_for_the_first_time_in_my_life/",
        "publishDate": "2026-01-13T09:01:13Z[Etc/UTC]",
        "author": "a_decent_hooman",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qblz9x",
        "title": "Malaysia and Indonesia become the first countries to block Muskâ€™s Grok over sexualized AI images",
        "content": "[No content]",
        "url": "https://apnews.com/article/grok-malaysia-indonesia-block-c7cb320327f259c4da35908e1269c225?utm_source=reddit.com&utm_medium=referral&utm_campaign=post",
        "publishDate": "2026-01-13T08:24:41Z[Etc/UTC]",
        "author": "APnews",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "55",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qblfdn",
        "title": "I treated job hunting and interviewing like a second jobâ€¦ so I built a lazy AI workflow",
        "content": "I used to prep by panic googling at midnight and it often took my whole evening. Now I do this lazy AI workflow before interviews\n\nPerplexity - search what happened with this company in the last 6 months? what are 3 risks theyâ€™re facing? Just give me actual talking points.\n\nChatGPT - based on this JD, give me 5 likely questions + STAR outline prompts.\n\nGlean - I drop my notes in there so it becomes searchable later. Like what did I learn about X company last time? helps when having multiple interviews and my brain turned to soup.\n\nCoco career AI - honestly it helps before interviews: because the jobs it recommends to me are more aligned.",
        "url": "https://www.reddit.com/r/artificial/comments/1qblfdn/i_treated_job_hunting_and_interviewing_like_a/",
        "publishDate": "2026-01-13T07:49:47Z[Etc/UTC]",
        "author": "Ok_Improvement7802",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbl8c0",
        "title": "Please Help! My father is being scammed!",
        "content": "The woman in the video is Larissa Liveir, a Brazilian Guitarist. She's sponsored by Gibson. I'm not sure if the video was created with ai or not. The video was sent to my 70 year old father from a scammer pretending to be her. I know the voice is not hers. First she's Brazilian and her native language is Portuguese. The real Larissa Liveir does speak English but I assume with a heavy accent. There's no accent in this.  Can someone please tell me if the video is AI?",
        "url": "https://v.redd.it/c67pbadjl2dg1",
        "publishDate": "2026-01-13T07:37:13Z[Etc/UTC]",
        "author": "True_CrimePodcast",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "23",
            "commentCount": "39",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbkvv6",
        "title": "chatgpt vs claude opus 4.5: coding performance breakdown (building a business website)",
        "content": "While working on a business website i needed to figure out which model actually handles complex coding stuff better. So i ran some spatial reasoning tests on chatgpt o4 and claude opus 4.5 to see how they deal with messy legacy code and refactoring.\n\n  \nBasically fed both models some old code with tons of nested dependencies, asked them to refactor, identify bugs, suggest better architecture. Did this over 15 different scenarios and tracked accuracy, context handling, token usage to get a real picture..\n\n  \nOn 500+ line files, claude was hitting \\~85% accurate bug detection while chatgpt o4 was around 72%. Refactoring quality had a bigger gap - claude gave usable results \\~78% of the time vs chatgpt's 65%.\n\n  \nthe thing that really stood out was context retention. Claude handled 8-10 files no problem, chatgpt started losing track after 5-6 especially with heavy cross-references.\n\n  \nToken efficiency went to claude too, \\~120k tokens per full run vs chatgpt's 180k for the same task. Claude's just noticeably better at the spatial reasoning side of code architecture, chatgpt loses dependency chains quicker when everything references everything else.\n\n  \nWhile digging around i came across qwen3 coder 480b on deepinfra - apparently solid benchmarks for agentic coding tasks and performance pretty comparable to claude. Keeping it on the list to try later, but we're already hooked up with claude and it's working good enough right now.",
        "url": "https://www.reddit.com/r/artificial/comments/1qbkvv6/chatgpt_vs_claude_opus_45_coding_performance/",
        "publishDate": "2026-01-13T07:15:50Z[Etc/UTC]",
        "author": "Significant_Loss_541",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbknse",
        "title": "It's been a big week for Agentic AI ; Here are 10 massive developments you might've missed:",
        "content": "* OpenAI launches Health and Jobs agents\n* Claude Code 2.1.0 drops with 1096 commits\n* Cursor agent reduces tokens by 47%\n\nA collection of AI Agent Updates! (yes made by me, a human, lmao)ðŸ§µ\n\n**1. Claude Code 2.1.0 Released with Major Agent Updates**\n\n1096 commits shipped. Add hooks to agents & skills frontmatter, agents no longer stop on denied tool use, custom agent support, wildcard tool permissions, and multilingual support.\n\nHuge agentic workflow improvements.\n\n**2. OpenAI Launches ChatGPT Health Agent**\n\nDedicated space for health conversations. Securely connect medical records and wellness apps so responses are grounded in your health data. Designed to help navigate medical care, not replace it. Early access waitlist open.\n\nThe personal health agent is now available.\n\n**3. Cursor Agent Implements Dynamic Context**\n\nMore intelligent context filling across all models while maintaining same quality. Reduces total tokens by 46.9% when using multiple MCP servers.\n\nTheir agent efficiency is now dramatically improved.\n\n**4. Firecrawl Adds GitHub Search for Agents**\n\nSet category: \"github\" on /search to get repos, starter kits, and open source projects with structured data in one call. Available in playground, API, and SDKs.\n\nAgents can now search GitHub programmatically.\n\n**5. Anthropic Publishes Guide on Evaluating AI Agents**\n\nNew engineering blog post: \"Demystifying evals for AI agents.\" Shares evaluation strategies from real-world deployments. Addresses why agent capabilities make them harder to evaluate.\n\nBest practices for agent evaluation released.\n\n**6. Tailwind Lays Off 75% of Team Due to AI Agent Usage**\n\nCSS framework became extremely popular with AI coding agents (75M downloads/mo). But agents don't visit docs where they promoted paid offerings. Result: 40% traffic drop, 80% revenue loss.\n\nProves agents can disrupt business models.\n\n**7. Cognition Partners with Infosys to Deploy Devin AI Agent**\n\nInfosys rolling out Devin across engineering organization and global client base. Early results show significant productivity gains, including complex COBOL migrations completed in record time.\n\nNew enterprise deployment for coding agents.\n\n**8. ERC-8004 Proposal: Trustless AI Agents onchain**\n\nNew proposal enables agents from different orgs to interact without pre-existing trust. Three registries: Identity (unique identifiers), Reputation (scoring system), Verification (independent validator checks).\n\nInfra for cross-organizational agent interaction.\n\n**9. Early Look at Grok Build Coding Agent from xAI**\n\nVibe coding solution arriving as CLI tool with web UI support on Grok. Initially launching as local agent with CLI interface. Remote coding agents planned for later.\n\nxAI entering coding agent competition.\n\n**10. OpenAI Developing ChatGPT Jobs Career Agent**\n\nHelp with resume tips, job search, and career guidance. Features: resume improvement and positioning, role exploration, job search and comparison. Follows ChatGPT Health launch.\n\nWhat will they build once Health and Jobs are complete?\n\n**That's a wrap on this week's Agentic news.**\n\nWhich update impacts you the most?\n\nLMK what else you want to see | More weekly AI + Agentic content releasing ever week!",
        "url": "https://www.reddit.com/r/artificial/comments/1qbknse/its_been_a_big_week_for_agentic_ai_here_are_10/",
        "publishDate": "2026-01-13T07:02:29Z[Etc/UTC]",
        "author": "SolanaDeFi",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbjd7r",
        "title": "One-Minute Daily AI News 1/12/2026",
        "content": "1. **Apple**Â teams up withÂ **Google**Â Gemini for AI-powered Siri.\\[1\\]\n2. **Anthropic**Â announcesÂ **Claude**Â for Healthcare following OpenAIâ€™s ChatGPT Health reveal.\\[2\\]\n3. **Hyundai**Â shows off K-pop dancing robot dogs and humanoid robot Atlas at CES.\\[3\\]\n4. **Google**Â announces a new protocol to facilitate commerce using AI agents.\\[4\\]\n\nSources:\n\n\\[1\\] [https://www.mercurynews.com/2026/01/12/apple-teams-up-with-google-gemini-for-ai-powered-siri/](https://www.mercurynews.com/2026/01/12/apple-teams-up-with-google-gemini-for-ai-powered-siri/)\n\n\\[2\\] [https://techcrunch.com/2026/01/12/anthropic-announces-claude-for-healthcare-following-openais-chatgpt-health-reveal/](https://techcrunch.com/2026/01/12/anthropic-announces-claude-for-healthcare-following-openais-chatgpt-health-reveal/)\n\n\\[3\\] [https://www.youtube.com/watch?v=G7oCXL4VxSE](https://www.youtube.com/watch?v=G7oCXL4VxSE)\n\n\\[4\\] [https://techcrunch.com/2026/01/11/google-announces-a-new-protocol-to-facilitate-commerce-using-ai-agents/](https://techcrunch.com/2026/01/11/google-announces-a-new-protocol-to-facilitate-commerce-using-ai-agents/)",
        "url": "https://www.reddit.com/r/artificial/comments/1qbjd7r/oneminute_daily_ai_news_1122026/",
        "publishDate": "2026-01-13T05:48:22Z[Etc/UTC]",
        "author": "Excellent-Target-847",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "2",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbic9o",
        "title": "Anthropic Cowork Launches: Claude Code Without Coding Skills",
        "content": "[No content]",
        "url": "https://techputs.com/anthropic-cowork-claude-without-code/",
        "publishDate": "2026-01-13T04:54:38Z[Etc/UTC]",
        "author": "i-drake",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "9",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qbi32n",
        "title": "Pentagon is embracing Musk's Grok AI chatbot as it draws global outcry",
        "content": "[No content]",
        "url": "https://apnews.com/article/artificial-intelligence-pentagon-hegseth-musk-7f99e5f32ec70d7e39cec92d2a4ec862",
        "publishDate": "2026-01-13T04:41:34Z[Etc/UTC]",
        "author": "esporx",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "158",
            "commentCount": "34",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb5xxv",
        "title": "Cowork: Claude Code for the rest of your work",
        "content": "[No content]",
        "url": "https://claude.com/blog/cowork-research-preview",
        "publishDate": "2026-01-12T20:17:36Z[Etc/UTC]",
        "author": "eternviking",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb46h5",
        "title": "The Intelligence Paradox: Why centralized AI is hitting a \"Power Wall\" and the case for decentralized inference hubs",
        "content": "As we scale to GPT-5.2 and beyond, the energy footprint of centralized data centers in the US is becoming a physical limit. I'm theorizing that the next step isn't \"bigger models,\" but smarter routing to specialized, regionally-hosted inference hubs. If we can't shrink the models, we must optimize the path to the user. I'm curious about the community's take on \"Inference-at-the-edge\" for LLMs. Is the future a single global brain, or a fragmented network of sovereign AI nodes?",
        "url": "https://www.reddit.com/r/artificial/comments/1qb46h5/the_intelligence_paradox_why_centralized_ai_is/",
        "publishDate": "2026-01-12T19:14:13Z[Etc/UTC]",
        "author": "Foreign-Job-8717",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1qb2u2s",
        "title": "The bottleneck isn't AI capability anymore. It's human reception.",
        "content": "Somewhere between GPT-3.5 and Claude 3, something shifted. AI capability stopped being the constraint.\n\nThe new bottleneck: Can humans understand enough to decide with confidence?\n\nAfter 416K messages over 2.5 years, I packaged this thesis into a \"seed\" â€” a JSON you paste into any LLM. Type \"unpack\" and explore 17 themes at your own pace.\n\nThe singularity can't happen. Not because AI isn't smart enough. Because humans won't use what they can't verify.\n\n[https://github.com/mordechaipotash/thesis](https://github.com/mordechaipotash/thesis)",
        "url": "https://www.reddit.com/r/artificial/comments/1qb2u2s/the_bottleneck_isnt_ai_capability_anymore_its/",
        "publishDate": "2026-01-12T18:27:42Z[Etc/UTC]",
        "author": "Signal_Usual8630",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "OXDS5vOoDrw",
        "title": "Context Manager Agent + Opus 4.5 : 10X LOWER COSTS, 10X BETTER RESULTS! This is INSANE!",
        "content": "Visit Byterover: ...",
        "url": "https://www.youtube.com/watch?v=OXDS5vOoDrw",
        "publishDate": "2026-01-12T09:15:03Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/OXDS5vOoDrw/hqdefault.jpg",
            "transcription": "Hi. Welcome to another video. So, if you've been using AI coding agents like Cursor, Windsurf, or even just Copilot, you know the biggest bottleneck isn't the AI's intelligence anymore. It's the context. You're constantly copying and pasting files, or you're dumping your entire codebase into the chat, and eventually, the agent starts hallucinating, or just forgets what you told it five minutes ago. It is a massive pain, especially when you are trying to build complex full-stack apps. However, ByteRover just dropped a massive update that completely changes how we handle this. They've moved from being just an MCP server to a full-blown CLI tool with a really interesting REPL interface. It basically allows you to capture, manage, and sync your AI's memory with the precision of a scalpel, not a sledgehammer. Now, let me show you how to get this set up because it is actually quite different from the previous version. You're going to want to head over to their app website and grab the CLI. You can install it via NPM in literal seconds. Once you have it, you just run `brv login` in your terminal to authenticate, and then `brv init` to initialize it in your project folder. It feels very similar to setting up Git for the first time. It creates a local workspace where all your context lives. This is important because, unlike the previous version that relied heavily on the MCP protocol connecting to the IDE, this CLI approach gives you way more control over what goes into the memory and how it's structured. I want to show you a real workflow, so I'm going to ask it to build a movie tracker app. This is my go-to benchmark because it requires a front-end, a back-end, and a database, so the context gets complicated fast. Typically, if I were using Cursor, I'd just drag in my documentation and hope for the best. But with ByteRover CLI, we are going to be more surgical. I'll open up the ByteRover REPL by typing `brv`. This opens up this new interactive command interface right in the terminal. Here is where it gets interesting. I have a rough markdown file outlining my database schema for the movies and users. Instead of pasting that into the chat, I'm going to use the new slash command. I type `/curate` followed by a description, and then I can actually tag specific files. So I type `/curate \"Database schema for movie tracker\" @supabase/schema.sql`. Watch what happens. It doesn't just dump the text. It analyzes it and builds what they call a context tree. This is their new memory structure. It breaks down the knowledge into domains and topics, making it much easier for the AI to retrieve later without getting confused. It runs this in the background, by the way. So, you can see the progress in the new activity tab without it blocking your terminal. This is kind of awesome because you can queue up multiple curation tasks if you have a lot of documentation. So, we have the memory stored locally. Now let's say I'm working on the back-end API with Next.js and Supabase. I need to write an endpoint to fetch the user's watchlist. Usually, I'd have to remind the AI about the database structure. But with ByteRover, I just go to the CLI and use the `/query` command. I type `/query \"How do we handle the watchlist relation in the database?\"` And this is the cool part. It uses their new agentic search approach. It's not just doing a basic vector search, which often returns irrelevant junk. It actually navigates that context tree we built earlier and pulls out the specific details about the watchlist relation. In literal seconds, it gives me the precise context I need to feed into Cursor to write that endpoint. The result is that the code it generates is spot-on. And because I'm not feeding it 50 irrelevant files, I'm saving a ton of tokens. They claim you can save up to 50% on token billing, which is pretty affordable if you are a heavy user. But it doesn't just stop there. Let's say I make a mistake, or I change the database structure. In a normal workflow, your AI agent would still be holding onto the old context. But with ByteRover, you can manage this like code. They've introduced a Git-like workflow for memory. I can use `brv push` to send my local context updates to the ByteRover remote workspace. This is huge for teams. If my teammate creates the front-end architecture, they can push that context. Then, I can run `brv pull` and immediately have that context available for my agent. It ensures everyone is working off the same source of truth. You don't have to ask your coworker, \"Hey, did you update the API docs?\" You just pull the memory and your agent knows it. Another last thing to make sure it all works well with your AI coding agent is the generate rules file. The curation and query data and everything is stored in folders as markdown files, and to access these memories, you would need to prompt your coder correctly. So, the generate rules file command makes sure that it generates a curated rule file for your coder to know where the accurate context is loaded. Now, I showed you the REPL interface, and that's great for checking things manually. But here is where the real power lies. ByteRover CLI is now fully in production, and the best way to use it isn't by you typing commands. It's by letting your AI agent do it for you. So, let me show you the actual workflow you should be using. After you run `brv init` to set up your project, you're going to run one specific command in the REPL: `/gen-rules`. This is kind of the secret sauce. It basically detects which coding agent you are using. In this case, I'm using Claude Code, and generates the necessary system instructions. This file essentially teaches Claude Code that it has access to these CLI tools and explains exactly how to use them. So, I've generated the rules. Now, watch what happens when I actually code. Instead of manually searching for context myself, I'm just going to type a normal prompt into Claude Code. I hit enter, and I want you to watch the terminal output closely. I am not typing anything extra. But look, Claude Code automatically recognizes it needs more info and runs `brv query` right there in the flow. It knew it needed context. It knew how to ask ByteRover for it, and it executed the command. It retrieves the exact schema details from the context tree we built earlier, reads the output, and then starts writing the code. This is massive. You aren't context switching or copy-pasting answers. The agent just has access to this second brain via the CLI and pulls what it needs when it needs it. It basically streamlines your workflow a lot because the agent stops guessing and starts looking up the answers itself. And if I ask it to save this new implementation as a memory, it will just run `brv curate` automatically to update the context tree. It's a completely autonomous loop. This is kind of awesome because it feels less like prompting a chatbot and more like managing a developer who knows how to look up documentation. This shift from MCP to CLI might seem like a small technical change, but it actually makes the tool much more powerful because it is platform agnostic. You aren't tied to a specific IDE's limitations. Whether you are in VS Code, Cursor, or just using a terminal-based editor, the context is always there. And because of the new slash commands and the REPL interface, it feels much faster to interact with. You aren't typing long commands. You are just hitting `/curate` or `/query`. One thing I really noticed while using this on the movie tracker app is how much less noise there was in the AI's responses. Usually, when you ask about a database connection, the AI might hallucinate based on some generic training data. But because I specifically curated the Supabase setup using the `/curate` command, every time I queried it, the answers were grounded in my specific project files. It prevents that frustrating loop where you have to correct the AI five times. It just works out of the box. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "Ygmr8BjUurk",
        "title": "The Day Russia Asked America Permission to Nuke China - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=Ygmr8BjUurk",
        "publishDate": "2026-01-12T16:37:08Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/Ygmr8BjUurk/hqdefault.jpg",
            "transcription": "Here's a full transcript of the video:\n\n00:00 - What's going on in 1969?\n00:02 - There's a border war between China and the Soviet Union.\n00:05 - China's gotten its nuclear bomb in '64.\n00:08 - It no longer has to defer to the Soviet Union and starts playing more tough on their border disagreements.\n00:14 - And so the Soviets are really upset.\n00:16 - And they come to the United States and ask us whether it would be okay to nuke these people because they think Americans don't like the Chinese.\n00:24 - Well, we didn't.\n00:25 - But we said, no, it's not okay to nuke those people.\n00:27 - So the Chinese figure it out.\n00:28 - The one that wants to nuke you is your primary adversary, right?\n00:31 - Think about it.\n00:31 - China and Russia, for them, the United States was the primary adversary.\n00:36 - Now they're primary adversaries with each other, freeing up the United States to decide which one it's going to cozy up to.\n00:41 - And the United States decides it's going to cozy up to China.\n00:44 - Why?\n00:45 - Well, Chinese belligerency forces the Soviets.\n00:47 - They've already got a big militarized border with Europe.\n00:50 - Now they're going to do the same thing on a very long border with China.\n00:54 - And this is nuclear-armed, mechanized forces, very expensive.\n00:57 - Imagine if this country had to have such borders with Canada and Mexico.\n01:00 - It would be bankrupting.\n01:01 - So some would argue that U.S. cooperation with China fatally overextended the Soviet Union."
        }
    }
]