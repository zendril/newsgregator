# News Summary - 2025-05-25 08:16:44

## AI & Development Briefing Overview

This briefing covers recent developments in AI, focusing on new models and tools that enhance conversational AI and coding capabilities. Key themes include the emergence of sophisticated no-code platforms for building interactive chatbots, advancements in AI-powered coding agents integrated directly into development workflows, and ongoing challenges with API reliability and pricing for cutting-edge AI models. Several platforms are offering solutions to these challenges, along with free credits for users to experiment with these new technologies.

---

## Briefing Details

### Unable to retrieve content from r/ChatGPTCoding

*   **Source:** ChatGPTCoding (Reddit)
*   **Source Url:** [https://www.reddit.com/r/ChatGPTCoding/new](https://www.reddit.com/r/ChatGPTCoding/new)
*   **Key Points:**
    *   Content could not be retrieved from the specified Reddit subreddit.
    *   The error message indicates an API access issue: "403 Blocked."

### Gemini 2.5 Converse Agents: This FULLY FREE Way to create CONVERSATIONAL AI Agents is AMAZING!

*   **Source:** AI Code King YouTube Channel
*   **Source Url:** [https://www.youtube.com/watch?v=C3rOKcp9yzY](https://www.youtube.com/watch?v=C3rOKcp9yzY)
*   **Transcription:**
    ```
    [ 0m0s428ms - 0m7s758ms ] Hi, welcome to another video.
    [ 0m8s308ms - 0m16s68ms ] So, Vector Shift has just rolled out something really exciting, a new AI workflow mode called Conversational AI Workflows.
    [ 0m16s68ms - 0m20s228ms ] Let me tell you, it's a game changer for building truly custom and interactive chatbots.
    [ 0m20s728ms - 0m26s648ms ] It's pretty awesome to see them add this level of control.
    [ 0m27s688ms - 0m32s388ms ] First of all, if you don't know about Vector Shift, it's an AI automation platform that allows you to make workflows
    [ 0m32s388ms - 0m43s788ms ] where you can connect any data source to AI, create custom workflows, and build the AI agents you need.
    [ 0m44s338ms - 0m49s868ms ] You could already create custom workflows and I have a ton of videos on that, which you can check out.
    [ 0m50s568ms - 0m54s558ms ] But now, they have launched Conversational AI Workflows.
    [ 0m54s908ms - 1m5s828ms ] Now, you're probably wondering how this is different from the standard pipelines. Well, the standard way is usually input to output, one straight shot.
    [ 1m6s508ms - 1m14s358ms ] But with these new conversational nodes, you get to define exactly what happens at every single stage of the conversation.
    [ 1m14s948ms - 1m21s348ms ] Think about it, you can guide the user step-by-step, which is super great for so many use cases.
    [ 1m21s878ms - 1m25s788ms ] Let's dive right into the no-code builder and see how this works.
    [ 1m26s318ms - 1m32s838ms ] When you go to create a new pipeline, you'll see an option for conversational.
    [ 1m33s278ms - 1m38s998ms ] Clicking that, you'll notice a start flag pops up on your canvas. That's where your chat begins.
    [ 1m39s648ms - 1m45s368ms ] And look, there's a whole new conversational tab on the left with new nodes.
    [ 1m45s788ms - 1m59s288ms ] You've got Talk nodes and Listen nodes. Talk nodes are for the bot to send stuff, like a message node for text, or you can send images, cards, or carousels.
    [ 1m59s598ms - 2m10s388ms ] Listen nodes are for when the bot needs to get input, like the Capture Response node to grab what the user types, or you can even add buttons.
    [ 2m10s388ms - 2m17s418ms ] So, let's build a simple lead collection chatbot to really see this in action, just like they showed.
    [ 2m18s318ms - 2m29s878ms ] First up, from the start flag, we'll drag in a message node from the talk nodes. Let's make it ask, "What is your name?"
    [ 2m30s128ms - 2m38s368ms ] Then, we need to wait for the user to actually type their name, right? So, we connect a Capture Response node, which is a listen node, to our message.
    [ 2m38s368ms - 2m40s798ms ] Next, we'll add another message node and ask, "What is your email?"
    [ 2m40s798ms - 2m54s258ms ] And you guessed it, another Capture Response node connected to that to get the email.
    [ 2m54s258ms - 3m0s118ms ] What's super cool is that when you run this, you can see the chatbot actually waits at each capture step.
    [ 3m0s118ms - 3m5s188ms ] It doesn't just rush through.
    [ 3m5s188ms - 3m19s958ms ] It'll ask, "What is your name?" Wait for your input, then, "What is your email?" And wait again. This gives you that fine-grained control. Okay, so we've got the name and email.
    [ 3m20s588ms - 3m25s788ms ] Let's make this even more useful. Say we want to save these leads to a Google Sheet.
    [ 3m25s788ms - 3m36s588ms ] To do that, we can just drag in a Google Sheets node. You can configure it to "Add New Row." You'll pick your spreadsheet file and it'll show you the columns.
    [ 3m37s208ms - 3m57s328ms ] Now, here's the magic. The first capture node for the name might be called something like Capture Zero in its output. You map that to your name column in Google Sheets. The second capture for email, say Capture One, maps to your email column.
    [ 3m57s718ms - 4m12s8ms ] Now, when the user provides their name and email, after both are captured, the workflow will automatically add a new row to your Google Sheet with that info. That is super great as well. But wait, there's more.
    [ 4m12s8ms - 4m20s88ms ] What if after collecting the lead info, you want the bot to be a helpful AI assistant?
    [ 4m20s88ms - 4m35s38ms ] Let's add another message node after the Google Sheet step, saying something like, "Thanks, how can I help you today?" Then, a Capture Response node to get the user's question.
    [ 4m35s38ms - 4m59s278ms ] Now, for the AI part, we can build a simple RAG or Retrieval Augmented Generation setup. Drag in a Knowledge Base node. You can point this to a website like the Vector Shift URL to scrape it for context.
    [ 4m59s278ms - 5m11s688ms ] Connect the user's question from that Capture node to this Knowledge Base. Then, drag in an LLM node like OpenAI. In the prompt, you tell it to answer the question based on the provided context. The question will come from that Capture node and the context will come from your Knowledge Base Reader output.
    [ 5m12s728ms - 5m32s428ms ] Finally, take the response from the LLM and send it back to the user with another message node. This is where it gets really powerful. You can have deterministic steps for lead collection and then seamlessly transition into an AI powered Q&A.
    [ 5m32s428ms - 5m36s98ms ] And you know what else is super cool? It's looping.
    [ 5m36s98ms - 6m2s578ms ] So, after the bot answers a question, you probably want the user to be able to ask another one. Just drag the connection from your last message node, the LLM's answer, and loop it back to the "How can I help you today?" message node. Vector Shift even highlights the loop for you. They've also added a neat little feature for these loops. Cyclical input.
    [ 6m2s578ms - 6m10s388ms ] This means the first time it asks, "How can I help?" But on subsequent loops, it can say something different like, "Do you have any additional questions?"
    [ 6m10s898ms - 6m17s308ms ] This makes the conversation flow much more naturally. You can see it in action.
    [ 6m17s308ms - 6m34s538ms ] Ask one question, get an answer, then it asks if you have more questions. Ask another and it does the same. It's pretty great. All right. So you've built this amazing conversational AI.
    [ 6m34s538ms - 6m41s768ms ] How do you deploy it? It's actually the same straightforward process as other chatbots in Vector Shift. Just hit "Deploy Changes."
    [ 6m42s378ms - 6m45s388ms ] Go to Export and select Chatbot.
    [ 6m45s388ms - 7m0s368ms ] Give your chatbot a name. There's even an additional field for these conversational chatbots called Message Delay, which lets you set the time you want between each message from the bot.
    [ 7m0s368ms - 7m5s878ms ] Maybe half a second or so. Then just export it.
    [ 7m6s8ms - 7m15s478ms ] You can embed it right into your website using a script or iFrame, or just use the Chat GPT style interface they provide to test it out.
    [ 7m15s478ms - 7m29s668ms ] So, that's the new conversational AI workflows in Vector Shift. This is super exciting for anyone who wants to build more guided, interactive, and intelligent chatbots.
    [ 7m29s668ms - 7m57s288ms ] Whether it's for advanced lead generation, step-by-step customer support, or any process where you need to control the conversation flow precisely, this is a massive upgrade. The ability to define exactly what happens at each stage, collect information, integrate with tools like Google Sheets, all with looping capabilities is just fantastic. Overall, it's pretty cool.
    [ 7m57s668ms - 8m2s418ms ] Anyway, share your thoughts below and subscribe to the channel.
    [ 8m2s418ms - 8m6s148ms ] You can also donate via Super Thanks option or join the channel as well and get some perks.
    [ 8m6s148ms - 8m7s578ms ] I'll see you in the next video. Bye.
    [ 8m7s578ms - 8m13s928ms ] I think you missed this: Hi, welcome to another video. So, Vector Shift has just rolled out something really exciting, a new AI workflow mode called Conversational AI Workflows. Let me tell you, it's a game changer for building truly custom and interactive chatbots. It's pretty awesome to see them add this level of control. First of all, if you don't know about Vector Shift, it's an AI automation platform that allows you to make workflows where you can connect any data source to AI, create custom workflows, and build the AI agents you need. You could already create custom workflows and I have a ton of videos on that, which you can check out. But now, they have launched Conversational AI Workflows. Now, you're probably wondering how this is different from the standard pipelines. Well, the standard way is usually input to output, one straight shot. But with these new conversational nodes, you get to define exactly what happens at every single stage of the conversation. Think about it, you can guide the user step-by-step, which is super great for so many use cases. Let's dive right into the no-code builder and see how this works. When you go to create a new pipeline, you'll see an option for conversational. Clicking that, you'll notice a start flag pops up on your canvas. That's where your chat begins. And look, there's a whole new conversational tab on the left with new nodes. You've got Talk nodes and Listen nodes. Talk nodes are for the bot to send stuff, like a message node for text, or you can send images, cards, or carousels. Listen nodes are for when the bot needs to get input, like the Capture Response node to grab what the user types, or you can even add buttons. So, let's build a simple lead collection chatbot to really see this in action, just like they showed. First up, from the start flag, we'll drag in a message node from the talk nodes. Let's make it ask, "What is your name?" Then, we need to wait for the user to actually type their name, right? So, we connect a Capture Response node, which is a listen node, to our message. Next, we'll add another message node and ask, "What is your email?" And you guessed it, another Capture Response node connected to that to get the email. What's super cool is that when you run this, you can see the chatbot actually waits at each capture step. It doesn't just rush through. It'll ask, "What is your name?" Wait for your input, then, "What is your email?" And wait again. This gives you that fine-grained control. Okay, so we've got the name and email. Let's make this even more useful. Say we want to save these leads to a Google Sheet. To do that, we can just drag in a Google Sheets node. You can configure it to "Add New Row." You'll pick your spreadsheet file and it'll show you the columns. Now, here's the magic. The first capture node for the name might be called something like Capture Zero in its output. You map that to your name column in Google Sheets. The second capture for email, say Capture One, maps to your email column. Now, when the user provides their name and email, after both are captured, the workflow will automatically add a new row to your Google Sheet with that info. That is super great as well. But wait, there's more. What if after collecting the lead info, you want the bot to be a helpful AI assistant? Let's add another message node after the Google Sheet step, saying something like, "Thanks, how can I help you today?" Then, a Capture Response node to get the user's question. Now, for the AI part, we can build a simple RAG or Retrieval Augmented Generation setup. Drag in a Knowledge Base node. You can point this to a website like the Vector Shift URL to scrape it for context. Connect the user's question from that Capture node to this Knowledge Base. Then, drag in an LLM node like OpenAI. In the prompt, you tell it to answer the question based on the provided context. The question will come from that Capture node and the context will come from your Knowledge Base Reader output. Finally, take the response from the LLM and send it back to the user with another message node. This is where it gets really powerful. You can have deterministic steps for lead collection and then seamlessly transition into an AI powered Q&A. And you know what else is super cool? It's looping. So, after the bot answers a question, you probably want the user to be able to ask another one. Just drag the connection from your last message node, the LLM's answer, and loop it back to the "How can I help you today?" message node. Vector Shift even highlights the loop for you. They've also added a neat little feature for these loops. Cyclic input. This means the first time it asks, "How can I help?" But on subsequent loops, it can say something different like, "Do you have any additional questions?" This makes the conversation flow much more naturally. You can see it in action. Ask one question, get an answer, then it asks if you have more questions. Ask another and it does the same. It's pretty great. All right. So you've built this amazing conversational AI. How do you deploy it? It's actually the same straightforward process as other chatbots in Vector Shift. Just hit "Deploy Changes." Go to Export and select Chatbot. Give your chatbot a name. There's even an additional field for these conversational chatbots called Message Delay, which lets you set the time you want between each message from the bot. Maybe half a second or so. Then just export it. You can embed it right into your website using a script or iFrame, or just use the Chat GPT style interface they provide to test it out. So, that's the new conversational AI workflows in Vector Shift. This is super exciting for anyone who wants to build more guided, interactive, and intelligent chatbots. Whether it's for advanced lead generation, step-by-step customer support, or any process where you need to control the conversation flow precisely, this is a massive upgrade. The ability to define exactly what happens at each stage, collect information, integrate with tools like Google Sheets, all with looping capabilities is just fantastic. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye. I think you missed this:
    ```
*   **Key Points:**
    *   Vector Shift has launched "Conversational AI Workflows," a new AI workflow mode for building custom and interactive chatbots.
    *   Unlike standard input-to-output pipelines, this mode allows precise control over each conversation stage using "Talk" (bot output) and "Listen" (user input) nodes.
    *   **Talk nodes** can send text messages, images, cards, or carousels.
    *   **Listen nodes** can capture user responses or present buttons for interaction.
    *   The platform supports deterministic steps (e.g., lead collection for Google Sheets integration) and seamless transitions to AI-powered Q&A (using RAG setup with a Knowledge Base and LLM).
    *   A "looping" feature allows chatbots to ask follow-up questions, with "cyclical input" enabling variations in prompts for natural conversation flow.
    *   Deployment is straightforward, offering embeddable script/iFrame options or a ChatGPT-style interface for testing, with a customizable message delay.

### Claude 4 ASYNC Coder + Cline, Roo, Kilo + Free API Credits: RIP Codex &amp; Jules! This is INSANE!

*   **Source:** AI Code King YouTube Channel
*   **Source Url:** [https://www.youtube.com/watch?v=jLYXzcuTjaQ](https://www.youtube.com/watch?v=jLYXzcuTjaQ)
*   **Transcription:**
    ```
    [ 0m0s428ms - 0m5s388ms ] Hi, Welcome to another video.
    [ 0m5s388ms - 0m6s58ms ] So,
    [ 0m6s58ms - 0m25s78ms ] Anthropic launched the Claude Sonnet 4 and Opus 4 models yesterday, which is quite good.
    [ 0m25s78ms - 0m35s368ms ] I have done some testing myself and it seems to perform a tad bit better than Gemini 2.5 Pro, which is already a really superior model.
    [ 0m35s368ms - 0m42s918ms ] But the difference is close and I still think that Gemini is better at front-end tasks, while Claude is a tad bit better overall.
    [ 0m42s918ms - 1m9s348ms ] I would still keep using Gemini because the price is lower and it is better, at least for my tasks.
    [ 1m9s348ms - 1m16s718ms ] The vibes are a bit off with these models for me, and the pricing isn't as justifiable for me, as Gemini is quite cheaper with catching.
    [ 1m16s718ms - 1m28s198ms ] I won't recommend the Opus model as much because I can't justify how little it brings over the Sonnet model for the price, at least for agentic coding, which is what I generally do.
    [ 1m28s198ms - 1m36s618ms ] But they actually launched some quite cool Claude Code features as well, which I found quite interesting.
    [ 1m36s618ms - 1m39s268ms ] And I'm mainly going to talk about that in this video.
    [ 1m39s268ms - 1m43s538ms ] But, before we do that, let me just wrap up how you can use Cly and Ru code with it, and how you can get $100 of free credits for usage as well.
    [ 1m43s538ms - 1m44s878ms ] But, before we do that,
    [ 1m44s878ms - 1m48s178ms ] let me tell you about today's sponsor, Dart.
    [ 1m48s178ms - 1m50s678ms ] Dart is the only truly AI native project management tool that you'll ever need.
    [ 1m50s678ms - 1m58s908ms ] You can use it to manage your tasks for a project, create multiple boards, organize them, and do everything that you generally do.
    [ 1m58s908ms - 2m12s248ms ] But you can also use AI with it to manage your tasks.
    [ 2m12s248ms - 2m28s448ms ] For example, you can ask it to generate tasks for you by brainstorming or planning projects, as well as performing duplicate detection to keep you focused.
    [ 2m28s448ms - 2m35s588ms ] You can even assign whole tasks to Dart and it can get them done for you.
    [ 2m35s588ms - 2m39s48ms ] You can use their composer-like AI agent that has the context of all your tasks and you can chat in natural language to just ask it to do something.
    [ 2m39s48ms - 2m40s28ms ] It can delete tasks,
    [ 2m40s28ms - 2m42s98ms ] create tasks,
    [ 2m42s98ms - 2m43s468ms ] edit tasks,
    [ 2m43s468ms - 2m45s368ms ] and handle multiple things like that.
    [ 2m45s368ms - 2m48s88ms ] Apart from this, you can integrate it into your AI clients or coders with its MCP server, which allows your MCP client or coder to reference tasks from your Dart boards.
    [ 2m48s88ms - 2m50s58ms ] You can even integrate it into Claude,
    [ 2m50s58ms - 2m52s118ms ] ChatGPT, and much more.
    [ 2m52s118ms - 2m55s238ms ] Most of the features in Dart are free,
    [ 2m55s238ms - 2m59s208ms ] while you can also get the $8 subscription for more features.
    [ 2m59s208ms - 3m3s828ms ] Make sure that you check Dart out through the link in the description.
    [ 3m3s828ms - 3m4s828ms ] Now, back to the video.
    [ 3m4s828ms - 3m9s618ms ] So, you can just go ahead and upgrade Klen and Roo code to the latest version.
    [ 3m9s618ms - 3m13s548ms ] And then you can just go ahead and set that up accordingly.
    [ 3m13s548ms - 3m16s878ms ] I use Requesti and you can use that as well,
    [ 3m16s878ms - 3m24s838ms ] because it routes between Vertex, Bedrock, and original Anthropic for better rate limits and everything, which is great.
    [ 3m24s838ms - 3m29s158ms ] You also get $5 of free credit there,
    [ 3m29s158ms - 3m33s958ms ] but you can also get free $100 credits to use as well if you use Kilo Code.
    [ 3m33s958ms - 3m43s978ms ] So, Kilo Code is giving out $100 of free credits that you can use by just signing up on their event site.
    [ 3m43s978ms - 3m50s48ms ] And you'll get $100 credit that you can use throughout the weekend.
    [ 3m50s48ms - 3m55s538ms ] It will be only available for the weekend.
    [ 3m55s538ms - 4m1s598ms ] So, you can use that accordingly and use both Opus 4 and Sonnet 4, as well as all the models on Kilo Code for free, which is quite awesome.
    [ 4m1s598ms - 4m4s338ms ] So, you can use this as well accordingly.
    [ 4m4s338ms - 4m9s178ms ] I have tested both the models and they are really good.
    [ 4m9s178ms - 4m12s248ms ] But you can try it yourself and check out with Kilo Code as well.
    [ 4m12s248ms - 4m17s378ms ] Also, just so you know, the outages on Claude's API are pretty wild.
    [ 4m17s378ms - 4m22s758ms ] Like, Opus is at something like 15% reliability, which is almost not usable, while Sonnet is fine.
    [ 4m22s758ms - 4m26s698ms ] But it is also heavily rate-limited.
    [ 4m26s698ms - 4m32s838ms ] Kilo Code fixes it because it routes to whatever provider is able to fulfill the request, similar to Requesti and Open Router.
    [ 4m32s838ms - 4m36s578ms ] But yeah, you will encounter some rate limits for sure.
    [ 4m36s578ms - 4m38s998ms ] I don't know why Anthropic can't figure out their infrastructure.
    [ 4m38s998ms - 4m43s268ms ] Anyway, now I want to talk about the new Claude GitHub agent, which is actually really cool.
    [ 4m43s268ms - 4m45s388ms ] So, what is the Claude GitHub agent?
    [ 4m45s388ms - 4m56s188ms ] Well, it is basically a bot in GitHub that uses Claude code and can basically achieve tasks that you assign it in something like a PR or an issue and just let it work.
    [ 4m56s188ms - 5m3s98ms ] It's technically quite similar to OpenAI's Code X or Jewels, but it is more integrated into GitHub itself.
    [ 5m3s98ms - 5m9s618ms ] I found it quite cool and there is also some pretty minor but good stuff in Claude Code as well, which I also want to talk about.
    [ 5m9s618ms - 5m14s198ms ] So, first of all, make sure that you upgrade Claude Code to the latest version.
    [ 5m14s198ms - 5m16s148ms ] And now we can just open it up.
    [ 5m16s148ms - 5m17s498ms ] Now, when you open it up in something like VS Code,
    [ 5m17s498ms - 5m37s8ms ] then you'll see that it will automatically install a VS Code extension called Claude Code that will now basically integrate Claude Code and VS Code in a way that will allow you to see the diff views of what Claude Code is proposing in VS Code itself.
    [ 5m37s8ms - 6m6s898ms ] Plus, after it has installed, you will see this Claude icon at the top, which you can just click, and this will just open up Claude Code in a terminal.
    [ 6m6s898ms - 6m12s228ms ] But you can keep it in a different layout than the general terminal, which is quite good.
    [ 6m12s228ms - 6m15s488ms ] And it almost makes it a VS Code extension now, which is awesome.
    [ 6m15s488ms - 6m18s648ms ] So, I can send a simple message here.
    [ 6m18s648ms - 6m24s848ms ] And you can see that the diff view immediately opens and just gives you the stuff to use.
    [ 6m24s848ms - 6m27s368ms ] I liked it a lot and it works amazingly well.
    [ 6m27s368ms - 6m30s148ms ] Plus, it's also much faster now from what I feel.
    [ 6m30s148ms - 6m33s968ms ] This is also available in Jet Brains if you use that.
    [ 6m33s968ms - 6m38s998ms ] I would really like a Z integration that does the same, as that would be awesome, because the memory footprint of that is super low.
    [ 6m38s998ms - 6m42s948ms ] And that would be kind of cool for sure.
    [ 6m42s948ms - 6m50s678ms ] Also, you can use Claude 4 mostly unlimited with Claude Code with the $100 plans, which is a really worth it plan if you ask me.
    [ 6m50s678ms - 6m57s718ms ] Though I haven't tried it myself, and some people say that the context gets limited or something.
    [ 6m57s718ms - 7m0s68ms ] But I'm not sure, and it seems like a good one.
    [ 7m0s68ms - 7m4s18ms ] So, this is good.
    [ 7m4s18ms - 7m8s308ms ] But there's another thing in Claude Code, and that is the GitHub integration.
    [ 7m8s308ms - 7m17s928ms ] So, Claude Code now has an SDK, meaning that you can now integrate it in your applications and use Claude Code in your programs to do something similar to Ator's SDK as well.
    [ 7m17s928ms - 7m25s788ms ] Anyway, so, to demo that off, they made a GitHub integration that uses that in the back end.
    [ 7m25s788ms - 7m38s908ms ] So, to install the GitHub bot in your repo, you can just run the install GitHub app command in Claude Code and it will ask you to install it in GitHub, which you can just do.
    [ 7m38s908ms - 7m45s848ms ] Once done, you can now use it accordingly.
    [ 7m45s848ms - 7m48s868ms ] So, to use it, you can either do it in an issue or in a pull request.
    [ 7m48s868ms - 8m10s38ms ] Like here I have an issue, and here we can just mention Claude and then write what we want it to do.
    [ 8m10s38ms - 8m16s868ms ] Like here, I wanted to just accomplish and fix this issue for us, and in just a bit, you'll see that it gets started on it.
    [ 8m16s868ms - 8m22s228ms ] And the animation and stuff here is quite good.
    [ 8m22s228ms - 8m23s148ms ] And in just a bit,
    [ 8m23s148ms - 8m26s168ms ] it gets done.
    [ 8m26s168ms - 8m28s198ms ] And you can see the diff of what it has done here.
    [ 8m28s198ms - 8m29s848ms ] And this looks pretty good for sure.
    [ 8m29s848ms - 8m33s908ms ] This is basically how it works.
    [ 8m33s908ms - 8m39s258ms ] And in theory, it is very similar to something like Code X and stuff.
    [ 8m39s258ms - 8m44s388ms ] It uses GitHub actions for the VM and stuff.
    [ 8m44s388ms - 8m50s158ms ] So, if you're on the free GitHub tier, then there are limits on that.
    [ 8m50s158ms - 9m0s248ms ] But if you are a Pro member, then the actions should be fine.
    [ 9m0s248ms - 9m7s108ms ] And the code and example of it is also open source, and you can use it accordingly, and see how you can also install it in your CI or CD workflows as well, which is also cool.
    [ 9m7s108ms - 9m15s648ms ] And you can also integrate it to automatically trigger and stuff like that.
    [ 9m15s648ms - 9m19s528ms ] It also works amazingly well.
    [ 9m19s528ms - 9m24s878ms ] So, these are the major things about it.
    [ 9m24s878ms - 9m28s328ms ] The models are good, and I liked these Claude upgrades as well.
    [ 9m28s328ms - 9m32s838ms ] And I also thought to talk about the free $100 credits by Kilo Code that should be great for you guys to try out.
    [ 9m32s838ms - 9m35s198ms ] Overall, it's pretty cool.
    [ 9m35s198ms - 9m38s998ms ] Anyway, share your thoughts below and subscribe to the channel.
    [ 9m38s998ms - 9m42s608ms ] You can also donate via super thanks option or join the channel as well and get some perks.
    [ 9m42s608ms - 9m43s798ms ] I'll see you in the next video.
    [ 9m43s798ms - 9m44s188ms ] Bye.
    ```
*   **Key Points:**
    *   Anthropic has launched Claude Sonnet 4 and Opus 4 models; Sonnet is considered "a tad bit better" than Gemini 2.5 Pro overall, though Gemini excels in front-end tasks and is more cost-effective. Opus is not recommended due to its high price relative to Sonnet's performance for agentic coding.
    *   Claude's API experiences significant reliability issues (e.g., Opus at 15% reliability) and heavy rate limits.
    *   **Claude Code** has new features:
        *   **VS Code Integration:** Automatically installs a VS Code extension that integrates Claude Code directly, providing diff views of proposed code changes and a dedicated terminal. Also available for JetBrains.
        *   **GitHub Integration (Claude GitHub Agent):** A bot that uses Claude Code within GitHub repositories. It can be assigned tasks (e.g., bug fixes) in pull requests or issues by mentioning `@claude`.
        *   **SDK:** Claude Code now includes an SDK for integration into custom applications.
    *   The Claude GitHub Agent leverages GitHub Actions for its virtual machine, and its code is open-source, allowing for custom CI/CD integrations.
    *   **Dart** (a sponsor) is an AI-native project management tool that helps manage tasks, generate ideas, and perform duplicate detection using AI, with integration capabilities for AI clients like Claude and ChatGPT.

---

## Product Announcements/Releases

*   **Vector Shift's Conversational AI Workflows:** A new AI workflow mode for building custom, interactive, and guided chatbots using "Talk" and "Listen" nodes.
*   **Anthropic's Claude Sonnet 4 and Opus 4 models:** New large language models released by Anthropic.
*   **Claude Code VS Code Extension:** An integration that allows Claude Code to operate directly within VS Code, offering diff views and a dedicated terminal.
*   **Claude GitHub Agent:** A bot that integrates Claude Code into GitHub issues and pull requests to automate coding tasks.

---

## Promotional Offers

*   **Requesti:** Offers $5 of free credit.
*   **Kilo Code:** Providing $100 of free credits for usage over the weekend, accessible by signing up on their event site.