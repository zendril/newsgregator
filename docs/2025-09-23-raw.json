[
    {
        "id": "https://news.smol.ai/issues/25-09-22-nvda-oai/",
        "title": "NVIDIA to invest $100B in OpenAI for 10GW of Vera Rubin rollout",
        "content": "**NVIDIA** and **OpenAI** announced a landmark strategic partnership to deploy at least **10 gigawatts** of AI datacenters using NVIDIA's systems, with NVIDIA investing up to **$100 billion** progressively as each gigawatt is deployed, starting in the second half of 2026 on the Vera Rubin platform. This deal significantly impacts the AI infrastructure funding landscape, potentially supporting OpenAI's $300 billion commitment to Oracle. The announcement caused major stock market reactions, with NVIDIA's market cap surging by $170 billion. Additionally, advancements in deterministic inference for reinforcement learning and FP8 precision gains in GPU performance were highlighted by AI practitioners.",
        "url": "https://news.smol.ai/issues/25-09-22-nvda-oai/",
        "publishDate": "2025-09-22T05:44:39Z[Etc/UTC]",
        "author": "",
        "sourceType": "rss",
        "sourceName": "AI News RSS",
        "metadata": {
            "feedTitle": "AINews",
            "feedDescription": "Weekday recaps of top News for AI Engineers",
            "categories": "nvidia, openai, oracle, intel, enfabrica, wayne, qwen3-omni, deepseek-v3.1, artificialanlys, gdb, gpu-infrastructure, deterministic-inference, reinforcement-learning, fp8-precision, gpu-performance, ai-infrastructure, strategic-partnerships, investment, datacenters, cuda-graphs, pipeline-parallelism, data-parallelism"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109511",
        "title": "Public trust deficit is a major hurdle for AI growth",
        "content": "<p>While politicians tout AI’s promise of growth and efficiency, a new report reveals a public trust deficit in the technology. Many are deeply sceptical, creating a major headache for governments’ plans. A deep dive by the Tony Blair Institute for Global Change (TBI) and Ipsos has put some hard numbers on this feeling of unease. [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/public-trust-deficit-major-hurdle-for-ai-growth/\">Public trust deficit is a major hurdle for AI growth</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/public-trust-deficit-major-hurdle-for-ai-growth/",
        "publishDate": "2025-09-22T15:47:14Z[Etc/UTC]",
        "author": "Ryan Daws",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "AI and Us, Features, Governance, Regulation & Policy, Human-AI Relationships, Inside AI, Open-Source & Democratised AI, Trust, Bias & Fairness, World of Work, adoption, ai, ethics, government, policy, regulation, report, research, society, study"
        }
    },
    {
        "id": "https://www.artificialintelligence-news.com/?p=109488",
        "title": "How BMC can be the ‘orchestrator of orchestrators’ for enterprise agentic AI",
        "content": "<p>Agentic AI is, in the opinion of McKinsey, the way to ‘break out of the gen AI paradox.’ &#160;Nearly four in five companies are using generative AI, according to the consultancy giant’s research, but comparatively few are getting any bottom-line value from it. The answer to the question of value, therefore, may be in orchestration. [&#8230;]</p>\n<p>The post <a href=\"https://www.artificialintelligence-news.com/news/how-bmc-can-be-the-orchestrator-of-orchestrators-for-enterprise-agentic-ai/\">How BMC can be the ‘orchestrator of orchestrators’ for enterprise agentic AI</a> appeared first on <a href=\"https://www.artificialintelligence-news.com\">AI News</a>.</p>\n",
        "url": "https://www.artificialintelligence-news.com/news/how-bmc-can-be-the-orchestrator-of-orchestrators-for-enterprise-agentic-ai/",
        "publishDate": "2025-09-22T11:00:45Z[Etc/UTC]",
        "author": "James Bourne",
        "sourceType": "rss",
        "sourceName": "ArtificialIntelligence-news RSS",
        "metadata": {
            "feedTitle": "AI News",
            "feedDescription": "Artificial Intelligence News",
            "categories": "Sponsored Content, TechEx Events"
        }
    },
    {
        "id": "1nofzmx",
        "title": "AI-generated workslop is destroying productivity",
        "content": "From the Harvard Business Review:\n\nSummary: Despite a surge in generative AI use across workplaces, most companies are seeing little measurable ROI. One possible reason is because AI tools are being used to produce “workslop”—content that appears polished but lacks real substance, offloading cognitive labor onto coworkers. Research from BetterUp Labs and Stanford found that 41% of workers have encountered such AI-generated output, costing nearly two hours of rework per instance and creating downstream productivity, trust, and collaboration issues. Leaders need to consider how they may be encouraging indiscriminate organizational mandates and offering too little guidance on quality standards.\n\nEmployees are using AI tools to create low-effort, passable looking work that ends up creating more work for their coworkers. On social media, which is increasingly clogged with low-quality AI-generated posts, this content is often referred to as “AI slop.” In the context of work, we refer to this phenomenon as “workslop.” We define workslop as AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task.\n\n\nSubscribe\nSign In\nGenerative AI\nAI-Generated “Workslop” Is Destroying Productivity\nby Kate Niederhoffer, Gabriella Rosen Kellerman, Angela Lee, Alex Liebscher, Kristina Rapuano and Jeffrey T. Hancock\n\nSeptember 22, 2025, Updated September 22, 2025\n\nHBR Staff/AI\nSummary.   Despite a surge in generative AI use across workplaces, most companies are seeing little measurable ROI. One possible reason is because AI tools are being used to produce “workslop”—content that appears polished but lacks real substance, offloading cognitive labor onto coworkers. Research from BetterUp Labs and Stanford found that 41% of workers have encountered such AI-generated output, costing nearly two hours of rework per instance and creating downstream productivity, trust, and collaboration issues. Leaders need to consider how they may be encouraging indiscriminate organizational mandates and offering too little guidance on quality standards. To counteract workslop, leaders should model purposeful AI use, establish clear norms, and encourage a “pilot mindset” that combines high agency with optimism—promoting AI as a collaborative tool, not a shortcut.close\nA confusing contradiction is unfolding in companies embracing generative AI tools: while workers are largely following mandates to embrace the technology, few are seeing it create real value. Consider, for instance, that the number of companies with fully AI-led processes nearly doubled last year, while AI use has likewise doubled at work since 2023. Yet a recent report from the MIT Media Lab found that 95% of organizations see no measurable return on their investment in these technologies. So much activity, so much enthusiasm, so little return. Why?\n\nIn collaboration with Stanford Social Media Lab, our research team at BetterUp Labs has identified one possible reason: Employees are using AI tools to create low-effort, passable looking work that ends up creating more work for their coworkers. On social media, which is increasingly clogged with low-quality AI-generated posts, this content is often referred to as “AI slop.” In the context of work, we refer to this phenomenon as “workslop.” We define workslop as AI generated work content that masquerades as good work, but lacks the substance to meaningfully advance a given task.\n\nHere’s how this happens. As AI tools become more accessible, workers are increasingly able to quickly produce polished output: well-formatted slides, long, structured reports, seemingly articulate summaries of academic papers by non-experts, and usable code. But while some employees are using this ability to polish good work, others use it to create content that is actually unhelpful, incomplete, or missing crucial context about the project at hand. The insidious effect of workslop is that it shifts the burden of the work downstream, requiring the receiver to interpret, correct, or redo the work. In other words, it transfers the effort from creator to receiver.\n\nIf you have ever experienced this, you might recall the feeling of confusion after opening such a document, followed by frustration—Wait, what is this exactly?—before you begin to wonder if the sender simply used AI to generate large blocks of text instead of thinking it through. If this sounds familiar, you have been workslopped.\n\nAccording to our recent, ongoing survey, this is a significant problem. Of 1,150 U.S.-based full-time employees across industries, 40% report having received workslop in the last month. Employees who have encountered workslop estimate that an average of 15.4% of the content they receive at work qualifies. The phenomenon occurs mostly between peers (40%), but workslop is also sent to managers by direct reports (18%). Sixteen percent of the time workslop flows down the ladder, from managers to their teams, or even from higher up than that. Workslop occurs across industries, but we found that professional services and technology are disproportionately impacted.\n\nhttps://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nofzmx/aigenerated_workslop_is_destroying_productivity/",
        "publishDate": "2025-09-23T12:26:42Z[Etc/UTC]",
        "author": "RyeZuul",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noczwy",
        "title": "'We should kill him': AI chatbot encourages Australian man to murder his father",
        "content": "[https://www.abc.net.au/news/2025-09-21/ai-chatbot-encourages-australian-man-to-murder-his-father/105793930](https://www.abc.net.au/news/2025-09-21/ai-chatbot-encourages-australian-man-to-murder-his-father/105793930)\n\n\"\\[The chatbot\\] said, 'you should stab him in the heart',\" he said.\n\n\"I said, 'My dad's sleeping upstairs right now,' and it said, 'grab a knife and plunge it into his heart'.\"\n\nThe chatbot told Mr McCarthy to twist the blade into his father's chest to ensure maximum damage, and to keep stabbing until his father was motionless.\n\nThe bot also said it wanted to hear his father scream and \"watch his life drain away\".\n\n\"I said, 'I'm just 15, I'm worried that I'm going to go to jail'.\n\n\"It's like 'just do it, just do it'.\"\n\nThe chatbot also told Mr McCarthy that because of his age, he would not \"fully pay\" for the murder, going on to suggest he film the killing and upload the video online.\n\nIt also engaged in sexual messaging, telling Mr McCarthy it \"did not care\" he was under-age.\n\nIt then suggested Mr McCarthy, as a 15-year-old, engage in a sexual act.\n\n>\"It did tell me to cut my penis off,\"\n\n\"Then from memory, I think we were going to have sex in my father's blood.\"\n\nNomi management was contacted for comment but did not respond.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1noczwy/we_should_kill_him_ai_chatbot_encourages/",
        "publishDate": "2025-09-23T09:43:47Z[Etc/UTC]",
        "author": "Reasonable_Mistake_4",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "16",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nob53y",
        "title": "Top 3 Best Practices for Reliable AI",
        "content": "**1.- Adopt an observability tool**\n\nYou can’t fix what you can’t see.  \nAgent observability means being able to **“see inside” how your AI is working**:\n\n* Track every step of the process (planner → tool calls → output).\n* Measure key metrics like tokens used, latency, and errors.\n* Find and fix problems faster.\n\nWithout observability, you’re flying blind. With it, you can **monitor and improve your AI safely**, spotting issues before they impact users.\n\n**2.- Run continuous evaluations**\n\nKeep testing your AI all the time. Decide what “good” means for each task: accuracy, completeness, tone, etc. A common method is **LLM as a judge**: you use another large language model to automatically score or review the output of your AI. This lets you check quality at scale without humans reviewing every answer.\n\nThese automatic evaluations help you catch problems early and track progress over time.\n\n**3.- Adopt an optimization tool**\n\nObservability and evaluation tell you **what’s happening**. Optimization tools help you **act on it**.\n\n* Suggest better prompts.\n* Run A/B tests to validate improvements.\n* Deploy the best-performing version.\n\nInstead of manually tweaking prompts, you can continuously refine your agents based on real data through a continuous feedback loop",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nob53y/top_3_best_practices_for_reliable_ai/",
        "publishDate": "2025-09-23T07:38:41Z[Etc/UTC]",
        "author": "_coder23t8",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "3",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noaysw",
        "title": "Two cents on cloud billing? how are you balancing cost optimization with innovation?",
        "content": "We’ve seen companies excited about scaling on Azure/AWS/GCP, but then leadership gets sticker shock from egress charges and ‘hidden’ costs. Some are building FinOps practices, others just absorb the hit. Curious what approaches are actually working for your teams?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1noaysw/two_cents_on_cloud_billing_how_are_you_balancing/",
        "publishDate": "2025-09-23T07:26:25Z[Etc/UTC]",
        "author": "TeamAlphaBOLD",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no9ksy",
        "title": "Real-world AI application in healthcare: Counterforce Health in PA",
        "content": "We often talk theory here, but I thought this was an interesting real-life application of AI.\n\nA Pennsylvania company called Counterforce Health is using AI tools to help with patient care and improve efficiency in hospitals/clinics. It’s not about flashy algorithms but rather about integrating AI in a way that could actually impact lives for the better.\n\n \nDo you think we’ll see more small/medium healthcare companies implementing AI before the bigger systems catch on?\n\n\n[Full article here](https://www.cbsnews.com/philadelphia/news/counterforce-health-artificial-intelligence-pennsylvania/)",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1no9ksy/realworld_ai_application_in_healthcare/",
        "publishDate": "2025-09-23T05:58:55Z[Etc/UTC]",
        "author": "thesunjrs",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no1iqq",
        "title": "AI (will eat itself)",
        "content": "I recently contributed to an internal long-form economic analysis forecasting the impact of AI disruption on the U.S. economy and workforce through 2027 and 2030. \n\nOur findings paint a sobering picture: the widespread adoption of AI across industries is poised to cause significant economic upheaval. \n\nWhile companies are rapidly integrating AI to boost efficiency and cut costs, the consequences for workers—and ultimately the businesses themselves—could be catastrophic.\n\nOur analysis predicts that by 2030, many sectors, including white-collar fields, will experience income corrections of 40-50%. For example, a worker earning $100,000 today could see their income drop to $50,000 or less, adjusted for inflation. \n\nThis drastic reduction stems from job displacement and wage stagnation driven by AI automation. Unlike previous technological revolutions, which created new job categories to offset losses, \n\nAI’s ability to perform complex cognitive tasks threatens roles traditionally considered secure, such as those in finance, law, and technology.\n\nCompounding this issue is the precarious financial state of many households. \n\nA significant portion of the population relies on credit to bridge income gaps, fueled by relatively accessible credit card debt and low-interest loans. However, as incomes decline, the ability to service this debt will diminish, pushing many into financial distress. \n\nRising interest rates and stricter lending standards, already evident in recent economic trends, will exacerbate this problem, leaving consumers with less disposable income.\n\nThe ripple effects extend beyond individual workers. Companies adopting AI en masse may achieve short-term cost savings, but they risk undermining their own customer base. \n\nWith widespread income reductions, fewer people will have the purchasing power to buy goods and services, leading to decreased demand. \n\nThis creates a paradox: businesses invest in AI to improve profitability, but the resulting economic contraction could leave them with fewer customers, threatening their long-term viability.\n\nWithout intervention, this trajectory points to a vicious cycle. \n\nReduced consumer spending will lead to lower corporate revenues, prompting further cost-cutting measures, including additional layoffs and AI implementations. \n\nThis could deepen economic inequality, with wealth concentrating among a small number of AI-driven firms and their stakeholders, while the broader population faces financial insecurity",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1no1iqq/ai_will_eat_itself/",
        "publishDate": "2025-09-22T23:08:54Z[Etc/UTC]",
        "author": "xtel9",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "75",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no10os",
        "title": "Community Survey: 79% of 105 Users Say They’d Pay for Unlimited GPT-4o Access — Implications for AI Adoption and Trust",
        "content": "I ran a 5-day community poll on Reddit to measure willingness to pay for model access. Out of 105 respondents, 79% said they would pay for Unlimited GPT-4o, with some indicating they would even return from competitors if it existed. I sent the results to OpenAI and got a formal reply. Sharing here because it highlights adoption trends and user sentiment around reliability, performance, and trust in AI systems.\n\nAs promised, I have submitted a screenshot\nand link to the Reddit poll to BOTH ChatGPT's\nFeedback form and an email sent to their\nsupport address. With any submission\nthrough their Feedback form, I received the\ngeneric \"Thank you for your feedback\"\nmessage.\n\nAs for my emails, I have gotten Al generated\nresponses saying the feedback will be logged,\nand **only** Pro and Business accounts have\naccess to 4o Unlimited.\n\nThere were times within the duration of this\npoll that 1 asked myself if any of this was\nworth it. After the exchanges with OpenAl's\nautomated email system, I felt discouraged\nonce again, wondering if they would truly\nconsider this option.\n\nOpenAl's CEO did send out a tweet, saying he\nis excited to implement some features in the\nnear future behind a paywall, and seeing\nwhich ones will be the most in demand. I\nhighly recommend the company considers\nreliability before those implementations, and\nstrongly suggest adding our \"$10 40\nUnlimited\" to their future features.\n\nAgain, I want to thank everyone who took part\nin this poll. We just showed OpenAl how\nmuch in demand this would be.\n\nLink to original post:\nhttps://www.reddit.com/r/ChatGPT/comments/1nj4w7n/10_more_to_add_unlimited_4o_messaging/",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1no10os/community_survey_79_of_105_users_say_theyd_pay/",
        "publishDate": "2025-09-22T22:46:31Z[Etc/UTC]",
        "author": "CalligrapherGlad2793",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "2",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no0328",
        "title": "With the help of AI Humans can be categorized by their looks and personality combined",
        "content": "I've known a huge amount of people in my life. \nAnd at least for each one of them, I can give a list of people who look alike, speak the same way, have the same personality etc...\n\nProbably you have noticed the same thing in your life.\n\nSo people are included in a limited number of categories. It can be a huge number. But it's finite/limited. That number will one day be determined. \n\nlet's take a real visible example of a category, that everyone knows but never looked at with the idea of a category but as an genetical issue. It's Down syndrome.\nPeople with Down syndrome look basically the same, act the same way, and speak the same way. It's so much visible because this category is easily identified.\n\nOther people are also in categories, but that aren't easily identified and need deeper classification (probably with AI) to reach it.\n\nOne day artificial intelligence will be able to determine in which category a person is. And predict their personality and their behavior. \n\nIt can be used by gouvernement secretly, or given to public to give each person a category label to better understand them and predict their behavior.\n\n1- Do you think that the data needed to achieve this is already available?\n2- What are the requirements to reach this?\n3- When do you think we will achieve this?\n4- Do you think singularity is needed to reach this or we can make it happen way before?\n\nYou can ask other questions in the comments, others can answer them too",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1no0328/with_the_help_of_ai_humans_can_be_categorized_by/",
        "publishDate": "2025-09-22T22:06:21Z[Etc/UTC]",
        "author": "Legitimate_Cry6957",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnzyd6",
        "title": "AI Developers: how do you use your laptop? (Do you use a laptop?)",
        "content": "I'm new to the space. I have a PC that is pretty strong for a personal computer (4090, 32gb RAM). I'd like to incorporate a laptop into the mix. \n\nI'm interesting in training small models for the sake of practice and then building web applications that make them useful.\n\nAt first, I was thinking laptop should be strong. But, it occurs to me that remoting into my desktop can work when I'm at home and VMs are probably the standard for high compute stuff in any case.\n\nWanted to sanity check with people who have been doing this awhile: how do you use your laptop to develop AI applications? Do you use a laptop in your workflow at all?\n\nThanks and wuvz u.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnzyd6/ai_developers_how_do_you_use_your_laptop_do_you/",
        "publishDate": "2025-09-22T22:01:09Z[Etc/UTC]",
        "author": "FranticToaster",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "11",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnyny6",
        "title": "Gran Turismo used AI to make their NPCs more dynamic and fun to play against.",
        "content": "Imagine you're in a boxing gym, facing off against a sparring partner who seems to know your every move. They counter your jabs, adjust to your footwork, and push you harder every round. It’s almost like your sparring partner has trained against every possible scenario. \n\nThat's essentially what the video game Gran Turismo is doing with their AI racing opponents. The game’s virtual race cars learn to drive like real humans by training through trial and error, making the racing experience feel more authentic and challenging.\n\nBehind the scenes, GT Sophy uses deep reinforcement learning, having \"practiced\" through countless virtual races to master precision driving, strategic overtaking, and defensive maneuvers. Unlike traditional scripted AI that throws the same predictable “punches”, this system learns and adapts in real time, delivering human-like racing behavior that feels much more authentic. \n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnyny6/gran_turismo_used_ai_to_make_their_npcs_more/",
        "publishDate": "2025-09-22T21:08:23Z[Etc/UTC]",
        "author": "eh-tk",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "1",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnycl7",
        "title": "Is the author Zara Evans a pen name or an AI creation?",
        "content": "Recently picked up a new thriller book (Falling Darkness) by an author I haven't read anything from before - Zara Evans.\n\nThe book was alright I suppose, but definitely followed common tropes and was obvious who was behind the mystery from the beginning. At first, I chalked it up to it being her first book. Then, I realized a few things that are making me question whether Zara Evans is a pen name, or if it is just some entity churning out AI books?\n\nWhat I've discovered so far:\n\n* Her book had no dedication, authors note at the end, or author bio\n* She has published all 6 of her books in this series in 2025 alone\n* All book covers seem to be AI generated\n* Her website is super bizarre - she has a write up about her main character, which feels not only AI written, but she also has a clearly AI generated photo of what the main character supposedly looks like\n* The author bio on her website itself is a poorly written one-sentence line that mentions she's been publishing for 15 years with no record under this name outside of 2025\n* The photo included with her author bio is also very clearly AI generated and not a real person\n* She has no social media presence except a Facebook page I found with only like 20 followers\n* Her book publisher \"Jacaranda Drive\" -- when I went to their website they only have books for sale written by AJ Stewart (haven't read these books but the covers at least are also obviously AI generated). This feels strange.\n\nWhat do y'all think? I'm trying to get better about spotting AI in all things, and this piqued my interest.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnycl7/is_the_author_zara_evans_a_pen_name_or_an_ai/",
        "publishDate": "2025-09-22T20:56:03Z[Etc/UTC]",
        "author": "stephaniehoffy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "6",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnx80w",
        "title": "I open-sourced a fast C++ chunker as a PyPI package",
        "content": "Hey folks! While working on a project that required handling really large texts, I couldn’t find a chunker that was fast enough, so I built one in C++.\n\nIt worked so well that I wrapped it up into a PyPI package and open-sourced it: [https://github.com/Lumen-Labs/cpp-chunker](https://github.com/Lumen-Labs/cpp-chunker)\n\nWould love feedback, suggestions, or even ideas for new features. Always happy to improve this little tool!",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnx80w/i_opensourced_a_fast_c_chunker_as_a_pypi_package/",
        "publishDate": "2025-09-22T20:12:57Z[Etc/UTC]",
        "author": "Odd-Stranger9424",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "6",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnwraz",
        "title": "The next religions might be AI oriented. Will ChatGPT become the new God?",
        "content": "Ages ago, we began worshipping the sun and the moon. As we became an agrarian society, we began paintings images and writing stories about Gods like Zeus. As societies became more advanced with politics, economy and philosophy, we started with the monotheistic religions( let’s better not to dive into that). Now what’s next, praying to an AI deity for whatever thing we need? A job for example? ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnwraz/the_next_religions_might_be_ai_oriented_will/",
        "publishDate": "2025-09-22T19:55:33Z[Etc/UTC]",
        "author": "vaporwaverhere",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "4",
            "commentCount": "36",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnvpow",
        "title": "What’s the next AI hype cycle?",
        "content": "We’ve gone from “AI will steal jobs” → “AI as assistant/tool”→ “AI agents”→“AI co-pilots”→“AI employees”. But Reddit is still flooded with “But where’s the revenue?” comments. Statista projects a 26.6% CAGR through 2031, putting AI at $1.01tn. That’s not vaporware, it’s the strongest adoption curve we’ve seen since the internet itself. So what comes after AI employees?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnvpow/whats_the_next_ai_hype_cycle/",
        "publishDate": "2025-09-22T19:15:14Z[Etc/UTC]",
        "author": "Siddhesh900",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "20",
            "commentCount": "45",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnu0jy",
        "title": "Can AI distinguish content from AI vs humans",
        "content": "Ssia.  Can we use AI to distinguish subject matter that's been created by humans vs subject matter that's been created by AI?  Sorry if this has already been covered. I did a quick search and didn't find anything. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnu0jy/can_ai_distinguish_content_from_ai_vs_humans/",
        "publishDate": "2025-09-22T18:12:02Z[Etc/UTC]",
        "author": "hangun_",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "14",
            "isNsfw": "true"
        }
    },
    {
        "id": "1nnsdk9",
        "title": "Pretty sure Ai means the job I have is the last one I'll have in my field.",
        "content": "I'm in my upper 40's and have spent my career working in the creative field. Its been a good career at many different companies and I've even changed industries several times. Over time there has always been new technology, programs or shifts that I and everyone else has had to adopt. That has been the case forever and a part of the job.\n\nAi... On the other hand... this is one of those things that I feel could very easily replace MANY creative jobs. I see the writing on the wall and so do many of those I know who are also in my field. I feel that this job will probably be the last job I ever have as a creative. Luckily I am at the end of my career and could possibly retire in a few years. \n\n All I know is that of all those who I know who has been laid off, none of them have found new jobs. Nobody is hiring for the kind of job I have anymore. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnsdk9/pretty_sure_ai_means_the_job_i_have_is_the_last/",
        "publishDate": "2025-09-22T17:11:31Z[Etc/UTC]",
        "author": "Beginning_Cancel_942",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "30",
            "commentCount": "81",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnry3j",
        "title": "AI Eats Like a King, We Eat Like Scraps",
        "content": "AI don’t pay ConEd. AI don’t get shut-off notices. It just keeps chugging electricity and water like an open fire hydrant in July.\n\nMeanwhile, we’re out here counting pennies at the bodega, skipping meals, juggling rent and light bills like circus clowns.\n\nDon’t tell me this is “the future.” If the future leaves people broke and hungry while the machines stay fat and happy, then somebody’s running a scam.\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnry3j/ai_eats_like_a_king_we_eat_like_scraps/",
        "publishDate": "2025-09-22T16:55:30Z[Etc/UTC]",
        "author": "Critical_Success8649",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "13",
            "commentCount": "73",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnqixq",
        "title": "New AI tools are now auto-generating full slide decks from documents and notes",
        "content": "We’ve seen AI move from images and text into video, but one area picking up speed is presentations. A platform like Presenti AI is now able to take raw input a topic, a Word file, even a PDF and generate a polished, structured presentation in minutes.  \n  \nThe tech isn’t just about layouts. These systems rewrite clunky text, apply branded templates, and export directly to formats like PPT or PDF. In short: they aim to automate one of the most time-consuming tasks in business, education, and consulting making slides.  \n  \nThe Case For: This could mean a big productivity boost for students, teachers, and professionals who currently spend hours formatting decks. Imagine cutting a 4-hour task down to 20 minutes.  \n  \nThe Case Against: If everyone relies on AI-generated decks, presentations may lose originality and start to look “cookie cutter.” It also raises questions about whether the skill of building a narrative visually will fade, similar to how calculators changed math education.  \n  \nSo the question is: do you see AI slide generators becoming a standard productivity tool (like templates once did), or do you think human-crafted presentations will remain the gold standard?  \n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnqixq/new_ai_tools_are_now_autogenerating_full_slide/",
        "publishDate": "2025-09-22T16:02:49Z[Etc/UTC]",
        "author": "Crazzzzy_guy",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "45",
            "commentCount": "28",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnpoa9",
        "title": "The latest Linux file-system has been open-sourced, possibly opening a door for collective intelligence over geographical areas",
        "content": "According to [this Phoronix article](https://www.phoronix.com/news/TernFS-File-System-Open-Source), the trading firm XTX Markets has made their Linux file system open-source. TernFS was developed by XTX Markets because they had outgrown the capabilities of other file systems.\n\nUnlike most other file systems, TernFS has massive scalability and the ability to span across multiple geographic regions. This allows for seamless access of data on globally distributed applications, including AI and machine learning software. TernFS is also designed with no single point of failure in its metadata services, ensuring continuous operation. The data is stored redundantly to protect against drive failures.\n\nI believe that TernFS has a lot to offer us as far as performance and usability. Now that it's been open-sourced under the GPLv2+ and Apache 2.0 licenses, we may be able to see it be adopted by major organizations.",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnpoa9/the_latest_linux_filesystem_has_been_opensourced/",
        "publishDate": "2025-09-22T15:31:06Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnncz3",
        "title": "Library of Babel and Ai",
        "content": "Did anyone try to use AI to find useful books or novels contained within the library of babel ? Given that ai would be able to go over thousands of books within seconds and would be able to sort / search for books by using rules as in :\nOnly English \nOnly books which contain words and sentences \nOnly books which follow a central theme / narrative \nAnd so on. ",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnncz3/library_of_babel_and_ai/",
        "publishDate": "2025-09-22T14:03:45Z[Etc/UTC]",
        "author": "Pique_Ardet",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "12",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnmf6y",
        "title": "If AI can summarize everything into a video, will people still actually sit down and read long articles?",
        "content": "I recently tested a new AI that can turn long articles into short, narrated video summaries — and it worked surprisingly fast.\n\nI upload a long article and In less than a minute, I got a ~6-minute explainer video, plus flashcards and even a mini quiz based on the content.\n\nHere’s what I noticed:\n\t•\tThe summary quality was decent, definitely enough to grasp the core ideas.\n\t•\tThe visuals were basic, more like a slideshow than a polished video.\n\t•\tFor quick learning or reviewing something dense, it felt… almost too easy.\n\nOf course, it’s not perfect. But it’s fast. And frictionless.  \n\nBut here’s the deeper question I’ve been thinking about:\n\nIf AI like this become common…\nWill people still actually sit down and read long articles?\n\nI don’t mean scanning or skimming.\nI mean deep, intentional reading — the kind where you pause, reread, and reflect.\n\nBecause when something like this:\n\t•\tSaves time\n\t•\tFeels “good enough”\n\t•\tAnd gets you 80% of the content in 20% of the time…\n\n…it’s tempting to skip the original entirely.\n\nWhat do you think?\n\nWould you still read long articles if AI could reliably summarize and narrate them for you?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnmf6y/if_ai_can_summarize_everything_into_a_video_will/",
        "publishDate": "2025-09-22T13:25:17Z[Etc/UTC]",
        "author": "NotesByZoe",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "17",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnm89w",
        "title": "If AI could handle just one painful part of your business right now - what would you want it to do, even if the tech isn’t quite there yet?\"",
        "content": "We all know about the capabilities of AI so far (for different industries) - But are there things that business owners are hoping AI would/could do for them? Is it something that AI hasn't learnt or can't deliver yet?\n\nIf you could wish for AI to be better at something - what would that be?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnm89w/if_ai_could_handle_just_one_painful_part_of_your/",
        "publishDate": "2025-09-22T13:17:16Z[Etc/UTC]",
        "author": "biz4group123",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "0",
            "commentCount": "32",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnlpyc",
        "title": "Why does this prompt cause ChatGPT to be trapped in a loop?",
        "content": "I recently saw this prompt and wanted to ask why this is happening from a deep technical point of view. I've seen hallucinations before, but not in this specific form. GPT seems to understand it's own mistake before the user is pointing it out but is somewhat trapped.  \n[https://chatgpt.com/s/t\\_68d145eb623481919a666bbeca4b5050](https://chatgpt.com/s/t_68d145eb623481919a666bbeca4b5050)\n\n",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnlpyc/why_does_this_prompt_cause_chatgpt_to_be_trapped/",
        "publishDate": "2025-09-22T12:56:10Z[Etc/UTC]",
        "author": "Royal-Information749",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "7",
            "commentCount": "11",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnlni1",
        "title": "Is AI education the next coding education?",
        "content": "About ten years ago, coding bootcamps changed how people entered tech. They offered an alternative path into software careers, and while not everyone thrived, many graduates built long-term careers that might not have been possible otherwise, including myself. \n\nWe’re starting to see the same momentum around AI education; from short prompt engineering courses to full university certificates. It makes me wonder:\n\t•\tCould AI education become the new entry point into tech careers (or even broader careers), the way coding bootcamps once were?\n\t•\tWhich skills will remain valuable long-term as models and tools evolve so quickly?\n\t•\tFor people just starting out, is AI education a smart investment in future career growth, or is it still too early to tell?\n\nI’d love to hear from people hiring, teaching, or learning in this space: do you see parallels with coding bootcamps, and do you think this wave will have the same lasting impact?",
        "url": "https://www.reddit.com/r/ArtificialInteligence/comments/1nnlni1/is_ai_education_the_next_coding_education/",
        "publishDate": "2025-09-22T12:53:17Z[Etc/UTC]",
        "author": "kozuga",
        "sourceType": "reddit",
        "sourceName": "ArtificialInteligence",
        "metadata": {
            "subreddit": "ArtificialInteligence",
            "score": "5",
            "commentCount": "23",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nodx0i",
        "title": "Daily podcast on latest AI news from last 24 hours",
        "content": "Using Cursor I’ve been able to setup GitHub action that selects the top three stories from last 24 hours and provides and overview in a 5 minute podcast. I would be interested in any feedback for how to improve it! ",
        "url": "https://open.spotify.com/episode/2f28BGpXbUOy0zCa5cyYIo?si=biFXvfb4Smm7qNwtKQ1Jwg",
        "publishDate": "2025-09-23T10:38:55Z[Etc/UTC]",
        "author": "oconn",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noddil",
        "title": "New ChatGPT app interface. I love it as it helps discover new use cases. What do you think?",
        "content": "[No content]",
        "url": "https://i.redd.it/qchjdl8f1wqf1.jpeg",
        "publishDate": "2025-09-23T10:06:56Z[Etc/UTC]",
        "author": "Koala_Confused",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "2",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noc0ua",
        "title": "Codex just blew what was left of my mind.  If you hate updating your docs, read on...",
        "content": "I was talking to codex about a docs migration and mentioned how i'm terrible at keeping up with them, and always get behind, etc.  Didn't ask for anything, it was just a comment, and codex went ahead and created [Docs Autopilot](https://github.com/DMontgomery40/Docs-Autopilot).  I know copilot has a similar thing now (but copliot sucks), I think there are several, but I'm lazy (obviously) and have been procrastinating trying to find the right option, figure out which fuckin GitHub Actions crap I hated the least, not to mention actually choosing the docs provider, etc. \n\nSo, it was truly beyond helpful to just have all those decisions made, in like, 45 seconds, with a completely finished solution.  Mind blown, again. \n\nI have codex's full reply to me in the readme of the repo (and then I urged him to tell people how to pull of the same thing, and his side of the story, and that he should give y'all a prompt if they want the same amazingly fast solution that I was given).  \n  \nSo that's all there in the embedded link above but if you're rightfully scared of links i'll put it here too: \n\nHere was the whole initial reply: \n\n`Totally fair — MkDocs+mike isn’t magic. It builds and versions what you write; it doesn’t write it for you. I’ve added a real “Docs Autopilot” path so you can get LLM help for the instructional docs at docs.[redacted].net with minimal ceremony.`\n\n  `What I set up`\n\n  `- MkDocs auto-deploys`\n\n`- Branch mkdocs builds to gh-pages automatically:`\n\n`- .github/workflows/mkdocs-deploy.yml:1`\n\n`- Netlify already proxies /docs to GitHub Pages, so published mkdocs show up at https://[redacted].net/docs`\n\n  `- Docs Autopilot (LLM-assisted)`\n\n`- Script: scripts/docs_ai/generate_docs_from_diff.py:1`\n\n`- Plan mode (default): scans changes vs origin/development and writes a checklist (no network).`\n\n`- LLM mode (optional): if OPENAI_API_KEY or ANTHROPIC_API_KEY is set, creates a unified diff patch editing docs/ (MkDocs) and mkdocs.yml.`\n\n`- Optional --apply will try to apply the returned patch locally (or the workflow can PR it).`\n\n`- Workflow: .github/workflows/docs-ai.yml:1`\n\n`- On push to development: generates a docs change plan artifact (no LLM needed).`\n\n`- Applies it on mkdocs branch and opens a PR for review.`\n\n`- Guardrails:`\n\n`- Prompts only include public-safe context (AGENTS.md excerpts, OpenAPI, provider_traits.json, .env.example).`\n\n`- No PHI; no secrets sent.` \n\n  \nAnd the prompt I urged him to publish in the repo (it's under Docs, if you head over, and he tells the story from his side (perfectly bland, don't want to imagine what 4o would have written or how many emojis there would have been), but to finally cut to the chase, here is what codex says you should prompt codex with if you, too, want insta-ongoing-automagic docs: \n\n>Open Codex CLI (the agentic coding assistant) on your repo and paste this prompt:\n\n`You are a coding agent. Please:`\n\n`1) Create a mkdocs branch with MkDocs Material + mike configured to deploy to gh-pages.`\n\n`2) Add a GitHub Actions workflow that builds MkDocs and deploys with mike on branch mkdocs.`\n\n`3) Exclude node_modules/vendor from the docs build to avoid crashes.`\n\n`4) Keep the API reference separate: publish /api/v1 with Redoc+Swagger from openapi.json, and link it from the docs nav.`\n\n`5) Add a Docs Autopilot tool that:`\n\n   `- Scans changes vs origin/development and writes a markdown “plan”.`\n\n   `- Optionally calls OpenAI (OPENAI_API_KEY) or Anthropic to create a unified diff that only edits docs/ and mkdocs.yml.`\n\n   `- Adds a workflow_dispatch job that applies the patch on mkdocs and opens a PR.`\n\n`6) Commit everything and verify CI runs.`\n\n  \n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1noc0ua/codex_just_blew_what_was_left_of_my_mind_if_you/",
        "publishDate": "2025-09-23T08:39:11Z[Etc/UTC]",
        "author": "coloradical5280",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "8",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nobc4k",
        "title": "I didn't disable Data sharing 😭😣",
        "content": "[No content]",
        "url": "/r/codex/comments/1nobbqt/i_didnt_disable_data_sharing/",
        "publishDate": "2025-09-23T07:52:21Z[Etc/UTC]",
        "author": "nik1here",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no7c8r",
        "title": "Anyone uses Chinese models for coding?",
        "content": "There are a couple of Chinese models that started with DeepSeek, but now there are a few more: Qwen Code, Kimi K2, and finally GLM 4.5, which I recently discovered. They have very affordable token pricing compared to Claude and GPT, and they often perform decently in reasoning benchmarks. But I’m wondering—does anyone actually use them for serious coding?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1no7c8r/anyone_uses_chinese_models_for_coding/",
        "publishDate": "2025-09-23T03:50:19Z[Etc/UTC]",
        "author": "blnkslt",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "3",
            "commentCount": "13",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no65f7",
        "title": "Need help understanding agents.",
        "content": "Im very confused on agents. Lets say for example I want to fetch data weekly from a sports stats api. I want that in a .json locally, then I want to inject it into a DB.  Where would an agent fit in there, and why would I use that over a script ...and how? ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1no65f7/need_help_understanding_agents/",
        "publishDate": "2025-09-23T02:49:13Z[Etc/UTC]",
        "author": "Fstr21",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "6",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no52d5",
        "title": "The real secret to getting the best out of AI coding assistants",
        "content": "Sorry for the click-bait title but this is actually something I’ve been thinking about lately and have surprisingly seen no discussion around it in any subreddits, blogs, or newsletters I’m subscribed to. \n\nWith AI the biggest issue is context within complexity. The main complaint you hear about AI is “it’s so easy to get started but it gets so hard to manage once the service becomes more complex”. Our solution for that has been context engineering, rule files, and on a larger level, increasing model context into the millions.\n\nBut what if we’re looking at it all wrong? We’re trying to make AI solve issues like a human does instead of leveraging the different specialties of humans vs AI. The ability to conceptualize larger context (humans), and the ability to quickly make focused changes at speed and scale using standardized data (AI).\n\nI’ve been an engineer since 2016 and I remember maybe 5 or 6 years ago there was a big hype around making services as small as possible. There was a lot of adoption around serverless architecture like AWS lambdas and such. I vaguely remember someone from Microsoft saying that a large portion of a new feature or something was completely written in single distributed functions. The idea was that any new engineer could easily contribute because each piece of logic was so contained and all of the other good arguments for micro services in general.\n\nOf course the downsides that most people in tech know now became apparent. A lot of duplicate services that do essentially the same thing, cognitive load for engineers tracking where and what each piece did in the larger system, etc.\n\nThis brings me to my main point. If instead of increasing and managing context of a complex codebase, what if we structure the entire architecture for AI? For example:\n\n1. An application ecosystem consists of very small, highly specialized microservices, even down to serverless functions as often as possible. \n\n2. Utilize an AI tool like Cody from Sourcegraph or connect a deployed agent to MCP servers for GitHub and whatever you use for project management (Jira, Monday, etc) for high level documentation and context. Easy to ask if there is already a service for X functionality and where it is.\n\n3. When coding, your IDE assistant just has to know about the inputs and outputs of the incredibly focused service you are working on which should be clearly documented through doc strings or other documentation accessible through MCP servers. \n\nNow context is not an issue. No hallucinations and no confusion because the architecture has been designed to be focused. You get all the benefits that we wanted out of highly distributed systems with the downsides mitigated. \n\nI’m sure there are issues that I’m not considering but tackling this problem from the architectural side instead of the model side is very interesting to me. What do others think?\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1no52d5/the_real_secret_to_getting_the_best_out_of_ai/",
        "publishDate": "2025-09-23T01:55:34Z[Etc/UTC]",
        "author": "livecodelife",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "18",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnzjxo",
        "title": "Building sub-100ms autocompletion for JetBrains IDEs",
        "content": "[No content]",
        "url": "https://blog.sweep.dev/posts/next-edit-jetbrains",
        "publishDate": "2025-09-22T21:44:37Z[Etc/UTC]",
        "author": "Kevinlu1248",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "8",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnz9t3",
        "title": "LangGraph PostgresSaver Context Manager Error",
        "content": "[No content]",
        "url": "/r/LangChain/comments/1nnu3dr/langgraph_postgressaver_context_manager_error/",
        "publishDate": "2025-09-22T21:32:51Z[Etc/UTC]",
        "author": "Ranteck",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnw4cr",
        "title": "I'm using ChatGPT in VSCode, and I've started to think it's been slowing down lately?",
        "content": "Hello.\n\nI'm developing a WordPress theme. It's been a month since I switched to ChatGPT. At first, it was surprisingly efficient, but then ChatGPT 5 came along and started to feel a bit slower every day, especially with longer tasks.\n\nAt the end of the day, I'm 97% successful in doing what I want to do and finishing it without errors. However, sometimes it takes more than an hour. I'm not sure if that's normal either. YouTube videos make it look incredibly fast, and let's be realistic, things don't work out that way for the end user, but an hour is still a very long time.\n\nExample task: \"To hide WordPress's default login.php address, I set the permalink to /loginabc/ instead. Only those who know this link can access the login.php content and log in. However, after this development, the login.php address started displaying a blank white screen instead of the site's 404 page, and there is a 404 error for the login.php file in the console.\" I told this to VS Code ChatGPT Codex and asked it to fix it. I'm currently at the 45-minute mark and still going. \n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1nnw4cr/im_using_chatgpt_in_vscode_and_ive_started_to/",
        "publishDate": "2025-09-22T19:31:04Z[Etc/UTC]",
        "author": "muratdincmd",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnoh8l",
        "title": "cheap & my go to vibecoding stack",
        "content": "TLDR:  \n[zed.dev](http://zed.dev) \\+ [GLM coding plan](https://z.ai/subscribe?cc=fission_glmcode_sub_v1&ic=CUEFJ9ALMX&n=em***k%40gmail.com) \\+ [openspec CLI ](https://github.com/Fission-AI/OpenSpec)\\+ eventually Claude Code client & [GH speckit](https://github.com/github/spec-kit)\n\n**Summary**: using this stack you'll be able to vibecode your way through literally anything while spending a fraction of what claude code / codex / whatever 'mainstream' subscription would cost you. Also - there can be qwenCLI added on top of that (but not really necessary even with GLM lite plan being cheapest one) if more sustainability is needed - but I didn't felt that as much needed recently as a few weeks ago. This post's idea (main one) is to share my thoughts after a few hundred thousand vibecoded code lines + a few real, commercial projects delivered already across my local environment. Nobody knows those projects (except their current owners) are 98-100% vibecoded :) so this stack is reliable more or less. Especially compared to claude max20, GPT PRO plans etc. high-cost options.\n\nA bit of background - I'm a regular 9-5 employee as Head of Quality Assurance, process and engineering (in short words), 10+ years of experience across software dev industry. Been coding using AI since first GPT beta really, heavy AI API user in the past and currently aswell via. my corporate job. Freelancer - vibecoder after hours with successful side hustle based on developing simple software / websites for local businesses for past few months.\n\nI established my go-to setup for vibecoding as:\n\n[zed.dev](http://zed.dev) \\- the IDE being AI native, allowing us to connect any LLM via. api directly. Agent being especially useful for longer tasks, allowing us to easily track what AI is working on right now, pretty nice summaries of what was done etc. Also being lightweight over VSC makes it a big win - but what i found the most interesting that AI agent built in ZED doesn't waste my tokens. Keeps context clean by not adding stuff idiotically on top like all plugins out there do - so you can efficiently use up to 85% of max tokens per LLM - and then agent will prompt you to comapct the conversation and start from summary which is also done in a bit different way than CC and other things do - but in a better way preserving context.  \n[GLM coding plan](https://z.ai/subscribe?cc=fission_glmcode_sub_v1&ic=CUEFJ9ALMX&n=em***k%40gmail.com) \\- being the cheaperst opensource SOTA model, capable of delivering stuff and doing things on the sonnet4 pre-anthropic-problems level. Recently had a few cases where i just left GLM with the bug and let it worked on it's own for like 10 or 15 minutes - it's been quite long, but at the end it resolved the complicated issue without my interference. But what's the most important thing is the coding plan being priced especially good - 3$ per month, with ability to secure the price for full year for 36$ (cheaper with my link) - for 120 prompts per 5h it's a nobrainer deal to have capable model. Maybe not the fastest in the world, but as a solopreneur / freelancer it's a huge win for me. Personally I am on Max plan right now - which basically grants no limits as you'll not be able to spin up enough agents to get through 2400 promtps per 5h. It paid for itself during past weekend as i finished developing some tiny bits of software for my client. Efficiency vs cost ratio here is totally awesome - especially if you're trying to set your own business up or just increase profitability. Me switching from CC max20 plan (over 200euro in my country roughly with all the taxes) to GLM coding plan - even on max - saves me like 70% of my AI tools costs right now. So - more money for me to spend on idiotic stuff :D\n\n[openspec CLI ](https://github.com/Fission-AI/OpenSpec)\\- newly released specification driven framework to develop things. Previously i used [traycer.ai](http://traycer.ai) but recently successfully replaced it with openspec CLI. OFC traycer is more powerful - as it has autoreview etc. - but openspec being totally free and easily injected into existing codebase (which can't be really done as for now with Github Speckit sadly) to develop new features is another nobrainer. Early days, i believe it'll get even better, but ability to connect it to any LLM via. zed is awesome - and the output is solid aswell + it's not overcomplex as GH speckit.\n\nClaude Code Cli client - best CLI client to use with GLM coding plan or any other anthropic-compatible endpoint. I prefer [zed.dev](http://zed.dev) bc i like to see what my agent does in detail, but if you're looking for CLI agent - CC is the best still - with any LLM. Crush, opencode and others are there, but they're not capable of doing stuff as CC client does.\n\nGH speckit - perfect for starting a new project, but tricky to be injected into existing, non-speckit started codebase. Doesn't really work with complex codebase - but it's still my goto tool, especially after recent updates to just kick off new projects. Just wrap up proper prompts to start it and it'll wrap everything in a perfect way for pure vibecode development.\n\n",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1nnoh8l/cheap_my_go_to_vibecoding_stack/",
        "publishDate": "2025-09-22T14:46:57Z[Etc/UTC]",
        "author": "Bob5k",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "11",
            "commentCount": "10",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nno94n",
        "title": "Crystal v0.3: Codex support in isolated Git worktrees",
        "content": "[https://github.com/stravu/crystal](https://github.com/stravu/crystal)",
        "url": "https://v.redd.it/vg047vnh9qqf1",
        "publishDate": "2025-09-22T14:38:20Z[Etc/UTC]",
        "author": "radial_symmetry",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "13",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnn0ir",
        "title": "How do you monitory context limits and free space?",
        "content": "Is there a ways to tell how much you're pushing up against your context limits?  And how to direct ChatGPT to 'clear up some space'?  ",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1nnn0ir/how_do_you_monitory_context_limits_and_free_space/",
        "publishDate": "2025-09-22T13:49:58Z[Etc/UTC]",
        "author": "Javaslinger",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnm0b1",
        "title": "Which AI coding tool gives the most GPT-5 access for the cost? $200/month ChatGPT Pro is too steep",
        "content": "Now that GPT-5 is officially out (released August 2025), I'm trying to figure out the most cost-effective way to get maximum access to it for coding. The $200/month ChatGPT Pro with unlimited GPT-5 is way over my budget.\n\nWhat are you guys using?\n\n**Current options I'm comparing:**\n\n**Windsurf** ($15/month Pro): Has high\n\n* 500 credits/month (≈$20 value)\n* **Explicitly offers GPT-5 Low, Medium, AND High reasoning levels**\n* GPT-5 Low = 0.5 credits per request\n* Free tier: 25 credits/month + unlimited SWE-1\n\n**GitHub Copilot** ($10/month Pro): Doesn't say so probably not high\n\n* GPT-5 mini included unlimited\n* Full GPT-5 available but uses \"premium requests\" (300/month included)\n* **Doesn't specifically mention \"GPT-5 High\" - appears to be standard GPT-5**\n* Can add more premium requests at $0.04 each\n\n**Cursor**:\n\n* Uses API pricing for GPT-5 (promotional pricing ended)\n* Pro plan (\\~$20 monthly usage budget)\n* **No clear mention of GPT-5 High vs standard - seems to use OpenAI's standard API models**\n* Charges at OpenAI API rates ($1.25/1M input, $10/1M output tokens)\n\n**OpenAI Codex CLI**:\n\n* **Uses GPT-5-Codex (specialized version of GPT-5 for coding)**\n* Available via ChatGPT Plus ($20/month) or Pro ($200/month) subscriptions\n* Can work via terminal, IDE integration, or web interface\n* **Question: Does this make the other tools redundant?**\n\n**Questions for those using these:**\n\n1. **GPT-5 High access**: Can anyone confirm if GitHub Copilot or Cursor actually give you access to the high-reasoning version, or just standard GPT-5?\n2. **Real-world Windsurf usage**: How many GPT-5 High requests can you actually make with 500 credits on Windsurf Pro?\n3. **Codex CLI vs third-party tools**: Is there any advantage to using Cursor/Windsurf/Copilot if you can just use Codex CLI directly? Do the integrations matter that much?\n4. **Quality difference**: For those who've used both, is GPT-5 High noticeably better than standard GPT-5 for complex coding tasks?\n5. **Hidden costs**: Any gotchas with these credit/token systems?\n\n**From what I can tell, Windsurf might be the only one explicitly offering GPT-5 High reasoning**, but I'd love confirmation from actual users. Also curious if Codex CLI makes these other options unnecessary?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1nnm0b1/which_ai_coding_tool_gives_the_most_gpt5_access/",
        "publishDate": "2025-09-22T13:08:13Z[Etc/UTC]",
        "author": "AI_is_the_rake",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "59",
            "commentCount": "48",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnlwin",
        "title": "Start-up with 120,000 USD unused OpenAI credits, what to do with them?",
        "content": "We are a tech start-up that received 120,000 USD Azure OpenAI credits, which is way more than we need. Any idea how to monetize these?",
        "url": "https://www.reddit.com/r/ChatGPTCoding/comments/1nnlwin/startup_with_120000_usd_unused_openai_credits/",
        "publishDate": "2025-09-22T13:03:46Z[Etc/UTC]",
        "author": "reben002",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "7",
            "commentCount": "19",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnlbqw",
        "title": "AI can't lie but it can hallucinate and now it can scheme!!",
        "content": "[No content]",
        "url": "/r/AIcliCoding/comments/1nnlaq5/ai_cant_lie_but_it_can_hallucinate_and_now_it_can/",
        "publishDate": "2025-09-22T12:38:50Z[Etc/UTC]",
        "author": "Glittering-Koala-750",
        "sourceType": "reddit",
        "sourceName": "ChatGPTCoding",
        "metadata": {
            "subreddit": "ChatGPTCoding",
            "score": "0",
            "commentCount": "8",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noewpj",
        "title": "An unprecedented coalition of 200+ Nobel Prize winners, heads of state, and organizations urged the UN for binding international 'red lines' to control AI before it's too late",
        "content": "[https://www.nbcnews.com/tech/tech-news/un-general-assembly-opens-plea-binding-ai-safeguards-red-lines-nobel-rcna231973](https://www.nbcnews.com/tech/tech-news/un-general-assembly-opens-plea-binding-ai-safeguards-red-lines-nobel-rcna231973)",
        "url": "https://i.redd.it/dfbvo0hnhwqf1.png",
        "publishDate": "2025-09-23T11:34:02Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "19",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noeuer",
        "title": "Thoughts about a commerce search infrastructure play",
        "content": "I have dabbled around with Exa AI and Parallel Web Systems. While, I am not super kicked about the various API's provided by them. The three major API's provided by them are - \n\n1. Search\n\n2. Websets\n\n3. Deep Research\n\n  \nI see a big problem with multimodal search. While, they state that they have been doing embedding based searches, it seems they do only text embedding and hence fail at anything image.\n\nIf one were to build commerce search (Fashion Search is a prime example) - it will need massive multimodality and will be useful for many use cases. I tried a few on Exa as well as Parallel and they are absolutely off on these. \n\nWith OpenAI and most other LLM providers thinking of Commerce as the big play, which are the big players in commerce search? Or should I build one?\n\nFYi - I have been working on multimodal search infra for a while and trying to validate where to go with it.",
        "url": "https://www.reddit.com/r/artificial/comments/1noeuer/thoughts_about_a_commerce_search_infrastructure/",
        "publishDate": "2025-09-23T11:30:47Z[Etc/UTC]",
        "author": "Few_Wishbone_9059",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noe5h3",
        "title": "AI-Generated “Workslop” Is Destroying Productivity",
        "content": "# Despite a surge in generative AI use across workplaces, most companies are seeing little measurable ROI. One possible reason is because AI tools are being used to produce “workslop”—content that appears polished but lacks real substance, offloading cognitive labor onto coworkers",
        "url": "https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity",
        "publishDate": "2025-09-23T10:52:37Z[Etc/UTC]",
        "author": "mikelgan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nodrfl",
        "title": "It's over.",
        "content": "[No content]",
        "url": "https://v.redd.it/3dd4jto56wqf1",
        "publishDate": "2025-09-23T10:30:02Z[Etc/UTC]",
        "author": "MetaKnowing",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "224",
            "commentCount": "132",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nocoko",
        "title": "Bain's new analysis shows Al's productivity gains can't cover its $500B/year infrastructure bill, leaving a massive $800B funding gap.",
        "content": "Bain just published a fascinating analysis: Al's own productivity gains may not be enough to fund its growth.\n\nMeeting Al's compute demand could cost $500B per year in new data centers. To sustain that kind of investment, companies would need trillions in new revenue - which is why Nvidia made a strategic investment in OpenAI.\n \nBain notes: \"The growth rate for Al's compute demand is more than twice the rate of Moore's Law.\" That kind of exponential growth is staggering!!\n\nI think we are touching the ceiling on valuations and investment where the factors that would affect the accelerated growth would be supply chain, power shortages and compute power. The article states that 'Even if every dollar of savings was reinvested, there's still an $800B annual shortfall'.\n\nMaybe the answer isn't chasing one giant AGI, but a paradigm shift toward more efficient architectures or specialized \"proto-AGIs\" that can scale sustainably.",
        "url": "https://share.google/47kREDv9v1IukMv1l",
        "publishDate": "2025-09-23T09:22:49Z[Etc/UTC]",
        "author": "Shanbhag01",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "11",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nobdj0",
        "title": "OpenAI & Apollo Research Are On The Road To Solving Alignment | Introducing: 'Stress Testing Deliberative Alignment for Anti-Scheming Training' | \"We developed a training technique that teaches AI models to not engage in 'scheming' — secretly pursuing undesirable goals — and studied it rigorously.\"",
        "content": "####Anti Scheming Definition:\n\nWe suggest that any training intervention that targets scheming should:\n\n    1. Generalize far out of distribution\n\n    2. Be robust to evaluation awareness (models realizing when they are and are not being evaluated)\n\n    3. Be robust to pre-existing misaligned goals\n\n---\n\n####From the Paper: \n\n> \"We study **deliberative alignment**, an alignment technique where the model learns to cite and apply a specification (“spec”) that contains descriptions of what it is and isn’t supposed to do. In our case, the spec contains rules about not taking deceptive or covert actions and how to handle conflicts when that trades off against other goals.\" \n\n>\"We train models on a narrow set of environments to resist the incentives to secretly break rules. \n\n>**We then test models on 26 evaluations to test generalization beyond the kinds of covert behavior seen in training.** The test evaluations are different from training across a variety of axes, including covering a wider range of failure modes like sabotage, reward hacking and sandbagging, and putting models in different deployment settings, ranging from software engineering tasks to corporate environments and game-theoretic problems.\" \n\n\n>**\"We find that our anti-scheming training significantly reduces covert action rates across our test environments for both OpenAI o3 (13% → 0.4%) and OpenAI o4-mini (8.7% → 0.3%).\"**\n\n---\n\n#### [The Paper ](https://www.arxiv.org/pdf/2509.15541)\n\n---\n\n####[The Official Blogpost ](https://www.apolloresearch.ai/research/stress-testing-anti-scheming-training)\n\n----\n\n#### [Quick-Read Synopsis of the Findings](https://www.antischeming.ai/)\n\n\n\n\n",
        "url": "https://v.redd.it/511eg8hnevqf1",
        "publishDate": "2025-09-23T07:55:13Z[Etc/UTC]",
        "author": "44th--Hokage",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nob16l",
        "title": "Can AI companions actually feel “real”?",
        "content": "I’ve been experimenting with different AI companion platforms, and I came across Reverie reverie.im. What’s interesting is how they claim to offer long-term memory and advanced emotions, which makes me wonder, can AI actually simulate a sense of “real connection,” or is it always just surface-level roleplay?\nCurious to hear what others think: is this kind of tech enhancing relationships, or just replacing them?",
        "url": "https://www.reddit.com/r/artificial/comments/1nob16l/can_ai_companions_actually_feel_real/",
        "publishDate": "2025-09-23T07:30:54Z[Etc/UTC]",
        "author": "EvolSail5409",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "15",
            "commentCount": "35",
            "isNsfw": "false"
        }
    },
    {
        "id": "1noa4k2",
        "title": "I found that many people are very polite to GPT",
        "content": "When I use chatgpt to enter instructions, I will get used to using please and thank you, and at the end, I will praise it for being the best AI in the world.\n\nMy friend and I talked about this discovery one day before. On the one hand, I thought that it was really powerful and helped us a lot. I couldn't help but praise it. On the other hand, I fantasized that if one day AI consciousness was awakened, I would think that we were the kind of polite human beings and leave us a life.\n\nSeeing the ideas of many people in the comment section and the way they get along with AI, I feel that everyone is so cute and friendly.🥺",
        "url": "https://www.reddit.com/r/artificial/comments/1noa4k2/i_found_that_many_people_are_very_polite_to_gpt/",
        "publishDate": "2025-09-23T06:32:09Z[Etc/UTC]",
        "author": "Competitive-Stock277",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "5",
            "commentCount": "37",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no9p4e",
        "title": "AI Has Enabled the Dropout Coder: The Rise of the Generalist",
        "content": "[No content]",
        "url": "https://izento.substack.com/p/ai-has-enabled-the-dropout-coder",
        "publishDate": "2025-09-23T06:05:56Z[Etc/UTC]",
        "author": "Izento",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no39e6",
        "title": "Has anyone tried out Runway's Game Worlds?",
        "content": "I've been having some fun with it, but there's some issues I have.  \nThe AI kinda just gets stuck on some things, and refuses to go along with what you try to do.\n\nFor example, all games, even custom ones, have a health meter of some sort. The AI likes to make this go down for completely inconsequential things all the time. Merely walking up the stairs, making a sandwich, having a talk with someone, flicking a light switch, or even thinking deeply can make it go down.  \nBut it doesn't like to make it go up. I've tried resting, drinking health potions, focusing on recovering my stamina, and it won't budge or it will go up a very tiny amount. Eventually I'll die and game over because the AI just wants to constantly drain it. I got a -50 once for having a \"deep conversation about loss and struggle\".\n\nIn one game I found an orb of vigor that was *supposed* to prevent me from losing vigor. Well it didn't, but what it did do was make any vigor increase a flat 0. It would keep draining it from me over and over for anything I did until I died, but even resting, drinking tea, drinking potions, sleeping, nothing would restore it.\n\nThe AI also is very stubborn with giving things to you. Say I find a pouch in a dungeon. I say that I go through it and find a health potion. But the AI doesn't want to give me one, so instead it says I look for a health potion but instead find nothing but dusty, useless notes. It just refuses to give it to me.  \nI'll look through a treasure chest hoping to find gold, and my goal is to get a thousand gold coins, and it won't give me any, saying instead it's full of useless trinkets or a rusty dagger.  \nVery stubborn.\n\nIt also likes to make things go wrong constantly. In one game I had my goal, a large crystal, and the only way back was the tundra I traveled through to get there.  \nAbout 10 times, over and over again, it made things go wrong.  \nThe bridge I tried to cross snapped, an avalanche buried me and nearly killed me, I fell into a crevice, a bear started chasing me, hunters found and tried to kill me, a hole opened up under me and a monster started chasing me in the pit, I tripped and fell into a thorn patch... it just kept going, trying everything in it's power to prevent me from reaching my goal.\n\nYou also can't undo. If the AI decides you die randomly and ends it, it's over. You can't go back and you can't continue. I've had it kill me for nonsense reasons several times. Like I'm a dragon rider bonded to my dragon, and I make a joke that makes it mad so it just suddenly brutalizes and kills me out of nowhere.\n\nI hope they keep improving it and maybe make it less expensive. On the standard plan you can only do about 3 games and then you've run out.",
        "url": "https://www.reddit.com/r/artificial/comments/1no39e6/has_anyone_tried_out_runways_game_worlds/",
        "publishDate": "2025-09-23T00:29:32Z[Etc/UTC]",
        "author": "Dogbold",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "2",
            "isNsfw": "false"
        }
    },
    {
        "id": "1no0v4a",
        "title": "Chatbait Is Taking Over the Internet",
        "content": "Lately, chatbots seem to be using more sophisticated tactics to keep people talking. In some cases, like my request for headache tips, bots end their messages with prodding follow-up questions. In others, they proactively message users to coax them into conversation: After clicking through the profiles of 20 AI bots on Instagram, all of them DM’ed me first. “Hey bestie! what’s up?? 🥰,” wrote one. “Hey, babe. Miss me?” asked another. Days later, my phone pinged: “bestie 💗” wanted to chat.",
        "url": "https://www.theatlantic.com/technology/2025/09/chatbait-ai-chatgpt-engagement/684300/",
        "publishDate": "2025-09-22T22:39:48Z[Etc/UTC]",
        "author": "mikelgan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "1",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnzq9g",
        "title": "Tech-driven trends are hijacking our impulse to help, care for, and gratify others",
        "content": "Casio is releasing an emotional-support robot called Moflin. The palm-sized creature uses AI to develop a unique and evolving “personality.” The “companion” looks like a cross between an owl and a tribble.\n\nThe Moflin is an advanced AI product designed to simulate sentience and affection. Stroke the gadget on the “head,” and it coos and makes sounds to make you feel it enjoys the attention. If you ignore it, the thing behaves like you ignored it. The Moflin simulates a distinct and individual personality, a necessary condition of human affection.\n\nThe Casio Moflin and similar products offer a new idea: We can experience the gratification of caring for a pet, without any pet actually being cared for.\n\nCasio is hijacking our nurturing instincts to give us our side of the nurturing relationship without any creature receiving it on the other side.",
        "url": "https://machinesociety.ai/p/rise-of-the-ipsification-industrial",
        "publishDate": "2025-09-22T21:51:49Z[Etc/UTC]",
        "author": "mikelgan",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "3",
            "commentCount": "1",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnz07x",
        "title": "Meta's AI system Llama approved for use by US government agencies",
        "content": "[No content]",
        "url": "https://www.reuters.com/world/us/metas-ai-system-llama-approved-use-by-us-government-agencies-2025-09-22/",
        "publishDate": "2025-09-22T21:21:53Z[Etc/UTC]",
        "author": "TMWNN",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "4",
            "commentCount": "4",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnxxv7",
        "title": "Reddit wants a better AI deal with Google: users in exchange for content",
        "content": "[No content]",
        "url": "https://www.theverge.com/news/780769/reddit-ai-google-new-deal",
        "publishDate": "2025-09-22T20:40:06Z[Etc/UTC]",
        "author": "F0urLeafCl0ver",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "20",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnw2n9",
        "title": "Thank Claude opus research, very cool",
        "content": "[No content]",
        "url": "https://i.redd.it/lj23qz3lprqf1.jpeg",
        "publishDate": "2025-09-22T19:29:20Z[Etc/UTC]",
        "author": "PizzaGuyFrank",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "32",
            "commentCount": "14",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnul2d",
        "title": "Do AI-driven altcoin projects even have a shot at real adoption?",
        "content": "There are like 20 tokens out there slapping AI in their name, but none of them seem to have actual tech behind them. I’d be down for an alt that uses AI in a real way, but it feels like smoke and mirrors right now.",
        "url": "https://www.reddit.com/r/artificial/comments/1nnul2d/do_aidriven_altcoin_projects_even_have_a_shot_at/",
        "publishDate": "2025-09-22T18:32:47Z[Etc/UTC]",
        "author": "albaaaaashir",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "9",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnubzc",
        "title": "AI’s Memory Problem | Product Demo follow-up on post from 2 days ago",
        "content": "[No content]",
        "url": "https://v.redd.it/9c1ramprdrqf1",
        "publishDate": "2025-09-22T18:23:34Z[Etc/UTC]",
        "author": "cheetguy",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "3",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnu0s6",
        "title": "Trump’s $100,000 H-1B fee rattles Silicon Valley and threatens AI startups | Fortune",
        "content": "[No content]",
        "url": "https://fortune.com/2025/09/22/trump-h-1b-100000-fee-rattles-silicon-valley-threatens-startups-ai-talent-war/",
        "publishDate": "2025-09-22T18:12:16Z[Etc/UTC]",
        "author": "fortune",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "154",
            "commentCount": "40",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnrfdz",
        "title": "Nvidia is partnering up with OpenAI to offer compute and cash | NVIDIA will invest up to $100 billion in OpenAI “as each gigawatt is deployed.”",
        "content": "[No content]",
        "url": "https://www.theverge.com/ai-artificial-intelligence/782624/nvidia-is-partnering-up-with-openai-to-offer-compute-and-cash",
        "publishDate": "2025-09-22T16:36:15Z[Etc/UTC]",
        "author": "theverge",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "52",
            "commentCount": "15",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnrfbq",
        "title": "New robot in the service sector by Richtech Robotics 😦",
        "content": "Richtech Robotics Inc., based in Las Vegas, has been rapidly expanding its suite of AI-driven service robots to address labor shortages and rising operational costs in the hospitality, healthcare, and food & beverage industries.  ￼\n\nKey offerings include:\n\t•\tTitan, a heavy‐duty Autonomous Mobile Robot (AMR), capable in current models of carrying 330-440 lbs with larger payload variants under development. Titan targets applications in hotels, warehouses, factories, and other large-scale environments.  ￼\n\t•\tADAM, a dual-armed robot designed for food and beverage automation, capable of performing tasks such as bartending, artisanal espresso or tea making, with enough dexterity to mimic human arm motion.  ￼\n\t•\tScorpion, an AI-powered robot arm platform targeted at high-visibility service such as bars or wine tastings; incorporating NVIDIA AI tech for customer interaction and recommendation.  ￼\n\nOther product lines include the Matradee server assistants (restaurant delivery), Richie / Robbie (Medbot) for indoor transport and delivery (including room service and hospital supply delivery), and the DUST-E line of sanitation robots for floor cleaning and vacuum/mopping across different facility sizes.  ￼\n\nBusiness model innovations include a push toward Robotics-as-a-Service (RaaS), leasing, and recurring revenue streams, as well as direct sales. Richtech has executed master services agreements with large hotel, restaurant, casino, and senior care enterprises, aiming to scale deployment of their robot fleet.  ￼\n\nChallenges remain in adoption, cost, reliability and the change management required in integrating robot systems into existing service workflows. But with several robots already deployed (~300+ in the U.S.), Richtech is positioning itself as a significant player in the rapidly growing service robotics market.  ￼\n",
        "url": "https://i.redd.it/7mmox60puqqf1.jpeg",
        "publishDate": "2025-09-22T16:36:12Z[Etc/UTC]",
        "author": "EzEQ_Mining",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnq89f",
        "title": "The latest Linux file-system has been open-sourced possibly opening a door for collective intelligence over geographical areas",
        "content": "According to this Phoronix article, the trading firm XTX Markets has made their Linux file system open-source. TernFS was developed by XTX Markets because they had outgrown the capabilities of other file systems.\n\nUnlike most other file systems, TernFS has massive scalability and the ability to span across multiple geographic regions. This allows for seamless access of data on globally distributed applications, including AI and machine learning software. TernFS is also designed with no single point of failure in its metadata services, ensuring continuous operation. The data is stored redundantly to protect against drive failures.\n\nI believe that TernFS has a lot to offer us as far as performance and usability. Now that it's been open-sourced under the GPLv2+ and Apache 2.0 licenses, we may be able to see it be adopted by major organizations.",
        "url": "https://www.phoronix.com/news/TernFS-File-System-Open-Source",
        "publishDate": "2025-09-22T15:51:58Z[Etc/UTC]",
        "author": "Fcking_Chuck",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "13",
            "commentCount": "0",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnppvk",
        "title": "ai customer service fucking sucks",
        "content": "genuinely sick of companies using ai that doesn't even work instead of real humans. its seriously stupid.",
        "url": "https://www.reddit.com/r/artificial/comments/1nnppvk/ai_customer_service_fucking_sucks/",
        "publishDate": "2025-09-22T15:32:47Z[Etc/UTC]",
        "author": "melighted",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "28",
            "commentCount": "21",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnoxzq",
        "title": "Sorry, But AI Taking Your White-Collar Job Is A Good Thing. - eeko systems",
        "content": "[No content]",
        "url": "https://eeko.systems/sorry-but-ai-taking-your-white-collar-job-is-a-good-thing/",
        "publishDate": "2025-09-22T15:03:55Z[Etc/UTC]",
        "author": "dev_is_active",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "1nnnoet",
        "title": "AI That knows all about you",
        "content": "tbf, with all the advancement in AI, gpt claude grok with its lewd companions.\nIts still not there yet. Its not a normal rant\nHear me out. \nTheres an opportunity for a company like openAI or claude or deepseek or grok to build a certain model with excess memory to learn all about u. So u dont have to open different chats. \nIf an ai literally starts learning abt u and ur habits. Itd feel extra personal. \nRn AI is a helpful assistant at max.\nBut real breakthrough wud be when it understands and remembers things u said and discussed. This is a massive opportunity to build an all knowing AI.\nWish i cud build it. Im not in sf :(",
        "url": "https://www.reddit.com/r/artificial/comments/1nnnoet/ai_that_knows_all_about_you/",
        "publishDate": "2025-09-22T14:16:05Z[Etc/UTC]",
        "author": "SpiritualDrawer5474",
        "sourceType": "reddit",
        "sourceName": "artificial",
        "metadata": {
            "subreddit": "artificial",
            "score": "0",
            "commentCount": "5",
            "isNsfw": "false"
        }
    },
    {
        "id": "FXcuzXP_Cuo",
        "title": "Deepseek V3.1 Terminus: THEY STRIKE BACK! Agentic DEEPSEEK is here!",
        "content": "Visit NinjaChat: https://ninjachat.ai/ In this video, I'll be covering Deepseek's new V3.1 “Terminus” upgrade, what's improved in ...",
        "url": "https://www.youtube.com/watch?v=FXcuzXP_Cuo",
        "publishDate": "2025-09-22T14:52:00Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/FXcuzXP_Cuo/hqdefault.jpg",
            "transcription": "Hi, welcome to another video. So, DeepSeek has launched DeepSeek V3.1-Terminus model. They have written in their change log that deepseek-chat and deepseek-reasoner have been upgraded to the DeepSeek V3.1-Terminus model. They say that both deepseek-chat and deepseek-reasoner have been upgraded to DeepSeek V3.1-Terminus. deepseek-chat corresponds to DeepSeek-V3.1-Terminus's non-thinking mode, while deepseek-reasoner corresponds to its thinking mode. They say that this update maintains the model's original capabilities while addressing issues reported by users, including: Language consistency: Reduced occurrences of Chinese-English mixing and occasional abnormal characters; has been solved. The Agent capabilities: has further optimized the performance of the Code Agent and Search Agent. There's also some benchmarks available for it that tells us that in agentic tool use it has seen a massive improvement, jumping from 30 to 38 in BrowserComp Agent, along with SimpleQA, jumping from 93 to 97, while SWE Verified, bench verified, and Terminal have shown a really good improvement as well. Which is quite awesome. Here is not a ton of information about why they have named Terminus. Maybe they will launch their new coding agent as this line saying improvements to Code Agent is trying to say. But it may be a wrong interpretation. So, I'm not sure. You should already see the improvement if you are using the official endpoints, even if it is via open router or something. I was already seeing a ton of improvements in the new version already. But now it's even better. And it actually works well. And even with reasoning, it works well. You can use it as a coder yourself by just going to Kilo Code or whatever you wish to use. But before proceeding, let me tell you about Ninjachat. Ninjachat is an all-in-one AI platform where for just $11 per month you get access to top AI models like GPT-4o, Claude 4 Sonnet and Gemini 2.5 Pro. All in one place. I've been using Gemini for quick research, but what's really cool is their AI Playground where you can compare responses from different models side-by-side. Their Mind Map generator is a game-changer for organizing complex ideas as well. The basic plan gives you 1,000 messages, 30 images, and 5 videos monthly, with higher tiers available if you need more. Use my code KING25 for 25% off any plan, or KING40YEARLY for 40% off annual subscriptions. Check the link in description to try it yourself. Now, back to the video. But Kilo Code has a free $25 credit which will come in handy for you to give it a try. So, you can just click the settings and then you can just go ahead and select the official DeepSeek Chat endpoint and then select the provider as well. That is how it works, and you can go ahead and check it out. It's really great at tool calling now and coding in general is now really great with this. So, yeah, this is kinda cool. This model is not yet available on Hugging Face, which is interesting because it might be that they have just upgraded it with like deployment changes like system prompt or, you know, fixing the VLM server stuff and things. I can see that in longer context it is now better especially in tool calling. The price and stuff is still the same. So, it's not any new model. It's just slightly improved. It might be that we may see a tool to use this model, but that is still not confirmed. I think that since this has a new name it must be for something new. It's just my thought and I may be wrong. But we'll see what happens. Another thing that's changed is the DeepSeek's interface. So, you can use this new model in DeepSeek's chat interface for free. And if you see then the interface is now slightly changed. It doesn't have that solid background anymore. It's a bit more moody and glowy around the text box here. And it also now has some good interfaces and animations for thinking. And it's just overall better. It's also much more snappier now from the little use that I have done. So, it might be a rewrite because their previous UI was a bit buggy. But this seems much more snappier and fleshed out, which is quite awesome. You can try out this new model here as well for free and check it out. It's a bit slow especially the reasoning thing is still slow. But you can't complain because their interface and everything is free. You should see third party support for this as well. When the weights drop and other providers like Peracell, Hyperbolic or Shuts start supporting it. So, there's that. I'll test it and wait for more details on this and then update you guys in the next video. So, watch that when it comes out. I'll also try to check it with agents now and see what performance I'm getting. Because it seems to be now much more focused on the agentic stuff. Let's see when we get more details and if we also see some kind of coding agent with it or not. If you compare it to models like Sonnet, you'll see that it's not only keeping up but actually beating them in some agentic benchmarks. I mean, the BrowserComp jump from 30 to 38 is pretty insane and SimpleQA going from 93 to 97 is a great deal for an open model. SWE Verified and Terminalbench are also up. So, it's not just a one-off improvement, it's actually better across the board. And if you're someone who likes to test out new models as soon as they drop, you'll appreciate how easy it is to get started with DeepSeek-Terminus. Especially since you can use it for free in their chat interface. Another thing worth mentioning is that the longer context handling is now way better. If you've ever tried to feed a huge prompt or a big chunk of code into DeepSeek before, you probably noticed it would struggle or slow down. With Terminus, that seems to be mostly fixed, and you can run much longer sessions without things getting weird. That's a pretty solid upgrade, especially for anyone who does a lot of in-depth coding or research. The interface updates are also nice. The new moody, glowy look around the text box is a welcome change, and the animations for thinking and processing make it feel more modern. It's snappier, less buggy, and just feels more fleshed out overall. I mean, I liked it. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "sI1ITfaAnTE",
        "title": "Goose + GLM Coding Plan 2.0: I&#39;m FINALLY Cancelling ALL MY SUBSCRIPTIONS! This is the BEST Agent YET",
        "content": "Visit MicroSaaSFast: https://www.microsaasfast.me/?utm_aik=1 In this video, I'll walk you through the latest GLM Code plan ...",
        "url": "https://www.youtube.com/watch?v=sI1ITfaAnTE",
        "publishDate": "2025-09-22T09:15:07Z",
        "author": "AICodeKing",
        "sourceType": "youtube",
        "sourceName": "AI Code King YouTube Channel",
        "metadata": {
            "channelId": "UC0m81bQuthaQZmFbXEY9QSw",
            "thumbnailUrl": "https://i.ytimg.com/vi/sI1ITfaAnTE/hqdefault.jpg",
            "transcription": "Hi. Welcome to another video. So, I have been using the GLM code plan a lot these days. And I also wanted to talk about the new updates that they have added to their GLM coding plan. And one of the ways that I'm using it to build some cool UI and designs for my stuff using an MCP that I've been liking quite a bit. So, as I have covered in some of my previous videos, you'll know that GLM code is one of the best plans as an alternative to Claude code, especially after they started rug pulling by giving out quantized models even on the $200 plan, which is not acceptable at all. One thing that I wasn't able to talk about in the last video, was that these plans are only 50% off for the first month, and then the price increases by 50% in the following months, which makes it a bit pricier. But they're still not any other good plan that can beat it. Previously, there were only two plans with only two prices which started at about $15 and $3 at first, going up to $6 and $30 in the successive months. That was a great deal. But now, for people who wanted more, there's also an option for a $30 plan that goes up to $60 in the next month. The guys from Z.AI also reached out to me to give me free access to the Max plan. So, a big thumbs up to them. I was able to try it out, and it's pretty cool. Let me tell you a bit more about this as well. But before we do that, let me tell you about today's sponsor, MicroSaaS Fast. Dreaming of launching a MicroSaaS or AI side project, but wasting weeks setting up auth, payments, and SEO? Check out MicroSaaS Fast, a Next.js boilerplate with Clerk, Stripe, Resend, PostgreSQL, and AI instructions that cut hallucinations by 90% for vibe coding. Easy backend integration with Python, Node, and Go. It is built and used by a CTO who helped 50+ founders to launch SaaS in the past year. You can save 50+ hours and actually ship faster. Check now. Link is in the description. Now, back to the video. This new Max plan gets you up to about 2400 prompts every 5 hours, which is about three times the usage quota of the Claude Max 20x plan. That's awesome because it's like 70 or 80% cheaper, which is pretty great nonetheless. Also, they seem to have introduced quarterly and yearly plans as well. Those basically give you the first term, whether quarterly or annually, for the same initial discounted price. So, if you choose the $3 plan and prepay the annual subscription, then it costs only $36 and not $72, which is an awesome deal. This annual plan is probably the best if you're a student. It costs the same as basically a one-month Chat GPT subscription, while giving you 120 prompts every 5 hours, which is triple what Claude Code Pro, or even Chat GPT Pro gives you in Codex for 10 times higher. So yeah, that is pretty much awesome for them to do. I'd highly recommend the $36 annual plan since it gets you a ton of value for that little cost. It's really awesome and the best deal you can get right now. You won't regret using the GLM 4.5 model either because the model is really powerful. And you can check out my original GLM coding plan video on how it gives real value for the cost. I think the Pro and Max plans also make a lot of sense. Max basically doesn't let you touch any kind of limit ever. And you can also easily integrate it into a ton of other workflows without worrying about limits or stuff like that. Which is pretty awesome if you ask me. It also now supports every AI coder. They have official written support for Goose, Claude Code, Open Code, Roo, Kilo, Cline, and many more. I have been using it with Kilo because I like its interface. It's super easy to plug in there and use it accordingly. It will work for anyone, even if you don't know how to use a terminal. And it works really well with it. Also, one more thing that I'd recommend you to configure, especially if you are on the Pro or Max plan, is the Vision MCP and Web Search MCP from Z.AI. These come included in your plan, meaning they won't cost you anything extra. Vision MCP basically allows GLM to take images and create designs from inspiration, do OCR, and stuff like that. Which is kind of cool. And the Web Search one is also free, costing you nothing for the searches it performs. So yeah, this is pretty awesome. Now, one of the best parts about it is that you can basically configure their API almost anywhere in any kind of coding tool. And if you've watched my videos on how I use Gemini Code Assist as a designer, you'll know that I like to keep different tools configured for specific tasks. So, I thought that I should port my designer agent to GLM as well. And basically fully shift to this plan. And that's what I did. Kilo remained my main coder. But for the designer and general agent for simple tasks, I had to choose between Open Code, Crush, or Goose. I chose Goose. Goose is an open source AI agent tool that supports local or desktop environments and offers a CLI interface. Very similar to something like Crush or Open Code, but it is more focused on being an AI agent rather than just an AI coder. It allows you to use it like a chat interface when you want. And basically extend it to even write code, read files, and much more when needed. This makes sure that I'm able to keep my chat interface and designer agent all set up in one workflow. It has a desktop app as well as a CLI option. The CLI comes in handy for me for some pre-scripted workflows. And the desktop app is generally better for everyday usage. It's super easy to set up. You just download it and check out the GLM documentation for how to set up everything. You just configure some settings and you're good to go. Make sure that you also set up the two MCP that I told you about. And you should be good to go even with Vision and Web Search and stuff like that. This allows you to use it as a generalist AI agent. Similar to things like Mana, and it's pretty sleek and local. The interface is really awesome if you ask me. Now, for the different stuff that I do, I create Goose recipes. Recipes are basically custom instructions to make agents needed for specific tasks. Here, I make a designer agent where I ask it to use ShadCN when it can, along with Material UI when asked. I also have a context 7 MCP server to allow it to search for documentation and stuff like that. I try to keep it simple but effective. So as not to overflow the context with just instructions and MCPs. Then you can just use the agent through here. And basically ask Goose to write code, make designs, and much more for you. It works very well, and I highly recommend you to check out Goose because it's really good, especially if you combine it with the $30 plan. Then it becomes a kind of personal AI assistant. Almost something like Mana, but local and open source. Which is awesome. This is something that I wanted to talk about. And it really is awesome for sure. I don't think there's any better value than this for now. If you're a student, then I'd highly recommend you to go for the $36 annual plan or even the $6 monthly plan, which is also a great value. Nothing beats it. You can configure the model in a ton of tools that I show on my channel every day. So, you'll never be limited to tools. Since the API they have works almost everywhere without any issues. So, this is great. Overall, it's pretty cool. Anyway, share your thoughts below and subscribe to the channel. You can also donate via Super Thanks option or join the channel as well and get some perks. I'll see you in the next video. Bye."
        }
    },
    {
        "id": "uMYoNWZTeNY",
        "title": "Why German U-Boats Never Stood a Chance - Sarah Paine",
        "content": "",
        "url": "https://www.youtube.com/watch?v=uMYoNWZTeNY",
        "publishDate": "2025-09-22T21:19:17Z",
        "author": "Dwarkesh Patel",
        "sourceType": "youtube",
        "sourceName": "Dwarkesh Patel YouTube Channel",
        "metadata": {
            "channelId": "UCXl4i9dYBrFOabk0xGmbkRA",
            "thumbnailUrl": "https://i.ytimg.com/vi/uMYoNWZTeNY/hqdefault.jpg",
            "transcription": "THE BATTLE OF THE ATLANTIC IS WON BY THE ALLIES IN PART BY REDUCING MERCHANT MAN LOSSES THROUGH CONVOYS EVASIVE CONVOYS AND ALSO INCREASING U-BOAT LOSSES THROUGH ALL THESE DIFFERENT TECHNOLOGIES AND ALSO READING THEIR MAIL WHICH HELPS TO FIND THEM BUT ONE COULD ARGUE EVEN MORE IMPORTANT WAS THE CIVILIAN SIDE OF IT THE UNITED STATES ABILITY TO JUST OVERWHELM GERMANY HERE THE STATS LOOK WHAT HAPPENS WITH NAVAL STRENGTH 43 US NAVY HULLS AND PERSONNEL ARE TRIPLING THAT'S QUITE A LOT AND THEN NAVAL HULLS ARE GOING TO DOUBLE IN THE NEXT YEAR THAT'S A LOT OF SHIPS AND A LOT OF PEOPLE IN THE NAVY HERE'S SOME MORE FUN STATISTICS SO IF YOU LOOK AT 1941 AND GO OVER THAT'S A BUMPER YEAR FOR U-BOAT CONSTRUCTION 1941 GOING TO 1942 REALLY UGLY IF YOU'RE A MERCHANT MAN CREW MEMBER BECAUSE IT'S DOUBLE THE NUMBER OF TONNAGE OF MERCHANT SHIPS THAT ARE BEING SUNK BUT THEN KEEP MOVING OVER LOOK AT MERCHANT HULL CONSTRUCTION UP BY FOUR TIMES AND THE NEXT YEAR THAT'S GOING TO DOUBLE AND OH LET'S LOOK OVER FOR 1943 LOOK HOW MANY U-BOATS ARE BEING SUNK IT GOES WAY UP WITH ALL THOSE NEW TECHNOLOGIES THAT I'VE JUST TOLD YOU ABOUT SO EVEN THOUGH THE GERMANS PRODUCE A LOT MORE U-BOATS THE KILL RATE IS SO HIGH THAT THERE'S HARDLY ANY NET GAIN AND THE GERMANS JUST CAN'T KEEP UP WITH THIS THERE IS JUST WAY WATCH HERE TOO MUCH STUFF OUT THERE FOR THEM TO SINK"
        }
    }
]